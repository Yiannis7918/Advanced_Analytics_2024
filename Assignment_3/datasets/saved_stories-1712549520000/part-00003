{"aid": "39964410", "title": "Optimizing the timeout issue in Geth using key-value storage as a caching layer", "url": "https://blog.reddio.com/optimizing-the-timeout-issue-in-geth-when-querying-large-span-sparse-logs-through-kv/", "domain": "reddio.com", "votes": 1, "user": "web3dev", "posted_at": "2024-04-07 22:11:40", "comments": 0, "source_title": "Optimizing the timeout issue in Geth when querying large-span sparse logs through KV.", "source_text": "Optimizing the timeout issue in Geth when querying large-span sparse logs\nthrough KV.\n\nReddio Technology Blog\n\n# Optimizing the timeout issue in Geth when querying large-span sparse logs\nthrough KV.\n\n#### Reddio\n\nMar 13, 2024 \u2022 6 min read\n\nBefore we begin, let's take a look at a request sent to Geth:\n\n    \n    \n    { \"method\": \"eth_getLogs\", \"params\": [ { \"fromBlock\": \"0x0\", \"toBlock\": \"0x120dc53\", \"address\": \"0xb62bcd40a24985f560b5a9745d478791d8f1945c\", \"topics\": [ [ \"0xcfb473e6c03f9a29ddaf990e736fa3de5188a0bd85d684f5b6e164ebfbfff5d2\" ] ] } ], \"id\": 62, \"jsonrpc\": \"2.0\" }\n\nThe semantics of this request are clear: it searches for logs with the topic\n\"0xcfb473e6c03f9a29ddaf990e736fa3de5188a0bd85d684f5b6e164ebfbfff5d2\" on the\naddress \"0xb62bcd40a24985f560b5a9745d478791d8f1945c\" from block 0x0 to block\n0x120dc53 (decimal 18930771) in the entire Ethereum blockchain.\n\nHowever, when we send this request to our own ETH node, we experience a\n30-second wait time followed by a timeout response:\n\n    \n    \n    { \"jsonrpc\": \"2.0\", \"id\": 62, \"error\": { \"code\": -32002, \"message\": \"request timed out\" } }\n\nWhy is this happening?\n\nTo understand the reason behind this, we need to start with the working\nmechanism of Geth for the eth_getLogs query.\n\n## Bloom Filter\n\nIn Ethereum, there is a data structure called the Bloom filter.\n\n  * Bloom Filter is a probabilistic data structure used to quickly determine whether an element belongs to a set. It is often used to efficiently check if an element exists in a large dataset without actually storing the entire dataset.\n  * The core idea of a Bloom Filter is to use multiple hash functions and a bit array to represent elements in the set. When an element is added to the Bloom Filter, its hash values from multiple hash functions are mapped to corresponding positions in the bit array, and these positions are set to 1. When checking if an element exists in the Bloom Filter, the hash values of the element are again mapped to the corresponding positions in the bit array, and if all positions are 1, it is considered that the element may exist in the set, although there may be a certain probability of false positives.\n  * The advantages of Bloom Filters are that they occupy relatively small space and provide very fast membership tests. They are suitable for scenarios where a certain false positive rate can be tolerated, such as fast retrieval or filtering in large-scale datasets.\n\nIn Ethereum, the Bloom filter for each block is calculated based on the\ntransaction logs in the block.\n\nIn each Ethereum block, transaction logs are an important part where contract\nevents and state changes are stored. The Bloom filter is constructed by\nprocessing the data in the transaction logs. Specifically, for each\ntransaction log, it extracts key information such as the contract address and\nlog data. Then, using hash functions, it converts this information into a\nseries of bit array indices and sets the corresponding positions in the bit\narray to 1.\n\nIn this way, each block has a Bloom filter that contains the key information\nfrom the transaction logs. When querying for a specific contract address or\nother information related to the transaction logs in a block, the Bloom filter\ncan be used to quickly determine whether the relevant information exists. This\nquery method improves efficiency by avoiding direct access and processing of a\nlarge amount of transaction log data.\n\nWe can see the Bloom value of a specific block by sending the following\nrequest:\n\n    \n    \n    {\"method\":\"eth_getBlockByNumber\",\"params\":[\"latest\",false],\"id\":1,\"jsonrpc\":\"2.0\"}\n\nThe response is as follows:\n\n    \n    \n    { \"jsonrpc\": \"2.0\", \"id\": 1, \"result\": { \"baseFeePerGas\": \"0xbf7b14fbe\", ... \"hash\": \"0x86f79ed4401eb79c899c3029c54c679fd91f22c6b81a651c78c0f664b1316ce6\", \"logsBloom\": \"0xf4b37367e1d1dd2f9fb1e3b298b7fe61e7f40b0dbc71fcf4af5b1037f67238294d3257ffd35b2f3dcde1db20fb77139edb3f086cff3a79bda56575baac7ead457a4ef95c7fc7bf7afec2e00fbeaae6ff5daa5a9d8b5698ce5bfdf66ac8741c3e9e4d364c1e631dc326cdfe97fc6bfedfe2ae47fb14aeb70d938b5dde00dac77aab17bad6976ddedd30c5a57a3bcd563f826dc319d9914dea66614dee59d5346a8b7a076c63966af73ee7d7f4daffac4c86ff9f79c90efd82c5ab3d8299bb04f874d1a4420c3f4ef825dc0b0b2a6e7b434da4b74f0d6b9816a87eed4f35323d0094f8ee2e33531560db2e7feebe191a888da87499f9ff555cbc5f9e36e89dbd07\", \"stateRoot\": \"0x48f5a24f3f42d5f5650fbaaccf6713ba0b85d371e0ec7c5d5e1d16df47\" }\n\nThe logsBloom field in the response represents the Bloom filter value of that\nblock. Its length is 512 hexadecimal characters, which corresponds to 2048\nbits in binary.\n\nSo, when we want to query for a specific topic, Geth calculates the Bloom\nfilter needed based on the topic and then iterates through the logsBloom field\nof each block within the specified range (from fromBlock to toBlock) to\ndetermine if the block may contain the corresponding log.\n\nIt is important to note that due to the probabilistic nature of Bloom filters\nand the limited size of the Bloom filter (2048 bits) compared to the vast\nnumber of blocks in Ethereum, there will be a large number of blocks that may\nresult in false positives. This means that the Bloom filter may match, but the\nactual log may not exist in those blocks, leading to a significant amount of\nquery time and even timeouts.\n\nThis issue has been discussed in the Geth GitHub repository, for example:\n\n  * https://github.com/ethereum/go-ethereum/issues/25336\n  * https://github.com/ethereum/go-ethereum/issues/28765\n\nHowever, there hasn't been a mature solution yet. One approach discussed is to\nincrease the length of the Bloom filter. Another approach is to introduce a\nsubscription mechanism where clients can subscribe to similar requests and\nallow Geth to query in the background without requiring synchronous queries\nthat may result in timeouts.\n\n## Reverse KV\n\nThis article attempts to propose an approach to mitigate this issue, and we\nhave observed its effectiveness in our internal Proof of Concept (PoC). For\nthe example you provided, where we are searching for logs with the topic\n\"0xcfb473e6c03f9a29ddaf990e736fa3de5188a0bd85d684f5b6e164ebfbfff5d2\" on the\naddress \"0xb62bcd40a24985f560b5a9745d478791d8f1945c\", which is very sparse\n(only two records), we can use a caching layer that maps topics to the blocks\nwhere they exist.\n\nFor example, for the given topic, we can store the value as the block number\n\"0xed6e42\" (decimal 15560258).\n\nIn this way, when we encounter a similar request, we can quickly determine the\nblock where the log exists based on the topic and reassemble the request. In\nthis case, since we already know that the log is in block \"0xed6e42\", we can\nmodify the request as follows (note that both fromBlock and toBlock are set to\n\"0xed6e42\"):\n\n    \n    \n    { \"method\": \"eth_getLogs\", \"params\": [ { \"fromBlock\": \"0xed6e42\", \"toBlock\": \"0xed6e42\", \"address\": \"0xb62bcd40a24985f560b5a9745d478791d8f1945c\", \"topics\": [ [ \"0xcfb473e6c03f9a29ddaf990e736fa3de5188a0bd85d684f5b6e164ebfbfff5d2\" ] ] } ], \"id\": 62, \"jsonrpc\": \"2.0\" }\n\nWe can then send the modified requests to the actual Geth backend, optimizing\nthe response time.\n\n## Implementation\n\nOur key-value (KV) storage implementation uses Pebble, a Go implementation\nsimilar to LevelDB/RocksDB, which is also the underlying storage\nimplementation for Juno.\n\n### Block\n\nTo implement storage, we first need to fetch blocks. Since we have our own ETH\nnode, we can start fetching blocks from the first block on our node. The key\ncode snippet is as follows:\n\n    \n    \n    if LatestBlockNumberInDBKey < LatestBlockNumberOnChain { for i := LatestBlockNumberInDBKey; i < LatestBlockNumberOnChain; i++ { fmt.Println(\"Dealing with block number: \", i) // Get topic list from block number topicList, err := getTopicListByBlockNumber(i) if err != nil { fmt.Printf(\"Failed to get topic list: %v\\n\", err) // Retry return } fmt.Printf(\"Total topics: %d\\n\", len(topicList)) if len(topicList) > 0 { for _, topic := range topicList { SetKeyNumberArray(topic, i) } // Flush DB FlushDB() } // Update LatestBlockNumberInDB SetKeyNumber(\"LatestBlockNumberInDB\", i) } }\n\nSince the value in Pebble is a byte array, we need two helper functions:\n\n    \n    \n    func SetKeyNumberArray(key string, number uint64) error { // Check if key exists, if exists, read array and append number to array // If not exists, create array with number keyByteSlice := []byte(key) existingNumberArray, err := GetKeyNumberArray(key) if err != nil { return err } if existingNumberArray != nil { // Append number to array existingNumberArray = append(existingNumberArray, number) // Deduplicate array existingNumberArray = DeduplicateUint64Array(existingNumberArray) numberByteSlice := Uint64ArrayToByteSlice(existingNumberArray) err := DB.Set(keyByteSlice, numberByteSlice, pebble.NoSync) if err != nil { return err } return nil } else { // Create array with number numberArray := []uint64{number} numberByteSlice := Uint64ArrayToByteSlice(numberArray) err := DB.Set(keyByteSlice, numberByteSlice, pebble.NoSync) if err != nil { return err } return nil } } func GetKeyNumberArray(key string) ([]uint64, error) { keyByteSlice := []byte(key) value, closer, err := DB.Get(keyByteSlice) if err != nil { // Check if key is not found if err == pebble.ErrNotFound { return nil, nil } return nil, err } defer closer.Close() numberArray := ByteSliceToUint64Array(value) return numberArray, nil }\n\nSince we aim for performance during the Set operation, we use pebble.NoSync\nmode for writing. After processing each block, we manually call FlushDB to\nflush the writes to disk.\n\n### Handler\n\nOnce we have fetched the blocks, we can handle user POST requests. The general\napproach is as follows:\n\n  * Parse the user's POST request. If the request is for eth_getLogs, split the user's topics and query the KV database.\n  * Retrieve the corresponding block range from the KV database based on the topics.\n  * Consolidate the block range.\n  * Reassemble the user's request by replacing fromBlock and toBlock with the consolidated block range.\n  * Send the reassembled requests to the Geth backend and concatenate the returned data.\n  * Return the data to the user.\n\n### Demo\n\nIn our local environment, we verified that with this KV caching layer, the\nabove query can return results in approximately 450ms (note that the majority\nof the 450ms is the round-trip time (RTT) between the local environment and\nour ETH node, while the actual KV response speed is within 20ms).\n\n## Future Plans\n\nIn the example above, we have completed a PoC for optimization. However, there\nare still several areas that need improvement, such as:\n\n  * Handling multiple topic intersections and queries.\n  * Dealing with large block ranges for a specific topic, where the caching layer needs to be able to prevent requests from reaching the actual Geth backend to avoid excessive backend pressure.\n\nWe have already deployed this caching layer on an internal test node and open-\nsourced the program on GitHub at: https://github.com/reddio-com/eth_logcache.\nWe welcome interested individuals to use it and contribute to further\ndevelopment.\n\n## Introducing Itachi: A Fully Decentralized Modular Sequencer for Appchain,\nStarting from Starknet\n\n\"Itachi\" introduces a revolutionary, fully decentralized sequencer framework\ntailored for Layer 2 (L2)/L3 Appchains, kicking off with Starknet integration.\nIt's built on the Yu framework, developed by the Reddio team in Golang, known\nfor its modularity and customisation capabilities, a much more developer\nfriendly framework compared to Substrate or\n\nApr 3, 2024 8 min read\n\n## Twilio CEO Jeff Lawson Stepped Down, Twilions Follow His Path\n\nTwo weeks ago, Twilio co-founder Jeff Lawson stepped down as CEO. This story\nhas more than the usual \"investors forcing the founder to quit\". There are\nlots of articles talking about that, however, I want to focus on my experience\nas ex-Twilion, my journey at Twilio, why I quit Twilio\n\nJan 20, 2024 3 min read\n\n## Building a ERC20 Token App on Starknet with Starknet React: A Comprehensive\nGuide\n\nThis guide offers steps to build a React web application with Starknet React\nto interact with ERC20 smart contract on Starknet. Meanwhile you can get the\nsource code from our Github repo. Readers will: * Understand how to implement\nthe ERC20 interface * Discover ways to engage with contracts within a React\n\nJan 16, 2024 3 min read\n\nReddio Technology Blog \u00a9 2024\n\nPowered by Ghost\n\n", "frontpage": false}
