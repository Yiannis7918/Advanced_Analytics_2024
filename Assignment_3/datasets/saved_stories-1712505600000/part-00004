{"aid": "39958331", "title": "Vulnerability Detection with Code Language Models: How Far Are We?", "url": "https://arxiv.org/abs/2403.18624", "domain": "arxiv.org", "votes": 1, "user": "waffleshype", "posted_at": "2024-04-07 05:15:29", "comments": 0, "source_title": "Vulnerability Detection with Code Language Models: How Far Are We?", "source_text": "[2403.18624] Vulnerability Detection with Code Language Models: How Far Are\nWe?\n\nSkip to main content\n\nWe gratefully acknowledge support from the Simons Foundation, member\ninstitutions, and all contributors. Donate\n\n> cs > arXiv:2403.18624\n\n# Computer Science > Software Engineering\n\narXiv:2403.18624 (cs)\n\n[Submitted on 27 Mar 2024]\n\n# Title:Vulnerability Detection with Code Language Models: How Far Are We?\n\nAuthors:Yangruibo Ding, Yanjun Fu, Omniyyah Ibrahim, Chawin Sitawarin, Xinyun\nChen, Basel Alomair, David Wagner, Baishakhi Ray, Yizheng Chen\n\nView a PDF of the paper titled Vulnerability Detection with Code Language\nModels: How Far Are We?, by Yangruibo Ding and 8 other authors\n\nView PDF HTML (experimental)\n\n> Abstract:In the context of the rising interest in code language models (code\n> LMs) and vulnerability detection, we study the effectiveness of code LMs for\n> detecting vulnerabilities. Our analysis reveals significant shortcomings in\n> existing vulnerability datasets, including poor data quality, low label\n> accuracy, and high duplication rates, leading to unreliable model\n> performance in realistic vulnerability detection scenarios. Additionally,\n> the evaluation methods used with these datasets are not representative of\n> real-world vulnerability detection. To address these challenges, we\n> introduce PrimeVul, a new dataset for training and evaluating code LMs for\n> vulnerability detection. PrimeVul incorporates a novel set of data labeling\n> techniques that achieve comparable label accuracy to human-verified\n> benchmarks while significantly expanding the dataset. It also implements a\n> rigorous data de-duplication and chronological data splitting strategy to\n> mitigate data leakage issues, alongside introducing more realistic\n> evaluation metrics and settings. This comprehensive approach aims to provide\n> a more accurate assessment of code LMs' performance in real-world\n> conditions. Evaluating code LMs on PrimeVul reveals that existing benchmarks\n> significantly overestimate the performance of these models. For instance, a\n> state-of-the-art 7B model scored 68.26% F1 on BigVul but only 3.09% F1 on\n> PrimeVul. Attempts to improve performance through advanced training\n> techniques and larger models like GPT-3.5 and GPT-4 were unsuccessful, with\n> results akin to random guessing in the most stringent settings. These\n> findings underscore the considerable gap between current capabilities and\n> the practical requirements for deploying code LMs in security roles,\n> highlighting the need for more innovative research in this domain.\n\nSubjects:| Software Engineering (cs.SE); Computation and Language (cs.CL)  \n---|---  \nCite as:| arXiv:2403.18624 [cs.SE]  \n(or arXiv:2403.18624v1 [cs.SE] for this version)  \nhttps://doi.org/10.48550/arXiv.2403.18624arXiv-issued DOI via DataCite  \n  \n## Submission history\n\nFrom: Yangruibo Ding [view email] [v1] Wed, 27 Mar 2024 14:34:29 UTC (661 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Vulnerability Detection with Code Language\nModels: How Far Are We?, by Yangruibo Ding and 8 other authors\n\n  * View PDF\n  * HTML (experimental)\n  * TeX Source\n  * Other Formats\n\nview license\n\nCurrent browse context:\n\ncs.SE\n\n< prev | next >\n\nnew | recent | 2403\n\nChange to browse by:\n\ncs cs.CL\n\n### References & Citations\n\n  * NASA ADS\n  * Google Scholar\n  * Semantic Scholar\n\na export BibTeX citation Loading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer (What is the Explorer?)\n\nLitmaps (What is Litmaps?)\n\nscite Smart Citations (What are Smart Citations?)\n\n# Code, Data and Media Associated with this Article\n\nCatalyzeX Code Finder for Papers (What is CatalyzeX?)\n\nDagsHub (What is DagsHub?)\n\nGotit.pub (What is GotitPub?)\n\nPapers with Code (What is Papers with Code?)\n\nScienceCast (What is ScienceCast?)\n\n# Demos\n\nReplicate (What is Replicate?)\n\nHugging Face Spaces (What is Spaces?)\n\nTXYZ.AI (What is TXYZ.AI?)\n\n# Recommenders and Search Tools\n\nInfluence Flower (What are Influence Flowers?)\n\nConnected Papers (What is Connected Papers?)\n\nCORE Recommender (What is CORE?)\n\n  * Author\n  * Venue\n  * Institution\n  * Topic\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new\narXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and\naccepted our values of openness, community, excellence, and user data privacy.\narXiv is committed to these values and only works with partners that adhere to\nthem.\n\nHave an idea for a project that will add value for arXiv's community? Learn\nmore about arXivLabs.\n\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n\n  * About\n  * Help\n\n  * Contact\n  * Subscribe\n\n  * Copyright\n  * Privacy Policy\n\n  * Web Accessibility Assistance\n  * arXiv Operational Status Get status notifications via email or slack\n\n", "frontpage": false}
