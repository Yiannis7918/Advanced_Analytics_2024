{"aid": "40013604", "title": "Differential Synchronization (2009)", "url": "https://neil.fraser.name/writing/sync/", "domain": "fraser.name", "votes": 1, "user": "Tomte", "posted_at": "2024-04-12 14:52:41", "comments": 0, "source_title": "Neil Fraser: Writing: Differential Synchronization", "source_text": "Neil Fraser: Writing: Differential Synchronization\n\n# Differential Synchronization\n\nby Neil Fraser, January 2009\n\nRead this as a DocEng paper.\n\nWatch this as a Google Tech Talk.\n\nKeeping two or more copies of the same document synchronized with each other\nin real-time is a complex challenge. This paper describes the differential\nsynchronization algorithm. Differential synchronization offers scalability,\nfault-tolerance, and responsive collaborative editing across an unreliable\nnetwork.\n\n## 1 Conventional Strategies\n\nThe three most common approaches to synchronization are ownership, event\npassing and three-way merges. These methods are conceptually simple, but all\nhave drawbacks.\n\nLocking is the simplest technique. In its most basic form, a shared document\nmay only be edited by one user at a time. A familiar example is Microsoft\nWord's behaviour when opening a document on a networked drive.^[?] The first\nuser to open the document has global write access, while all others have read-\nonly access. This does not allow for real-time collaboration by multiple\nusers.\n\nA refinement would be to dynamically lock and release subsections of the\ndocument. However this still prevents close collaboration. Subsection locking\nalso restricts editability when the document is small. Furthermore, support\nfor fine-grained locking would have to be explicitly built into the\napplication. Finally, locking is ill-suited for operation in environments with\nunreliable connectivity since the lock or unlock signals can get lost, leaving\nno owner.\n\nEvent passing is also a simple technique. It relies on capturing all user\nactions and mirroring them across the network to other users. Algorithms based\non Operation Transformation^[?] are currently popular for implementing edit-\nbased collaborative systems. Obtaining a snapshot of the state is usually\ntrivial, but capturing edits is a different matter altogether. A practical\nchallenge with event passing synchronization is that all user actions must be\ncaptured. Obvious ones include typing, but edits such as cut, paste, drag,\ndrop, replacements and autocorrect must also be caught. The richness of modern\nuser interfaces can make this problematic, especially within a browser-based\nenvironment.\n\nAny failure during edit passing results in a fork. Since each edit changes the\nlocation of subsequent edits, one lost edit may cause subsequent edits to be\napplied incorrectly, thus increasing the gap between the two versions. This is\nfurther complicated by the best-effort nature of most networking systems. If a\npacket gets lost or significantly delayed, the system must be able to recover\ngracefully. Google Wave^[?] is an example of a multi-user application which\nuses event passing as its synchronization strategy.\n\nEvent passing is not naturally convergent.\n\nThree-way merges are found in Subversion,^[?] the Mj\u00f8lner Project^[?] and many\nother products. An overview of the process is:\n\n  1. The client sends the contents of the document to the server.\n  2. The server performs a three-way merge to extract the user's changes and merge them with changes from other users.\n  3. The server sends a new copy of the document to the client.\n\nIf the user made any changes to the document during the time this\nsynchronization was in flight, the client is forced to throw the newly\nreceived version away and try again later. This is a half-duplex system: as\nlong as one is typing, no changes are arriving. Shortly after one stops\ntyping, the input from other users is integrated and either appears, or else a\ndialog pops up to let one know that there was a collision.\n\nThis system could be compared to an automobile with a windshield which becomes\nopaque while driving. Look at the road ahead, then drive blindly for a bit,\nthen stop and look again. Major collisions become commonplace when everyone\nelse on the road has the same type of \"look xor drive\" cars.\n\nThree-way merges are not a good solution for real-time collaboration across a\nnetwork with latency.\n\n## 2 Differential Synchronization Overview\n\nDifferential synchronization is a symmetrical algorithm employing an unending\ncycle of background difference (diff) and patch operations. There is no\nrequirement that \"the chickens stop moving so we can count them\" which plagues\nserver-side three-way merges.\n\nBelow is an idealized data flow diagram for differential synchronization. It\nassumes two documents (misleadingly called Client Text and Server Text) which\nare located on the same computer with no network.\n\nThe following walk-through starts with Client Text, Common Shadow and Server\nText all being equal. Client Text and Server Text may be edited at any time.\nThe goal is to keep these two texts as close as possible with each other at\nall times.\n\n  1. Client Text is diffed against the Common Shadow.\n  2. This returns a list of edits which have been performed on Client Text.\n  3. Client Text is copied over to Common Shadow. This copy must be identical to the value of Client Text in step 1, so in a multi-threaded environment a snapshot of the text should have been taken.\n  4. The edits are applied to Server Text on a best-effort basis.\n  5. Server Text is updated with the result of the patch. Steps 4 and 5 must be atomic, but they do not have to be blocking; they may be repeated until Server Text stays still long enough.\n\nThe process now repeats symmetrically in the other direction. This time the\nCommon Shadow is the same as Client Text was in the previous half of the\nsynchronization, so the resulting diff will return modifications made to\nServer Text, not the result of the patch in step 5.\n\nThe enabling feature is that the patch algorithm is fuzzy, meaning patches may\nbe applied even if the document has changed. Thus if the client has typed a\nfew keystrokes in the time that the synchronization took to complete, the\npatches from the server are likely to have enough recognizable context that\nthey may still be applied successfully. However, if some or all of the patches\nfail in step 4, they will automatically show up negatively in the following\ndiff and will be patched out of the Client Text. Here's an example of actual\ndata flow.\n\n  1. Client Text, Common Shadow and Server Text start out with the same string: \"Macs had the original point and click UI.\"\n  2. Client Text is edited (by the user) to say: \"Macintoshes had the original point and click interface.\" (edits underlined)\n  3. The Diff in step 1 returns the following two edits:\n    \n        @@ -1,11 +1,18 @@ Mac +intoshe s had th @@ -35,7 +42,14 @@ ick -UI +interface .\n\n  4. Common Shadow is updated to also say: \"Macintoshes had the original point and click interface.\"\n  5. Meanwhile Server Text has been edited (by another user) to say: \"Smith & Wesson had the original point and click UI.\" (edits underlined)\n  6. In step 4 both edits are patched onto Server Text. The first edit fails since the context has changed too much to insert \"intoshe\" anywhere meaningful. The second edit succeeds perfectly since the context matches.\n  7. Step 5 results in a Server Text which says: \"Smith & Wesson had the original point and click interface.\"\n  8. Now the reverse process starts. First the Diff compares Server Text with Common Shadow and returns the following edit:\n    \n        @@ -1,15 +1,18 @@ -Macintoshes +Smith & Wesson had\n\n  9. Finally this patch is applied to Client Text, thus backing out the failed \"Macs\" -> \"Macintoshes\" edit and replacing it with \"Smith & Wesson\". The \"UI\" -> \"interface\" edit is left untouched. Any changes which have been made to Client Text in the mean time will be patched around and incorporated into the next synchronization cycle.\n\nA live demo of diff and patch algorithms for plain text may be used here:\nhttp://neil.fraser.name/software/diff_match_patch/demo_patch.html\n\n## 3 Dual Shadow Method\n\nThe method described above is the simplest form of differential\nsynchronization, but it will not work on client-server systems since the\nCommon Shadow is, well, common. In order to execute on two systems, the shadow\nneeds to be split in two and updated separately. Conceptually this is the same\nalgorithm.\n\nClient Text and Server Shadow (or symmetrically Server Text and Client Shadow)\nmust be absolutely identical after every half of the synchronization. This\nshould be the case since \"(v1 Diff v2) Patch v1 == v2\". Thus assuming the\nsystem starts in a consistent state, it should remain in a consistent state.\nNote that the patches on the shadows should fit perfectly, thus they may be\nfragile patches, whereas the patches on the texts are best-effort fuzzy\npatches.\n\nHowever, on a network with best-effort delivery, nothing is guaranteed.\nTherefore a simple checksum of Client Shadow ought to be sent along with the\nEdits and compared to Server Shadow after the patches have been applied. If\nthe checksum fails to match, then something went wrong and one side or the\nother must transmit the whole body of the text to get the two parties back in\nsync. This will result in data loss equal to one synchronization cycle.\n\n## 4 Guaranteed Delivery Method\n\nIn the event of a transitory network failure, an outbound or a return packet\nmay get lost. In this case the client might stop synchronizing for a while\nuntil the connection times out. When the connection is restored on the\nfollowing synchronization, the shadows will be out of sync which requires a\ntransmission of the full text to get back in sync. This will destroy all\nchanges since the previous successful synchronization. If this form of data-\nloss is unacceptable, a further refinement adds guaranteed delivery.\n\nIn a nutshell: Normal operation works identically to the Dual System Method\ndescribed above. However in the case of packet loss, the edits are queued up\nin a stack and are retransmitted to the remote party on every sync until the\nremote party returns an acknowledgment of receipt. The server keeps two copies\nof the shadow, \"Server Shadow\" is the most up to date copy, and \"Backup\nShadow\" is the previous version for use in the event that the previous\ntransmission was not received.\n\nNormal operation: Client Text is changed by the user. A Diff is computed\nbetween Client Text and Client Shadow to obtain a set of edits which were made\nby the user. These edits are tagged with a client version number ('n')\nrelating to the version of Client Shadow they were created from. Client Shadow\nis updated to reflect the current value of Client Text, and the client version\nnumber is incremented. The edits are sent to the server along with the\nclient's acknowledgment of the current server version number ('m') from the\nprevious connection. The server's Server Shadow should match both the provided\nclient version number and the provided server version number. The server\npatches the edits onto Server Shadow, increments the client version number of\nServer Shadow and takes a backup of Server Shadow into Backup Shadow. Finally\nthe server then patches the edits onto Server Text. The process then repeats\nsymmetrically from the server to the client, with the exception that the\nclient doesn't take a backup shadow. During the return communication the\nserver will inform the client that it received the edits for version 'n',\nwhereupon the client will delete edits 'n' from the stack of edits to send.\n\nDuplicate packet: The client appears to send Edits 'n' to the server twice.\nThe first communication is processed normally and the response sent. Server\nShadow's 'n' is incremented. The second communication contains an 'n' smaller\nthan the 'n' recorded on Server Shadow. The server has no interest in edits it\nhas already processed, so does nothing and sends back a normal response.\n\nLost outbound packet: The client sends Edits 'n' to the server. The server\nnever receives it. The server never acknowledges receipt of the edit. The\nclient leaves the edits in the outbound stack. After the connection times out,\nthe client takes another diff, updates the 'n' again, and sends both sets of\nedits to the server. The stack of edits transmitted keeps increasing until the\nserver eventually responds with acknowledgment that it got a certain version.\n\nLost return packet: The client sends Edits 'n' to the server. The server\nreceives it, but the response is lost. The client leaves the edits in the\noutbound stack. After the connection times out, the client takes another diff,\nupdates the 'n' again, and sends both sets of edits to the server. The server\nobserves that the server version number 'm' which the client is sending does\nnot match the server version number on Server Shadow. But both server and\nclient version numbers do match the Backup Shadow. This indicates that the\nprevious response must have been lost. Therefore the server deletes its edit\nstack and copies the Backup Shadow into Shadow Text (step 4). The server\nthrows away the first edit because it already processed (same as a duplicate\npacket). The normal workflow is restored: the server applies the second edit,\nthen computes and transmits a fresh diff to the client.\n\nOut of order packet: The server appears to lose a packet, and one (or both) of\nthe lost packet scenarios is played out. Then the lost packet arrives, and the\nduplicate packet scenario is played out.\n\nData corruption in memory or network: There are too many potential failure\npoints to list, however if the shadow checksums become out of sync, or one\nside's version number skips into the future, the system will reinitialize\nitself. This will result in data loss for one side, but it will never result\nin an infinite loop of polling.\n\n### Asymmetry\n\nAn obvious question is that given the otherwise perfect symmetry between\nclient and server, why does the server have a Backup Shadow whereas the client\ndoes not? The source of this asymmetry is the asymmetrical nature of the\nconnections. In a web-based client-server configuration, the client is the\nonly entity which can initiate a connection. Depending on data losses, there\nare only three possible outcomes: 1) client sends data which is lost before\nreaching the server, 2) client sends data to server, but server's response is\nlost before reaching client, 3) client and server complete a successful round-\ntrip. Notably missing is the possibility that the client's data is lost but\nthe server's data is received. Every time the server sends information to the\nclient, that implies a successful connection must have been established from\nthe client to the server. Thus the server cannot get into a situation where it\nrepeatedly sends packets to the client which don't arrive -- while not\nobtaining any packets from the client.\n\nThe client could implement a Backup Shadow, but it would never get used when\nrun on a web-based client-server architecture. For symmetrical architectures\n(e.g. peer-to-peer or server-to-server) where either side can initiate a\nconnection to the other, then a Backup Shadow would be required on both sides.\n\n## 5 Topology\n\nThe above diagrams demonstrate synchronization between two parties, either a\nuser and a server, or a pair of users. This same synchronization strategy can\nbe multiplied to service any number of additional clients in a server-centric\nnetwork. The Server Text for each synchronization loop is common with all the\nother loops. When Client 1 changes his document, Server Text is updated upon\nthe next synchronization cycle, and those changes are passed on to all other\nclients on the following cycle.\n\nScalability may become an issue as the number of clients increase. Diff and\npatch can be expensive operations, thus a server may become overloaded. There\nare two simple methods of distributing the system onto multiple servers.\n\nOne method is to separate the database from the algorithm. Thus one database\nwould service any number of load-balanced servers. A client could hit any\nserver, and as long as the view of the shared database is identical across all\nservers, the system remains consistent.\n\nAnother method is to introduce a server-to-server topology. In the diagram\nbelow, the clients are divided equally between two servers and the two servers\nare linked to each other with exactly the same type of connection as between\nthe servers and the clients. Additional servers may be added seamlessly\nwhenever capacity is exceeded. Servers may only be removed when all their\nclients depart and they only have a single connection to another server.\n\nAs the network expands, a potential problem is latency. Each link might\nsynchronize every five seconds (see section 7). Thus it would take a change\nfrom Client 1 up to fifteen seconds to appear for Client 4. As latency\nincreases, so does the potential for non-trivial collisions. Accordingly it is\nimportant to avoid a long chain of servers; a balanced tree offers the\nshortest path between clients, and thus the least latency. Latency may also be\nreduced by significantly increasing the synchronization frequency between\nservers. If the servers are located next to each other, then there is no\nbandwidth cost in synchronizing several times a second.\n\n## 6 Diff and Patch\n\nAll the examples in this paper have shown synchronization of plain text.\nDifferential synchronization can handle any content (plain text, rich text,\nbitmaps, vector graphics, etc) as long as a difference algorithm and a fuzzy\npatch algorithm is available for the content.\n\nAs the most computationally expensive components, improving the efficiency of\nthese algorithms dramatically improves the responsiveness of the system.\nLikewise, improving the accuracy of these algorithms greatly reduces the\nnumber and severity of collisions.\n\nThe diff operation is fulfilling two very different roles within the\nsynchronization cycle. The first is to update Server Shadow with the current\ncontent of Client Text and Client Shadow. The result should make all three\ntexts identical. This is a simple task which could use any form of\nsynchronization; diff, delta edits or even transmission of the full text. The\nsecond operation is more of a challenge: updating Server Text with the changes\nmade to Client Text. Server Text may have changed in the mean time, which\nmeans that the diff must be semantically meaningful.\n\nFor instance, if the word \"cat\" was deleted and replaced with \"hag\", then\ntechnically one could think of it as the replacement of the first and third\nletters, with the second letter being preserved. This would be the minimal\ndiff.\n\nClient Text: The cat is here. Client Shadow: The hag is here. Minimal Diff:\nThe chatg is here. Semantic Diff: The cathag is here.\n\nBut this was not the semantic intent of the user. The user changed the word,\nnot two letters. The fact that 'a' was the same in both words was completely\ncoincidental. This distinction matters because if in the mean time another\nuser changed the server's text from \"cat\" to \"cut\", the result when applying\nthe first user's patch should be either \"hag\" (client wins) or \"cut\" (server\nwins), but certainly not \"hug\" (merged differences). An algorithm must be used\nto expand minimal diffs into semantically meaningful diffs. One such algorithm\nfor plain-text is described in Diff Strategies, along with a set of\noptimizations to make diff significantly faster.\n\nThe patch operation is just as critical to the operation of the system. This\nsystem requires that patches be applied in and around text which may not\nexactly match the expected text. Furthermore, patches must be applied\n'delicately', taking care not to overwrite changes which do not need to be\noverwritten. One such algorithm for plain-text is described in Fuzzy Patch,\nalong with a set of optimizations to make patch significantly faster.\n\n## 7 Adaptive Timing\n\nThe frequency of each client's update cycle is a key factor in determining the\nresponsiveness of the system. Insufficiently frequent updates result in more\ncomputationally expensive diff and patch operations, major edit collisions,\nmerge failures, and frustration when attempting to interact with other users.\nOverly frequent updates result in higher network traffic and increased system\nload.\n\nThe most computationally expensive operation is extracting the difference\nbetween what was last synced and the current document contents (thus obtaining\nthe changes). This algorithm is O(n^2) where n is the length of the changes.\nThus if synchronizations can generally occur one change apart (where one\nchange can be an insertion or a deletion of arbitrary length), then the most\nexpensive operation becomes O(1). An advantage of the Guaranteed Delivery\nMethod described above is that it decouples the differencing operation from\nthe network transmission. Diffs can be taken at frequent intervals (to\nconserve CPU resources), added to the edit stack, then transmitted in batches\nat a slower rate (to conserve network resources).\n\nAn adaptive system can continuously modify the network synchronization\nfrequency for each client based on current activity. Hard-coded upper and\nlower limits would be defined to keep the cycle within a reasonable range\n(e.g. 1 second and 10 seconds respectively). User activity and remote activity\nwould both decrease the time between updates (e.g. halving the period).\nSending and receiving an empty update would increase the time between updates\n(e.g. increasing the period by one second). This adaptive timing automatically\ntunes the update frequency so that each client gradually backs off when\nactivity is low, and quickly reengages when activity is high.\n\n## 8 Further Issues\n\nDespite the inherent complexity, this synchronization system works extremely\nwell. It is robust, self-healing and (with the proper diff and patch\nalgorithms) impressively accommodating of users who are working on the same\ntext. Try the demonstration of MobWrite, a web-based multi-user editor which\nuses this differential synchronization.\n\nOne limitation of differential synchronization as described here is that only\none synchronization packet may be in flight at any given time. This would be a\nproblem if there was very significant latency in the connection. An example\nwould be a client on Mars and a server on Earth. A half hour for the round\ntrip at the speed of light is unavoidable, however it would be better to send\na continuous stream of updates in each direction, not waiting for the reply to\narrive. The algorithm does not currently support this feature.\n\nAnother avenue for exploration would be to keep track of which user was\nresponsible for which edits. Currently the edits from all users are blended\ntogether on the server, making attribution difficult. Untangling this blend\nwould allow incoming edits to be visually attributed to specific users, as\nwell as potentially allowing rollbacks of individual contributions and other\nCVS-like features.\n\nNeil Fraser: Writing: Differential Synchronization\n\nLast modified: 8 September 2009\n\n", "frontpage": false}
