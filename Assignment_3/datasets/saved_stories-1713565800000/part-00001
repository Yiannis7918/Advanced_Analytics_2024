{"aid": "40088782", "title": "Developers with AI assistants need to follow the pair programming model", "url": "https://stackoverflow.blog/2024/04/03/developers-with-ai-assistants-need-to-follow-the-pair-programming-model/", "domain": "stackoverflow.blog", "votes": 3, "user": "taubek", "posted_at": "2024-04-19 16:28:04", "comments": 0, "source_title": "Developers with AI assistants need to follow the pair programming model", "source_text": "Developers with AI assistants need to follow the pair programming model -\nStack Overflow\n\nBlog\n\nProducts\n\nStack Overflow for Teams\n\nCapture, share, & collaborate on knowledge internally.\n\nAdvertising\n\nPromote your product or service to developers and technologists.\n\nTalent\n\nEngage the world\u2019s technology talent with your employer brand.\n\nApril 3, 2024\n\n# Developers with AI assistants need to follow the pair programming model\n\nCodeGen is fast, but you need to be good.\n\nCredit: Alexandra Francis\n\nNow that generative AI, large language models, and CodeGen applications have\nbeen out for a while, we\u2019ve seen developers figure out their strengths, their\nweaknesses, and how they can deliver value to customers faster without getting\nhung up on untangling LLM confabulations. CodeGen applications pump out code\nfast for pretty cheap prices, but it\u2019s not always good. AI-generated code\nalways needs a strong code review, and that can reduce the productivity gains\nit offers.\n\nHowever, there\u2019s a programming model that incorporates continuous code review\nand produces better code: pair programming. In pair programming, two\nprogrammers work on the same code together to produce something that is\nhigher-quality than either of them would produce by themselves.\n\nIn this article, we\u2019ll discuss how and why pair programming is so effective,\nhow you can treat your AI assistant as a paired programmer, and the best ways\nto make this pairing work (as well as the methods that don\u2019t).\n\n## Benefits of pair programming\n\nWay back in 2016, we published a piece on the benefits of pair programming:\n\nIn pair programming one participant is the \u201cdriver,\u201d who actually writes code,\nand the other is the \u201cnavigator,\u201d who checks the driver\u2019s work as it\u2019s done\nand keeps an eye on the big picture.\n\nStudies have shown that, contrary to early objections that the practice would\nbe twice as expensive in terms of \u201cman hours,\u201d coding this way actually adds\njust 15% more time to the development process, and in exchange returns 15%\nfewer bugs and defects.\n\nYou might think that two people working on the same code with only one\nkeyboard would slow down the process. But the above study linked found that\nwhen one person wrote the code, then sent it to another for code review, the\nprocess actually took longer than pair programming. The coder had to convey\neverything that they learned from writing the code, which took twice as long\nas making the original changes. Pairing and doing both the coding and the\nreview simultaneously saved time by parallelizing the learning\u2014both\nprogrammers learned simultaneously. And if the review had to convey something\nto the coder to correct a mistake, they could do that in real time, too, and\nthe coder could avoid building additional code on that mistake.\n\nIn a recent question on the Software Engineering Stack Exchange site, user h22\ncompared pair programming to having two pilots in an airplane cockpit: \u201cIn\naviation, then there are two pilots, there is a pilot flying and the pilot\nmonitoring. The pilot monitoring is also fully in the course and can take over\nat any time. This works very well and is unlikely to change, even if\ntechnically these aircraft could be flown by a single human.\u201d\n\nFor pairings between junior and senior programmers, the knowledge asymmetry\nmay make the exercise feel like a training session, with the senior frustrated\nand rattling off commands to \u201cadd this, change this, no, not like that\u201d. Pair\nprogramming is not the same thing as training or mentoring, and unless you\u2019re\ntelling someone how to defuse a bomb via walkie talkie, you\u2019re collaborating.\nAs user Flater wrote, \u201cWork-related conversations are precisely the point of\npair programming; it allows the pair to convey their knowledge to each other\nand/or helps them work together to learn something that's new to both of\nthem.\u201d\n\nYou\u2019re not telling someone how to code; you\u2019re collaborating on the spot and\ngiving/receiving instant peer reviews as solutions are proposed. If you run\ninto roadblocks, overthinking things to death, user candied_orange suggests\nunderthinking things. \u201cThe easy cure for analysis paralysis is doing something\nstupid and making people explain to you why it's wrong. Iterate on that until\nyou run out of wrong.\u201d\n\nNow, you may already agree with all this, pairing on the regular as super-\nproductive duos. Let\u2019s take a look at how you can take these methods and apply\nthem to your GenAI/CodeGen assistants.\n\n## A junior dev with 1000 words per minute\n\nMany people, particularly people who are less familiar with code, think that\nCodeGen assistants are tools that write code for you based on natural language\nprompts. A study by GitClear found that copying and pasting is on the rise:\nsince 2022, more code is being copied and pasted from external sources, while\nless is being moved (a sign of refactoring), leading to greater churn\u2014code\nupdated, removed, or reverted within two weeks. They conclude that \u201cthe rise\nof AI assistants is strongly correlated with \u2018mistake code\u2019 being pushed to\nthe repo.\u201d\n\nCodeGen assistants have been found to write code that isn\u2019t always up to\nsnuff. Isaac Lyman, writing in this blog about AI-assisted programmers, said,\n\u201cStudies have found that [CodeGen] tools deliver code that is \u2018valid\u2019 (runs\nwithout errors) about 90% of the time, passes an average of 30% to 65% of unit\ntests, and is \u2018secure\u2019 about 60% of the time.\u201d They\u2019ve included libraries,\nfunctions, and variables out of thin air. Imagine a newly-hired mediocre\njunior programmer who\u2019s read tons of documentation, taken every bootcamp, and\nchecked out every Stack Overflow Q&A page. That\u2019s who you\u2019re pairing with when\nyou use CodeGen.\n\nTo set up a pair programming paradigm with CodeGen, you take the navigator\nrole, while the AI is the coder. As the knowledgeable one, you should be\nplanning, thinking about design, and reviewing any code produced, while the\ntool does what it does best: cranks out code fast. As Lyman wrote, \u201cIt\u2019s the\nAI\u2019s job to be fast, but it\u2019s your job to be good.\u201d\n\nWhen Replit CEO Amjad Masad came on the Stack Overflow podcast, he talked\nabout how many of the current CodeGen tools run the pairing relationship the\nother way: \u201cThey call it Copilot because you're still the driver. It is\nlooking over your shoulder and giving you suggestions about what you might\nwant to do next.\u201d But he also pointed out the dangers of not giving the human\npartner the final say. \u201cThe reliability, the hallucination problem, is\nunsolved. That's the fundamental problem with neural networks, we don't know,\nactually, what they're doing, and therefore we can't trust them. There will\nalways need to be a software engineer that is actually verifying and looking\nat the code.\u201d\n\nProgramming fundamentals will become more important than ever, as will\nseasoned programmers who know the ins and outs of what makes for quality\ncode\u2014by following SOLID principles, keeping code simple and easy to read, and\nbuilding self-contained components. When Marcos Grappeggia, the product\nmanager for Google Duet, joined the Stack Overflow podcast, he was clear on\nthe limits of CodeGen tools: \u201cThey're not a great replacement for day-to-day\ndevelopers. If you don't understand your code, that's still a recipe for\nfailure. The model is still going to help explain the code for you, to get the\nhigh level, but it doesn't replace developers fully understanding the code.\u201d\n\nAs the navigator to the AI\u2019s coder, the syntax and library knowledge may be\nless important in the long run compared to architecting, requirements\ndetailing (and pivoting), and refactoring. High-level fluency and\nunderstanding what makes software well-engineered will make you a better pair\npartner. When we talked to William Falcon, an AI researcher and creator of\nPyTorch Lightning, on the podcast, he emphasized the importance of domain\nknowledge: \u201cIf you're a new developer, you're just going to copy it. I'm like,\n\u2018I know this is not written by you because it's too over-engineered and a\nlittle bit too complicated.\u2019 You know that there are control flows, you know\nthat there are bad practices around global variables. There's all these\nstandard things that we all know. It's like an English lawyer using a\ntranslator for French. They're going to do a great job because they already\nknow the law. But having someone who speaks English that's not a lawyer try to\ndo law in French won\u2019t work.\u201d\n\nBut when you grasp that your partner here is flawed and can adjust on the fly,\nwhy, then you can get that mythical 10x productivity. At the end of 2022,\nright after ChatGPT was loosed upon the wilds, David Clinton wrote about using\nit to create Bash scripts. While it wasn\u2019t perfect, its imperfections were\nilluminating. \u201cI began to realize that there was an even more powerful benefit\nstaring me in the face: an opportunity to pair-program with an eminently\nhelpful partner. The AI ultimately failed to solve my problem, but the way it\nfailed was absolutely fascinating. It's just mind-blowing how the AI is\ncompletely engaged in the process here. It remembers its first code, listens\nto and understands my complaint, and thinks through a solution.\u201d\n\nAs we\u2019ll see, approaching CodeGen with this mindset\u2014as a flawed but helpful\npartner\u2014can help you make the most of the code it gives you.\n\n## Benefit/techniques\n\nAre there specific ways to take advantage and mitigate code from a fast and\ndumb pair programming partner? I reached out to Bootstrap IT\u2019s David Clinton,\nwho wrote the Bash article linked above, to see if he\u2019d learned how to best\nwork with CodeGen partners. \u201cEmbrace multiple LLM tools and interfaces,\u201d he\nadvised. \u201cResults can completely change from one week to the next. That's why\nwe decided to call my Manning book \u2018The Complete Obsolete Guide to GenAI.\u2019\u201d\n\nLeaning into the fast part means that you can get a quick draft/prototype of\nsomething and build off it. \u201cThere are times when I'll upload a complex CSV\nfile\u2014or even the unstructured data in a PDF\u2014to ChatGPT Plus and ask it to do\nits own analytics,\u201d said Clinton. \u201cI appreciate the immediate insights, but\nGPT also gives me the code it used to do its work, which I can cut-and-paste\nto jump-start my own analytics. I talk a lot about that in my new Pluralsight\ncourse.\u201d\n\nWhile many developers have spent their careers specializing in a few\nlanguages, CodeGen knows most of them. Many programming languages operate with\nsimilar logic, so if you let your AI partner handle the syntax, you can create\ncode in languages you don\u2019t know. Anand Das, cofounder and CTO of Bito AI,\ntold us about this dynamic: \u201cPeople who are coming into the project and are\ntrying to solve bugs and don't really know a particular language\u2014somebody\nwrote a script in Python and the guy doesn't know Python\u2014they can actually\nunderstand what that script does and logically figure out that there is an\nissue and then have AI actually write code.\u201d\n\nAs I\u2019ve written about before, one of the things that AI does well is\nscaffolding\u2014applying a known pattern to new data. Under your guidance, you can\nget your CodeGen buddy to apply known fixes/templates/type declarations to new\nitems. It\u2019s what automatic security flaw patcher Mobb does. CEO and cofounder\nEitan Worcel told us: \u201cOur approach is to build a fix and use the AI to\nenhance our coverage on that fix. It will take the results of a scan, identify\nthe problem\u2014let's say SQL injection which is a very known one. We have\npatterns to find that root cause, and with a mix of our algorithms and GenAI,\nwe will generate a fix for the developer, present that fix to the developer in\ntheir GitHub so they don't need to go anywhere.\u201d\n\nBut Worcel\u2019s experience developing Mobb speaks to the other side of pairing\nwith CodeGen\u2014mitigating the dumb stuff. \u201cThe first few researches that we did\naround AI were underwhelming to the extreme. We got about a 30% success rate\nwith fixes, and even those, sometimes it fixed the problem in a way that no\none should do. Sometimes it actually introduced new vulnerabilities. We needed\nto put guardrails around the AI and not let it go outside of those guardrails\nand hallucinate stuff.\u201d In a pairing paradigm, you are those guardrails.\n\nYou can provide guardrails in two ways. The first is by including detailed\nrequirements in the prompt, including all your variable names. \u201cInclude\ndetails like actual column and dataframe names in your prompt,\u201d said Clinton.\n\u201cThat way the code you get back won't need as much rewriting. And don't be\nembarrassed to ask for the same dumb syntax over and over again. The LLM\ndoesn't care how dumb I am.\u201d\n\nThe second is by testing the pants off of any code the AI gives you, including\nensuring that libraries, methods, and APIs actually exist and are implemented\nin a safe way. \u201cFor example, I want to access this API and the API doesn't\nexist,\u201d said Das. \u201cYou don't want any model that you're using to suddenly give\nyou an API which doesn't exist and you think you can use this. When you start\nrunning it, there's no definition for it.\u201d\n\nRight now, CodeGen tools won\u2019t be writing good code without a knowledgeable\ndeveloper navigating over their shoulder. Maybe they never will. But humans\nand GenAI work better together, with the humans getting fast first drafts of\ncode and the AI getting feedback and checks on their instant output. When we\ntalked with Doug Seven, director of software development at AWS and the GM for\nCodeWhisperer, he framed CodeGen tools like this: \u201cCodeWhisperer is like\nhaving a new hire developer join your team. They understand the basics of\nsoftware development, they know how to write code in lots of different ways,\nbut they don't understand your code that\u2019s in your organization that\u2019s private\nand proprietary.\u201d\n\nIn other words, it\u2019s the AI\u2019s job to be fast. It\u2019s your job to be good.\n\n## The power of two\n\nPair programming has proven itself to be a force multiplier on the individuals\nsharing a keyboard. One focuses on the syntax and implementation, while the\nother focuses on the big picture and provides instant code review. By making a\nCodeGen tool your syntax and implement partner, you can reduce the feedback\nwindow between code and code review to minutes, allowing you to iterate and\nelaborate on ideas without futzing about with semicolons and type definitions.\n\nThat said, you still need to understand any code that you and your AI partner\npush to code. No matter where code comes from\u2014AI, copy and paste,\ncoworkers\u2014understanding it like you wrote it yourself is essential to keeping\na codebase humming along.\n\nAuthors\n\nRyan Donovan\n\nStaff\n\npair programmingai codingProductivityse-techse-stackoverflow\n\nRecent articles\n\nApril 15, 2024\n\n# How to succeed as a data engineer without the burnout\n\nApril 4, 2024\n\n# How do mixture-of-experts layers affect transformer models?\n\nMarch 27, 2024\n\n# Community products: Reflections and looking ahead\n\nMarch 18, 2024\n\n# Exploring what inspired folks to start coding\n\nLatest Podcast\n\nApril 19, 2024\n\n# Why configuration is so complicated\n\nLogin with your stackoverflow.com account to take part in the discussion.\n\nStack Overflow for Teams\n\nPricingCustomersOur solutionIntegrationsFeaturesCustomer SuccessSecurityReturn\non Investment (ROI) OverflowAI Try freeLog in\n\nUse casesEngineersData ScientistsDevOps & SRESupportProduct Managment\nResourcesProductivityAI/MLGuides and InsightsCustomer Academy FAQHelp center\n\nStack Overflow Advertising\n\nWhy Stack Overflow?What to expect Advertise to developersAttract tech\ntalentEngage your community\n\nUse casesMarketing TeamsEmployer Branding TeamsDevRel TeamsTalent\nTeamsTechnology TeamsAgencies ResourcesProduct guides & insightsCommunity\ninsightsAdvertising best practicesTalent best practicesCollectivesTM\n\nCompany\n\nOverflowAPI NEW\n\nStack Overflow\u2019s subscription-based API service to train and fine-tune large\nlanguage models.\n\nAboutLeadershipSocial ImpactPressCareersOpen positionsContact us\nBlogNewsletterPodcastLabs\n\nSite design / logo \u00a9 2024 Stack Exchange Inc. User contributions licensed\nunder CC BY-SA.\n\nTermsPrivacy policyCookie policyCookie settings Go to stackoverflow.com\n\n## Your privacy\n\nBy clicking \u201cAccept all cookies\u201d, you agree Stack Exchange can store cookies\non your device and disclose information in accordance with our Cookie Policy.\n\n## Cookie Settings\n\nWhen you visit any of our websites, it may store or retrieve information on\nyour browser, mostly in the form of cookies. This information might be about\nyou, your preferences or your device and is mostly used to make the site work\nas you expect it to. The information does not usually directly identify you,\nbut it can give you a more personalized web experience. Because we respect\nyour right to privacy, you can choose not to allow some types of cookies.\nClick on the different category headings to find out more and manage your\npreferences. Please note, blocking some types of cookies may impact your\nexperience of the site and the services we are able to offer.\n\n### Manage Consent Preferences\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nThese cookies are necessary for the website to function and cannot be switched\noff in our systems. They are usually only set in response to actions made by\nyou which amount to a request for services, such as setting your privacy\npreferences, logging in or filling in forms. You can set your browser to block\nor alert you about these cookies, but some parts of the site will not then\nwork. These cookies do not store any personally identifiable information.\n\n#### Functional Cookies\n\nThese cookies enable the website to provide enhanced functionality and\npersonalisation. They may be set by us or by third party providers whose\nservices we have added to our pages. If you do not allow these cookies then\nsome or all of these services may not function properly.\n\n#### Targeting Cookies\n\nThese cookies are used to make advertising messages more relevant to you and\nmay be set through our site by us or by our advertising partners. They may be\nused to build a profile of your interests and show you relevant advertising on\nour site or on other sites. They do not store directly personal information,\nbut are based on uniquely identifying your browser and internet device.\n\n#### Performance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure\nand improve the performance of our site. They help us to know which pages are\nthe most and least popular and see how visitors move around the site. All\ninformation these cookies collect is aggregated and therefore anonymous. If\nyou do not allow these cookies we will not know when you have visited our\nsite, and will not be able to monitor its performance.\n\n### Cookie List\n\nlabel\n\nConsent Leg.Interest\n\nlabel\n\nlabel\n\nlabel\n\n", "frontpage": false}
