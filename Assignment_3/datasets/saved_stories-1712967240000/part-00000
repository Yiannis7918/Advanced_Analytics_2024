{"aid": "40015926", "title": "Go for AI?", "url": "https://go.dev/blog/survey2024-h1-results#mlai", "domain": "go.dev", "votes": 2, "user": "grandimam", "posted_at": "2024-04-12 18:12:07", "comments": 0, "source_title": "Go Developer Survey 2024 H1 Results - The Go Programming Language", "source_text": "Go Developer Survey 2024 H1 Results - The Go Programming Language\n\n# The Go Blog\n\n# Go Developer Survey 2024 H1 Results\n\nAlice Merrick and Todd Kulesza 9 April 2024\n\n## Background\n\nThis post shares the results of our most recent Go Developer Survey, conducted\nin January and February 2024. Along with capturing sentiments and challenges\naround using Go and Go tooling, our primary focus areas for this survey were\nabout how developers are starting to use Go (or other languages) for AI-\nrelated use cases, and particular challenges for those who are learning Go or\nlooking to expand their Go skill set.\n\nWe recruited participants from the Go blog and through randomized prompts in\nthe VS Code Go plug-in. This year, with the help of JetBrains, we also\nincluded a randomized survey prompt in the GoLand IDE, allowing us to recruit\na more representative sample of Go developers. We received a total of 6,224\nresponses! A huge thank you to all those who contributed to making this\npossible.\n\n## Highlights\n\n  * Developer sentiment remains high, with 93% of respondents expressing satisfaction with Go over the past year.\n  * A majority of respondents (80%) said they trust the Go team to \u201cdo what\u2019s best\u201d for developers like themselves when maintaining and evolving the language.\n  * Among survey respondents who build AI-powered applications and services, there is a shared sense that Go is a strong platform for running these types of applications in production. For example, a majority of respondents working with AI-powered applications already use Go or would like to migrate to Go for their AI-powered workloads, and the most serious challenges developers encounter are related to the library and documentation ecosystems rather than the core language and runtime. That said, the most commonly documented paths for getting started are currently Python-centric, resulting in many organizations starting AI-powered work in Python before moving to a more production-ready language.\n  * The most common kinds of AI-powered services respondents are building include summarization tools, text generation tools, and chatbots. Responses suggest that many of these use cases are internal-facing, such as chatbots trained upon an organization\u2019s internal documentation and intended to answer employee questions. We hypothesize that organizations are intentionally starting with internal use cases to develop in-house expertise with LLMs while avoiding potential public embarrassment when AI-powered agents behave unexpectedly.\n  * Lack of time or opportunities was the most commonly cited challenge for respondents to reaching their Go-related learning goals, suggesting that language learning is difficult to prioritize without a specific goal or business case in mind. The next most common challenge was in learning new best practices, concepts, and idioms that are particular to Go when coming from other language ecosystems.\n\n## Contents\n\n  * Developer sentiment\n  * Developer environments\n  * Resource and performance priorities\n  * Understanding AI use cases for Go\n  * Learning challenges\n  * Demographics\n  * Firmographics\n  * Methodology\n  * Closing\n\n## Developer sentiment\n\nOverall satisfaction remains high in the survey with 93% of respondents saying\nthey were somewhat or very satisfied with Go during the last year. This isn\u2019t\nsurprising, considering our audience is those who have voluntarily taken our\nsurvey. But even among those who were randomly sampled from both VS Code and\nGoLand, we still see comparable rates of satisfaction (92%). Although the\nexact percentages fluctuate slightly from survey to survey, we do not see any\nstatistically significant differences from 2023 H2, when the satisfaction rate\nwas 90%.\n\n### Trust\n\nThis year we introduced a new metric for measuring developer trust. This was\nan experimental question and its wording may change over time as we learn more\nabout how respondents interpreted it. Because this is the first time we asked\nthis question, we don\u2019t have previous years to give us context for our\nresults. We found that 80% of respondents somewhat or strongly agree that they\ntrust the Go team to do what\u2019s best for users like them. Respondents with 5 or\nmore years of experience with Go tended to agree more (83%) than those with\nless than 2 years of experience (77%). This could reflect survivorship bias in\nthat those who trust the Go team more are more likely to continue using Go, or\nmay reflect how trust is calibrated over time.\n\n### Community satisfaction\n\nIn the last year, almost a third of respondents (32%) said they participated\nin the Go developer community either online or at in-person events. More\nexperienced Go developers were more likely to have participated in a community\nevent and were more satisfied with community events overall. Although we can\u2019t\ndraw causal conclusions from this data, we did see a positive correlation\nbetween community satisfaction and overall satisfaction with Go. It could be\nthat participating in the Go community increases satisfaction through\nincreased social interaction or technical support. In general, we also found\nthat respondents with less experience were less likely to have participated in\nevents in the last year. This may mean they haven\u2019t discovered events or found\nopportunities yet to be involved.\n\n### Biggest challenges\n\nFor several years, this survey has asked participants about their biggest\nchallenge when using Go. This has always been in the form of an open text box\nand has elicited a wide variety of responses. In this cycle we introduced a\nclosed form of the question, where we provided the most common write-in\nresponses from prior years. Respondents were randomly shown either the open or\nclosed forms of the question. The closed form helps us validate how we\u2019ve\nhistorically interpreted these responses, while also increasing the number of\nGo developers we hear from: this year participants who saw the closed form\nwere 2.5x more likely to answer than those who saw the open form. This higher\nnumber of responses narrows our margin of error and increases our confidence\nwhen interpreting survey results.\n\nIn the closed-form, only 8% of respondents selected \u201cOther\u201d, which suggests we\ncaptured the majority of common challenges with our response choices.\nInterestingly, 13% of respondents said they don\u2019t face any challenges using\nGo. In the open text version of this question, only 2% of respondents gave\nthis response. The top responses in the closed-form were learning how to write\nGo effectively (15%) and the verbosity of error handling (13%). This matches\nwhat we saw in the open-text form, where 11% of responses mentioned learning\nGo, learning best practices, or issues with documentation as their biggest\nchallenge, and another 11% mentioned error handling.\n\nRespondents who saw the closed form of the question also received a follow-up\nopen-text question to give them an opportunity to tell us more about their\nbiggest challenge in case they had wanted to provide more nuanced answers,\nadditional challenges, or anything else they felt was important.The most\ncommon response mentioned Go\u2019s type system, and often asked specifically for\nenums, option types, or sum types in Go. Often we did not get much context for\nthese requests, but we suspect this is due to some recent proposals and\ncommunity discussions related to enums, an increase in folks coming from other\nlanguage ecosystems where these features are common, or the expectation that\nthese features will reduce writing boilerplate code. One of the more\ncomprehensive comments related to the type system explained as follows:\n\n> \u201cThese aren\u2019t big challenges, but more conveniences I miss in the language.\n> There\u2019s ways around all of them, but it would be nice not to have to think\n> about it.\n\n> Sum types/closed enums can be emulated but its a lot of faff. It\u2019s a very\n> handy feature to have when interacting with APIs that only have a limited\n> set of values for a particular element/field in a response and a value\n> outside of it is an error. It helps with validation and catching issues at\n> the point of entry and can often directly be generated from API\n> specifications like JSON Schema, OpenAPI or heaven forbid XML Schema\n> Definitions.\n\n> I don\u2019t mind the error checking verbosity at all, but the nil-checking with\n> pointers gets tedious especially when [I] need to drill into a deeply nested\n> struct of pointer fields. Some form of Optional/Result type or an ability to\n> chase through a chain of pointers and simply get a nil back instead of\n> triggering a runtime panic would be appreciated.\u201d\n\n## Developer environments\n\nAs in previous years, most survey respondents develop with Go on Linux (61%)\nand macOS (58%) systems. Although the numbers haven\u2019t changed much from year\nto year, we did see some interesting differences in our self-selected sample.\nThe randomly sampled groups from JetBrains and VS Code were more likely (31%\nand 33%, respectively) to develop on Windows than the self-selected group\n(19%). We don\u2019t know exactly why the self-selected group is so different, but\nwe hypothesize that, because they likely encountered the survey from reading\nthe Go Blog, these respondents are some of the most engaged and experienced\ndevelopers in the community. Their operating system preferences might be\nreflective of historical priorities of the core development team who typically\ndeveloped on Linux and macOS. Thankfully we have the random samples from\nJetBrains and VS Code to provide a more representative view of developer\npreferences.\n\nAs a followup for the 17% of respondents who develop on WSL, we asked which\nversion they\u2019re using. 93% of respondents who develop on WSL are using version\n2, so going forward, the Go team at Microsoft has decided to focus their\nefforts on WSL2.\n\nGiven that two of our sample populations were recruited from within VS Code or\nGoLand, they are strongly biased towards preferring those editors. To avoid\nskewing the results, we show the data here from the self-selected group only.\nSimilar to previous years, the most common code editors among Go Developer\nSurvey respondents continue to be VS Code (43%) and GoLand (33%). We don\u2019t see\nany statistically significant differences from mid-2023, (44% and 31%,\nrespectively).\n\nWith the prevalence of Go for cloud development and containerized workloads,\nit\u2019s no surprise that Go developers primarily deploy to Linux environments\n(93%). We didn\u2019t see any significant changes from last year.\n\nGo is a popular language for modern cloud-based development, so we typically\ninclude survey questions to help us understand which cloud platforms Go\ndevelopers are using and how satisfied they are with the three most popular\nplatforms: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud. This\nsection was only shown to respondents who said they use Go for their primary\njob, about 76% of total respondents. 98% of those who saw this question work\non Go software that integrates with cloud services. Over half of respondents\nused AWS (52%), while 27% used GCP for their Go development and deployments.\nFor both AWS and Google Cloud, we don\u2019t see any differences between small or\nlarge companies in their likelihood to use either provider. Microsoft Azure is\nthe only cloud provider that is significantly more likely to be used in large\norganizations (companies with > 1,000 employees) than smaller shops. We didn\u2019t\nsee any significant differences in usage based on the size of the organization\nfor any other cloud providers.\n\nThe rates of satisfaction for using Go with AWS and Google Cloud were both\n77%. Historically these rates have been about the same. As in previous years,\nthe satisfaction rate for Microsoft Azure was lower (57%).\n\n## Resource and Security Priorities\n\nTo help prioritize the Go team\u2019s work, we wanted to understand the top\nresource cost and security concerns for teams using Go. About half of\nrespondents using Go at work reported having at least one resource cost\nconcern in the last year (52%). The engineering costs of writing and\nmaintaining Go services was more common (28%) than concern for the costs of\nrunning Go services (10%) or both about equally (12%). We didn\u2019t see any\nsignificant differences in resource concerns between small and large\norganizations. To address concerns about resource costs, the Go team is\ncontinuing to optimize Go and enhance profile-guided optimization (PGO).\n\nAs for security priorities, we asked respondents to tell us up to three of\ntheir top concerns. Of those who did have security concerns, overall, the top\nconcern was insecure coding practices (42%), followed by system\nmisconfiguration (29%). Our main takeaway is that respondents are especially\ninterested in tooling to help find and fix potential security issues while\nthey\u2019re writing code. This aligns with what we\u2019ve learned from prior research\ninto how developers find and address security vulnerabilities.\n\n### Performance Tooling\n\nOur goals for this section were to measure how respondents perceive the ease\nor difficulty of diagnosing performance issues and determine whether this task\nis more or less difficult depending on their editor or IDE usage.\nSpecifically, we wanted to know if it\u2019s more difficult to diagnose performance\nissues from the command line, and if we should invest in improving the\nintegration of performance diagnostic tooling within VS Code to make this task\neasier. In our analyses, we show comparisons between respondents who prefer VS\nCode or GoLand to highlight what we learned about the experience of using VS\nCode compared to another common editor.\n\nWe first asked a general question about different kinds of tools and\ntechniques respondents use with Go to have some points of comparison. We found\nthat only 40% of respondents use tools to improve code performance or\nefficiency. We didn\u2019t see any significant differences based on editor or IDE\npreference, that is, VS Code users and GoLand users were about equally likely\nto use tools to improve code performance or efficiency.\n\nMost respondents (73%) told us that identifying and addressing performance\nissues is at least moderately important. Again, we didn\u2019t see any significant\ndifferences here between GoLand and VS Code users in how important they found\ndiagnosing performance issues.\n\nOverall, respondents did not find diagnosing performance issues easy, with 30%\nreporting it was somewhat or very difficult and 46% saying it was neither easy\nnor difficult. Contrary to our hypothesis, VS Code users were not more likely\nto report challenges when diagnosing performance issues vs. other respondents.\nThose using their command line for diagnosing performance issues, regardless\nof their preferred editor, also did not report this task as more challenging\nthan those using their IDE. Years of experience was the only significant\nfactor we observed, where less experienced Go developers found it overall more\ndifficult to diagnose performance issues than more experienced Go developers.\n\nTo answer our original question, most developers found it difficult to\ndiagnose performance issues in Go, regardless of their preferred editor or\ntooling. This was especially true for developers with less than two years of\nexperience in Go.\n\nWe also included a follow-up for respondents who rated diagnosing performance\nissues as at least slightly important to understand which issues were most\nimportant to them. Latency, total memory, and total CPU were the top concerns.\nThere could be several explanations to the significance of these areas. First,\nthey are measurable and easily convertible into business costs. Secondly,\ntotal memory and CPU usage represent physical constraints that necessitate\nhardware upgrades or software optimizations for improvement. Moreover,\nlatency, total memory, and total CPU are more manageable by developers and can\nimpact even straightforward services. In contrast, GC performance and memory\nallocation may only be relevant in rare cases or for exceptionally heavy\nworkloads. Additionally, latency stands out as the most user-visible metric,\nas high latency results in slow services and dissatisfied users.\n\n## Understanding AI use cases for Go\n\nOur previous survey asked Go developers about their early experiences with\ngenerative AI systems. To go a bit deeper this cycle, we asked several AI-\nrelated questions to understand how respondents are building AI-powered (more\nspecifically, LLM-powered) services. We found that half of survey respondents\n(50%) work at organizations that are building or exploring AI-powered\nservices. Of these, just over half (56%) said they were involved with adding\nAI capabilities to their organization\u2019s services. Our remaining AI-related\nquestions were only shown to this slice of respondents.\n\nPlease be cautious about generalizing these participant responses to the\noverall population of Go developers. Because only about 1\u20444 of survey\nrespondents are working with AI-powered services, we suggest using this data\nto understand the early adopters in this space, with the caveat that early\nadopters tend to be a bit different than the majority of people who will\neventually adopt a technology. As an example, we expect that this audience is\nexperimenting with more models and SDKs than may be the case a year or two\nfrom now, and encountering more challenges related to integrating those\nservices into their existing code base.\n\nAmong the audience of Go developers working professionally with generative AI\n(GenAI) systems, a solid majority (81%) reported using OpenAI\u2019s ChatGPT or\nDALL-E models. A collection of open-source models also saw high adoption, with\na majority of respondents (53%) using at least one of Llama, Mistral, or\nanother OSS model. We see some early evidence that larger organizations\n(1,000+ employees) are a bit less likely to be using OpenAI models (74% vs.\n83%) and a bit more likely to be using other proprietary models (22% vs. 11%).\nWe do not, however, see any evidence of differences in adoption of OSS models\nbased on organization size\u2013both smaller companies and larger enterprises show\nsmall majorities adopting OSS models (51% and 53%, respectively). Overall we\nfound that a plurality of respondents prefer to use open-source models (47%)\nwith only 19% preferring proprietary models; 37% said they had no preference.\n\nThe most common kinds of services respondents are building include\nsummarization tools (56%), text generation tools (55%), and chatbots (46%).\nOpen-text responses suggested that many of these use cases are internal-\nfacing, such as chat bots trained upon an organization\u2019s internal\ndocumentation and intended to answer employee questions. Respondents raised\nseveral concerns about external-facing AI features, most notably due to\nreliability (e.g., do slight changes in my question lead to very different\nresults?) and accuracy (e.g., are the results trustworthy?) issues. An\ninteresting theme running through these responses was a sense of tension\nbetween the risk of not adopting AI tooling at all (and thereby losing a\npotential competitive advantage should generative AI become necessary in the\nfuture), balanced against the risk of negative publicity or violating\nregulations/laws by using untested AI in high-criticality customer-facing\ndomains.\n\nWe found evidence that Go is already being used in the GenAI space, and there\nappears to be an appetite for more. Roughly 1\u20443 of respondents who were\nbuilding AI-powered features told us they were already using Go for a variety\nof GenAI tasks, including prototyping new features and integrating services\nwith LLMs. These proportions tick up slightly for two areas where we believe\nGo is a particularly well-suited tool: data pipelines for ML/AI systems (37%)\nand hosting API endpoints for ML/AI models (41%). In addition to these (likely\nearly) adopters, we found that about 1\u20444 of respondents want to use Go for\nthese types of uses, but are currently blocked by something. We\u2019ll return to\nthese blockers shortly, after exploring why respondents wanted to use Go for\nthese tasks in the first place.\n\n### Reasons for using Go with generative AI systems\n\nTo help us understand what benefits developers hope to derive from using Go in\ntheir AI/ML services, we asked developers why they feel Go is a good choice\nfor this domain. A clear majority (61%) of respondents mentioned one or more\nof Go\u2019s core principles or features, such as simplicity, runtime safety,\nconcurrency, or single-binary deployments. One third of respondents cited\nexisting familiarity with Go, including a desire to avoid introducing new\nlanguages if they can avoid it. Rounding out the most common responses were\nvarious challenges with Python (particularly for running production services)\nat 14%.\n\n> \u201cI think that the robustness, simplicity, performance and native binaries\n> that the language offers make it a far stronger choice for AI workloads.\u201d \u2014\n> Open-source Go developer at a large organization with up to 1 year of\n> experience\n\n> \u201cWe want to keep our tech stack as homogenous as possible across the\n> organization to make it easier for everybody to develop on all areas. Since\n> we are already writing all our backends in Go, it is of interest to us to be\n> able to write ML model deployments in Go and avoid having to rewrite parts\n> of the stack for logging, monitoring, etc... in a separate language [like]\n> Python.\u201d \u2014 Professional Go developer at a mid-sized organization with 5 \u2013 7\n> years of experience\n\n> \u201cGo is better for us at running API servers and background tasks on worker\n> pools. Go\u2019s lower resource usage has allowed us to grow without using more\n> resources. And we have found that Go projects are easier to maintain over\n> time both in code changes and when updating dependencies. We run the models\n> as a separate service written in Python and interact with them in Go.\u201d \u2014\n> Professional Go developer at a large organization with 5 \u2013 7 years of\n> experience\n\nIt appears that among Go developers who are interested in ML/AI, there is a\nshared sense that 1) Go is inherently a good language for this domain (for the\nreasons articulated above), and 2) there is reluctance to introduce a new\nlanguage once organizations have already invested in Go (this point reasonably\ngeneralizes to any language). Some respondents also expressed frustration with\nPython for reasons such as type safety, code quality, and challenging\ndeployments.\n\n### Challenges when using Go with GenAI systems\n\nRespondents were largely unified on what currently prevents them from using Go\nwith AI-powered services: the ecosystem is centered around Python, their\nfavorite libraries/frameworks are all in Python, getting started documentation\nassumes Python familiarity, and the data scientists or researchers exploring\nthese models are already familiar with Python.\n\n> \u201cPython just seems to have all the libraries. PyTorch for example is widely\n> used to run models. If there were frameworks in Go to run these models, we\u2019d\n> much rather be doing that.\u201d \u2014 Professional Go developer at a large\n> organization with 2 \u2013 4 years of experience\n\n> \u201cPython tools are substantially more mature and usable out of the box,\n> making them a significantly lower cost to implement.\u201d \u2014 Professional Go\n> developer at a small organization with 2 \u2013 4 years of experience\n\n> \u201c[The] Go world is missing many AI libraries. If I have a LLM PyTorch model,\n> I can\u2019t even serve it (or I\u2019m unaware how to do it). With Python it\u2019s\n> basically a few lines of code.\u201d \u2014 Professional Go developer at a small\n> organization with up to 1 year of experience\n\nThese findings triangulate well with our observation above that Go developers\nbelieve Go should be a great language for building production-ready AI\nservices: only 3% of respondents said that something specific to Go was\nblocking their path forward, and only 2% cited specific interoperability\nchallenges with Python. In other words, most blockers developers face could be\nresolved in the module and documentation ecosystem, rather than necessitating\ncore language or runtime changes.\n\nWe also asked survey participants whether they were already working with\nPython for GenAI, and if so, whether they\u2019d prefer to use Go. Respondents who\nsaid they\u2019d prefer to use Go rather than Python also received a follow-up\nabout what would enable them to use Go with GenAI systems.\n\nA solid majority (62%) of respondents reported already using Python to\nintegrate with generative AI models; of this group, 57% would rather use Go\ninstead. Given that our survey audience are all Go developers, we should\nexpect this to be an approximate upper bound on the proportion of overall\ndevelopers who are interested in moving from Python to Go for GenAI tasks,\ngiven the state of each ecosystem today.\n\nOf the respondents who are already using Python but would prefer to use Go,\nthe vast majority (92%) said that the availability of Go equivalents for\nPython libraries would enable them to integrate Go with GenAI systems.\nHowever, we should be cautious when interpreting this result; the open-text\nresponses and a separate set of contextual interviews with developers working\non GenAI services describe a Python-centric ecosystem around GenAI; it\u2019s not\nonly that Go lacks many libraries when compared with the Python ecosystem, but\nalso that the perceived level of investment into Go libraries is lower,\ndocumentation and examples are predominantly in Python, and the network of\nexperts working in this area are already comfortable with Python.\nExperimenting and building proofs-of-concept in Python is almost certain to\ncontinue, and the lack of Go variants of Python libraries (for example,\npandas) is only the first barrier developers would encounter when trying to\nport from Python to Go. Libraries and SDKs are necessary, but unlikely by\nthemselves to be sufficient, to build a robust Go ecosystem for production\nML/AI applications.\n\nFurther, contextual interviews with Go developers building AI-powered services\nsuggest that calling APIs from Go is not a major issue, particularly with\nhosted models such as GPT-4 or Gemini. Building, evaluating, and hosting\ncustom models is seen as challenging in Go (primarily due to the lack of\nframeworks and libraries that support this in Python), but interview\nparticipants distinguished between hobbyist use cases (e.g., playing around\nwith custom models at home) and business use cases. The hobbyist cases are\ndominated by Python for all of the reasons enumerated above, but the business\nuse cases are more focused around reliability, accuracy, and performance while\ncalling hosted models. This is an area where Go can shine without building a\nlarge ecosystem of ML/AI/data science libraries, though we expect developers\nwill still benefit from documentation, best practice guidance, and examples.\n\nBecause the field of GenAI is so novel, best practices are still being\nidentified and tested. Initial contextual interviews with developers have\nsuggested that one of their goals is to be prepared for a future in which\nGenAI becomes a competitive advantage; by making some investment in this area\nnow, they hope to moderate future risk. They\u2019re also still trying to\nunderstand what GenAI systems might be helpful for and what the return on\ninvestment (if any) may look like. Due to these unknowns, our early data\nsuggests that organizations (especially outside the tech industry) may be\nhesitant to make long-term commitments here, and will instead pursue a lean or\nscrappy approach until either a reliable use case with clear benefits emerges,\nor their industry peers begin to make large, public investments in this space.\n\n## Learning challenges\n\nIn order to improve the experience of learning Go, we wanted to hear from\ninexperienced Go developers, as well as those who might have already mastered\nthe basics on what they see as their biggest challenge to meeting their\nlearning goals. We also wanted to hear from developers who might primarily be\nfocused on helping others get started with Go rather than their own learning\ngoals, since they might have some insights on common challenges they see when\nonboarding developers.\n\nOnly 3% of respondents said that they were currently learning the basics of\nGo. This isn\u2019t too surprising, considering most of our survey respondents have\nat least a year of experience with Go. Meanwhile, 40% of respondents said that\nthey have already learned the basics but want to learn more advanced topics\nand another 40% said that they help other developers learn Go. Only 15% said\nthey didn\u2019t have any learning goals related to Go.\n\nWhen we looked at more finely grained time segments of Go experience, we found\nthat 30% of those who\u2019ve been using Go for less than three months say they\u2019re\nlearning the basics of Go, while about two-thirds of them say that they\u2019ve\nalready learned the basics. That\u2019s good evidence that someone can at least\nfeel like they\u2019ve learned the basics of Go in a short amount of time, but it\nalso means we don\u2019t have as much feedback from this group who are at the\nbeginning of their learning journey.\n\nTo determine what kinds of learning materials might be most needed in the\ncommunity, we asked what kind of learning content respondents preferred for\ntopics related to software development. They were able to select multiple\noptions so the numbers here exceed 100%. 87% of respondents said they\npreferred written content, which was by far the most preferred format. 52%\nsaid they preferred video content, and in particular this format was more\noften preferred by developers with less experience. This could indicate a\ngrowing desire for learning content in video format. The less experienced\ndemographic did not prefer written content any less than other groups,\nhowever. Providing both written and video formats together has been shown to\nimprove learning outcomes and helps developers with different learning\npreferences and abilities, which could increase the accessibility of learning\ncontent in the Go community.\n\nWe asked respondents who said they had a learning goal related to Go what\ntheir biggest challenge was to reaching their goal. This was intentionally\nleft broad enough that someone who was just getting started or who had already\nmastered the basics could respond to this question. We also wanted to give\nrespondents the opportunity to tell us about a wide range of challenges, not\njust topics they find difficult.\n\nOverwhelmingly, the most common challenge mentioned was a lack of time or\nother personal limitations such as focus or motivation to learn or (44%).\nAlthough we can\u2019t give respondents more time, we should be mindful when we\u2019re\nproducing learning materials or introducing changes in the ecosystem that\nusers may be operating under significant time constraints. There may also be\nopportunities for educators to produce resources that are digestible in\nsmaller portions or at a regular cadence to keep learners motivated.\n\nOther than time, the top challenge was learning new concepts, idioms or best\npractices that are unique to Go (11%). In particular, adapting to a statically\ntyped compiled language from Python or JavaScript and learning how to organize\nGo code can be particularly challenging. Respondents also asked for more\nexamples (6%), both in documentation and real world applications to learn\nfrom. Developers coming from a larger developer community expected to be able\nto find more existing solutions and examples.\n\n> \u201cMoving from a language like Python to a statically typed, compiled language\n> has been challenging, but Go itself hasn\u2019t been. I like to learn through\n> quick feedback, so Python\u2019s REPL was great for that. So now I need to focus\n> on really reading documentation and examples to be able to learn. Some of\n> the documentation for Go is quite sparse and could do with more examples.\u201d \u2014\n> Respondent with less than 3 years of experience with Go.\n\n> \u201cMy main challenge is the lack of example projects for enterprise-level\n> applications. How to organize a big Go project is something I would like to\n> have more examples as reference. I would like to refactor the current\n> project I am working [on] to a more modular/clean architecture style, and I\n> find it difficult in Go due to lack of examples / a more opinionated\n> \u2018folder/package\u2019 reference.\u201d \u2014 Respondent with 1\u20132 years of experience with\n> Go.\n\n> \u201cIt\u2019s a smaller ecosystem than I am used to so online searches don\u2019t yield\n> as many results to specific issues. The resources that are out there are\n> incredibly helpful and I usually am able to solve issues eventually, it just\n> takes a little longer.\"\u2014 Respondent with less than 3 months of experience\n> with Go.\n\nFor respondents whose primary learning goal was to help others get started\nwith Go, we asked what might make it easier for developers to get started with\nGo. We got a wide range of responses including documentation suggestions,\ncomments on difficult topics (e.g., using pointers or concurrency), as well as\nrequests for adding more familiar features from other languages. For\ncategories that made up less than 2% of responses, we lumped them into \u201cOther\u201d\nresponses. Interestingly, nobody mentioned \u201cmore time.\u201d We think this is\nbecause lack of time or motivation is most often a challenge when there isn\u2019t\nan immediate necessity to learn something new related to Go. For those helping\nothers get started with Go, there may be a business reason for doing so,\nmaking it easier to prioritize, and hence \u201clack of time\u201d is not as much of a\nchallenge.\n\nConsistent with the previous results, 16% of those who help others get started\nwith Go told us that new Go developers would benefit from having more\nrealistic examples or project-based exercises to learn from. They also saw the\nneed to help developers coming from other language ecosystems through\ncomparisons between them. Previous research tells us that experience with one\nprogramming language can interfere with learning a new one, especially when\nnew concepts and tooling are different from what developers are used to. There\nare existing resources that aim to address this issue (just try searching for\n\u201cGolang for [language] developers\u201d for examples), but it could be difficult\nfor new Go developers to search for concepts they don\u2019t have the vocabulary\nfor yet or these kinds of resources might not adequately address specific\ntasks. In the future we would like to learn more about how and when to present\nlanguage comparisons to facilitate learning new concepts.\n\nA related need that this group reported was more explanations behind Go\u2019s\nphilosophy and best practices. It could be the case that learning not only\nwhat makes Go different but also why would help new Go developers understand\nnew concepts or ways of doing tasks that might be different from their\nprevious experience.\n\n## Demographics\n\nWe ask similar demographic questions during each cycle of this survey so we\ncan understand how comparable the year-over-year results may be. For example,\nif a majority of respondents reported having less than one year of experience\nwith Go in one survey cycle, it\u2019d be very likely that any other differences in\nresults from prior cycles stem from this major demographic shift. We also use\nthese questions to provide comparisons between groups, such as satisfaction\naccording to how long respondents have been using Go.\n\nThis year we introduced some minor changes to how we ask about experience with\nGo to match the JetBrains developer survey. This allowed us to make\ncomparisons between our survey populations and facilitated data analysis.\n\nWe saw some differences in experience level depending on how developers\ndiscovered our survey. The population who responded to survey notifications in\nVS Code skewed toward less experience with Go; we suspect this a reflection of\nVS Code\u2019s popularity with new Go developers, who may not be ready to invest in\nan IDE license while they\u2019re still learning. With respect to years of Go\nexperience, the respondents randomly selected from GoLand are more similar to\nour self-selected population who found the survey through the Go Blog. Seeing\nconsistencies between samples such as these allows us to more confidently\ngeneralize findings to the rest of the community.\n\nIn addition to years of experience with Go, this year we also measured years\nof professional coding experience. We were surprised to find that 26% of\nrespondents have 16 or more years of professional coding experience. For\ncomparison, the JetBrains Developer Survey audience from 2023 had a majority\nof respondents with 3\u20135 years of professional experience. Having a more\nexperienced demographic could affect differences in responses. For example, we\nsaw significant differences in what kinds of learning content respondents with\ndifferent levels of experience preferred.\n\nWhen we looked at our different samples, the self-selected group was even more\nexperienced than the randomly selected groups, with 29% having 16 or more\nyears of professional experience. This suggests that our self-selected group\nis generally more experienced than our randomly selected groups and can help\nexplain some of the differences we see in this group.\n\nWe introduced another demographic question during this cycle on employment\nstatus to help us make comparisons with JetBrains\u2019 Developer Survey. We found\nthat 81% of respondents were fully employed, significantly more than 63% on\nthe JetBrains survey. We also found significantly fewer students in our\npopulation (4%) compared to 15% on the JetBrains survey. When we look at our\nindividual samples, we see a small but significant difference within our\nrespondents from VS Code, who are slightly less likely to be fully employed\nand slightly more likely to be students. This makes sense given that VS Code\nis free.\n\nSimilar to previous years, the most common use cases for Go were API/RPC\nservices (74%) and command line tools (63%). We\u2019ve heard that Go\u2019s built-in\nHTTP server and concurrency primitives, ease of cross-compilation, and single-\nbinary deployments make Go a good choice for these kinds of applications.\n\nWe also looked for differences based on respondents\u2019 level of experience with\nGo and organization size. More experienced Go developers reported building a\nwider variety of applications in Go. This trend was consistent across every\ncategory of app or service. We did not find any notable differences in what\nrespondents are building based on their organization size.\n\n## Firmographics\n\nWe heard from respondents at a variety of different organizations. About 27%\nworked at large organizations with 1,000 or more employees, 25% were from\nmidsize organizations of 100\u20131,000 employees, and 43% worked at smaller\norganizations with less than 100 employees. As in previous years, the most\ncommon industry people work in was technology (48%) while the second most\ncommon was financial services (13%) .\n\nThis is statistically unchanged from the past few Go Developer Surveys\u2014we\ncontinue to hear from people in different countries and in organizations of\ndifferent sizes and industries at consistent rates year after year.\n\n## Methodology\n\nPrior to 2021, we announced the survey primarily through the Go Blog, where it\nwas picked up on various social channels like Twitter, Reddit, or Hacker News.\nIn 2021 we introduced a new way to recruit respondents by using the VS Code Go\nplugin to randomly select users to be shown a prompt asking if they\u2019d like to\nparticipate in the survey. This created a random sample that we used to\ncompare the self-selected respondents from our traditional channels and helped\nidentify potential effects of self-selection bias. For this cycle, our friends\nat JetBrains generously provided us with an additional random sample by\nprompting a random subset of GoLand users to take the survey!\n\n64% of survey respondents \u201cself-selected\u201d to take the survey, meaning they\nfound it on the Go blog or other social Go channels. People who don\u2019t follow\nthese channels are less likely to learn about the survey from them, and in\nsome cases, they respond differently than people who do closely follow them.\nFor example, they might be new to the Go community and not yet aware of the Go\nblog. About 36% of respondents were randomly sampled, meaning they responded\nto the survey after seeing a prompt in VS Code (25%) or GoLand (11%). Over the\nperiod of January 23 \u2013 February 13, there was roughly a 10% chance that users\nwould have seen this prompt. By examining how the randomly sampled groups\ndiffer from the self-selected responses, as well as from each other, we\u2019re\nable to more confidently generalize findings to the larger community of Go\ndevelopers.\n\n### How to read these results\n\nThroughout this report we use charts of survey responses to provide supporting\nevidence for our findings. All of these charts use a similar format. The title\nis the exact question that survey respondents saw. Unless otherwise noted,\nquestions were multiple choice and participants could only select a single\nresponse choice; each chart\u2019s subtitle will tell the reader if the question\nallowed multiple response choices or was an open-ended text box instead of a\nmultiple choice question. For charts of open-ended text responses, a Go team\nmember read and manually categorized all of the responses. Many open-ended\nquestions elicited a wide variety of responses; to keep the chart sizes\nreasonable, we condensed them to a maximum of the top 10-12 themes, with\nadditional themes all grouped under \u201cOther\u201d. The percentage labels shown in\ncharts are rounded to the nearest integer (e.g., 1.4% and 0.8% will both be\ndisplayed as 1%), but the length of each bar and row ordering are based on the\nunrounded values.\n\nTo help readers understand the weight of evidence underlying each finding, we\nincluded error bars showing the 95% confidence interval for responses;\nnarrower bars indicate increased confidence. Sometimes two or more responses\nhave overlapping error bars, which means the relative order of those responses\nis not statistically meaningful (i.e., the responses are effectively tied).\nThe lower right of each chart shows the number of people whose responses are\nincluded in the chart, in the form \u201cn = [number of respondents]\u201d. In cases\nwhere we found interesting differences in responses between groups, (e.g.,\nyears of experience, organization size, or sample source) we showed a color-\ncoded breakdown of the differences.\n\n## Closing\n\nAnd that\u2019s it for our semi-annual Go Developer Survey. Many thanks to everyone\nwho shared their thoughts on Go and everyone who contributed to making this\nsurvey happen! It means the world to us and truly helps us improve Go. This\nyear we\u2019re also excited to announce the forthcoming release of this survey\u2019s\ndataset. We expect to share this anonymized data by the end of April, allowing\nanyone to slice and dice survey responses as needed to answer their own\nquestions about the Go ecosystem.\n\n\u2014 Alice and Todd (on behalf of the Go team at Google)\n\nPrevious article: More powerful Go execution traces Blog Index\n\nWhy Go Use Cases Case Studies\n\nGet Started Playground Tour Stack Overflow Help\n\nPackages Standard Library About Go Packages\n\nAbout Download Blog Issue Tracker Release Notes Brand Guidelines Code of\nConduct\n\nConnect Twitter GitHub Slack r/golang Meetup Golang Weekly\n\nOpens in new window.\n\n  * Copyright\n  * Terms of Service\n  * Privacy Policy\n  * Report an Issue\n\ngo.dev uses cookies from Google to deliver and enhance the quality of its\nservices and to analyze traffic. Learn more.\n\n", "frontpage": false}
