{"aid": "40016283", "title": "A Gentle Introduction to Risk Frameworks Beyond Forecasting", "url": "https://www.lesswrong.com/posts/ae3HecTe2uKscabPe/a-gentle-introduction-to-risk-frameworks-beyond-forecasting", "domain": "lesswrong.com", "votes": 1, "user": "rntn", "posted_at": "2024-04-12 18:42:28", "comments": 0, "source_title": "A Gentle Introduction to Risk Frameworks Beyond Forecasting \u2014 LessWrong", "source_text": "A Gentle Introduction to Risk Frameworks Beyond Forecasting \u2014 LessWrong\n\n##\n\nLESSWRONG\n\nLW\n\n# A Gentle Introduction to Risk Frameworks Beyond Forecasting\n\nby pendingsurvival\n\n33 min read11th Apr 20246 comments\n\n# 61\n\nForecasting & PredictionTechnological ForecastingWorld Modeling\nTechniquesExistential RiskFuturismCivilizational CollapseAIWorld Modeling\n\nFrontpage\n\nA Gentle Introduction to Risk Frameworks Beyond Forecasting\n\n11th Apr 2024\n\nIntroduction\n\n1\\. Disaster Risk Models\n\n1.1 The Determinants of Risk\n\n1.2 Exposure\n\n1.3 Pressure and Release\n\n1.4 The Disaster Cycle\n\n1.5 Complexity and Causation\n\n2 Normal Accidents and High-Reliability Organisations\n\n3 Sexy and Unsexy Risks\n\n4 Forecasting, Foresight, and Futures\n\n4.1 Forecasting\n\n4.2 Foresight\n\n4.3 Futures Studies\n\nConclusion\n\nBibliography\n\n6 comments\n\nThis was originally posted on Nathaniel's and Nuno's substacks (Pending\nSurvival and Forecasting Newsletter, respectively). Subscribe here and here!\n\nDiscussion is also occurring on the EA Forum here (couldn't link the posts\nproperly for technical reasons).\n\n## Introduction\n\nWhen the Effective Altruism, Bay Area rationality, judgemental forecasting,\nand prediction markets communities think about risk, they typically do so\nalong rather idiosyncratic and limited lines. These overlook relevant insights\nand practices from related expert communities, including the fields of\ndisaster risk reduction, safety science, risk analysis, science and technology\nstudies\u2014like the sociology of risk\u2014and futures studies.\n\nTo remedy this state of affairs, this document\u2014written by Nathaniel Cooke and\nedited by Nu\u00f1o Sempere\u2014(1) explains how disaster risks are conceptualised by\nrisk scholars, (2) outlines Normal Accident Theory and introduces the concept\nof high-reliability organisations, (3) summarises the differences between\n\u201csexy\u201d and \u201cunsexy\u201d global catastrophic risk (GCR) scenarios, and (4) provides\na quick overview of the methods professionals use to study the future. This is\nnot a comprehensive overview, but rather a gentle introduction.\n\nRisk has many different definitions, but this document works with the IPCC\ndefinition of the \u201cpotential for adverse consequences\u201d, where risk is a\nfunction of the magnitude of the consequences and the uncertainty around those\nconsequences, recognising a diversity of values and objectives.1 Scholars vary\non whether it is always possible to measure uncertainty, but there is a\ngeneral trend to assume that some uncertainty is so extreme as to be\npractically unquantifiable.2 Uncertainty here can reflect both objective\nlikelihood and subjective epistemic uncertainty.\n\n## 1\\. Disaster Risk Models\n\nA common saying in disaster risk circles is that \u201cthere is no such thing as a\nnatural disaster\u201d. As they see it, hazards may arise from nature, but an\nasteroid striking Earth is only able to threaten humanity because our\nsocieties currently rely on vulnerable systems that an asteroid could disrupt\nor destroy.3\n\nThis section will focus on how disaster risk reduction scholars break risks\ndown into their components, model the relationship between disasters and their\nroot causes, structure the process of risk reduction, and conceptualise the\nbiggest and most complex of the risks they study.\n\nThe field of global catastrophic risk, in which EAs and adjacent communities\nare particularly interested, has incorporated some insights from disaster risk\nreduction. For example, in past disasters, states have often justified\ninstituting authoritarian emergency powers in response to the perceived risks\nof mass panic, civil disorder and violence, or helplessness among the public.\nHowever, disaster risk scholarship has shown these fears to be baseless.4\u20139\nand this has been integrated into GCR research under the concept of the \u201cStomp\nReflex\u201d.\n\nHowever, other insights from disaster risk scholarship remain neglected, so we\nencourage readers to consider how they might apply within their cause area and\ninterests.\n\n### 1.1 The Determinants of Risk\n\nPopular media often refers to things like nuclear war, climate change, and\nlethal autonomous weapons systems as \u201crisks\u201d in themselves. This stands in\ncontrast with how risk scholars typically think about risk. To these scholars,\n\u201crisk\u201d refers to outcomes\u2014the \u201cpotential for adverse consequences\u201d\u2014rather than\nthe causes of those outcomes. So what would a disaster risk expert consider a\nnuclear explosion to be if not a risk, and why does it matter?\n\nThere is no universal standard model of disaster risk. However, the vast\nmajority highlight how it emerges from the interactions of several different\ndeterminants, specifically the following:\n\n  * Hazard: potentially harmful or destructive phenomena\n\n    * \u201cThe spark\u201d, \u201cwhat kills you\u201d\n  * Exposure: the inventory of elements (people, animals, ecosystems, structures, etc.) present in an area in which hazard events may occur\n\n    * \u201cBeing in the wrong place at the wrong time\u201d, \u201cthe reaction surface\u201d\n  * Vulnerability: propensities of the exposed elements to suffer adverse effects when impacted by hazards\n\n    * \u201cThe tinder\u201d, \u201chow you die\u201d\n    * The outcome of an event usually depends more on the vulnerabilities than the hazards\n  * Adaptive capacity: the strengths, attributes, knowledge, skills, and resources available to manage and reduce disaster risks\n\n    * People are not only vulnerable to disasters, they are also able to anticipate, cope with, resist, and recover from them\n  * Response: actions taken directly before, during, or immediately after the hazard event\n\n    * These can have positive or negative consequences, or both\n\nThe term \u201cthreat\u201d is sometimes used as a general catch-all term for a\n\u201cplausible and significant contributor to total risk\u201d.10\n\nA common point of confusion is that these are sometimes presented as an\nequation, for instance \u201cRisk = Hazard x Exposure x Vulnerability/Capacity x\nResponse\u201d. Perhaps we could more accurately say Risk = f( H, E, V, C, R).\nHowever, this is not meant to be an equation you plug numbers into, but rather\na concise way to illustrate the composition of risk. Basically, this is a\nframework intended to highlight the interplay of various factors and is not a\nperfectly coherent from-first-principles ontology; there are areas of overlap.\n\nImagine that someone gets shot. The hazard is the bullet, their\nvulnerabilities are the ways in which their body relies upon not having being\nshot (blood circulation, functioning organs, etc.), their capacities are their\nabilities to prepare, damage-control, and heal, the exposure is their presence\nin the path of a flying bullet, and the response is somebody performing first\naid (and/or trying to cut out the bullet and accidentally making the situation\nworse).\n\nSame goes for an earthquake (hazard), striking a village in an earthquake zone\n(exposure) containing poorly-constructed buildings and no earthquake warning\nsystem (vulnerabilities) but also disaster-experienced, skilled people\npossessing useful tools and resources (capacities) who eventually organise\nrelief operation (response).\n\nThings can get more complicated: the earthquake could cause a landslide from\nabove the village (compounding hazards), or the collapse of the village\u2019s only\ngranary could trigger a famine and social strife (cascading disaster), and so\non.11\n\nThe Hazard-Exposure-Vulnerability-Capacity-Response (HEVCR) model was\ndeveloped for disaster risk reduction, with a recent wave of interest from\nclimate change scholars. It may not perfectly translate to other risks, for\ninstance global catastrophic risks. It\u2019s a start, though.\n\nWhat this model excels at is illustrating how catastrophic events are the\nresult of an interplay of factors, with multiple possible points of\nintervention. In contrast, a critique of the approach of the Effective\nAltruism and its adjacent forecasting communities is that they tend to\nconsider risk more simplistically, where catastrophes are \u201cActs of God\u201d\ntriggered by cosmic dice-rolls causing individual hazards to strike an\nabstract, undifferentiated \u201chumanity\u201d.12\n\nIt is difficult to cite an absence of sophisticated reasoning, but a\nforthcoming post by Ximena Barker Huesca surveys key texts by EA megafauna\n(MacAskill, Bostrom, Ord, etc.), and shows that they tend to pay little\nattention to risk determinants beyond hazards, and offer simplistic or\nnonexistent accounts of the social aspects of risk and the interactions\nbetween threats. Elsewhere, EAG \u201carea of interest\u201d lists focus exclusively on\nhazard, and it is only over the last year or two that the EA community has\nstarted to conceptualise AGI development as a human process that can be slowed\n(or even stopped) rather than a cosmic inevitability. Members of the EA\ncommunity have been known to absorb Toby Ord\u2019s table of probabilities of\nexistential risks uncritically, rather than considering the actual threats and\nmechanisms involved. This results in people making complex life decisions\nbased on very, very informal, abstract, and simplistic \u201cestimates of doom\u201d.\n\nWhat the HEVCR framework helps us see is that catastrophes happen in specific\nplaces to specific people in specific ways at specific times, and hazardous\nphenomena only threaten humanity because human society is structured in ways\nthat put people at risk from them.13\n\nFor a discussion of how hazard, vulnerability, and exposure can be applied to\nexistential risk, see Liu, Lauta, and Maas\u2019s Governing Boring Apocalypses,14\nwhich includes a list of potential \u201cexistential vulnerabilities\u201d like the lack\nof effective governance institutions or increasing global socioeconomic\nhomogeneity.\n\nSo, how exactly could an asteroid strike or some other risk threaten\nhumanity\u2019s existence? What particular things would need to happen to get from\n\u201casteroid hits the Earth\u201d to \u201cthe last human dies\u201d? The disaster risk\nreduction field proposes we look at the specifics of the current state of the\nworld and go from there,\n\n### 1.2 Exposure\n\nPeople sometimes dismiss exposure when studying GCR, since \u201ceveryone is\nexposed by definition\u201d. This isn\u2019t always true, and even when it is, it still\npoints us towards interesting questions.\n\nConsidering exposure can highlight the benefits of insulating people from\ncertain (categories of) hazards, for instance with island refuges.15,16\n\nIf everyone really were exposed to a given hazard (e.g. to an actively\nmalevolent superintelligent AGI), it simply raises the question of how the\nhazard was born. We weren\u2019t exposed before, so what happened? Was the creation\nof the AGI inevitable? What were the steps that led us from wholly unexposed\nto wholly exposed, and what were the points of intervention along the way?\nThinking in these terms may help us avoid falling into oversimplification, and\nassist us in finding leverage points.\n\n### 1.3 Pressure and Release\n\nThe Pressure and Release model (also known as \u201cPAR\u201d and the \u201ccrunch\u201d model)\nwas introduced to counter some deficiencies in previous models of risk.17\nPrevious approaches had focused on the physical aspects of hazards, neglecting\nthe ways in which they can be the consequences of failed or mismanaged\ndevelopment, thus affecting marginalised groups disproportionately.13\n\nAccording to PAR, vulnerability progresses through three stages:\n\n  * Root causes: interrelated large-scale structural forces\u2014economic systems, political processes, ideologies, and so on\u2014that shape culture, institutions, and the distribution of resources\n\n    * Often invisible or taken for granted as a result of being spatially distant, comparatively historically remote (e.g. colonisation), and/or buried in cultural assumptions and belief systems\n  * Dynamic pressures: more spatiotemporally specific material and ideological conditions that result (in large part) from root causes, and in turn generate unsafe conditions\n  * Unsafe conditions: the particular ways in which vulnerability manifests at the point of disaster\n\n    * Naturally these conditions also exist for some time before and often after the disaster event itself: poverty and marginalisation mean that, even before a hazard strikes, many people spend their daily lives in a \u201cdisaster state\u201d\n\nFig. 1: The Pressure and Release Model. Wisner et al., 2003.13\n\nThe model was developed to explain \u201cnatural\u201d disasters rather than\ntechnological disasters, global catastrophes, or intentional attacks. While\nthe specifics sometimes need adapting (and in some cases already have been,\nfor instance for global health emergencies),18 the broad thrust of \u201cdisasters\ndon\u2019t come from nowhere, address the root causes!\u201d remains vital.\n\n### 1.4 The Disaster Cycle\n\nThe disaster cycle breaks disasters down into separate phases to structure\nresilience efforts and emphasise how risk reduction should be treated as an\nongoing integrated process, rather than isolated projects and headline-\ngrabbing relief efforts.\n\nThe four phases of disaster are as follows:\n\n  * Mitigation (sometimes known as Prevention): actions taken to prevent or reduce the likelihood, impact, and/or consequences of disasters before they happen\n\n    * Assess the level of risk and survey its determinants, reduce vulnerability and exposure, minimise the probabilities and magnitudes of hazards\n  * Preparedness: actions taken to develop the knowledge and capacities necessary to effectively foresee, respond to, and recover from disasters\n\n    * Create and test plans and procedures, spread awareness, train people, stockpile and distribute resources\n  * Response: actions taken directly before, during, or immediately after the risk event\n\n    * Save lives, stabilise the situation, and reduce the potential for further harm\n    * Depends on the quality of the preparedness: \u201cpreparedness is the best response\u201d\n  * Recovery: actions taken to return affected communities to a state of normalcy\n\n    * There is currently a movement to \u201cbuild back better\u201d or \u201cbounce forward\u201d rather than \u201cbounce back\u201d, i.e. to put communities in a better position than they started rather than aim to restore the (vulnerable) status quo\n\nFig. 2: The Disaster Cycle. AkitaBox, 2023.\n\nWhile treated as \u201ccanon\u201d, the disaster cycle has some limitations: the stages\nare not always separate or temporally distinct (especially mitigation and\npreparedness) and is taken by some to suggest that disasters are necessary or\ninevitable \u201cparts of the cycle\u201d.^[1]\n\n### 1.5 Complexity and Causation\n\nThe HEVCR model points our attention towards the many factors involved in a\ngiven catastrophic scenario, and the importance of their interrelations.\n\nImagine that worsening climate change, economic inequality, and social\ndivision magnified by AI-powered misinformation campaigns motivate a group of\nomnicidal eco-terrorists to steal the information and technology necessary to\nengineer multiple highly virulent pathogens and release them at strategically-\nchosen airports across the world. This eventually wipes out humanity in large\npart due to dysfunctional governments failing to adequately respond in time.\n\nWas that \u201cextinction from synthetic biology\u201d?^[2]\n\nThus, many GCR researchers argue that the question is not \u201cIs X an extinction\nrisk?\u201d but \u201cHow (much) could X contribute to the overall level of extinction\nrisk?\u201d12\n\nThis is further complicated by the key issue of \u201cglobal systemic risk\u201d.19 By\nthis we mean that we live in a highly interdependent world; an exceptionally\ncomplex system blanketed with intricate networks of flowing food, energy,\npeople, information, trade, money, and culture. Global systemic risk is\npremised on the idea that this creates great efficiency, but the\ninterconnectedness and complexity it entails creates systemic fragility and\ninstability. Local events (e.g. a big boat gets stuck in the Suez Canal) can\nhave global consequences. Sudden changes (sometimes catastrophic ones) can\noccur purely as a result of internal system behaviour; no external \u201cspark\u201d is\nneeded.\n\nComplex system characteristics of particular interest are:\n\n  * Emergent behaviour: the system has properties and behaviours that its parts do not have on their own, and which emerge only when those parts interact as a whole.\n\n    * Examples can include language, material exchange, religion, or even society itself if humans are considered the parts, and e.g. World War II if you consider nations.\n    * A particularly famous example is crowd behaviour\n  * Feedback loops: where outputs of the system feed back into the system as new inputs.\n\n    * These can be:\n\n      * Positive (amplifying/reinforcing), e.g. decreasing demand eliminates jobs, which reduces demand, which eliminates jobs...\n      * Negative (dampening/stabilising), e.g. thermostats, various forms of homeostasis in the body^[3]\n  * Nonlinear responses: where a change in the output of the system is not proportional to the change in the input.\n\n    * A Tunisian street vendor named Mohamed Bouazizi sets himself on fire to protest police harassment, triggering the Arab Spring\n\nAs a question for the reader: how well do the models described in earlier\nsections apply in light of these dynamics? How easily can risks and\ncatastrophes be broken up into separate factors or stages, and what is gained\nor lost by doing so?\n\nFor those interested, related concepts to global systemic risk include\nglobally networked risks,20 anthropocene risk,21 femtorisks,22 synchronous\nfailure,23 critical transitions,24 and polycrisis.25\n\n## 2 Normal Accidents and High-Reliability Organisations\n\nA mainstay of the safety science and science and technology studies\nliteratures, Charles Perrow\u2019s Normal Accident Theory holds that it is\nreductive and unhelpful to explain major accidents as results of individual\nfailures like operator error^[4] or equipment malfunction.26\n\nInstead, many accidents (known as \u201csystem accidents\u201d) are seen as the\ninevitable structural consequences of highly complex and/or tightly coupled\nsystems, where one malfunction can trigger, conceal, or impede the repair of\nanother. The vast number of possible combinations between parts creates novel\nfailure combinations and chain reactions that make major accidents difficult\nor even impossible to anticipate. These accidents are considered \u201cnormal\u201d not\nbecause they are frequent or expected, but because they are inevitable\nfeatures of certain types of organisation.\n\nFor Perrow, an organisation has high interactive complexity if one part is\nable to affect many others. Complex organisations typically have many\ncomponents and control parameters, and exhibit nonlinear responses and\nfeedback loops. This gives rise to unfamiliar or unexpected sequences of\ninteractions that are either imperceptible or incomprehensible to their\noperators.\n\nTwo parts of the system are tightly coupled if there are close and rapid\nassociations between changes in one part and changes in another with little to\nno slack, buffer, or \u201cgive\u201d between them. If many components are tightly\ncoupled, disturbances propagate quickly across the system.\n\nThere is a wide range of classic safety features used by safety engineers and\nresilience professionals, for instance redundancies, safety barriers, and\nimproved operator training.\n\nWhile these are generally valuable, Perrow suggests a number of strategies\nspecific to the risk posed by normal accidents:\n\n  * Decrease interactive complexity\n\n    * Reduce opportunities for one malfunction to interact with another\n  * Increase legibility\n\n    * Improve the ability of operators to understand the dynamics of the system they control\n  * Loosen tight couplings\n\n    * Add buffers and lag time to improve the likelihood of a successful response to a malfunction\n  * Ensure that where a fast coupling exists, the systems designed to manage it can react at a similar speed to any potential unfolding incident\n  * Decentralise interactively complex systems\n\n    * Allow operators at the point of component/subsystem failures the discretion to respond to small failures independently and prevent them from propagating, rather than relying on instructions from senior managers who may lack the speed, information, specialist expertise, or contextual knowledge required\n    * Sometimes the manual must be disregarded in favour of local conditions or common sense\n  * Centralise tightly coupled systems\n\n    * Allow for rapid, reactive control\n\nPerrow is highly pessimistic of our ability to reduce normal accident risk in\nsystems that are both highly complex and tightly coupled, and recommends they\nshould be abandoned altogether. Other scholars criticise this as overly\nfatalistic.\n\nThere are some ways in which safety features can counterintuitively increase\ndanger. For instance, adding safety features increases the complexity of the\noverall system, which adds new possible unforeseen failure modes. They can\nalso encourage worker complacency, and sometimes embolden managers to operate\nat a faster pace with a more relaxed attitude to safety practices.\n\nIncidentally, this latter phenomenon is closely related to the economic\nconcept of moral hazard, where an actor is incentivised to adopt riskier\nbehaviour after acquiring some kind of protection. One may be more careless\nwith their phone if they know it is insured.\n\nAn outgrowth of Normal Accident Theory is the study of high reliability\norganisations. High reliability organisations such as air traffic control\nsystems and nuclear power plants tend to share a number of characteristics,\nsuch as deference to expertise, a strong safety culture that emphasises\naccountability and responsibility, and a preoccupation with proactively\nidentifying and addressing issues combined with a commitment to continually\nlearning and improving.27\u201333 There is an extensive literature on the topic,\nwhich may prove of use to those involved in GCR-relevant organisations where\naccidents could potentially be calamitous, for example nuclear weapons\nfacilities, BSL-4 labs, and AI companies.^[5]\n\nOne key takeaway that Normal Accident Theory shares with the rest of the\nsafety and resilience literature is that there is almost always a tradeoff\nbetween short-term efficiency and profitability, and long-term reliability and\nsafety. Short time-horizons combined with bad incentives and power structures\nlead to the latter frequently being hollowed out in service to the former.\n\nDespite its massive impact on the theory and practice of safety, Normal\nAccident Theory is not without its criticisms. Notably, it has been accused of\nbeing vague, hard to empirically measure or test, and difficult to practically\nimplement. Its position that major accidents are inevitable in a sufficiently\nlarge and complex organisation may lead to fatalism and thus missed\nopportunities.\n\nDespite this, Normal Accident\u2019s theory has reached beyond its home domains of\nelectricity generation, chemical processing, and so on, to more GCR-relevant\ndomains like artificial intelligence.34\u201338\n\n## 3 Sexy and Unsexy Risks\n\nKarin Kuhlemann argues that too much catastrophic risk scholarship is focused\non \u201csexy\u201d risks like asteroid strikes and hostile AI takeovers, rather than\n\u201cunsexy\u201d risks like climate change.39 In her view, this is due to a mixture of\ncomplexity, cognitive biases, and overconfident and over-certain failures of\nimagination.\n\nThe below simply summarises her argument; don\u2019t be confused if some of it\nseems incompatible with the HEVCR model outlined in section 1.1. Note that\nKuhleman uses the term \u201crisk\u201d to refer to a very heterogeneous group of\nphenomena; perhaps a more fitting term would have been \u201cthreats\u201d.\n\nIn any case, per Kuhleman, sexy risks are characterised by:\n\n  1. Epistemic neatness\n  2. Sudden onset\n  3. Technology is involved\n\nThey are easily categorisable, with clear disciplinary homes\n\n  * Hostile AGI takeover \u2192 computer science, neuroscience, and philosophy\n  * Meteor and asteroid strikes \u2192 astronomy\n  * Pandemic \u2192 epidemiology, pathology, medicine\n\nThey crystallise in a few hours, or maybe a few years.\n\n\u201cAll hell breaks loose\u201d.\n\nThey include flattering ideas about human technological capabilities, where\nadvanced (future) technologies are the problem\u2019s cause, its only solution, or\nboth.\n\nHumanity receiving Promethean punishment for uncovering things Man Was Simply\nNot Meant To Know and everyone-is-saved technofixes are different sides of the\nsame movie-plot coin.\n\nUnsexy risks, by contrast, are characterised by:\n\n  1. Epistemic messiness\n  2. Gradual build-up\n  3. Behavioural and attitudinal drivers\n\nThey are necessarily transdisciplinary, and cannot simply be governed by a\npre-existing institution that deals with \u201cthis sort of thing\u201d.\n\nDifficult to study, communicate, and fund.\n\nThey are often based on accumulated and latent damage to collective goods.\n\nBaselines shift as people gradually, often subconsciously, alter the\ndefinition of \u201cnormal\u201d.\n\nThey are driven primarily by human behaviour, and may require radical social\nchange to prevent or even just mitigate.\n\nKuhlemann argues that human overpopulation is the best example of an \u201cunsexy\u201d\nglobal catastrophic risk, but this is not taken seriously by the vast majority\nof global catastrophic risk scholars.\n\n## 4 Forecasting, Foresight, and Futures\n\n> The global consequences of nuclear war is not a subject amenable to\n> experimental verification \u2014 or at least, not more than once.\n\nCarl Sagan\n\n> One thing a person cannot do, no matter how rigorous his analysis or heroic\n> his imagination, is to draw up a list of things that would never occur to\n> him.\n\nThomas Schelling\n\nTrying to say useful things about events that have not yet happened and may\nnever happen is very difficult. This is especially true if the events in\nquestion are unprecedented, poorly-defined, and/or low-probability yet high\nimpact, when they exist in domains of high complexity and/or deep\nuncertainty,2 and when they are subject to significant amounts of expert\ndisagreement.40,41 Alas, this is where we find ourselves.\n\nA notable type of problem in this domain is the Black Swan, an event that is\nextremely impactful, yet so (apparently) unlikely that it lies wholly beyond\nthe realm of normal expectations. They are thus impossible to predict and\nexplainable only in hindsight.42 Commonly cited examples include 9/11, World\nWar I, and the 2008 financial crisis.\n\nLuckily, there is a field called \u201cFutures Studies\u201d that can help us out. There\nare many ways of cutting it up, but to make things easy we\u2019re just going to\nsay:\n\n  * Futures Studies: the systematic study of possible, probable, and preferable futures, including the worldviews and myths that underlie them\n  * Foresight methods: quantitative and qualitative tools for exploring the shape of possible futures\n\n    * (This is a subsection of Futures Studies)\n  * Forecasting methods: quantitative tools for estimating the future values of variables and/or the likelihoods of future events\n\n    * i.e. including questions like \u201cWhat will the average price of oil be next quarter?\u201d and \u201cWhat is the probability that X will win the 2028 US Presidential election?\u201d\n    * (This is a class of foresight methods)\n\nWe do not mean to set up any artificial conflict between forecasting and\nqualitative foresight methods: they complement each other, and there is broad\nagreement between them on a number of issues. For instance, foresight and\nforecasting professionals generally agree that a large, diverse group of\npeople sharing and processing lots of different sources of information is\nbetter than a single person or small homogenous group, and that producing\nquality work becomes dramatically harder as you extend your time horizon.\n\n### 4.1 Forecasting\n\nQuantitative forecasts are useful for several purposes, especially when\ndealing with comparisons. How should we prioritise different courses of\naction? What do we do about risk-risk trade-offs, that is, when a given action\ncould decrease risk from one source while increasing risk from another?^[6]\n\nHowever, they can also cause problems when produced by unrigorous or\ncontroversial means. For instance, some GCR scholars consider Toby Ord\u2019s\nsubjective judgements of existential risk from different sources44 (see below)\nto be useful formalisations of his views, valuable as order-of-magnitude\nestimates. Others are very critical of this approach, contending that Ord\u2019s\nnumbers are mostly mere guesses that are presented as far more rigorous than\nthey actually are, potentially giving Ord\u2019s personal biases a scientific\nsheen.^[7] The debate is ongoing.\n\nFig. 3. Toby Ord\u2019s subjective probability estimates. Ord, 2020.44\n\nNumbers provide an air of scientific rigour that is extremely compelling to\nthe lay public,45 and anchoring bias means that people\u2019s judgements can be\ninfluenced by a reference point (often the first one they see) regardless of\nits relevance and/or quality.\n\nAll this means is that numerical estimates are excellent for some purposes,\nbut must be generated and communicated responsibly.\n\nExamples of forecasting methods include:\n\n  * Toy models: deliberately simplistic mathematical models, e.g. assuming that pandemics occur according to a certain statistical distribution46\n  * Fault trees: branching a logic tree backwards from overall system failure, representing the proximate causes of failure as different nodes. Add nodes representing the conditions of those nodes failing, and then the conditions of those nodes failing, and so on. If possible, assign a probability of failure to each node, and sum/multiply to get the overall probability\n\n    * See, for example, the simple fault tree for inadvertent nuclear war between the US and Russia, below47\n  * Individual subjective opinion: one person\u2019s best guess\n  * Superforecasting: \u201csuperforecasters\u201d are people, often with certain traits (intelligence, cognitive flexibility/open-mindedness, political knowledge...) and some training, who combine their judgements in structured ways48\n\n    * These superforecasters are said to frequently outperform domain-experts in forecasting competitions, though the extent to which these are fair comparisons is debated, and in any case the literature leaves much to desired49\n\nFig. 4. Simple fault tree of inadvertent nuclear war pathways and conditions.\nBarrett et al., 2013.47\n\nVarious methods work better or worse when applied to/in different\nproblems/contexts. Superforecasting, for instance, has been extremely\nsuccessful at predicting the outcomes of binary propositions over short\ntimespans (things like \u201cBefore 1 May 2024, will Russia or Belarus detonate a\nnuclear device outside of Russian and Belarusian territory or airspace?\u201d), but\nshows comparatively less promise on less well-defined questions resolving more\nthan a few years in the future (\u201cIf a global catastrophe occurs, how likely is\nit that it will be due to either human-made climate change or\ngeoengineering?\u201d).50\n\nBeard et al outline the forecasting methods that have been used in GCR thus\nfar, and evaluates their rigour, how well they handle uncertainty, their\naccessibility, and their utility.51\n\nIn a response to this paper, Baum notes a negative correlation between the\nrigour of a method and its accessibility.52\n\nFig. 5. Rigour vs accessibility of each method as rated by Beard et al. Baum,\n2020.52\n\nThis is pretty unsurprising, and squares with Beard et al\u2019s observation that\nthe least rigorous methods are also the most popular and the most frequently\nreferenced. Virtually all quantitative existential risk estimates referenced\nin the popular press (and a surprisingly high proportion of those cited in the\nresearch and policy spheres!) are point estimates from individuals presented\nwith little to no methodology. The most notable examples here are Martin Rees\u2019\n1\u2044253 and Toby Ord\u2019s 1\u20446.44\n\nBeard et al conclude by arguing that (1) forecasting methods are valuable\ntools that form a key part of existential risk research, but (2) the mere fact\nthat a particular probability estimate has been produced does not mean it is\nworthy of consideration or reproduction, and (3) that scholars should be more\ntransparent about how their estimates are generated.\n\n### 4.2 Foresight\n\nForesight is a broader category, incorporating qualitative tools which often \u2013\nbut not always \u2013 eschew firm predictions in favour of generating information\nand insight about the broad contours of possible futures.50 This exploratory\napproach makes them particularly useful for identifying Black Swans,\nespecially when intentionally modified to do so.54\n\nThe goal is usually not to create fine-tuned predictions and optimise\naccordingly, but to create robust and flexible plans that allow organisations\nto adapt in response to a changing and uncertain future. This overlaps with\ndecision theories developed for problems with similar characteristics to GCR,\nfor instance decision-making under deep uncertainty (DMDU).2\n\nThere is a rough split between technocratic foresight methods, and\nparticipatory or critical ones. Examples of the former include:\n\n  * Horizon scans: a wide class of techniques for the early detection and assessment of emerging issues\n\n    * These are often based on structured expert elicitation processes, e.g. the Delphi method55 or the IDEA protocol,56 where experts repeatedly deliberate and vote on the likelihood and magnitude of the impacts of various issues by a certain date\n  * Causal loop diagrams: map out the various elements of the system and how they affect each other, sometimes performing computational simulations to explore different knock-on effects\n  * Scenario plans: participants collectively generate multiple (usually 3-5) widely differing descriptions of plausible states of a particular system (the world, the Singaporean tech sector...) at a given time, with the scenarios collectively forming an envelope of plausible futures\n  * Wargames: serious games and role-play exercises, used for both training and analysis\n\nFig. 6. Causal loop diagram of climate change, food insecurity, and societal\ncollapse. Richards et al., 2021.57\n\nWhile valuable, these tools have been critiqued for restricting the task of\nexploring and deciding the future to a tiny homogenous group of privileged\nexperts, and in consequence producing outputs that reflect the preferences and\nbiases of that group.58\n\nIn contrast, participatory foresight techniques place a greater emphasis on\ndemocratic legitimacy and the meaningful involvement of citizens, especially\nthose from otherwise marginalised groups. Examples include:^[8]\n\n  * Citizens\u2019 assemblies: randomly-chosen stakeholders participate in facilitated discussions or exercises designed to help and encourage them think about the future, often in order to generate policy recommendations\n\n    * Some fascinating examples are summarised here\n  * Games: games or role-plays in which citizens experience and experiment with the long-term impacts of near-term decisions\n  * Immersive experiences: interactive simulations, exhibitions, or theatre that make possible futures feel \u201creal\u201d and allow participants to explore them in an intuitive and embodied way\n\nFor an overview of more technocratic methods see the UK government\u2019s Futures\nToolkit;59 for more participatory methods see Nesta\u2019s Our Futures report.60\nSome approaches, like speculative fiction, do not fit easily into either\ncategory.\n\nAs with forecasting, foresight methods each have different context/question-\ndependent strengths and weaknesses. They are rarely used in isolation, and\nusers are more confident when a variety of methods converge on similar\nresults.\n\nMany foresight methods share similar disadvantages. For example, the lack of\nconcrete predictions makes falsifiability and validation difficult, which\nmeans that there is a huge range of foresight tools out there, yet few ways of\neasily distinguishing the good from the bad ones. The rigorous evaluation of\nthe effectiveness of various foresight tools is a major research gap.^[9]\nThere have been a few studies on Delphi-based horizon-scanning and the IDEA\nprotocol, which have yielded positive results.54\n\nIn addition, the rejection of prediction and optimisation in favour of\nexploration and adaptation can lead to missed opportunities, especially when\nin domains that actually are fairly stable and/or predictable. Where behaviour\nis well-characterised and unexpected events are likely to be rare and low-\nimpact, for instance industrial production or energy demand in stable regions,\nthen optimisation makes the most sense. In any case, optimality vs robustness\nis a spectrum; there is almost always a role for both.\n\nFinally, those who use foresight tools usually do so in order to better\nnavigate the future, which means combatting or avoiding the very problems they\nforesaw. Thus, people may make their foresight results less accurate by using\nthem. A few examples of similar problems are catalogued here. The future is\nprofoundly affected by how people understand it in the present.\n\n### 4.3 Futures Studies\n\nThe field of futures studies incorporates far more than the above methods, and\nso this review has been, by necessity, limited. For instance, futures studies\nincludes huge amounts of discourse on the politics of the future and how\npredictions and statements made about possible futures are used as tools (and\nweapons) in the present.^[10] Elsewhere, scholars consider how we should\ndecide on the desirability of various kinds of futures, and how those\ndecisions are affected by structures and inequalities of power.\n\nA relatively well-defined field is the study of sociotechnical imaginaries,\n\u201ccollectively held, institutionally stabilised, and publicly performed visions\nof desirable futures, animated by shared understandings of forms of social\nlife and social order attainable through, and supportive of, advances in\nscience and technology\u201d.61 Focused study of the sociotechnical imaginaries\nsurrounding GCR is surprisingly neglected, but some work has been done on the\nnarratives surrounding AI, geoengineering, and space colonisation.62\u201364\n\nAnother relevant example is utopian studies, which is more or less what it\nsays on the tin. Utopian studies scholars have taken a significant interest in\nExistential Risk Studies, as well as Longtermism and the extropian\ntranshumanism and Californian Ideology that it emerged from.65\u201370\n\nGiven that modern GCR research is so profoundly influenced by Nick Bostrom\u2019s\nvision of an interstellar transhumanist utopia\u2014a utopian imaginary with as\nlarge a potential for misuse for power and profit as any other\u2014it may indeed\nbe advisable to turn the microscope on ourselves.\n\nOn a related note, there is a long tradition of powerful actors (often with\nvast conflicts of interest) telling the public that we have no choice but to\nbuild catastrophically dangerous technologies, either because somebody else\nwill or because the benefits are too big to turn down. These technological\nprophecies have been influential in fields from nuclear weapons to climate\nchange to AI safety, and act to shift accountability from those taking risky\ndecisions while circumventing the democratic process. This rhetoric is usually\nunfalsifiable, and the historical track-record of its predictions is\nunimpressive.71\n\nSelf-fulfilling future visions are not restricted to prophecies: fantasies are\njust as\u2014if not more\u2014influential. Science fiction has a vast track record of\ninforming and shaping future technological and design decisions, from Star\nTrek\u2019s Personal Access Display Devices to how Neuromancer\u2019s concepts of\n\u201ccyberspace\u201d and \u201cconsole cowboys\u201d shaped the development of the internet,\nhacker culture, and digital technology more broadly.\n\nAlong those lines, it is notable that Sam Altman has commented that \u201celiezer\n[yudkowsky] has IMO done more to accelerate AGI than anyone else.\u201d Those\nworking in AI Safety (or other fields) may wish to dedicate significantly more\nattention to the ways in which they may increase (or have already increased)\nthe level of risk. Assuming the creation of a dangerous technology to be\ninevitable might just make it so.\n\n## Conclusion\n\nWhen funders and academics have tried to make sense of global catastrophic\nrisks, they have occasionally used judgmental forecasting of the Tetlock\nvariety, but they also have relied on hedgehog-style thinking and stylized\nmathematical models. These approaches can be valuable, but they are not the\nwhole story. Fields like disaster risk reduction, science and technology\nstudies, safety science, risk analysis, and futures studies have been studying\nproblems remarkably similar to ours for a long time. Hopefully this piece has\ngiven readers some notion of the value to be found in these fields. Members of\nthese fields often show considerable interest in GCR when it is mentioned to\nthem, and we have an opportunity to build networks in valuable and neglected\nareas.\n\nWe have surveyed several promising routes for GCR theory and practice over the\ncourse of this essay. Disaster risk can be productively analysed by breaking\nit up into hazard, exposure, vulnerability, adaptive capacity and response.\nCurrent GCR work places a huge emphasis on hazard, neglects the societal\nvulnerabilities that put us at risk from the hazards in the first place, and\neven further neglects the underlying root causes that generate vulnerabilities\n(and in our case, technological hazards as well).\n\nDisasters often occur in cycles, with work clustering into mitigation,\npreparedness, response, and recovery, but this can be complicated given the\ncomplexity and interconnectivity of the world as a system. From this\nperspective, most mainstream GCR research is excessively reductive, often\nignoring complicated causal networks and the behavioural characteristics of\ncomplex systems. The study of global systemic risk and related phenomena is of\nextreme relevance to GCR work, and we would do well to add it to our\nconceptual toolkit.\n\nTechnological systems are often complex and tightly coupled, and thus fall\nvictim to \u201cnormal accidents\u201d. Many interconnected components rapidly impacting\none another breed unexpected\u2014and sometimes calamitous\u2014interactions, and\ntraditional safety features can sometimes counterintuitively increase risk,\nfor instance through the creation of moral hazards. High-reliability\norganisations, with their preoccupation with proactive continuous improvement\nand a culture of accountability, may prove to be a promising route for\nreducing risks posed by some organisations in hazardous sectors.\n\nEvaluations of different sources of GCR may be biased towards \u201csexy\u201d risks,\nwhich are epistemically neat, occur \u201cwith a bang\u201d, and involve futuristic\ntechnologies, at the expense of \u201cunsexy\u201d risks, which are epistemically messy,\nbuild up gradually, and are primarily driven by social factors.\n\nWhen attempting to understand the course of the future, quantitative forecasts\nare a useful tool, but they represent only a narrow subset of the concepts\ndeveloped to systematically study futures. At their best, quantitative\nforecasts can help us rigorously make decisions and allocate resources, but\nthese efforts can be hamstrung by an uncritical reliance on accessible but\nunrigorous techniques like individual subjective opinions.\n\nForecasting techniques also appear substantially less well-adapted for\nquestions involving poorly-defined and/or low-probability high-impact events\n(such as \u201cBlack Swans\u201d), which exist in domains of high complexity or deep\nuncertainty and subject to significant amounts of expert disagreement.\nQualitative foresight techniques may be able to help in this regard, focusing\nas they do on exploring the shape of possible futures and developing plans\nthat are robust to a wide variety of outcomes. The best approach will likely\ninvolve a combination of foresight and forecasting techniques, combining\ndifferent information streams to create plans with a balance of efficiency to\nrobustness that is appropriate to the situation at hand.\n\nThere is a large body of work that can help us contextualise the\nsociotechnical imaginaries and utopian philosophies that unconsciously shape\npeoples\u2019 perceptions and decisions. These concepts can be productively applied\nto classic global catastrophic threats, as well as the field itself. GCR\nresearch is new in some ways, but painfully unoriginal in others, and self-\nfulfilling prophecies and fantasies that may cause people to inadvertently\ncreate the problems they seek to solve is a well-known and dangerous pattern.\n\nThis post has been long; it is also just the tip of the iceberg.\n\nOne term that has been conspicuous by its absence is \u201cresilience\u201d: there is an\nextensive body of research on \u201cresilience theory\u201d that focuses on how to\nimprove the robustness and adaptability of systems subjected to shocks. It has\nbeen excluded because there is already an introduction to resilience for GCR\nresearchers and practitioners in the form of \u201cWeathering the Storm: Societal\nResilience to Existential Catastrophes\u201d available here.\n\nHopefully, after becoming more acquainted with these concepts, people in EA,\nforecasting and adjacent communities will be able to incorporate them into\ntheir decision-making methods, and critically and productively engage with the\nrelevant fields rather than dismissing them out of hand.\n\nEffective Altruists (and readers in general) interested in these topics may\nwish to look at other related EA Forum posts, for instance:\n\n  * Doing EA Better (specifically section two: \u201cExpertise and Rigour\u201d)\n  * Beyond Simple Existential Risk: Survival in a Complex Interconnected World\n  * How to think about an uncertain future: lessons from other sectors & mistakes of longtermist EAs\n  * A practical guide to long-term planning \u2013 and suggestions for longtermism\n  * Foresight for Governments: Singapore\u2019s Long-termist Policy Tools & Lessons\n  * Foresight for AGI Safety Strategy\n  * Statement on Pluralism in Existential Risk Studies\n  * Model-Based Policy Analysis under Deep Uncertainty\n  * ...and a forthcoming post by Ximena Barker Huesca evaluating how risk is conceptualised in GCR and how disaster risk reduction frameworks may be applied to GCR mitigation\n\n## Bibliography\n\n1\\. Reisinger, A. et al. The Concept of Risk in the IPCC Sixth Assessment\nReport. (2020).\n\n2\\. Decision Making under Deep Uncertainty: From Theory to Practice.\n(Springer, Cham, 2019).\n\n3\\. Kelman, I. Disaster by Choice: How Our Actions Turn Natural Hazards into\nCatastrophes. (Oxford University Press, 2020).\n\n4\\. Alexander, D. E. Misconception as a Barrier to Teaching about Disasters.\nPrehospital Disaster Med. 22, 95\u2013103 (2007).\n\n5\\. Quarantelli, E. Conventional Beliefs and Counterintuitive Realities. Soc.\nRes. Int. Q. Soc. Sci. 75, 873\u2013904 (2008).\n\n6\\. Tierney, K., Bevc, C. & Kuligowski, E. Metaphors Matter: Disaster Myths,\nMedia Frames, and Their Consequences in Hurricane Katrina. Ann. Am. Acad. Pol.\nSoc. Sci. 604, 57\u201381 (2006).\n\n7\\. Drury, J., Novelli, D. & Stott, C. Psychological disaster myths in the\nperception and management of mass emergencies. J. Appl. Soc. Psychol. (2013).\n\n8\\. Clarke, L. Panic: Myth or Reality? Contexts 1, 21\u201326 (2002).\n\n9\\. Clarke, L. & Chess, C. Elites and Panic: More to Fear than Fear Itself.\nSoc. Forces 87, 993\u20131014 (2008).\n\n10\\. Kemp, L. et al. Climate Endgame: A Research Agenda for Exploring\nCatastrophic Climate Change Scenarios. PNAS 119, (2022).\n\n11\\. Pescaroli, G. & Alexander, D. Understanding Compound, Interconnected,\nInteracting, and Cascading Risks: A Holistic Framework. Risk Anal. 38,\n2245\u20132257 (2018).\n\n12\\. Cremer, C. Z. & Kemp, L. T. Democratising Risk: In Search of a\nMethodology to Study Existential Risk.\nhttps://papers.ssrn.com/abstract=3995225 (2021).\n\n13\\. Wisner, B., Blaikie, P., Cannon, T. & Davis, I. At Risk: Natural Hazards,\nPeople\u2019s Vulnerability and Disasters. (Routledge, London, 2003).\n\n14\\. Liu, H.-Y., Lauta, K. C. & Maas, M. M. Governing Boring Apocalypses: A\nnew typology of existential vulnerabilities and exposures for existential risk\nresearch. Futures 102, 6\u201319 (2018).\n\n15\\. Boyd, M. & Wilson, N. Optimizing Island Refuges against global\nCatastrophic and Existential Biological Threats: Priorities and Preparations.\nRisk Anal. 41, 2266\u20132285 (2021).\n\n16\\. Boyd, M. & Wilson, N. Island refuges for surviving nuclear winter and\nother abrupt sunlight-reducing catastrophes. Risk Anal. 43, 1824\u20131842 (2022).\n\n17\\. Naheed, S. Understanding Disaster Risk Reduction and Resilience: A\nConceptual Framework. in Handbook of Disaster Risk Reduction for Resilience:\nNew Frameworks for Building Resilience to Disasters (eds. Eslamian, S. &\nEslamian, F.) 1\u201325 (Springer International Publishing, Cham, 2021).\ndoi:10.1007/978-3-030-61278-8_1.\n\n18\\. Hammer, C. C., Brainard, J., Innes, A. & Hunter, P. R. (Re-)\nconceptualising vulnerability as a part of risk in global health emergency\nresponse: updating the pressure and release model for global health\nemergencies. Emerg. Themes Epidemiol. 16, 2 (2019).\n\n19\\. Centeno, M. A., Nag, M., Patterson, T. S., Shaver, A. & Windawi, A. J.\nThe Emergence of Global Systemic Risk. Annu. Rev. Sociol. 41, 65\u201385 (2015).\n\n20\\. Helbing, D. Globally networked risks and how to respond. Nature 497,\n51\u201359 (2013).\n\n21\\. Keys, P. W. et al. Anthropocene risk. Nat. Sustain. 2, 667\u2013673 (2019).\n\n22\\. Frank, A. B. et al. Dealing with femtorisks in international relations.\nProc. Natl. Acad. Sci. 111, 17356\u201317362 (2014).\n\n23\\. Homer-Dixon, T. et al. Synchronous failure: the emerging causal\narchitecture of global crisis. Ecol. Soc. 20, art6 (2015).\n\n24\\. Scheffer, M. et al. Anticipating Critical Transitions. Science 338,\n344\u2013348 (2012).\n\n25\\. Lawrence, M., Janzwood, S. & Homer-Dixon, T. What Is a Global Polycrisis?\n11.\n\n26\\. Perrow, C. Normal Accidents: Living with High Risk Technologies - Updated\nEdition. Normal Accidents (Princeton University Press, 2011).\ndoi:10.1515/9781400828494.\n\n27\\. Sutcliffe, K. M. High reliability organizations (HROs). Best Pract. Res.\nClin. Anaesthesiol. 25, 133\u2013144 (2011).\n\n28\\. Weick, K. & Sutcliffe, K. Managing the Unexpected: Resilient Performance\nin an Age of Uncertainty. (Jossey-Bass, 2007).\n\n29\\. Schulman, P. R. General attributes of safe organisations. Qual. Saf.\nHealth Care 13, ii39\u2013ii44 (2004).\n\n30\\. Roberts, K. H. & Rousseau, D. M. Research in nearly failure-free, high-\nreliability organizations: having the bubble. IEEE Trans. Eng. Manag. 36,\n132\u2013139 (1989).\n\n31\\. Roberts, K. H., Bea, R. & Bartles, D. L. Must Accidents Happen? Lessons\nfrom High-Reliability Organizations [and Executive Commentary]. Acad. Manag.\nExec. 1993-2005 15, 70\u201379 (2001).\n\n32\\. Weick, K. E. Organizational Culture as a Source of High Reliability.\nCalif. Manage. Rev. 29, 112\u2013127 (1987).\n\n33\\. Roberts, K. H. Some Characteristics of One Type of High Reliability\nOrganization. Organ. Sci. 1, 160\u2013176 (1990).\n\n34\\. Chan, A. Loss of Control: \u2018Normal Accidents\u2019 and AI Systems. in\n(International Conference on Learning Representations, 2021).\n\n35\\. Maas, M. M. Regulating for \u2018Normal AI Accidents\u2019: Operational Lessons for\nthe Responsible Governance of Artificial Intelligence Deployment. in\nProceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society 223\u2013228\n(Association for Computing Machinery, New York, NY, USA, 2018).\ndoi:10.1145/3278721.3278766.\n\n36\\. Maas, M. M. How viable is international arms control for military\nartificial intelligence? Three lessons from nuclear weapons. Contemp. Secur.\nPolicy 40, 285\u2013311 (2019).\n\n37\\. Williams, R. & Yampolskiy, R. Understanding and Avoiding AI Failures: A\nPractical Guide. Philosophies 6, 53 (2021).\n\n38\\. Carvin, S. Normal Autonomous Accidents: What Happens When Killer Robots\nFail? SSRN Scholarly Paper at https://doi.org/10.2139/ssrn.3161446 (2017).\n\n39\\. Kuhlemann, K. Complexity, creeping normalcy, and conceit: sexy and unsexy\ncatastrophic risks. Foresight 21, 35\u201352 (2019).\n\n40\\. ConcernedEAs. Doing EA Better. Effective Altruism Forum\nhttps://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1\n(2023).\n\n41\\. Sundaram, L., Maas, M. & Beard, S. J. Seven Questions for Existential\nRisk Studies: Priorities, downsides, approaches, coherence, impact, diversity\nand communication. in Managing Extreme Technological Risk (ed. Rhodes, C.)\n(World Scientific, 2024).\n\n42\\. Taleb, N. N. The Black Swan. (Random House, New York, 2007).\n\n43\\. Tang, A. & Kemp, L. A Fate Worse Than Warming? Stratospheric Aerosol\nInjection and Global Catastrophic Risk. Front. Clim. 3, 720312 (2021).\n\n44\\. Ord, T. The Precipice: Existential Risk and the Future of Humanity.\n(Bloomsbury, London, 2020).\n\n45\\. Porter, T. M. Trust in Numbers: The Pursuit of Objectivity in Science and\nPublic Life. (Princeton University Press, 2020).\ndoi:10.23943/princeton/9780691208411.001.0001.\n\n46\\. Millett, P. & Snyder-Beattie, A. Existential Risk and Cost-Effective\nBiosecurity. Health Secur. 15, 373\u2013383 (2017).\n\n47\\. Barrett, A. M., Baum, S. D. & Hostetler, K. Analyzing and Reducing the\nRisks of Inadvertent Nuclear War Between the United States and Russia. Sci.\nGlob. Secur. 21, 106\u2013133 (2013).\n\n48\\. Tetlock, P. E. & Gardner, D. Superforecasting: The Art and Science of\nPrediction. (Crown, New York, 2015).\n\n49\\. Leech, G. & Yagudin, M. Comparing top forecasters and domain experts.\nEffective Altruism Forum\nhttps://forum.effectivealtruism.org/posts/qZqvBLvR5hX9sEkjR/comparing-top-\nforecasters-and-domain-experts (2022).\n\n50\\. Foreseeing the End(s) of the World. (Cambridge Conference on Catastrophic\nRisk, 2022).\n\n51\\. Beard, S., Rowe, T. & Fox, J. An analysis and evaluation of methods\ncurrently used to quantify the likelihood of existential hazards. Futures 115,\n102469 (2020).\n\n52\\. Baum, S. D. Quantifying the probability of existential catastrophe: A\nreply to Beard et al. Futures 123, 102608 (2020).\n\n53\\. Rees, M. Our Final Century: Will the Human Race Survive the Twenty-First\nCentury? (William Heinemann, 2003).\n\n54\\. Kemp, L. Foreseeing Extreme Technological Risk. in Managing Extreme\nTechnological Risk (ed. Rhodes, C.) (World Scientific, 2024).\n\n55\\. Linstone, H. & Turoff, M. The Delphi Method: Techniques and Applications.\n(Addison-Wesley Publishing Company, 1975).\n\n56\\. Hemming, V., Burgman, M. A., Hanea, A. M., McBride, M. F. & Wintle, B. C.\nA practical guide to structured expert elicitation using the IDEA protocol.\nMethods Ecol. Evol. 9, 169\u2013180 (2018).\n\n57\\. Richards, C. E., Lupton, R. C. & Allwood, J. M. Re-framing the threat of\nglobal warming: an empirical causal loop diagram of climate change, food\ninsecurity and societal collapse. Clim. Change 164, (2021).\n\n58\\. Krishnan, A. Unsettling the Coloniality of Foresight. in Sacred Civics:\nBuilding Seven Generation Cities (eds. Engle, J., Agyeman, J. & Chung-Tiam-\nFook, T.) 93\u2013106 (Routledge, 2022).\n\n59\\. Waverly Consultants. The Futures Toolkit: Tools for Futures Thinking and\nForesight across UK Government. 116 (2017).\n\n60\\. Ramos, J., Sweeney, J., Peach, K. & Smith, L. Our Futures: By the People,\nfor the People. (2019).\n\n61\\. Jasanoff, S. Future Imperfect: Science, Technology, and the Imaginations\nof Modernity. in Dreamscapes of Modernity: Sociotechnical Imaginaries and the\nFabrication of Power 1\u201333 (University of Chicago Press, 2015).\n\n62\\. Tutton, R. J. Sociotechnical Imaginaries as Techno-Optimism : Examining\nOuter Space Utopias of Silicon Valley. Sci. Cult. 30, 416\u2013439 (2020).\n\n63\\. Augustine, G., Soderstrom, S., Milner, D. & Weber, K. Constructing a\nDistant Future: Imaginaries in Geoengineering. Acad. Manage. J. 62, 1930\u20131960\n(2019).\n\n64\\. Sartori, L. Minding the gap(s): public perceptions of AI and socio-\ntechnical imaginaries. AI Soc. 38, 443\u2013458 (2023).\n\n65\\. Taillandier, A. From Boundless Expansion to Existential Threat:\nTranshumanists and Posthuman Imaginaries. in Futures (eds. Kemp, S. &\nAndersson, J.) 332\u2013348 (Oxford University Press, 2021).\ndoi:10.1093/oxfordhb/9780198806820.013.20.\n\n66\\. Hauskeller, M. Utopia in Trans- and Posthumanism. in Posthumanism and\nTranshumanism (eds. Sorgner, S. & Ranisch, R.) (Peter Lang, 2013).\n\n67\\. Davidson, J. P. L. Extinctiopolitics: Existential Risk Studies, The\nExtinctiopolitical Unconscious, And The Billionaires\u2019 Exodus from Earth. New\nForm. 107, 48\u201365 (2023).\n\n68\\. Coenen, C. Utopian Aspects of the Debate on Convergent Technologies. in\nAssessing Societal Implications of Converging Technological Development (eds.\nBanse, G., Grunwald, A., Hronszky, I. & Nelson, G.) 141\u2013172 (edition sigma,\n2007).\n\n69\\. Bostrom, N. Letter from Utopia. Stud. Ethics Law Technol. 2, (2008).\n\n70\\. Barbrook, R. & Cameron, A. The Californian ideology. Sci. Cult. 6, 44\u201372\n(1996).\n\n71\\. Kemp, L. & Pelopidas, B. Self-Serving Prophets: Techno-prophecy and\nCatastrophic Risk. (Forthcoming).\n\n  1. ^^\n\nThis is tied to the \u201cTombstone mentality\u201d of ignoring problems until they kill\npeople.\n\n  2. ^^\n\nThis is simply an example to illustrate the point, not taking a side on how\nplausible such a situation is.\n\n  3. ^^\n\nThere is frequent confusion between positive/negative feedback loops and\nvirtuous/vicious cycles. While people sometimes understandably assume that\nvirtuous cycles must be \u201cpositive\u201d and vicious cycles \u201cnegative\u201d, in fact both\nvirtuous and vicious cycles are self-amplifying rather than self-dampening,\nand thus are simply desirable or undesirable types of positive feedback loop.\n\n  4. ^^\n\nIn the words of Perrow, a focus on blaming human error is not only unhelpful\nbut also \u201c...suggests an unwitting\u2014or perhaps conscious\u2014class bias; many jobs,\nfor example, require that the operator ignore safety precautions if she is to\nproduce enough to keep her job, but when she is killed or maimed, it is\nconsidered her fault.\u201d\n\n  5. ^^\n\nDepending on how concerned one is about AI risk.\n\n  6. ^^\n\nSee, for example, Stratospheric Aerosol Injection, which might reduce\nexistential (and other types of) risk from climate change while adding risks\nof its own.43\n\n  7. ^^\n\nSee section 1.5 for further complications.\n\n  8. ^^\n\nAttentive readers may notice that participatory methods appear to be generally\n\u201csofter\u201d, focusing on meaning and subjective experience at least as much as\nrational analysis. This may reflect several factors, but the Nesta report\nincludes a cognitive science argument that methods involving more of the\nformer attributes are more effective at influencing peoples\u2019 motivations and\nactions. Adjudicating the proper quantity and type of traits from each\napproach in any given foresight exercise is beyond the scope of this post, but\nit seems likely that the answer will (1) vary according to context, and (2)\nlie somewhere between the two extremes.\n\n  9. ^^\n\nIf, by any chance, somebody is looking for a research project...\n\n  10. ^^\n\nA common bogeyman here is tech companies: \u201cThe Metaverse is the future, so buy\nin before you\u2019re left behind!\u201d.\n\nForecasting & Prediction1Technological Forecasting1World Modeling\nTechniques1Existential Risk1Futurism1Civilizational Collapse1AI1World\nModeling1\n\nFrontpage\n\n# 61\n\nA Gentle Introduction to Risk Frameworks Beyond Forecasting\n\n11th Apr 2024\n\n6Dan H\n\n4EZ97\n\n1pendingsurvival\n\n2Chris_Leong\n\n2pendingsurvival\n\n2Chris_Leong\n\nNew Comment\n\n6 comments, sorted by\n\ntop scoring\n\nClick to highlight new comments since: Today at 7:31 PM\n\n[-]Dan H13h60\n\nIf people are interested, many of these concepts and others are discussed in\nthe context of AI safety in this publicly available chapter:\nhttps://www.aisafetybook.com/textbook/4-1\n\nReply\n\n[-]EZ9711h41\n\nStrongly upvoted, neat overview of the topic. I especially like the academic\nformat (e.g. with the sources clearly cited), as well as its conciseness and\nbreadth.\n\nReply\n\n[-]pendingsurvival8h10\n\nThanks!\n\nReply\n\n[-]Chris_Leong13h22\n\nThanks for this post.\n\nMy (hot-)take: lots of useful ideas and concepts, but also many examples of\npeople thinking everything is a nail/wanting to fit risks inside their pre-\nexisting framework.\n\nReply\n\n[-]pendingsurvival8h21\n\nNot sure what you mean here, can you explain?\n\nReply\n\n[-]Chris_Leong6h20\n\nI'll provide an example:\n\n> People sometimes dismiss exposure when studying GCR, since \u201ceveryone is\n> exposed by definition\u201d. This isn\u2019t always true, and even when it is, it\n> still points us towards interesting questions.\n\nEven if there are some edge cases when this applies to existential risks, it\ndoesn't necessarily mean that it is prominent enough to be worthwhile\nincluding as an element in an x-risk framework.\n\nReply\n\nModeration Log\n\n", "frontpage": false}
