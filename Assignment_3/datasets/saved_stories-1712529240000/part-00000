{"aid": "39961836", "title": "Show HN: Toolkit for LLM Fine-Tuning, Ablating and Testing", "url": "https://github.com/georgian-io/LLM-Finetuning-Toolkit", "domain": "github.com/georgian-io", "votes": 1, "user": "rsaha7", "posted_at": "2024-04-07 16:33:19", "comments": 0, "source_title": "GitHub - georgian-io/LLM-Finetuning-Toolkit: Toolkit for fine-tuning, ablating and unit-testing open-source LLMs.", "source_text": "GitHub - georgian-io/LLM-Finetuning-Toolkit: Toolkit for fine-tuning, ablating\nand unit-testing open-source LLMs.\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ngeorgian-io / LLM-Finetuning-Toolkit Public\n\n  * Notifications\n  * Fork 74\n  * Star 631\n\nToolkit for fine-tuning, ablating and unit-testing open-source LLMs.\n\n### License\n\nApache-2.0 license\n\n631 stars 74 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# georgian-io/LLM-Finetuning-Toolkit\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n3 Branches\n\n3 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nbenjaminyeMerge pull request #128 from georgian-io/readme-img-patch0cccb03 \u00b7\n\n## History\n\n434 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Merge pull request #122 from georgian-io/git-action-docker  \n  \n### assets\n\n|\n\n### assets\n\n| updated readme  \n  \n### examples\n\n|\n\n### examples\n\n| added example configs  \n  \n### llama2\n\n|\n\n### llama2\n\n| Merge pull request #53 from georgian-io/mistral  \n  \n### llmtune\n\n|\n\n### llmtune\n\n| set up dynamic versioning based on git metadata  \n  \n### mistral\n\n|\n\n### mistral\n\n| update readme  \n  \n### .dockerignore\n\n|\n\n### .dockerignore\n\n| docker image  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| bug fixes  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| docker image  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| poetry and dependency setup  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| fix poetry publish typo  \n  \n### README.md\n\n|\n\n### README.md\n\n| README image reference update  \n  \n### config.yml\n\n|\n\n### config.yml\n\n| updated changes  \n  \n### poetry.lock\n\n|\n\n### poetry.lock\n\n| remove twine  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Update pyproject.toml Metadata  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| downgrade and restrict transformer and trl versioning due to new impo...  \n  \n## Repository files navigation\n\n# LLM Finetuning Toolkit\n\n## Overview\n\nLLM Finetuning toolkit is a config-based CLI tool for launching a series of\nLLM finetuning experiments on your data and gathering their results. From one\nsingle yaml config file, control all elements of a typical experimentation\npipeline - prompts, open-source LLMs, optimization strategy and LLM testing.\n\n## Installation\n\n### pipx (recommended)\n\npipx installs the package and depdencies in a seperate virtual environment\n\n    \n    \n    pipx install llm-toolkit\n\n### pip\n\n    \n    \n    pip install llm-toolkit\n\n## Quick Start\n\nThis guide contains 3 stages that will enable you to get the most out of this\ntoolkit!\n\n  * Basic: Run your first LLM fine-tuning experiment\n  * Intermediate: Run a custom experiment by changing the componenets of the YAML configuration file\n  * Advanced: Launch series of fine-tuning experiments across different prompt templates, LLMs, optimization techniques -- all through one YAML configuration file\n\n### Basic\n\n    \n    \n    llmtune --config-path ./config.yml\n\nThis command initiates the fine-tuning process using the settings specified in\nthe default YAML configuration file config.yaml.\n\n### Intermediate\n\nThe configuration file is the central piece that defines the behavior of the\ntoolkit. It is written in YAML format and consists of several sections that\ncontrol different aspects of the process, such as data ingestion, model\ndefinition, training, inference, and quality assurance. We highlight some of\nthe critical sections.\n\n#### Data Ingestion\n\nAn example of what the data ingestion may look like:\n\n    \n    \n    data: file_type: \"huggingface\" path: \"yahma/alpaca-cleaned\" prompt: ### Instruction: {instruction} ### Input: {input} ### Output: prompt_stub: { output } test_size: 0.1 # Proportion of test as % of total; if integer then # of samples train_size: 0.9 # Proportion of train as % of total; if integer then # of samples train_test_split_seed: 42\n\n  * While the above example illustrates using a public dataset from Hugging Face, the config file can also ingest your own data.\n\n    \n    \n    file_type: \"json\" path: \"<path to your data file>\n    \n    \n    file_type: \"csv\" path: \"<path to your data file>\n\n  * The prompt fields help create instructions to fine-tune the LLM on. It reads data from specific columns, mentioned in {} brackets, that are present in your dataset. In the example provided, it is expected for the data file to have column names: instruction, input and output.\n\n  * The prompt fields use both prompt and prompt_stub during fine-tuning. However, during testing, only the prompt section is used as input to the fine-tuned LLM.\n\n#### LLM Definition\n\n    \n    \n    model: hf_model_ckpt: \"NousResearch/Llama-2-7b-hf\" quantize: true bitsandbytes: load_in_4bit: true bnb_4bit_compute_dtype: \"bf16\" bnb_4bit_quant_type: \"nf4\" # LoRA Params ------------------- lora: task_type: \"CAUSAL_LM\" r: 32 lora_dropout: 0.1 target_modules: - q_proj - v_proj - k_proj - o_proj - up_proj - down_proj - gate_proj\n\n  * While the above example showcases using Llama2 7B, in theory, any open-source LLM supported by Hugging Face can be used in this toolkit.\n\n    \n    \n    hf_model_ckpt: \"mistralai/Mistral-7B-v0.1\"\n    \n    \n    hf_model_ckpt: \"tiiuae/falcon-7b\"\n\n  * The parameters for LoRA, such as the rank r and dropout, can be altered.\n\n    \n    \n    lora: r: 64 lora_dropout: 0.25\n\n#### Quality Assurance\n\n    \n    \n    qa: llm_tests: - length_test - word_overlap_test\n\n  * To ensure that the fine-tuned LLM behaves as expected, you can add tests that check if the desired behaviour is being attained. Example: for an LLM fine-tuned for a summarization task, we may want to check if the generated summary is indeed smaller in length than the input text. We would also like to learn the overlap between words in the original text and generated summary.\n\n#### Artifact Outputs\n\nThis config will run finetuning and save the results under directory\n./experiment/[unique_hash]. Each unique configuration will generate a unique\nhash, so that our tool can automatically pick up where it left off. For\nexample, if you need to exit in the middle of the training, by relaunching the\nscript, the program will automatically load the existing dataset that has been\ngenerated under the directory, instead of doing it all over again.\n\nAfter the script finishes running you will see these distinct artifacts:\n\n    \n    \n    /dataset # generated pkl file in hf datasets format /model # peft model weights in hf format /results # csv of prompt, ground truth, and predicted values /qa # csv of test results: e.g. vector similarity between ground truth and prediction\n\nOnce all the changes have been incorporated in the YAML file, you can simply\nuse it to run a custom fine-tuning experiment!\n\n    \n    \n    python toolkit.py --config-path <path to custom YAML file>\n\n### Advanced\n\nFine-tuning workflows typically involve running ablation studies across\nvarious LLMs, prompt designs and optimization techniques. The configuration\nfile can be altered to support running ablation studies.\n\n  * Specify different prompt templates to experiment with while fine-tuning.\n\n    \n    \n    data: file_type: \"huggingface\" path: \"yahma/alpaca-cleaned\" prompt: - >- This is the first prompt template to iterate over ### Input: {input} ### Output: - >- This is the second prompt template ### Instruction: {instruction} ### Input: {input} ### Output: prompt_stub: { output } test_size: 0.1 # Proportion of test as % of total; if integer then # of samples train_size: 0.9 # Proportion of train as % of total; if integer then # of samples train_test_split_seed: 42\n\n  * Specify various LLMs that you would like to experiment with.\n\n    \n    \n    model: hf_model_ckpt: [ \"NousResearch/Llama-2-7b-hf\", mistralai/Mistral-7B-v0.1\", \"tiiuae/falcon-7b\", ] quantize: true bitsandbytes: load_in_4bit: true bnb_4bit_compute_dtype: \"bf16\" bnb_4bit_quant_type: \"nf4\"\n\n  * Specify different configurations of LoRA that you would like to ablate over.\n\n    \n    \n    lora: r: [16, 32, 64] lora_dropout: [0.25, 0.50]\n\n## Extending\n\nThe toolkit provides a modular and extensible architecture that allows\ndevelopers to customize and enhance its functionality to suit their specific\nneeds. Each component of the toolkit, such as data ingestion, finetuning,\ninference, and quality assurance testing, is designed to be easily extendable.\n\n## Contributing\n\nIf you would like to contribute to this project, we recommend following the\n\"fork-and-pull\" Git workflow.\n\n  1. Fork the repo on GitHub\n  2. Clone the project to your own machine\n  3. Commit changes to your own branch\n  4. Push your work back up to your fork\n  5. Submit a Pull request so that we can review your changes\n\nNOTE: Be sure to merge the latest from \"upstream\" before making a pull\nrequest!\n\n### Set Up Dev Environment\n\n### Checklist Before Pull Request (Optional)\n\n  1. Use ruff check --fix to check and fix lint errors\n  2. Use ruff format to apply formatting\n\nNOTE: Ruff linting and formatting checks are done when PR is raised via Git\nAction. Before raising a PR, it is a good practice to check and fix lint\nerrors, as well as apply formatting.\n\n### Releasing\n\nTo manually release a PyPI package, please run:\n\n    \n    \n    make build-release\n\nNote: Make sure you have pypi token for this PyPI repo.\n\n## About\n\nToolkit for fine-tuning, ablating and unit-testing open-source LLMs.\n\n### Topics\n\nnlp unit-testing falcon classification summarization lora nlp-machine-learning\nzephyr fine-tuning finetuning ablation-study large-language-models flan-t5\nredpajama qlora llm-test llama2 mistral-7b\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\nCustom properties\n\n### Stars\n\n631 stars\n\n### Watchers\n\n9 watching\n\n### Forks\n\n74 forks\n\nReport repository\n\n## Releases 3\n\nv0.1.4 Latest\n\nApr 5, 2024\n\n\\+ 2 releases\n\n## Packages 0\n\nNo packages published\n\n## Contributors 8\n\n## Languages\n\n  * Python 97.7%\n  * Shell 1.5%\n  * Other 0.8%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
