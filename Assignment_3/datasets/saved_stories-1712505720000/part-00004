{"aid": "39958815", "title": "How Airbnb Achieved 150X Payments Read Performance?", "url": "https://newsletter.systemdesigncodex.com/p/how-airbnb-achieved-150x-performance-payments", "domain": "systemdesigncodex.com", "votes": 1, "user": "kakakiki", "posted_at": "2024-04-07 07:06:48", "comments": 0, "source_title": "How Airbnb Achieved 150X Payments Read Performance?", "source_text": "How Airbnb Achieved 150X Payments Read Performance?\n\n# System Design Codex\n\nShare this post\n\n#### How Airbnb Achieved 150X Payments Read Performance?\n\nnewsletter.systemdesigncodex.com\n\n#### Discover more from System Design Codex\n\nThe best place to learn practical System Design with concepts and case studies\n\nOver 8,000 subscribers\n\nContinue reading\n\nSign in\n\n# How Airbnb Achieved 150X Payments Read Performance?\n\n### Journey from monolith to SOA and beyond...\n\nSaurabh Dashora\n\nApr 02, 2024\n\n15\n\nShare this post\n\n#### How Airbnb Achieved 150X Payments Read Performance?\n\nnewsletter.systemdesigncodex.com\n\nShare\n\nJust like any smart startup, Airbnb began life as a monolithic application and\nit was great going for a while.\n\nThe monolithic approach allowed them to get off the ground, test out their\nproduct with real users, and achieve a product-market fit.\n\nAnd the architecture also looked so simple...\n\nYou can play around with the diagram on Eraser.io\n\nHowever, they soon warped through the wormhole of growth and the monolithic\narchitecture just couldn\u2019t keep up with the scaling demands.\n\nAt this point, Airbnb embraced SOA (service-oriented architecture) and\nmigrated most of its backend functionalities to dedicated services. Payments\nbeing one of the oldest parts of the system went through the same\ntransformation, providing a couple of crucial benefits:\n\n  * Now, there were clear boundaries between different services. No more fights between teams on who owns what piece of data because everyone knew their responsibilities and limits. There was now less red tape while making changes and faster iterations.\n\n  * Data separation into domains helped with normalization, resulting in improved correctness and consistency. After all, who doesn\u2019t like consistency?\n\nBut there\u2019s no free lunch on the other side of the wormhole.\n\nNormalization helps reduce redundancy and data duplication. You break down a\ndatabase into multiple tables and define relations between them.\n\nDenormalization is the opposite. You introduce redundancy into a database by\ncombining data from multiple tables into a single table or adding redundant\ndata into an existing table. Overall less need for joins between tables.\n\n#\n\nChallenges of SOA\n\nThe payment data was normalized and scattered across multiple payment sub-\ndomains. Each sub-domain became the responsibility of a separate team and it\nlooked like life was sorted.\n\nHowever, this change had a side effect.\n\nSuddenly, the presentation services had to integrate with multiple services in\nthe payment domain to fetch all the required data.\n\nIn other words, what happened to be a single API call turned into multiple\nfetch requests to collect all the data and aggregate it based on the client's\nrequirements.\n\nYou can play around with the diagram on Eraser.io\n\nNeedless to say, this created a few problems:\n\n  * Clients now had to build a fair amount of understanding about the payments domain so that they could call the correct API. It\u2019s like going to a restaurant and rather than simply ordering the pizza you love, you need to explain to the chef about all the ingredients needed to prepare that pizza and how those ingredients should be combined. Not what you expect while going to a restaurant!\n\n  * Since the payments domain was split up, there were many instances where a change spanned multiple teams. Prioritizing a change request where multiple teams are involved is never straightforward and it negatively impacts time to market.\n\n  * Due to multiple integrations, the performance, reliability, and scalability of the overall system weren\u2019t at the expected levels.\n\n#\n\nCreating a Unified Payments Data Read Layer\n\nNaturally, this situation couldn\u2019t last and Airbnb was keen to find a long-\nterm solution to the problem.\n\nThey came up with two changes:\n\n##\n\n1 - Unified Entry Point\n\nThe first task was to unify the entry points to the payment system.\n\nThe Airbnb team built a data-oriented service mesh where clients can query for\nthe \u201centity\u201d instead of being forced to identify dozens of APIs. It\u2019s like a\ntypical restaurant where you go and order a specific pizza without worrying\nabout how it\u2019s actually made.\n\nHere\u2019s what the approach looked like on a high-level:\n\nYou can play around with the diagram on Eraser.io\n\nIn these entry points, they provided a bunch of filtering options to hide the\ncomplexity from the client and reduce the number of APIs they had to expose.\n\n##\n\n2 - Unified Higher-Level Data Entities\n\nWhile the unified entry point was a good start, it wasn\u2019t good enough to\nresolve all the complexity.\n\nThe payment system had 100+ data models and it still required a lot of domain\nknowledge to interact with all these models.\n\nTo make things easier for the client, they came up with higher-level domain\nentities to represent the payment domain. With this, the entire core payments\ndata was confined to less than ten high-level entities.\n\nSee the below example:\n\nYou can play around with the diagram on Eraser.io\n\nThree main principles were followed while designing the high-level entities:\n\n  * Keep the terminology simple for non-payment engineers\n\n  * Maintain loose coupling with the storage schema to allow backend changes without requiring client changes\n\n  * Hide the complexity behind a rich data model.\n\n#\n\nMaterialize Denormalized Data\n\nUnifying entry points and entities was a good way to remove complexity for the\nclient.\n\nBut it didn\u2019t mean that the platform itself became less complex. It was more\nlike picking up the mess from one place and putting it elsewhere.\n\nThere were still expensive and complex application layer aggregations that\nwere giving nightmares to the developers. The problem was that each client\nquery was dependent on many services for its fulfillment. Sure, the client\nwasn\u2019t doing the aggregation but it was still happening within the control\nflow.\n\nTo handle this, Airbnb decided to de-normalize the payment data and\nmaterialize it with less than 10 seconds of replication lag.\n\nThink of it like creating and packaging ready-to-eat meals before the customer\neven places an order.\n\nAirbnb built a special framework for this known as the Read-Optimized Store\nFramework that takes an event-driven lambda approach to materialize secondary\nindices. The framework takes data via data change capture mechanisms and daily\ndatabase dumps and builds a near real-time secondary store.\n\nThe below diagram shows how the Read-Optimized Store Framework works:\n\nYou can play around with the diagram on Eraser.io\n\n#\n\nResulting System\n\nAfter all the changes were made, the overall architecture for payment read\nflow looked something like this:\n\nYou can play around with the diagram on Eraser.io\n\nAs you can see, the clients had no reason to know about any payment services\nor database internals. At the same time, complex aggregation queries were\nremoved using the read-optimized store indexing service.\n\nSure, the index was eventually consistent but it was acceptable for their use\ncase.\n\nAirbnb first implemented this architecture for the transaction history page\nthat showed a list of all the transactions for a customer. After 100% of the\ntraffic was migrated to the new setup, they achieved a 150X latency\nimprovement while improving the reliability from 96% to 99.9%.\n\nThese results have allowed Airbnb to expand this setup to other areas within\nthe payment domain.\n\nSo - what do you think about Airbnb\u2019s solution? Would you have done things\ndifferently?\n\nLeave a comment\n\nThe reference for this article comes from the Airbnb Engineering Blog.\n\n#\n\nShoutout\n\nHere are a few interesting articles I read this week:\n\n  * Your system\u2019s exceptions are a ticking time bomb by\n\nHelen Sunshine\n\n  * Developing essential soft skills for engineers and leaders by\n\nNicola Ballotta\n\n  * 5 Non-Verbal Behaviors Killing Team Health by\n\nRaviraj Achar\n\n  * When AI meets DevOps by\n\nAmrut Patil\n\nThat\u2019s it for today! \u2600\ufe0f\n\nEnjoyed this issue of the newsletter?\n\nShare with your friends and colleagues.\n\nShare\n\nSee you later with another value-packed edition \u2014 Saurabh.\n\n15 Likes\n\n\u00b7\n\n2 Restacks\n\n15\n\nShare this post\n\n#### How Airbnb Achieved 150X Payments Read Performance?\n\nnewsletter.systemdesigncodex.com\n\nShare\n\nComments\n\nSDC#27 - Facebook's Memcache Breakdown\n\nDeep dive into handling billions of requests & trillions of data items...\n\nFeb 6 \u2022\n\nSaurabh Dashora\n\n26\n\nShare this post\n\n#### SDC#27 - Facebook's Memcache Breakdown\n\nnewsletter.systemdesigncodex.com\n\n4\n\nSDC#31 - Introduction to Pre-caching\n\nThe secret technique to boost application performance...\n\nMar 5 \u2022\n\nSaurabh Dashora\n\n23\n\nShare this post\n\n#### SDC#31 - Introduction to Pre-caching\n\nnewsletter.systemdesigncodex.com\n\n8\n\nHow LinkedIn Uses Caching to Serve 5M Profile Reads/Sec?\n\nCouchbase Cache, Espresso and Brooklin\n\nMar 19 \u2022\n\nSaurabh Dashora\n\n22\n\nShare this post\n\n#### How LinkedIn Uses Caching to Serve 5M Profile Reads/Sec?\n\nnewsletter.systemdesigncodex.com\n\n8\n\nReady for more?\n\n\u00a9 2024 Saurabh Dashora\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great writing\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
