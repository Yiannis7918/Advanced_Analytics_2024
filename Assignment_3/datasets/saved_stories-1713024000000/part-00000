{"aid": "40021884", "title": "Why Don't People Use Formal Methods?", "url": "https://www.hillelwayne.com/post/why-dont-people-use-formal-methods/", "domain": "hillelwayne.com", "votes": 2, "user": "rramadass", "posted_at": "2024-04-13 09:59:25", "comments": 0, "source_title": "Why Don't People Use Formal Methods?", "source_text": "Why Don't People Use Formal Methods?\n\nSkip to Content\n\nHillel Wayne\n\n# Why Don't People Use Formal Methods?\n\nPosted on Jan 21, 2019\n\nI saw this question on the Software Engineering Stack Exchange: What are the\nbarriers that prevent widespread adoption of formal methods? The question was\nclosed as opinion-based, and most of the answers were things like \u201cits too\nexpensive!!!\u201d or \u201cwebsite isn\u2019t airplane!!!\u201d These are sorta kinda true but\ndon\u2019t explain very much. I wrote this to provide a larger historical picture\nof formal methods, why they\u2019re actually so unused, and what we\u2019re doing to\nmake them used.\n\nBefore we begin, we need to lay down some terms. There really isn\u2019t a formal\nmethods community so much as a few tiny bands foraging in the Steppe.^1 This\nmeans different groups use terms in different ways. Very broadly, there are\ntwo domains in FM: formal specification is the study of how we write precise,\nunambiguous specifications, and formal verification is the study of how we\nprove things are correct. But \u201cthings\u201d includes both code and abstract\nsystems. Not only do we use separate means of specifying both things, we often\nuse different means to verify them, too. To make things even more confusing,\nif somebody says they do formal specification, they usually mean they both\nspecify and verify systems, and if somebody says they do formal verification,\nthey usually mean mean they both specify and verify code.\n\nFor clarity purposes, I will divide verification into code verification (CV)\nand design verification (DV), and similarly divide specification into CS and\nDS. These are not terms used in the wider FM world. We\u2019ll start by talking\nabout CS and CV, then move on to DS and DV.\n\nAdditionally, we can do partial verification, where we only verify a subset of\nthe spec, or full verification, where we verify the entire spec. This could be\nthe difference between proving \u201cit never crashes or accepts the wrong\npassword\u201d or \u201cit never crashes or admits the wrong password and locks the\naccount if you give the wrong password three times.\u201d Most of this history will\nassume we\u2019re doing full verification.\n\nWe should also clarify the type of software we\u2019re formalizing. Most people\nimplicitly divide software into high-assurance software, such as medical\ndevices and aircraft, and everything else. People assume that formal methods\nare widely used in the former and unnecessary for the latter. This, if\nanything, is too optimistic: most people in high-assurance software don\u2019t use\nformal methods. We\u2019ll focus instead on \u201cregular\u201d software.\n\nFinally, a disclaimer: I am not a historian, and while I tried to do my due\ndiligence there are probably mistakes here. Also, I specialize in formal\nspecification (DS and DV), so there are more likely to be mistakes in anything\nI say about code verification. If you see something wrong, email me and I\u2019ll\nfix it.^2\n\n# Formal Coding\n\n## Getting the Spec\n\nBefore we prove our code is correct, we need to know what is \u201ccorrect\u201d. This\nmeans having some form of specification, or spec, for what the code should do,\none where we can unambiguously say whether a specific output follows the spec.\nJust saying a list is \u201csorted\u201d is unclear: we don\u2019t know what we\u2019re sorting,\nwhat criteria we\u2019re using, or even what we mean by \u201csort\u201d. Instead, we might\nsay \u201cA list of integers l is sorted in ascending order if for any two indices\ni and j, if i < j, then l[i] <= l[j]\u201d.\n\nCode specs fall into three major camps:\n\n  1. The first is writing them as statements independent of the code. We would write our sort function, and in a separate file write the theorem \u201cthis returns sorted lists\u201d. This is the oldest form of spec and is still the way Isabelle and ACL2 do things.^3\n  2. The second embeds specs in the code in the form of pre/postconditions, assertions, and invariants. We might add a postcondition on the function that \u201cthe return value is a sorted list\u201d. Assertion-based specs were originally formalized as Hoare Logic and were first integrated into a programming language with Euclid in the early 1970s.^4 This style is also called Design by Contract and is the most popular form of industrial verification.^5\n  3. Finally, we have type systems. By Curry-Howard correspondence, any math theorem or proof can be encoded as a dependent type. We\u2019d define the type of \u201csorted lists\u201d and declare our function has the type signature [Int] -> Sorted [Int].\n\nYou can see examples of how all of these look at Let\u2019s Prove Leftpad. HOL4 and\nIsabelle are good examples of \u201cindependent theorem\u201d specs, SPARK and Dafny\nhave \u201cembedded assertion\u201d specs, and Coq and Agda have \u201cdependent type\u201d\nspecs.^6\n\nIf you squint a bit it looks like these three forms of code spec map to the\nthree main domains of automated correctness checking: tests, contracts, and\ntypes. This is not a coincidence. Correctness is a spectrum, and formal\nverification is one extreme of that spectrum. As we reduce the rigour (and\neffort) of our verification we get simpler and narrower checks, whether that\nmeans limiting the explored state space, using weaker types, or pushing\nverification to the runtime. Any means of total specification then becomes a\nmeans of partial specification, and vice versa: many consider Cleanroom a\nformal verification technique, which primarily works by pushing code review\nfar beyond what\u2019s humanly possible.\n\n## \u201cWhat\u2019s the right spec?\u201d\n\nVerification proves code matches its spec. This raises a question: how do we\nknow we have the right spec? Finding the right spec is one of the biggest\nchallenges in formal methods. It\u2019s also one of the most raised objections, but\nthe way skeptics mean it isn\u2019t exactly the same as the way advocates think of\nit.\n\nWhen outsiders say \u201chow do you have the right spec?\u201d they\u2019re usually thinking\nof validation: showing a spec actually does what the client wants. If you\nformally prove your code sorts a list, but the customer actually wants Uber\nFor Soups TM, you\u2019ve just wasted a bunch of time. Only by rapid iteration and\nshort feedback cycles, people argue, can you actually validate your\nrequirements.\n\nIt is true that verifying code does not validate the code. There are two\nproblems with this argument, though. The first is that it just delays the\nvalue of FM, not eliminate it entirely. Once you\u2019ve done your rapid\niterations, you presumably have an idea of what your customer wants. Then you\nstart verifying code. Second, while we don\u2019t know what exactly the customer\nwants, there are some things we can assume they don\u2019t want. They don\u2019t want\nthe software randomly crashing on them. They don\u2019t want security holes.\nEverybody recognizes the importance of this: after all, nobody is saying you\nshould skip unit tests while you iterate. So, at the very least, prove your\nversion control system doesn\u2019t randomly delete chapters of a user\u2019s book.^7\n\nThe problem with finding the right spec is more fundamental: we often don\u2019t\nknow what we want the spec to be. We think of our requirements in human terms,\nnot mathematical terms. If I say \u201cthis should distinguish parks from birds\u201d,\nwhat am I saying? I could explain to a human by giving a bunch of pictures of\nparks and birds, but that\u2019s just specific examples, not capturing the idea of\ndistinguishing parks from birds. To actually translate that to a formal spec\nrequires us to be able to formalize human concepts, and that is a serious\nchallenge.\n\nDon\u2019t get me wrong, it\u2019s possible to figure out the appropriate specs here and\nexperts do it all of the time. But writing appropriate specs is a skill you\nneed to develop, just as you needed to develop coding skills. This is why a\nlot of the more recent successes with code verification have been things with\nan obvious map between what we want and what we can express we want. For\nexample, CompCert is a formally verified C compiler. The spec there is \u201cthis\nwill never miscompile\u201d.\n\nAnd none of this is the actual verification part. Once you have a spec, you\nstill need to prove the code matches the spec.\n\n## Proving the Spec\n\nThe earliest means of code verification we see is the the Dijkstra-style\n\u201cthink really hard about why it\u2019s true\u201d method, which is basically what ALGOL\nwas designed to help do. For example, I might \u201cprove\u201d an insertion sort works\nby arguing\n\n  1. Base Case: if we have an empty list and add one element to it, that will be the only element, so it will be sorted.\n  2. If we have a sorted list with k elements and add one element, we insert the element so that it is after all smaller numbers and before all larger numbers. This means the list is still sorted.\n  3. By induction, insert sort will sort the entire list.\n\nObviously it\u2019d look more rigorous than that, but that\u2019s the general idea.\nDijkstra and others used this style to prove a bunch of algorithms were\ncorrect, including many concurrency primitives. It\u2019s also the style that gives\nrise to the Knuth quote \u201cBeware of bugs in the above code; I have only proved\nit correct, not tried it.\u201d It\u2019s pretty easy to screw up a math proof in a way\nnobody notices, and I\u2019ve read estimates that something like 20% of published\nmath proofs have errors in them. Peter Guttmann has a great essay on how\nfarcical code proofs got, where tons of \u201cproven\u201d code would immediately crash\nif run.\n\nAt the same time we were exploring how to automatically prove mathematical\ntheorems, the first such theorem prover coming out in 1967. Researchers in the\nPascal community were using theorem provers to verify programs by the early\n1970s, then programming in dedicated verification languages by mid-decade.\nPeople would write some properties of the code and then write a checkable\nproof that the code had those properties. Earlier theorem provers simply\nhelped humans check and verify proofs while more sophisticated ones could\nprove parts of the theorem on their own.\n\nWhich leads to the next problem.\n\n## Proofs are hard\n\nProofs are hard. Obnoxiously hard. \u201cQuit programming and join the circus\u201d\nhard. Surprisingly, formal code proofs are often more rigorous than the proofs\nmost mathematicians write! Mathematics is a very creative activity with a\ndefinite answer that\u2019s only valid if you show your work. Creativity,\nformalism, and computers are a bad combination.\n\nTake the above induction. Any mathematician could look at that and immediately\nknow what induction is, how it works, and how it\u2019s valid in this case. These\nare all things we need to rigorously formalize in the theorem prover. Same\nwith proof by contradiction, proof by contrapositive, etc. Along with this, we\nalso need to formalize every assumption, even the stuff that most\nmathematicians don\u2019t bother to prove. For example, addition is associative: a\n+ (b + c) = (a + b) + c. The theorem prover doesn\u2019t a priori know that\u2019s true.\nYou either have to prove it (hard), declare it an assumption the prover can\ntake as true (dangerous), or buy a theorem library from someone who already\nproved it (expensive). Early proof assistants competed on the number of\ninbuilt proof tactics and bundled theorem libraries. One of the first\nwidespread proof checkers, SPADE, advertised its complete arithmetic library\nas a key selling point.\n\nNext, you gotta actually get the proof. You can have the prover try to find it\non its own, or write it yourself. In the general case, automatically infering\na proof is undecidable. For extremely restricted cases, like propositional\nlogic or HM type-checking, it\u2019s \u201conly\u201d NP-complete. For the most part we\u2019re\nstuck writing most of the proof ourselves and having the computer verify it\u2019s\ncorrect. That means you need a strong background in:\n\n  * Math\n  * CS\n  * Whatever domain you\u2019re working on, like hardware or compilers or whatever\n  * The intricacies of your program and spec\n  * The intricacies of the theorem prover you\u2019re using, which is a specialty unto itself\n\nTo make things worse, computer properties throw a lot of wrenches into proofs.\nRemember how I said assuming addition was associative is dangerous? Some\nlanguages aren\u2019t associative. C++ has INT_MAX. ((-1) + INT_MAX) + 1 is\nINT_MAX. -1 + (INT_MAX + 1) is undefined. If you assume associative addition\nin C++, your proof will be wrong, and your code will be broken. You either\nhave to avoid making that assertion, or prove that for your specific snippet,\nyou never cause an overflow.\n\nNow you could say that undefined addition is a bug, and you should be using a\nlanguage with unbound integers. But most languages have positive features that\nimpede proofs. Take the following snippet:\n\n    \n    \n    a = true; b = false; f(a); assert a;\n\nIs that always true? Depends. Maybe f modifies a. Maybe another thread\nconcurrency modifies a. Maybe b is aliased to a, so modifying it also modifies\na.^8 If any of these are possible in your language, you have to explicitly\nprove they don\u2019t happen here. Purity helps in this case but can wreck proofs\nin other cases, as it forces you to use recursion and higher-order functions\nto get stuff done. Both of those, incidentally, are foundational to writing\ngood functional programs. What\u2019s good for coding is bad for proving!^9\n\nFormal verifiers have a dilemma: the more expressive the language, the harder\nit is to prove anything in it. But the less expressive the language, the\nharder it is to write anything in it. The first production verification\nlanguages were very restricted subsets of more expressive languages: ACL2 was\na subset of Lisp, Euclid was a subset of Pascal, etc. And nothing we\u2019ve\ndiscussed so far gets into actually proving real-world programs, this is all\njust the table stakes to start writing proofs in the first place.\n\nProofs are hard. They have, however, been getting better. Proof assistant\nresearchers keep adding new heuristics, theorem libraries, preverified\ncomponents, etc. Hardware improvements help, too: faster computers means\nfaster searches.\n\n### The SMT Revolution\n\nThese days the most population approach to proof automation is SMT.^10\nSpeaking very broadly, an SMT solver can turn (some) theorems into constraint\nsatisfaction problems. This turns a creative problem into a computational one.\nYou may still need to feed it intermediate problems (lemmas) as steps in your\ntheorem, but that\u2019s better than proving every damn thing yourself. Stanford\nreleased the first \u201cmodern\u201d SMT solver, the Stanford Validity Checker, in\n1998. They built on that to make CVC, released in 2002, which saw minor\nproduction use. ^11\n\nThe scene changed around 2006, when Microsoft Research released Z3. The big\nadvantage of Z3 was it was a lot more user-friendly than other SMTs, which\nhonestly wasn\u2019t saying much. MSR used it internally to help prove properties\nof the Windows kernel, meaning they invested more-than-the-bare-minimum in UX.\nZ3 arguably made SMT the default choice for general-purpose automated proving.\nMany tools in CV now rely on SMT, and most of those come with Z3 by default.\n\nAccessible SMT solving was a kick in the pants to the formal verification\ncommunity, as it makes a lot of simple proofs trivial and nasty proofs\ntractable. This, in turn, meant people could start proving things in more\nexpressive languages, as they now had the power to tackle the challenges of\nexpressive statements. The incredible progress here is evident in the\nIronFleet project: by using advanced SMT solvers and a cutting-edge\nverification language, Microsoft was able to write 5,000 lines of verified\nDafny code in only 3.7 person-years! That\u2019s a blazing-fast rate of four whole\nlines a day. ^12\n\nProofs are hard.\n\n## Why Bother?\n\nNow would be a good time to step back and ask \u201cwhat\u2019s the point?\u201d We\u2019re trying\nto prove some program conforms to some spec. Correctness is a spectrum. There\nare two parts of the verification question: how objectively \u201ccorrect\u201d your\nprogram is, and how much you\u2019ve rigorously verified the correctness.\nObviously, more verified is better than less verified, but verification costs\ntime and money. If we have multiple constraints to optimize (performance, time\nto market, cost, etc), the optimium isn\u2019t necessarily \u201cfully proved correct\u201d.\nThen the question becomes \u201cwhat\u2019s the minimal verification we need\u201d and \u201chow\nmuch does it cost to get there.\u201d In most cases you can get away with, like,\n90% or 95% or 99% correct. You may be better off spending time making the UX\nbetter than getting that last 1% of correctness.\n\nThe question, then: \u201cis 90/95/99% correct significantly cheaper than 100%\ncorrect?\u201d The answer is very yes. We all are comfortable saying that a\ncodebase we\u2019ve well-tested and well-typed is mostly correct modulo a few fixes\nin prod, and we\u2019re even writing more than four lines of code a day. In fact,\nthe vast majority of distributed systems outages could have been prevented by\nslightly-more-comprehensive testing. And that\u2019s just more comprehensive unit\ntesting, to say nothing of fuzzing, property-based testing, or model-testing.\nYou can get really far with simpler tricks without needing to go on to full\nproofs.\n\nWhat if types\u2019n\u2019tests isn\u2019t getting you enough verification? It\u2019s still much\neasier to go from 90% to 99% than from 99% to 100%. As mentioned earlier,\nCleanroom is a developer practice involving comprehensive documentation,\ncareful flow analysis, and extensive code review. No proofs, no formal\nverification, not even any unit testing. But done properly, Cleanroom reduces\nthe defect density to less than 1 bug/kLoC in production.^13 Teams using it\nhave equal or shorter delivery times than teams that don\u2019t use it- certainly\nbetter than 4 lines a day. And Cleanroom itself is just one of many high-\nassurance techniques that sit between mainstream software practices and code\nverification. You do not need full code verification to write good software or\neven to write near-perfect software. There are cases where it\u2019s necessary, but\nfor most of the industry it\u2019s a waste of money.\n\nHowever, that does not mean formal methods as a whole is uneconomical. Many\naforementioned high-assurance techniques rely on writing code specs that you\ndon\u2019t formally prove. As for verification, there are two common ways people\nbenefit from it in the industry. The first is verifying designs instead of\ncode, which we will cover in the next section. The second is partial code\nverification, which we will cover right now.\n\n## Partial Code Verification\n\nIt\u2019s too expensive doing full verification in day-to-day programming. What\nabout partial verification? I could still benefit from proving some properties\nof some parts of my code. Instead of proving that my sort function always\nsorts, I can at least prove it doesn\u2019t loop forever and never writes out of\nbounds. You can still get a lot of benefit out of this. For example, writing\neven basic proofs about C programs is a great way to cut out huge amounts of\nundefined behavior.\n\nThe limitation here is availability. Most languages are designed for either\nfull verification or no verification. In the former case, you\u2019re missing a lot\nof nice features in more expressive languages, and in the latter case you a\nneed a way to prove stuff in a language hostile to the concept. For this\nreason, most of the research on partial verification focuses on a few high-\npriority languages, like C and Java. You also see a lot of people working with\nrestricted subsets of languages. For example, SPARK is a restricted subset of\nAda, so you can write critical stuff in SPARK and have it interop with less-\ncritical Ada code. But most languages like that are pretty niche.\n\nMore commonly, people bake specific kinds of verification into the the core\nstructure of languages. Production type systems are a common form of this: you\nmay not know that tail always returns the tail, but at least you know that it\nhas type [a] -> [a]. You also have cases like Rust, which proves memory\nsafety, and Pony, which proves exception safety. These are slightly different\nfrom SPARK and Frama-C in that you can only do partial verification, not some\npartial and some full verification. They also tend to be made by programming\nlanguage experts over formal methods experts, two disciplines that have a lot\nof overlap but aren\u2019t identical. This might be why languages like Rust and\nHaskell are actually-kinda-usable in practice.\n\n# Design Specification\n\nSo far we\u2019ve only talked about code verification. There\u2019s another side to\nformal methods, though, which is going one step more abstract and verifying\nthe designs themselves. This is deep enough that it\u2019s synonymous with formal\nspecification: if somebody says they do formal specification, they probably\nmean they specify and verify designs.\n\nAs we talked about, proving every line of code is really, really hard. But\nmany problems with production systems aren\u2019t in a line of code: they\u2019re in the\ninteraction between components of a system. If we handwave away the details of\nimplementation, like saying \u201cjust assume it can identify birds\u201d, we can more\neasily look at how Park or Bird as a high-level module fits in with our\noverall design. Once you zoom out enough, though, it becomes possible (or at\nleast much easier) to describe things you couldn\u2019t possibly implement, like\nthe runtime environment, human interactions, or the merciless flow of time.^14\nAt this scale, we\u2019re now formalizing our intentions with the overall system\ninstead of our intentions with the lines of code. This is much closer to the\nhuman level, where designs and requirements can be much more ambiguous than at\nthe code level.\n\nTo give an example: take code procedure with the rough specification \u201cif\ncalled, it makes a syscall to persist data to storage and handles system\nerrors.\u201d The properties you need to verify, while difficult, are sort of\nstraightforward. Does it serialize data properly? Do malformed inputs violate\nour guarantees? Do we handle all possible ways the syscall could fail? Now\ncompare a high level logging system with the specification \u201call messages are\nlogged.\u201d You now have to answer:\n\n  * All messages, or all messages that reach the system? Are messages logged once or exactly once?\n  * How are messages being sent? Is it a queue? Does the transfer medium deliver once? Does it deliver in order?\n  * By \u201clogged\u201d, do we mean \u201cpermanently logged?\u201d Is the message allowed to be logged and later unlogged? Is it allowed to \u201cbounce\u201d between logged and unlogged before ending logged?\n  * What if the server explodes in the middle of logging the message? Do we need journaling?\n  * Are there any properties of the storage medium that matter? Is \u201cthe medium loses data\u201d outside the scope of our requirements or not?\n  * What about GDPR?\n  * etc etc etc\n\nWithout the benefit of a formal design, it\u2019s harder to express what you\nactually need the system to do. If you can\u2019t express what you need, you have\nno idea if your design actually gives you what you need or something else that\nsounds kinda the same but has very different consequences. By being formal in\nexpressing our intentions and our design, we can more easily make sure we\u2019re\nactually building what we need to build.\n\nJust as we use programming languages to represent code, we use specification\nlanguages to represent designs. Spec langs are usually oriented for design\nspecification, not code specification, although some languages can be used for\nboth.^15 Going forward, I am going to refer to specification languages as\ndesign languages (DLs) so as to absolutely minimize confusion.^16\n\nThe first full DL was arguably VDM, which came out around 1972. Since then,\nwe\u2019ve seen a huge variety of different spec langs. The space of design\nlanguages is a lot more diverse and fragmented than code verification\nlanguages. As a very rough stereotype, people invented DLs as a means to an\nend, while people invented CVLs as an end itself. Since they\u2019re heavily\ninfluenced by specific problem domains, DLs have all sorts of ideas and\nsemantics. As a very, very brief tour of some early design languages:\n\n$Language| modeled| with  \n---|---|---  \nZ| Business Requirements| Relational Algebra  \nPromela| Messaging| CSP  \nSDL| Telecommunications| Flowcharts  \nHarel Statecharts| Controllers| Automata  \nDecision Tables| Decisions| Tables  \n  \nAs people mostly designed DLs to solve specific problems, most of them have at\nleast two or three real-world case studies. Results are generally very\npositive. Practicioners say it gives them insight into the problems and makes\nit easier to explore solutions. For a long time the biggest champion was\nPraxis (now Altran), which used \u201ccorrect-by-construction\u201d- a combination of Z\ndesigns and SPARK code- to build safety critical systems. They claimed that\nthey could work much faster and more cheaply by writing specs, as they\nwouldn\u2019t discover design mistakes in the late-stage of the project.\n\nMore recently, Pamela Zave was dabbling with Alloy and discovered that Chord,\none of the major distributed hash tables, was fundamentally broken. More\nrecently than that, AWS started finding 35-step critical bugs by writing TLA+\nspecs. In my experience, people who try writing specs become big fans.\n\nBut there\u2019s also a big mismatch in the value between fans and outsiders. To\nfans, the biggest benefit is that the act of writing a design forces you to\nunderstand what you\u2019re writing. When you have to formally express what your\nsystem does, suddenly a lot of subtle errors become painfully obvious. This is\nutterly unpersuasive to outsiders. If you want to get people to try use a DL,\nyou need to give them a way to verify their design actually has the properties\nthey want.\n\nFortunately, this is also extremely important to a lot of specifiers, so\ndesign verification is a big field of research.\n\n## Model Checkers\n\nAs with code, we can verify designs by writing theorems. Thankfully, we\u2019ve got\nanother trick here: we can use a model checker. Instead of writing a proof\nthat a design is correct, we just brute force the state space and see if any\nreachable state is incorrect. If we can\u2019t find any, then we\u2019re good.^17\n\nThere\u2019s a lot of benefits to model checking. One, you don\u2019t have to write a\nproof. That saves a lot of time and effort. Two, you don\u2019t have to learn how\nto write a proof, so the skill barrier is a lot lower. Three, if your design\nis broken the model checker will give you an explicit counterexample. This\nmakes fixing issues much, much less painful, especially when the bug takes 35\nsteps to reproduce. Good luck finding that on your own.\n\nThere are also a couple of drawbacks. One is that they\u2019re a little less\npowerful. Specifically, you could be dealing with an unbounded model, where\nthere\u2019s an infinite number of distinct states. For example, if you\u2019re speccing\nout a message queue processor, it\u2019s pretty straightforward that it works when\ngiven a list of ten messages. But if you need to make sure it works for any\nlist of messages, well, there\u2019s an infinite number of those, so an infinite\nnumber of states. Most model checkers have various tricks to handle these,\nlike identifying equivalence classes or symmetries, but it\u2019s really on a case-\nby-case basis.\n\nThe other big drawback is state-space explosion. Imagine you have three\nprocesses, each four sequential steps long, and can they can interleave the\nsteps in any way. If they don\u2019t affect each other\u2019s behaviors, there are\n(4*3)! / (4!)^3 = 34,650 total possible executions (behaviors). If each\nprocess has one of five initial states, you now have 4,300,000 total\nbehaviors. And the model checker has to make sure all of them behave nicely.\nAnd this is assuming they don\u2019t interact with each other! If they do, the\nstate space gets bigger even faster. The combinatorial explosion is seen as\nthe primary challenge to model checking, and there\u2019s a lot of work put into\nmaking this more tractable.\n\nBut in the meantime, there\u2019s another way to handle state explosion: throw more\nhardware at it. The biggest challenge to model checking is \u201cjust\u201d a\nperformance problem, and we are very good at solving performance problems.\nMost (but not all) model checking is easily parallelizable. After optimizing\nyour model and checking it with small parameters, you can spin up an AWS\ncluster and run it with large parameters.\n\nIn practice, a lot of specifiers use model checkers and then switch to theorem\nprovers as necessary.^18 A lot more specifiers use model checkers and then,\nwhen reaching their limits, switch to less intensive forms of verification.\n\n### The Problem with Design Specs\n\nSo design verification is easier and faster than code verification and has a\nlot of spectacular successes. Then why don\u2019t people use it? The problem with\nDV is much more insidious. While code verification is a technical problem,\ndesign verification is a social problem: people just don\u2019t see the point.\n\nMuch of this is a consequence of designs are not code. With most design\nlanguages, there is no automatic way to generate code, nor is there a way to\ntake existing code and verify it matches a design.^19 Programmers tend to\nmistrust software artifacts that aren\u2019t code or forcibly synced with code.\nIt\u2019s the same reason documentation, comments, diagrams, wikis, and commit\nmessages are often neglected.\n\nProgrammers also just don\u2019t seem to believe there\u2019s any benefit to specifying.\nAt least in my experience, they assume whatever they currently use\n(pseudocode, diagrams, TDD) is more than sufficient to getting the design\nright. I don\u2019t know if this is universal, and I don\u2019t have a good explanation\nbesides general conservatism. My reasoning is that every methodology community\nI know has the exact same complaint: TDD folk gripe that people don\u2019t want to\ntry TDD, Haskellers gripe people don\u2019t care about static typing, etc etc\netc.^20 It\u2019s just really hard to get people excited about something they don\u2019t\nalready do, even if they agree that there are benefits.\n\n# Summary\n\nVerifying code is a hard problem. More and more people are doing it, though,\nas theorem provers and SMT solvers get more sophisticated. It will probably\nremain a specialist thing for the foreseeable future.\n\nVerifying designs is much easier, but has cultural barriers to adoption. I\nthink this is possible to change, though. Twenty years ago automated testing\nand code review were pretty niche things and they eventually went mainstream.\nThen again, code contracts was a niche thing and still is.\n\nHopefully this explains more about why FM is so niche, at least better than\nthe usual \u201cweb don\u2019t airplane\u201d argument. Feel free to yell at me if there is\nany obvious mistakes I made.\n\nInterested in using design specs at your work? Buy my book or Hire me!\n\nThanks to Nick P, Richard Whaling, Ron Pressler, and John Regehr for feedback.\n\n  1. TLA+ is one of the more popular formal specification languages and you can probably fit every TLA+ expert in the world in a large schoolbus. ^[return]\n  2. And a disclosure: I run TLA+ and Alloy workshops for a living, so I\u2019m highly biased towards those two languages. I tried to account for that in this history but y\u2019know bias is bias. ^[return]\n  3. ML was originally invented to help write specs of this form. ^[return]\n  4. It\u2019s up for debate whether work on Euclid or SPV was started first, but AFAICT I think Euclid was presented to the public earlier. ^[return]\n  5. Design by Contract is not using \u201cdesign\u201d in the same way I am using it in this essay. It is about using contracts as code specs, not as design specs. ^[return]\n  6. Oh hey, if you do formal verification in a language we don\u2019t have yet, why not make a pull request? ^[return]\n  7. Not that I\u2019m bitter or anything. ^[return]\n  8. Aliasing is so hostile to writing proofs that John C Reynolds had to create an entirely new logic, Separation Logic, to handle it. ^[return]\n  9. In his Turing Lecture, Edmund Clarke listed some challenging properties to verify: \u201cfloats, strings, user-defined types, procedures, concurrency, generics, storage, libraries...\u201d ^[return]\n  10. SMT stands for Satisfiability Modulo Theories: Solving a SAT problem where some of the variables can be math equations. ^[return]\n  11. This section originally said the first SMT solvers started appearing around 2004, which is incorrect. They\u2019re almost a decade older than that. It also sorta implied that SMT was the first major attempt at automated theorem proving, which is atrociously wrong. Thanks to Don Syme and Heidi Khlaaf for calling this out. ^[return]\n  12. The previous record was probably seL4, whose developers wrote the equivalent of two lines of C a day. ^[return]\n  13. Most of these numbers come from Stavely\u2019s research in Toward Zero-Defect Programming. As always, be skeptical of results and reread the original papers. ^[return]\n  14. If there\u2019s one thing that studying formal methods has taught me, it\u2019s that time is evil and I hate it. ^[return]\n  15. The process of mapping design specifications to code specifications is called refinement. ^[return]\n  16. As before, this is not common terminology. Most people use \u201cspecification language\u201d, but I want to make clear the distinction between code specifications and design specifications. ^[return]\n  17. Model checkers are also used in code verification, such as JMBC, but model checking makes up a much bigger percentage of design verifications than code verifications. ^[return]\n  18. Keep in mind \u201ca lot of specifiers\u201d is, like, ten people. ^[return]\n  19. Generating code from specifications is called synthesis. See Nadia Polikarpova\u2019s work for a good crash course. Proving code matches a spec (or one spec matches another spec) is called refinement. Both of these are active areas of research. ^[return]\n  20. One argument I\u2019ve heard is that Agile rejects up-front design, so nobody wants to do formal specification. This may contribute, but many of the people I\u2019ve met who reject Agile also reject FM about as often as Agilists do. Another argument I\u2019ve heard is that historically formal methods has consistently overpromised and failed to deliver. This may also contribute, but most people haven\u2019t even heard of FM, much less know about the history of it. ^[return]\n\nCategories: Programming\n\nTags: Specification, History, Formal Methods, Favorites\n\nPowered by Buttondown.\n\n\u00a9 2024 Hillel Wayne\n\n", "frontpage": false}
