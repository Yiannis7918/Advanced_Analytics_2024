{"aid": "40015015", "title": "GoEx: A Runtime for Autonomous LLM Applications", "url": "https://gorilla.cs.berkeley.edu/blogs/10_gorilla_exec_engine.html", "domain": "cs.berkeley.edu", "votes": 1, "user": "stanleydrew", "posted_at": "2024-04-12 16:52:47", "comments": 0, "source_title": "Gorilla Execution Engine", "source_text": "Gorilla Execution Engine\n\nHome Blogs Leaderboard API Zoo Index\n\n# \ud83e\udd8d GoEx: A Runtime for Autonomous LLM Applications\n\n####\n\nShishir G. Patil Tianjun Zhang Vivian Fang Noppapon C. Roy Huang Aaron Hao\nMartin Casado Joseph E. Gonzalez Raluca Ada Popa Ion Stoica\n\nshishirpatil@berkeley.edu, tianjunz@berkeley.edu\n\nLarge Language Models (LLMs) are evolving beyond their role of providing\ninformation within dialogue systems to actively engaging with tools and\nperforming actions on real-world applications and services. Today, humans\nverify the correctness and appropriateness of the LLM-generated outputs (e.g.,\ncode, functions, or actions) before putting them into real-world execution.\nThis poses significant challenges as code comprehension is well known to be\nnotoriously difficult. We study how humans can efficiently collaborate with,\ndelegate to, and supervise autonomous LLMs in the future. We argue that in\nmany cases, \"post-facto validation\"\u2014verifying the correctness of a proposed\naction after seeing the output\u2014is much easier than the aforementioned \"pre-\nfacto validation\" setting. The core concept behind enabling a post-facto\nvalidation system is the integration of an intuitive undo feature, and\nestablishing a damage confinement for the LLM-generated actions as effective\nstrategies to mitigate the associated risks. Using this, a human can now\neither revert the effect of an LLM-generated output or be confident that the\npotential risk is bounded. We believe this is critical to unlock the potential\nfor LLM agents to interact with applications and services with limited (post-\nfacto) human involvement. We describe the design and implementation of our\nopen-source runtime for executing LLM actions, Gorilla Execution Engine\n(GoEx), and present open research questions towards realizing the goal of LLMs\nand applications interacting with each other with minimal human supervision.\nGoEx is completely open source, under the Apache 2.0 license.\n\nQuick Links:\n\n  * Paper: https://arxiv.org/abs/2404.06921\n  * Github: https://github.com/ShishirPatil/gorilla/tree/main/goex\n\n####\n\n  1. GoEx Slack Demo \ud83e\udd16\n\nLet's first take a look at a demo of GoEx in action. In this example, Vivian\nuses GoEx to send a message, \"Hello Tianjun, it's nice to meet you! Let's get\nyou set up...\" to Tianjun in Slack. The user can choose to either commit or\nundo the action if the generated and executed code is incorrect.\n\nGoEx provides a simple and intuitive interface for executing LLM generated\ncode, with the option to commit or undo the action.\n\n####\n\n  2. Moving from Chatbots to Autonomous Agents \ud83d\ude80\n\nIn the example above, the LLM is autonomously using microservices, services,\nand applications, with little human supervision. Different autonomous LLM-\npowered applications can be built on top of the GoEx engine, such as a Slack\nbot that can send messages, a Spotify bot that can create playlists, or a\nDropbox bot that can create folders and files. However, in designing such\nsystems, several critical challenges must be addressed:\n\n    1. Hallucination, stochasticity, and unpredictability. LLM-based applications place an unpredictable and hallucination-prone LLM at the helm of a system traditionally reliant on trust. Currently, services and APIs assume a human-in-the-loop, or clear specifications to govern how and which tools are used in an application. For example, the user clicks the \u201cSend\u201d button after confirming the recipient and body of the email. In contrast, an LLM-powered assistant may send an email that goes against the user's intentions, and may even perform actions unintended by the user.\n    2. Unreliability. Given their unpredictability and impossibility to comprehensively test, it is difficult for a user to trust an LLM off the shelf. However, the growing utility of LLM-based systems means that we need mechanisms to express the safety-utility tradeoff to developers and users.\n    3. Delayed feedback and downstream visibility. Lastly, from a system-design principle, unlike chatbots and agents of today, LLM-powered systems of the future will not have immediate human feedback. This means that the intermediate state of the system is not immediately visible to the user and often only downstream effects are visible. An LLM-powered assistant may interact with many other tools (e.g., querying a database, browsing the web, or filtering push notifications) before composing and sending an email. Such interactions before the email is sent are invisible to the user.\n\nWe are moving towards a world where LLM-powered applications are evolving from\nchatbots to autonomous LLM-agents interacting with external applications and\nservices with minimal and punctuated human supervision. GoEx offers a new way\nto interface with LLMs, providing abstractions for authorization, execution,\nand error handling.\n\n####\n\n  3. GoEx Runtime Design \ud83d\udee0\ufe0f\n\nIn the realm of LLM-powered-systems, we introduce \u201cpost-facto LLM validation,\u201d\nwhich contrasts with traditional \u201cpre-facto\u201d methods. In \u201cpost-facto\nvalidation,\u201d humans evaluate the outcomes of actions executed by the LLM,\nrather than overseeing the intermediate processes. This approach assumes that\nvalidating results over processes, acknowledging that while verifying outcomes\nis crucial, understanding and correcting processes based on those outcomes is\nequally important. Forgoing \u201cpre-facto validation\u201d means execution of actions\nwithout prior validation, which introduces risks and potentially leads to\nundesirable outcomes. We propose two abstractions to mitigate the risk\nassociated with post-facto validation: undoing an action, and damage\nconfinement.\n\n    1. Reversibility/Undoing an Action\n\nWhen possible, actions executed by an LLM should give users the right to undo\nan action. This could require maintaining multiple versions of the system\nstate, leading to high costs in terms of memory and computational resources.\nFurthermore, the feasibility of implementing undoing an action is often\ndependent on the level of access granted to the system. For instance, in file\nsystems or databases, where root access is available, undoing actions is\npossible. However, in scenarios where such privileged access is not granted,\nsuch as in email clients like Gmail, the ability to undo an action may be\nlimited or require alternative approaches. One potential solution is for the\nruntime to make a local copy of the email before deleting, which introduces\nadditional state to the runtime but enables undo for email deletion. Read our\npaper for more details on how we implement undoing actions in the GoEx\nruntime.\n\n    2. Damage Confinement\n\nNot all applications or tools provide the ability to undo an action. For\nexample, emails currently cannot be unsent after some time has elapsed. In\nscenarios like these, we fall back to \"damage confinement\" or \"blast-radius\nconfinement,\" as it is necessary to provide users with mechanisms to quantify\nand assess the associated risks of the actions their LLM-powered application\nmay take. Damage confinement can be viewed as a quantification of the user's\nrisk appetite.\n\nOne approach to address this challenge is through the implementation of\ncoarse-grained access control mechanisms. A user could permit their LLM to\nonly read emails instead of sending emails, thus confining the blast radius to\nan tolerable level.\n\nDesign of the GoEx runtime, which provides abstractions for authorization,\nexecution, and error handling.\n\n####\n\n  4. GoEx Web App\n\nYou can try out the GoEx web app, hosted here. Currently, the web app supports\nonly RESTful calls. The web app displays generated LLM code, allowing users\nnot only to see, but to edit the model output. Then, users can decide whether\nto run the forward or reverse call and view the output. To save your queries\nfor later, you can log in with Google, automatically saving all content under\nyour account.\n\nTry GoEx without any installation using the GoEx web app.\n\nCurrently, the web app does not support all security functionality that the\nGoEx CLI provides. Notably, the CLI does not expose API keys to the LLM model,\ninstead passing in a file path to retrieve sensitive information. This is not\npossible on a web browser, and so the queries generated using the front end\ninvolve passing raw credentials to the LLM model. In the web app, all\nsensitive credentials are stored in browser local storage, then retrieved when\nnecessary to execute. We do not store any sensitive information on our\nservers. Currently, authentication can come in the form of OAuth credentials\nas well as raw API keys. The number of OAuth services we provide are limited\nto the ones we add support for, but any number of raw API keys can be added in\nthe browser for different services.\n\n####\n\n  5. GoEx CLI Overview \ud83d\udda5\ufe0f\n\nWe provide all our code at the repo here at github. Let us know what you\nthink!\n\nThe Gorilla CLI is an easy to use demo of the gorilla engine, right in your\nterminal. It has functionality for RESTful, database, filesystem calls. Here\nare the three types of APIs it supports:\n\n    1. RESTful: Gmail, Slack, Dropbox, Github, Spotify (awaiting approval)\n    2. Database\n    3. Filesystem\n\nThe CLI can be easily installed through pip. For more information on\ninstallation and execution check out the repo.\n\n####\n\n  6. Slack Example Walkthrough\n\nTo get yourself started with GoEx, follow along with this example. This\nexample requires a slack account. We will be walking through the process of\nsending a message to someone on slack. You can refer to our Github repo for\nmore examples and documentation.\n\n    1. Enviroment Setup and Installation:\n\nWe highly recommend using a new environment for GoEx. We will use conda for\nthis example. conda create --name goex python=3.10 -y conda activate goex\n\nWe then install goex using the following command in the exec-engine folder.\nYou will need to clone from the Gorilla repository. pip install -e .\n\nWe use Mkcert to support OAuth2 token exchange. This is necessary for all\nOAuth services. brew install mkcert mkcert -install mkcert localhost Windows\nusers can use choco to install mkcert.\n\n    2. Slack Authorization:\n\nTo authorize for slack use the following command: goex -authorize slack\n\nThis will open a window in your browser that prompts you to sign in. The link\nshould also be printed in the terminal like this: You will be asked to give\nGoEx permission to a workspace of your choice. Something like this should show\nup:\n\n    3. Execute with GoEx!\n\nTo execute prompts with goex, specify the server in your prompt, and add the\ntype of execution. (rest, db, fs). Feel free to play around with the prompt.\nMake sure to have docker desktop running in the background. goex execute\n-prompt send a funny joke to the user with email gorilla@yahoo.com on slack\n-type rest\n\nHopefully, after running you should see your new message:\n\nYour output should look something like this:\n\nTo unsend the message, select the undo option with the keyboard arrows and hit\nenter.\n\nIf you're having trouble sending a message with email, try using the slack\nchannel ID or slack handle.\n\nCongratulations! You've succesfully sent a message using the power of LLMs!\n\n####\n\n  7. Summary\n\nIn the evolution of LLMs from chatbots to empowering services and\napplications, slowly moving away from passively providing information to\nactively and autonomously making decisions has become an increasing trend. We\nintroduce the concept of post-facto validation as a execution paradigm for\nthese new system. We present GoEx as a means to this vision, a critical step\ntoward an LLM tool usage capabilities.\n\nBe sure to check out our Discord community for updates and any questions as\nwell as our official repo on Github.\n\n####\n\n  8. Citation\n    \n        @inproceedings{gorilla-exec-engine, title={GoEx: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications}, author={Shishir G. Patil and Tianjun Zhang and Vivian Fang and Noppapon C. and Roy Huang and Aaron Hao and Martin Casado and Joseph E. Gonzalez and Raluca Ada Popa and Ion Stoica}, year={2024}, journal={arXiv preprint arXiv:2404.06921} }\n\n", "frontpage": false}
