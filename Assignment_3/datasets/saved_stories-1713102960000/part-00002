{"aid": "40029469", "title": "Knuth\u2013Morris\u2013Pratt Illustrated", "url": "https://www.cambridge.org/core/journals/journal-of-functional-programming/article/knuthmorrispratt-illustrated/8EFA77D663D585B68630E372BCE1EBA4", "domain": "cambridge.org", "votes": 2, "user": "g0xA52A2A", "posted_at": "2024-04-14 07:55:22", "comments": 0, "source_title": "Knuth\u2013Morris\u2013Pratt illustrated | Journal of Functional Programming | Cambridge Core", "source_text": "Knuth\u2013Morris\u2013Pratt illustrated | Journal of Functional Programming | Cambridge Core\n\nSkip to main content Accessibility help\n\nWe use cookies to distinguish you from other users and to provide you with a\nbetter experience on our websites. Close this message to accept cookies or\nfind out how to manage your cookie settings.\n\n## Login Alert\n\nCancel\n\nLog in\n\n\u00d7\n\n\u00d7\n\nHome\n\nHostname: page-component-6b989bf9dc-pkhfk Total loading time: 0 Render date:\n2024-04-14T04:34:32.660Z Has data issue: false hasContentIssue false\n\n  * Home\n  * >Journals\n  * >Journal of Functional Programming\n  * >Volume 34\n  * >Knuth\u2013Morris\u2013Pratt illustrated\n\nYou have Access Open access\n\n  * English\n  * Fran\u00e7ais\n\nJournal of Functional Programming\n\n## Article contents\n\n  * Abstract\n  * Introduction\n\n  * Horizontally naive\n\n  * Vertically naive with a set\n\n  * Vertically naive with a list\n\n  * Morris\u2013Pratt\n\n  * Knuth\u2013Morris\u2013Pratt\n\n  * Correctness\n\n  * Conclusion\n\n  * Conflicts of Interest\n\n  * References\n\n# Knuth\u2013Morris\u2013Pratt illustrated\n\nPart of: JFP Functional Pearls\n\nPublished online by Cambridge University Press: 30 January 2024\n\nCAMERON MOY [Opens in a new window]\n\nShow author details\n\nCAMERON MOY*\n\n    \n\nAffiliation:\n\nNortheastern University, Boston, MA 02115, USA (e-mail: camoy@ccs.neu.edu)\n\nArticle\n\n  * Article\n  * Figures\n  * Discussions\n  * Metrics\n\nArticle contents\n\n  * Abstract\n  * Introduction\n  * Horizontally naive\n  * Vertically naive with a set\n  * Vertically naive with a list\n  * Morris\u2013Pratt\n  * Knuth\u2013Morris\u2013Pratt\n  * Correctness\n  * Conclusion\n  * Conflicts of Interest\n  * References\n\nSave PDF (0.37 mb) View PDF [Opens in a new window]\n\n  * Copy\n\n  * Share\n\n  * Share\n\n  * Share\n\n  * Share\n\n  * Post\n\n  * Share\n\n  * Mail\n\n  * Share\n\nRights & Permissions [Opens in a new window]\n\n## Abstract\n\nThe Knuth\u2013Morris\u2013Pratt (KMP) algorithm for string search is notoriously\ndifficult to understand. Lost in a sea of index arithmetic, most explanations\nof KMP obscure its essence. This paper constructs KMP incrementally, using\npictures to illustrate each step. The end result is easier to comprehend.\nAdditionally, the derivation uses only elementary functional programming\ntechniques.\n\nType\n\n    Functional Pearl\n\nInformation\n\n    \n\nJournal of Functional Programming , Volume 34 , 2024 , e3\n\nDOI: https://doi.org/10.1017/S0956796824000017 [Opens in a new window]\n\nCreative Commons\n\n    \n\nThis is an Open Access article, distributed under the terms of the Creative\nCommons Attribution licence (http://creativecommons.org/licenses/by/4.0/),\nwhich permits unrestricted re-use, distribution and reproduction, provided the\noriginal article is properly cited.\n\nCopyright\n\n    \n\n\u00a9 The Author(s), 2024. Published by Cambridge University Press\n\n## 1 Introduction\n\nBoth the Knuth\u2013Morris\u2013Pratt and the Boyer\u2013Moore algorithms require some\ncomplicated preprocessing on the pattern that is difficult to understand and\nhas limited the extent to which they are used.\n\nRobert Sedgewick, Algorithms\n\nString search is a classic problem. Given a string, the pattern, determine if\nit occurs in a longer string, the text. String search can be solved in\nO(n+m)O(n+m) time and O(m) space, where n is the size of the text and m is the\nsize of the pattern. Unfortunately, the algorithm that does so,\nKnuth\u2013Morris\u2013Pratt (KMP) (Knuth et al., Reference Knuth, Morris and\nPratt1977), is hard to understand. Its pseudocode is short, but most\nexplanations of it are not.\n\nStandard treatments, like that of Cormen et al. (Reference Cormen, Leiserson,\nRivest and Stein2009) or Sedgewick & Wayne (Reference Sedgewick and\nWayne2011), contain headache-inducing descriptions. Actually, neither even\nexplain the genuine KMP algorithm. Cormen et al. explain the simpler\nMorris\u2013Pratt (MP) algorithm and leave Knuth\u2019s optimization as an exercise.\nSedgewick & Wayne present a related algorithm for minimal DFA construction,\nwith greater memory consumption than KMP, and simply assert that it can be\nimproved.\n\nAlternatively, KMP can be derived via program transformation (Takeichi &\nAkama, Reference Takeichi and Akama1990; Colussi, Reference Colussi1991;\nHern\u00e1ndez & Rosenblueth, Reference Hern\u00e1ndez and Rosenblueth2001; Ager et al.,\nReference Ager, Danvy and Rohde2003; Bird, Reference Bird2010). Indeed, Knuth\nhimself calculated the algorithm (Knuth et al., Reference Knuth, Morris and\nPratt1977, p. 338) from a constructive proof that any language recognizable by\na two-way deterministic pushdown automaton can be recognized on a random-\naccess machine in linear time (Cook, Reference Cook1972).\n\nWhat follows is a journey from naive string search to the full KMP algorithm.\nLike other derivations, we will take a systematic and incremental approach.\nUnlike other derivations, visual intuition will be emphasized over program\nmanipulation. The explanation highlights each of the insights that, taken\ntogether, lead to an optimal algorithm. Lazy evaluation turns out to be a\ncritical ingredient in the solution.\n\n## 2 Horizontally naive\n\nThe naive O(nm) algorithm for string search attempts to match the pattern at\nevery position in the text. Consider the pattern mama and the text ammamaa.\nFigure 1 visualizes the naive approach on this example.\n\nFig. 1. Naive string search (horizontal).\n\nEach row corresponds to a new starting position in the text. Mismatched\ncharacters are colored red and underlined. The third row matches fully,\nindicated by the underlined \u03b5\u03b5, so the search is successful. If one just wants\nto determine if the pattern is present or not, then processing can stop at\nthis point. Related queries, such as counting the number of occurrences of the\npattern, require further rows of computation (as shown).\n\nTo summarize, naive search finds, if it exists, the left-most suffix of the\ntext whose prefix is the pattern:\n\nThe scanl function is similar to foldl but returns a list of all accumulators\ninstead of just the final one:\n\nThe any function determines if some element of the input list satisfies the\ngiven predicate:\n\nComing back to horizontal, the accumulator is initially the entire text. At\neach step, the accumulator shrinks by one character, generating the next\nsuffix. So, the result of scanl is a list containing all suffixes of the text.\nThen, any checks to see if some suffix has a prefix that is the pattern.\n\nIn the algorithms that follow, any and scanl remain the same; they differ only\nin the choice of init, step, and done.\n\n## 3 Vertically naive with a set\n\nFigure 2 is identical to Figure 1 except that it uses vertical lines instead\nof horizontal ones. This picture suggests a different algorithm. Each column\nis a set of pattern suffixes, all of which are candidates for a match.\nCalculating the next column involves three steps:\n\n  1. 1\\. Remove suffixes that do not match the current position in the text (colored red and underlined). These suffixes are failed candidates.\n\n  2. 2\\. Take the tail of those that do. These suffixes remain candidates.\n\n  3. 3\\. Add the pattern itself, corresponding to the diagonal line of mama. Doing so starts a new candidate at each position.\n\nFig. 2. Naive string search (vertical).\n\nLet us call the result of this procedure the successor of column C on\ncharacter x. A column containing the empty string, written as \u03b5\u03b5, indicates a\nsuccessful match.\n\nFollowing this picture yields a new approach. Now, accumulators are columns,\ncolumns are sets of strings, and step calculates successors:\n\nAs is, verticalSet consumes more memory than horizontal. While step for\nhorizontal does not allocate, step for verticalSet allocates an entirely new\nset.\n\nThere is a trick to negate this drawback. In the same way that sets of natural\nnumbers can be represented using bitstrings, sets of candidate strings can\nalso be represented in binary. Successors can be calculated using left shift\nand bitwise or. This optimized algorithm, known as Shift-Or (Baeza-Yates &\nGonnet, Reference Baeza-Yates and Gonnet1992), performs exceptionally well on\nsmall patterns. In particular, Shift-Or works well when the length of the\npattern is no greater than the size of a machine word.\n\n### Additional notes\n\nString search is equivalent to asking if the regular expression .*pattern.*\nmatches. Compiling this regular expression to an NFA and simulating it shows\nthat the columns of Figure 2 are sets of NFA states. The step function is then\nthe NFA transition function. Equivalently, columns can be viewed as Brzozowski\nderivatives (Brzozowski, Reference Brzozowski1964; Owens et al., Reference\nOwens, Reppy and Turon2009) of the regular expression. The step function is\nthen the derivative.\n\n## 4 Vertically naive with a list\n\nUsing a set to represent the accumulator has two drawbacks. First, set\noperations cannot be fused together. Ideally, step would traverse the\naccumulator only once, but with sets it must perform more than one traversal.\nSecond, done is not a constant-time operation.\n\nFigure 3 is derived from Figure 2 by removing whitespace from the columns and\ngiving each distinct suffix a unique color and background. This picture\nsuggests representing columns using lists instead of sets, where the first\nelement of the list is the top of the column. The verticalSet function can be\neasily adapted to this new representation:\n\nFig. 3. Columns as lists.\n\nTwo features of this snippet may seem unusual now but will be helpful shortly.\nFirst, instead of Haskell\u2019s built-in lists, the code defines a new datatype.\nThis will be useful in the next section where this datatype is extended.\nSecond, the highlighted expression could more simply be written as step r x\nsince head t is x in this branch. In the next section, x will be unavailable,\nand so step r (head t) is the only option at that point.\n\nNow, step is a straightforward recursive function that iterates over the list\njust once. Moreover, each list is automatically sorted by length. Thus, done\ncan be completed in constant time since it just needs to look at the first\nelement of the list:\n\nFinally, the check function determines whether the candidate at the top of acc\nmatches the current character of the text:\n\nFor the remaining algorithms, done and check stay the same.\n\n## 5 Morris\u2013Pratt\n\nTake another look at Figure 3. There is yet more structure that can be\nexploited. In particular, two key properties unlock the secret to KMP:\n\n  1. 1\\. For each pattern suffix, there is only one column \u201cshape\u201d where that suffix is top.\n\n  2. 2\\. The rest field of any column is a prior column.\n\nThese properties hold for all choices of pattern and text; both can be proved\ninductively using the definition of step. Informally:\n\n  1. 1\\. To start with, there is only one accumulator: init. A new accumulator can only be generated by calling step acc x when check acc x holds. Doing so yields a new accumulator, where top has shrunk by one character. Additionally, there is only one x such that check acc x holds. Thus, there is only one accumulator of size n, of size n\u22121n\u22121, and so forth. Figure 4 shows the five column \u201cshapes\u201d for the pattern mama.\n\nFig. 4. Column shapes with forward arrows.\n\n  2. 2\\. The rest of column init is empty. All other accumulator values must have been generated by calling step acc x when check acc x holds. Thus, step returns a column where rest is step r (head t). This expression returns a prior column. Figure 5 shows the five columns where rest is indicated by a dashed arrow.\n\nFig. 5. Column shapes with backward arrows.\n\nBefore, we assumed that columns could be any set of pattern suffixes. There\nare 2n such sets. Now we know that only n of these sets can ever materialize.\nMoreover, each column can be represented as a pair consisting of a pattern\nsuffix and a prior column. Combining Figures 4 and 5 yields a compact\nrepresentation of all possible columns as a graph, pictured in Figure 6.\n\nFig. 6. MP graph.\n\nAll that remains is to construct this graph. Just add a next field for the\nforward edge\n\nand then compute its value with a \u201csmart\u201d constructor (called make here):\n\nNote how the determination of successor columns has been moved from step (in\nverticalList) to the constructor (in mp). As a result, init is now the graph\nfrom Figure 6. Then, step traverses this graph instead of recomputing\nsuccessors across the entirety of the text.\n\nIn a call-by-value language, this definition would fail because Figure 6 is\ncyclic. The circularity arises because init is defined in terms of make, which\ncalls step, which returns init in the base case. Fortunately, this kind of\ncyclic dependency is perfectly acceptable in a lazy language such as Haskell.\n\nThis algorithm is called Morris\u2013Pratt (MP), and it runs in linear time. Just a\nsmall tweak delivers the full KMP algorithm.\n\n### Additional notes\n\nOne perspective is that Figure 6 depicts a two-way DFA (Rabin & Scott,\nReference Rabin and Scott1959). Backward arrows represent a set of transitions\nlabeled by \u03a3\u2216{x} where x is the matching character. These backward arrows do\nnot consume any input (making it a two-way DFA).\n\nHaskell makes cyclic data construction especially convenient, but it is pretty\neasy in many eager languages too. Only next needs to be lazy. Appendix A gives\na Racket implementation of KMP that uses delay and force to achieve the\ndesired laziness.\n\nLaziness has another benefit. In an eager implementation, the entire graph is\nalways computed, even if it is not needed. In a lazy implementation, if the\npattern does not occur in the text, then not of all the graph is used. Thus,\nnot all of the graph is computed.\n\n## 6 Knuth\u2013Morris\u2013Pratt\n\nTake another look at Figure 6. Suppose the current accumulator is the fourth\ncolumn (where the top field is a) and the input character is m. That is a\nmismatch, so MP goes back two columns. That is also a mismatch, so it goes\nback to the first column. That is a match, so the algorithm ends up at the\nsecond column.\n\nNote how a mismatch at column a always skips over column ama because the top\nvalues of the two columns start with the same character. Hence, going directly\nto column mama saves a step. Figure 7 shows the result of transforming Figure\n6 according to this insight.\n\nFig. 7. KMP graph.\n\nFigure 8 shows the code that implements this optimization, delivering the full\nKMP algorithm. When constructing a column, KMP checks to see if the first\ncharacter of top matches that of the rest field\u2019s top. If so, it uses the rest\nfield\u2019s rest instead. Since this happens each time a column is constructed,\nrest is always going to be the \u201cbest\u201d column, that is, the earliest one where\ntop has a different first character.\n\nFig. 8. KMP algorithm.\n\n## 7 Correctness\n\nOne way to test that these implementations are faithful is to check that their\ntraces match a reference implementation (Danvy & Rohde, Reference Danvy and\nRohde2006). A trace is the sequence of character comparisons performed during\na search. Experiments on a large test suite confirm that the code given in\nSections 5 and 6 implement MP and KMP, respectively. Moreover, the number of\ncomparisons made in the KMP implementation is always the same or fewer than in\nthe MP implementation, exactly as expected.\n\n## 8 Conclusion\n\nNaive string search works row-by-row. Going column-by-column yields a new\nalgorithm, but it is still not linear time. MP takes advantage of the\nunderlying structure of columns, representing them as a cyclic graph. This\ninsight yields a linear-time algorithm. KMP refines this algorithm further,\nskipping over columns that are guaranteed to fail on a mismatched character.\n\n## Acknowledgments\n\nThe author thanks Matthias Felleisen, Sam Caldwell, Michael Ballantyne, and\nanonymous JFP reviewers for their comments and suggestions. This research was\nsupported by National Science Foundation grant SHF 2116372.\n\n## Conflicts of Interest\n\nNone.\n\n## A Racket code\n\n## References\n\nAger, M., Danvy, O. & Rohde, H. (2003) Fast partial evaluation of pattern\nmatching in strings. In Partial Evaluation and Semantics-Based Program\nManipulation, pp. 3\u20139.CrossRefGoogle Scholar\n\nBaeza-Yates, R. & Gonnet, G. (1992) A new approach to text searching. Commun.\nACM 35(10), 74\u201382.CrossRefGoogle Scholar\n\nBird, R. (2010) Pearls of Functional Algorithm Design. Cambridge\nUniversity.Google Scholar\n\nBrzozowski, J. (1964) Derivatives of regular expressions. J. ACM 11(4),\n481\u2013494.Google Scholar\n\nCook, S. (1972) Linear time simulation of deterministic two-way pushdown\nautomata. Inf. Process. 71, 75\u201380.Google Scholar\n\nColussi, L. (1991) Correctness and efficiency of pattern matching algorithms.\nInf. Comput. 95, 225\u2013251.CrossRefGoogle Scholar\n\nCormen, T., Leiserson, C., Rivest, R. & Stein, C. (2009) Introduction to\nAlgorithms. MIT.Google Scholar\n\nDanvy, O. & Rohde, H. (2006) On obtaining the Boyer\u2013Moore string-matching\nalgorithm by partial evaluation. Inf. Process. Lett. 99(4),\n158\u2013162.CrossRefGoogle Scholar\n\nHern\u00e1ndez, M., & Rosenblueth, D. (2001) Development reuse and the logic\nprogram derivation of two string-matching algorithms. In Conference on\nPrinciples and Practice of Declarative Programming, pp. 38\u201348.Google Scholar\n\nKnuth, D., Morris, J. & Pratt, V. (1977) Fast pattern matching in strings.\nSIAM J. Comput. 6(2), 323\u2013350.Google Scholar\n\nOwens, S., Reppy, J. & Turon, A. (2009) Regular-expression derivatives re-\nexamined. J. Funct. Program. 19(2), 173\u2013190.CrossRefGoogle Scholar\n\nRabin, M. & Scott, D. (1959) Finite automata and their decision problems. IBM\nJ. Res. Dev. 3(2), 114\u2013125.CrossRefGoogle Scholar\n\nSedgewick, R. & Wayne, K. (2011) Algorithms. Addison-Wesley\nProfessional.Google Scholar\n\nTakeichi, M. & Akama, Y. (1990) Deriving a functional Knuth-Morris-Pratt\nalgorithm. J. Inf. Process. 13(4), 522\u2013528.Google Scholar\n\n## Related content\n\nAI-generated results: by\n\n    UNSILO [Opens in a new window]\n\n### Complex Words\n\nType\n\n    Book\nTitle\n\n    Complex Words\nAuthors\n\nJournal\n\n    Complex Words: Advances in Morphology\n\nPublished online:\n\n    18 September 2020\n\n### Searching Strings by Substring\n\nType\n\n    Chapter\nTitle\n\n    Searching Strings by Substring\nAuthors\n\n    Paolo Ferragina\nJournal\n\n    Pearls of Algorithm Engineering\n\nPublished online:\n\n    8 June 2023\n\n### Algorithms on Words\n\nType\n\n    Chapter\nTitle\n\n    Algorithms on Words\nAuthors\n\n    M. Lothaire\nJournal\n\n    Applied Combinatorics on Words\n\nPublished online:\n\n    5 June 2013\n\n### RESEARCHING VOCABULARY THROUGH A WORD KNOWLEDGE FRAMEWORK\n\nType\n\n    Article\nTitle\n\n    RESEARCHING VOCABULARY THROUGH A WORD KNOWLEDGE FRAMEWORK\nAuthors\n\n    Norbert Schmitt and Paul Meara\nJournal\n\n    Studies in Second Language Acquisition\n\nPublished online:\n\n    1 March 1997\n\n### Efficient Data Structures\n\nType\n\n    Chapter\nTitle\n\n    Efficient Data Structures\nAuthors\n\n    Maxime Crochemore , Thierry Lecroq and Wojciech Rytter\nJournal\n\n    125 Problems in Text Algorithms\n\nPublished online:\n\n    10 June 2021\n\n### Suffix arrays\n\nType\n\n    Chapter\nTitle\n\n    Suffix arrays\nAuthors\n\n    Maxime Crochemore , Christophe Hancart and Thierry Lecroq\nJournal\n\n    Algorithms on Strings\n\nPublished online:\n\n    3 October 2009\n\n### A general framework for the derivation of regular expressions\n\nType\n\n    Article\nTitle\n\n    A general framework for the derivation of regular expressions\nAuthors\n\n    Pascal Caron , Jean-Marc Champarnaud and Ludovic Mignot\nJournal\n\n    RAIRO - Theoretical Informatics and Applications\n\nPublished online:\n\n    27 May 2014\n\n### Structures for Indexes\n\nType\n\n    Chapter\nTitle\n\n    Structures for Indexes\nAuthors\n\n    M. Lothaire\nJournal\n\n    Applied Combinatorics on Words\n\nPublished online:\n\n    5 June 2013\n\n### Construction of tree automata from regular expressions\n\nType\n\n    Article\nTitle\n\n    Construction of tree automata from regular expressions\nAuthors\n\n    Dietrich Kuske and Ingmar Meinecke\nJournal\n\n    RAIRO - Theoretical Informatics and Applications\n\nPublished online:\n\n    22 August 2011\n\n### Inference of Network Expressions\n\nType\n\n    Chapter\nTitle\n\n    Inference of Network Expressions\nAuthors\n\n    M. Lothaire\nJournal\n\n    Applied Combinatorics on Words\n\nPublished online:\n\n    5 June 2013\n\nFig. 1. Naive string search (horizontal).\n\nFig. 2. Naive string search (vertical).\n\nFig. 3. Columns as lists.\n\nFig. 4. Column shapes with forward arrows.\n\nFig. 5. Column shapes with backward arrows.\n\nFig. 6. MP graph.\n\nFig. 7. KMP graph.\n\nFig. 8. KMP algorithm.\n\nSubmit a response\n\n## Discussions\n\nNo Discussions have been published for this article.\n\n# Cited by\n\nLoading...\n\nCited by\n\n  * 0\n\nNo CrossRef data available.\n\nGoogle Scholar Citations\n\nView all Google Scholar citations for this article.\n\n\u00d7\n\n  * Librarians\n  * Authors\n  * Publishing partners\n  * Agents\n  * Corporates\n\n  * Additional Information\n\n    * Accessibility\n    * Our blog\n    * News\n    * Contact and help\n    * Cambridge Core legal notices\n    * Feedback\n    * Sitemap\n\n## Join us online\n\n  * Legal Information\n\n    * Rights & Permissions\n    * Copyright\n    * Privacy Notice\n    * Terms of use\n    * Cookies Policy\n    * \u00a9 Cambridge University Press 2024\n    * Back to top\n\n  * \u00a9 Cambridge University Press 2024\n  * Back to top\n\nCancel\n\nConfirm\n\n\u00d7\n\n# Save article to Kindle\n\nTo save this article to your Kindle, first ensure coreplatform@cambridge.org\nis added to your Approved Personal Document E-mail List under your Personal\nDocument Settings on the Manage Your Content and Devices page of your Amazon\naccount. Then enter the \u2018name\u2019 part of your Kindle email address below. Find\nout more about saving to your Kindle.\n\nNote you can select to save to either the @free.kindle.com or @kindle.com\nvariations. \u2018@free.kindle.com\u2019 emails are free but can only be saved to your\ndevice when it is connected to wi-fi. \u2018@kindle.com\u2019 emails can be delivered\neven when you are not connected to wi-fi, but note that service fees apply.\n\nFind out more about the Kindle Personal Document Service.\n\nKnuth\u2013Morris\u2013Pratt illustrated\n\n  * Volume 34\n  * CAMERON MOY ^(a1)\n  * DOI: https://doi.org/10.1017/S0956796824000017\n\n\u00d7\n\n# Save article to Dropbox\n\nTo save this article to your Dropbox account, please select one or more\nformats and confirm that you agree to abide by our usage policies. If this is\nthe first time you used this feature, you will be asked to authorise Cambridge\nCore to connect with your Dropbox account. Find out more about saving content\nto Dropbox.\n\nKnuth\u2013Morris\u2013Pratt illustrated\n\n  * Volume 34\n  * CAMERON MOY ^(a1)\n  * DOI: https://doi.org/10.1017/S0956796824000017\n\n\u00d7\n\n# Save article to Google Drive\n\nTo save this article to your Google Drive account, please select one or more\nformats and confirm that you agree to abide by our usage policies. If this is\nthe first time you used this feature, you will be asked to authorise Cambridge\nCore to connect with your Google Drive account. Find out more about saving\ncontent to Google Drive.\n\nKnuth\u2013Morris\u2013Pratt illustrated\n\n  * Volume 34\n  * CAMERON MOY ^(a1)\n  * DOI: https://doi.org/10.1017/S0956796824000017\n\n\u00d7\n\n\u00d7\n\n#### Reply to: Submit a response\n\n# Citation Tools\n\nCopy and paste a formatted citation or download in your chosen format\n\nLoading citation...\n\n\u00d7\n\n", "frontpage": false}
