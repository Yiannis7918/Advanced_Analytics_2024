{"aid": "40076516", "title": "Python Tutorial: Use TensorFlow to Generate Predictive Text", "url": "https://thenewstack.io/python-tutorial-use-tensorflow-to-generate-predictive-text/", "domain": "thenewstack.io", "votes": 1, "user": "mooreds", "posted_at": "2024-04-18 14:15:49", "comments": 0, "source_title": "Python Tutorial: Use TensorFlow to Generate Predictive Text", "source_text": "Python Tutorial: Use TensorFlow to Generate Predictive Text - The New Stack\n\nTNS\n\nSUBSCRIBE\n\nJoin our community of software engineering leaders and aspirational\ndevelopers. Always stay in-the-know by getting the most important news and\nexclusive content delivered fresh to your inbox to learn more about at-scale\nsoftware development.\n\nREQUIRED\n\nIt seems that you've previously unsubscribed from our newsletter in the past.\nClick the button below to open the re-subscribe form in a new tab. When you're\ndone, simply close that tab and continue with this form to complete your\nsubscription.\n\nThe New Stack does not sell your information or share it with unaffiliated\nthird parties. By continuing, you agree to our Terms of Use and Privacy\nPolicy.\n\nWelcome and thank you for joining The New Stack community!\n\nPlease answer a few simple questions to help us deliver the news and resources\nyou are interested in.\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nGreat to meet you!\n\nTell us a bit about your job so we can cover the topics you find most\nrelevant.\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nREQUIRED\n\nWelcome!\n\nWe\u2019re so glad you\u2019re here. You can expect all the best TNS content to arrive\nMonday through Friday to keep you on top of the news and at the top of your\ngame.\n\nWhat\u2019s next?\n\nCheck your inbox for a confirmation email where you can adjust your\npreferences and even join additional groups.\n\nFollow TNS on your favorite social media networks.\n\nBecome a TNS follower on LinkedIn.\n\nCheck out the latest featured and trending stories while you wait for your\nfirst TNS newsletter.\n\nPREV\n\n1 of 2\n\nNEXT\n\nVOXPOP\n\nTech Conferences: Does Your Employer Pay?\n\nDoes your employer pay for you to attend tech conferences?\n\n\u2713\n\nYes, registration and travel are comped.\n\n0%\n\n\u2713\n\nYes, just registration but not travel expenses.\n\n0%\n\n\u2713\n\nYes, travel expenses but not registration.\n\n0%\n\n\u2713\n\nOnly virtual conferences.\n\n0%\n\n\u2713\n\nNo reimbursement.\n\n0%\n\nThanks for your opinion! Subscribe below to get the final results, published\nexclusively in our TNS Update newsletter:\n\nARCHITECTURE\n\nCloud Native Ecosystem Containers Edge Computing Microservices Networking\nServerless Storage\n\nENGINEERING\n\nAI Large Language Models Frontend Development Software Development API\nManagement Python JavaScript TypeScript WebAssembly Cloud Services Data\nSecurity\n\nOPERATIONS\n\nPlatform Engineering Operations CI/CD Tech Careers Tech Culture DevOps\nKubernetes Observability Service Mesh\n\nCHANNELS\n\nPodcasts Ebooks Events Newsletter TNS RSS Feeds\n\nTHE NEW STACK\n\nAbout / Contact Sponsors Sponsorship Contributions\n\nPODCASTS EBOOKS EVENTS NEWSLETTER\n\nARCHITECTURE ENGINEERING OPERATIONS\n\nCloud Native Ecosystem Containers Edge Computing Microservices Networking\nServerless Storage\n\nYour Engineering Organization Is too Expensive\n\nApr 17th 2024 11:19am, by Luca Galante\n\nTetrate Enterprise Gateway for Envoy Graduates\n\nApr 10th 2024 9:00am, by Steven J. Vaughan-Nichols\n\nThe Open Source Market\u2019s in Flux. How Can IT Managers Cope?\n\nApr 8th 2024 10:57am, by Joe Fay\n\nUse Podman to Create and Work with Virtual Machines\n\nApr 6th 2024 6:00am, by Jack Wallen\n\nKubeCon EU Q&A: Red Hat Engineer Bethany Griggs on Backstage\n\nApr 5th 2024 1:00pm, by Raghavan Srinivas\n\nKubernetes vs. YARN for Resource Management: How to Choose\n\nApr 10th 2024 8:16am, by Jacob Simkovich\n\nUse Podman to Create and Work with Virtual Machines\n\nApr 6th 2024 6:00am, by Jack Wallen\n\nPodman 5 Arrives with Multiplatform Images, VM Support\n\nApr 4th 2024 5:00am, by Jack Wallen\n\nChainguard: Outdated Containers Accumulate Vulnerabilities\n\nMar 29th 2024 3:00am, by Joab Jackson\n\nEvolve Manual and Templated Dockerfiles with Automation\n\nMar 26th 2024 10:33am, by Rak Siva\n\nChipmakers Putting a Laser Focus on Edge AI\n\nApr 12th 2024 10:06am, by Jeffrey Burt\n\nThe Future of AI: Hybrid Edge Deployments Are Indispensable\n\nMar 22nd 2024 10:00am, by Luis Ceze\n\nHow RapidAI Uses Edge, Kubernetes and AI to Boost Stroke Care\n\nMar 15th 2024 10:30am, by Charles Humble\n\nTrusted Boot: What to Know About Securing Devices at the Edge\n\nMar 14th 2024 7:15am, by Ettore di Giacinto\n\nArchitecting for Industrial IoT Workloads: A Blueprint\n\nJan 31st 2024 7:34am, by Dunith Danushka\n\nAPI Design Is Pretty Bad \u2014 Here's How to Fix It\n\nApr 3rd 2024 6:01am, by Lebin Cheng\n\nWill Spotify Open Source its Microservices Framework?\n\nApr 2nd 2024 7:45am, by Loraine Lawson\n\nEnhancing Business Security and Compliance with Service Mesh\n\nApr 1st 2024 10:00am, by Ninad Desai\n\n10 Ways Kubernetes Observability Boosts Productivity, Cuts Costs\n\nMar 27th 2024 6:08am, by Eric Schabell\n\nEvolve Manual and Templated Dockerfiles with Automation\n\nMar 26th 2024 10:33am, by Rak Siva\n\nEnhancing Kubernetes Network Security with Microsegmentation\n\nApr 11th 2024 6:23am, by Dhiraj Sehgal\n\nTetrate Enterprise Gateway for Envoy Graduates\n\nApr 10th 2024 9:00am, by Steven J. Vaughan-Nichols\n\nZero Trust for Legacy Apps: Load Balancer Layer Can Be a Solution\n\nApr 10th 2024 7:22am, by Prabhat Dixit\n\nHow Observability Is Different for Web3 Apps\n\nMar 15th 2024 12:00pm, by Sarah Morgan\n\nSimplify Kubernetes Hosted Control Planes with K0smotron\n\nMar 11th 2024 10:00am, by Jussi Nummelin\n\nMeet DBOS: A Database Alternative to Kubernetes\n\nMar 12th 2024 4:00am, by Joab Jackson\n\nPulumi Templates for GenAI Stacks: Pinecone, LangChain First\n\nFeb 21st 2024 9:00am, by Joab Jackson\n\nCNCF CloudEvents: A Li'l Message Envelope That Travels Far\n\nJan 31st 2024 4:00am, by Joab Jackson\n\nBringing the AWS Serverless Strategy to Azure\n\nJan 19th 2024 6:00am, by Rak Siva\n\nServerless Computing In 2024: GenAI Influence, Security, 5G\n\nJan 4th 2024 5:00am, by Chris J. Preimesberger\n\nHow to Get Peak Performance without a Vast Amount of Memory\n\nApr 9th 2024 10:17am, by Behrad Babaee\n\nFrom Postgres to ScyllaDB NoSQL, with a 349x Speed Boost\n\nApr 1st 2024 11:27am, by Cynthia Dunlop\n\nThe Architect\u2019s Guide: A Modern Data Lake Reference Architecture\n\nMar 26th 2024 9:17am, by Keith Pijanowski\n\nCloud Data Migration or Cloud Data Tiering?\n\nMar 25th 2024 10:00am, by Kumar Goswami\n\nKubeCon24: MinIO Object Store Equipped with Enterprise Features\n\nMar 19th 2024 2:00pm, by Joab Jackson\n\nAI Large Language Models Frontend Development Software Development API\nManagement Python JavaScript TypeScript WebAssembly Cloud Services Data\nSecurity\n\nApplying Agile Techniques to AI: Lessons from Amazon Fresh\n\nApr 17th 2024 5:00am, by David Eastman\n\nKey Infrastructure Takeaways from Google Cloud Next 2024\n\nApr 16th 2024 12:00pm, by Chris J. Preimesberger\n\nPython Tutorial: Use TensorFlow to Generate Predictive Text\n\nApr 16th 2024 11:00am, by Ryan Cartwright\n\nHow One Programmer Built an AI-Powered Interactive FAQ\n\nApr 16th 2024 9:04am, by Loraine Lawson\n\nGenAI Acceleration Depends on Infrastructure as Code\n\nApr 16th 2024 6:13am, by Jen Aspesi\n\nHow One Programmer Built an AI-Powered Interactive FAQ\n\nApr 16th 2024 9:04am, by Loraine Lawson\n\nA Developer's Guide to Getting Started with LlamaIndex\n\nApr 13th 2024 5:00am, by David Eastman\n\nTool Fragmentation \u2014 Is There a Fix?\n\nApr 12th 2024 9:37am, by Burhan Drak Sibai\n\n3 Reasons Tech Execs Are Slowing Down GenAI Projects\n\nApr 12th 2024 6:04am, by Mandi Walls\n\nA Coder Perspective: What It's Like to Develop an AI App\n\nApr 11th 2024 9:47am, by Loraine Lawson\n\nTop 5 Underutilized JavaScript Features\n\nApr 16th 2024 10:30am, by Alexander T. Williams\n\nHow One Programmer Built an AI-Powered Interactive FAQ\n\nApr 16th 2024 9:04am, by Loraine Lawson\n\nDev News: AI Coding Agent, Nue Glows, and New Android Beta\n\nApr 13th 2024 4:00am, by Loraine Lawson\n\nTool Fragmentation \u2014 Is There a Fix?\n\nApr 12th 2024 9:37am, by Burhan Drak Sibai\n\nA Coder Perspective: What It's Like to Develop an AI App\n\nApr 11th 2024 9:47am, by Loraine Lawson\n\nScala Creator Proposes 'Lean Scala' for Simpler Code\n\nApr 17th 2024 10:14am, by Darryl K. Taft\n\nLinux Foundation Overture Maps the Globe with Open Data\n\nApr 17th 2024 9:04am, by Joab Jackson\n\nZero-Day Vulnerabilities: A Beginner\u2019s Guide\n\nApr 17th 2024 8:31am, by Aaron Linskens\n\nWhat Are Python 'Sets' and How Do You Use Them?\n\nApr 17th 2024 6:17am, by Jack Wallen\n\nMeet the System Package Data Exchange: SPDX 3.0, with Profiles\n\nApr 16th 2024 3:28pm, by Steven J. Vaughan-Nichols\n\nIs Platform Engineering Really Just API Governance?\n\nApr 15th 2024 12:10pm, by Jennifer Riggins\n\nWhy You Should Have 100% Faith in Zero Trust\n\nApr 15th 2024 8:11am, by Kay James\n\nWhy Don\u2019t API Platform Efforts Deliver?\n\nApr 15th 2024 6:54am, by Sagar Batchu\n\nIngress: Kubernetes Example with ngrok\n\nApr 11th 2024 9:34am, by Eric Goebelbecker\n\nHasura Visualizes Data API Integration into a 'Supergraph'\n\nApr 4th 2024 3:00am, by Joab Jackson\n\nWhat Are Python 'Sets' and How Do You Use Them?\n\nApr 17th 2024 6:17am, by Jack Wallen\n\nPython Tutorial: Use TensorFlow to Generate Predictive Text\n\nApr 16th 2024 11:00am, by Ryan Cartwright\n\nJavaScript, Python Neck and Neck in GitHub Developer Usage\n\nApr 15th 2024 9:45am, by Darryl K. Taft\n\nA Coder Perspective: What It's Like to Develop an AI App\n\nApr 11th 2024 9:47am, by Loraine Lawson\n\nHow (and When) to Use a Python While Loop\n\nApr 10th 2024 7:55am, by Jack Wallen\n\nTop 5 Underutilized JavaScript Features\n\nApr 16th 2024 10:30am, by Alexander T. Williams\n\nJavaScript, Python Neck and Neck in GitHub Developer Usage\n\nApr 15th 2024 9:45am, by Darryl K. Taft\n\nDev News: React 19, Nuxt 3.11, a Python GUI, Tabnine LLMs\n\nApr 6th 2024 5:00am, by Loraine Lawson\n\nDev News: Deno Supports Open Source Repository JSR and an Offline AI\n\nMar 30th 2024 4:00am, by Loraine Lawson\n\nDev News: WordPress 6.5, Angular Signals and .NET Components\n\nMar 23rd 2024 4:00am, by Loraine Lawson\n\nDev News: Deno Supports Open Source Repository JSR and an Offline AI\n\nMar 30th 2024 4:00am, by Loraine Lawson\n\nAdvanced OOP in TypeScript: Interfaces and Abstract Classes\n\nMar 22nd 2024 10:30am, by Bob Reselman\n\nHow to Get Advantages of TypeScript in JavaScript\n\nOct 27th 2023 10:51am, by Phil Nash\n\nDev News: Udemy's New Docker Program, Plus TypeScript Beta\n\nOct 7th 2023 5:01am, by Loraine Lawson\n\nThe Angular Renaissance: Why Frontend Devs Should Revisit It\n\nSep 26th 2023 8:15am, by Loraine Lawson\n\nWebAssembly Adoption: Is Slow and Steady Winning the Race?\n\nApr 10th 2024 5:00am, by Richard Gall\n\nWhy WASI Preview 2 Makes WebAssembly Production Ready\n\nApr 5th 2024 6:21am, by Oscar Spencer\n\nKubeCon Europe: WebAssembly, eBPF Are Huge for Cloud Native\n\nMar 29th 2024 8:24am, by B. Cameron Gain\n\nFermyon Says WebAssembly on Kubernetes Is Now Doable\n\nMar 28th 2024 6:19am, by B. Cameron Gain\n\nWhy Wasm Wins Where Java Applets Failed\n\nMar 12th 2024 10:22am, by Liam Crilly\n\nAnswers to the 5 Most Common Cloud Cost-Optimization Questions\n\nApr 17th 2024 7:38am, by Roman Yegorov\n\nKey Infrastructure Takeaways from Google Cloud Next 2024\n\nApr 16th 2024 12:00pm, by Chris J. Preimesberger\n\nGoogle Vaunts New Gemini Code Assist Tool at Cloud Next 2024\n\nApr 10th 2024 9:05am, by Chris J. Preimesberger\n\nIf Dev and Ops Had a Baby \u2014 It Would Be Called Winglang\n\nApr 5th 2024 10:00am, by Elad Ben-Israel\n\nLack of Data Mobility Is a Root Cause of Cloud Native Ills\n\nApr 5th 2024 9:17am, by B. Cameron Gain\n\nPython Tutorial: Use TensorFlow to Generate Predictive Text\n\nApr 16th 2024 11:00am, by Ryan Cartwright\n\nQuery Apache Kafka with SQL\n\nApr 16th 2024 7:51am, by St\u00e9phane Derosiaux\n\nHow to Get Peak Performance without a Vast Amount of Memory\n\nApr 9th 2024 10:17am, by Behrad Babaee\n\nUsing SQL-Powered RAG to Better Analyze Database Data with GenAI\n\nApr 9th 2024 9:08am, by Marty Gubar\n\n5 Key Considerations for Chatbot Design\n\nApr 5th 2024 12:00pm, by Asmitha Rathis\n\nZero-Day Vulnerabilities: A Beginner\u2019s Guide\n\nApr 17th 2024 8:31am, by Aaron Linskens\n\nMeet the System Package Data Exchange: SPDX 3.0, with Profiles\n\nApr 16th 2024 3:28pm, by Steven J. Vaughan-Nichols\n\nLessons Learned about Secrets Protection after the Sisense Breach\n\nApr 15th 2024 10:42am, by David Melamed\n\nWhy You Should Have 100% Faith in Zero Trust\n\nApr 15th 2024 8:11am, by Kay James\n\nAttack (or Penetrate Test) Cloud Native the Easy Way\n\nApr 15th 2024 7:21am, by B. Cameron Gain\n\nPlatform Engineering Operations CI/CD Tech Careers Tech Culture DevOps\nKubernetes Observability Service Mesh\n\nYour Engineering Organization Is too Expensive\n\nApr 17th 2024 11:19am, by Luca Galante\n\nDrive Developer Self-Service with Crossplane, K8s and a Portal\n\nApr 17th 2024 9:46am, by Mor Paz\n\nWhat Comes after Internal Developer Platforms?\n\nApr 15th 2024 12:56pm, by Valerie Slaughter\n\nIs Platform Engineering Really Just API Governance?\n\nApr 15th 2024 12:10pm, by Jennifer Riggins\n\nIntegrating AI to Make Platform Engineering Intelligent\n\nApr 12th 2024 8:40am, by Michel Murabito\n\nGolang: How to Write a For Loop\n\nApr 16th 2024 5:00pm, by Jack Wallen\n\nWant to Be a Tech Company? Try Platform Engineering!\n\nApr 10th 2024 10:26am, by Luca Galante\n\nZero Trust for Legacy Apps: Load Balancer Layer Can Be a Solution\n\nApr 10th 2024 7:22am, by Prabhat Dixit\n\nHighlight.io: Open Source Application Monitoring for Developers\n\nApr 9th 2024 10:00am, by Jay Khatri\n\n2 Ways AI Assistants Are Changing Kubernetes Troubleshooting\n\nApr 8th 2024 12:00pm, by Blair Rampling\n\nAre You Delivering on Developer Experience?\n\nApr 16th 2024 10:00am, by No\u010dnica Mellifera\n\nWhat Comes after Internal Developer Platforms?\n\nApr 15th 2024 12:56pm, by Valerie Slaughter\n\nLessons Learned about Secrets Protection after the Sisense Breach\n\nApr 15th 2024 10:42am, by David Melamed\n\nWhy Don\u2019t API Platform Efforts Deliver?\n\nApr 15th 2024 6:54am, by Sagar Batchu\n\nGitOps Makes for Great DevEx, but Pragmatism Matters\n\nApr 9th 2024 6:30am, by Steve Fenton\n\nWhy Military Vets Are the Drama-Free Problem Solvers You Need\n\nMar 28th 2024 9:20am, by Joe Fay\n\nUsing AI to Improve Bad Business Writing\n\nMar 26th 2024 5:00am, by Jon Udell\n\nDevelopers Share What Helped Them Land New Roles\n\nMar 25th 2024 6:45am, by Jeff James\n\nUS Tech Cannot Comprehend the Digital Nomad Way of Life\n\nMar 23rd 2024 3:00am, by Paul Scanlon\n\nTech Works: How to Identify and Address Burnout on Your Team\n\nMar 22nd 2024 5:00am, by Jennifer Riggins\n\nAre You Delivering on Developer Experience?\n\nApr 16th 2024 10:00am, by No\u010dnica Mellifera\n\nIT Pioneers Assess the Future Impact of AI\n\nApr 14th 2024 6:00am, by David Cassel\n\nC# Compiler Lead Jared Parsons on 20 Years at Microsoft\n\nApr 7th 2024 6:00am, by David Cassel\n\nCustomer-Obsessed? 4 Steps to Improve Your Culture\n\nApr 5th 2024 8:21am, by Bharani Manapragada\n\nDeveloper Joy is the Productivity Metric You\u2019re Missing\n\nApr 4th 2024 12:06pm, by Jennifer Riggins\n\nQuery Apache Kafka with SQL\n\nApr 16th 2024 7:51am, by St\u00e9phane Derosiaux\n\nGitOps Makes for Great DevEx, but Pragmatism Matters\n\nApr 9th 2024 6:30am, by Steve Fenton\n\nPlatform Engineering and GenAI: \u2018Get Your House in Order\u2019\n\nApr 9th 2024 5:00am, by Loraine Lawson\n\nHow Platform Engineering Takes on DevOps Challenges\n\nApr 8th 2024 6:49am, by Kenn Hussey\n\nWhy Flux Isn\u2019t Dying after Weaveworks\n\nApr 8th 2024 5:00am, by B. Cameron Gain\n\nDrive Developer Self-Service with Crossplane, K8s and a Portal\n\nApr 17th 2024 9:46am, by Mor Paz\n\nGrafana 11: No Need to Create PromQL Queries for Prometheus\n\nApr 17th 2024 4:00am, by B. Cameron Gain\n\nAttack (or Penetrate Test) Cloud Native the Easy Way\n\nApr 15th 2024 7:21am, by B. Cameron Gain\n\nIngress: Kubernetes Example with ngrok\n\nApr 11th 2024 9:34am, by Eric Goebelbecker\n\nEnhancing Kubernetes Network Security with Microsegmentation\n\nApr 11th 2024 6:23am, by Dhiraj Sehgal\n\nGrafana 11: No Need to Create PromQL Queries for Prometheus\n\nApr 17th 2024 4:00am, by B. Cameron Gain\n\nHighlight.io: Open Source Application Monitoring for Developers\n\nApr 9th 2024 10:00am, by Jay Khatri\n\nHow Conviva Uses Endpoint Event Data to Measure UX at Scale\n\nMar 29th 2024 9:16am, by Vicki Walker\n\nLarge Language Model Observability: The Breakdown\n\nMar 28th 2024 1:46pm, by Alex Williams\n\nWill the Real Test Observability Please Stand up?\n\nMar 27th 2024 7:27am, by Ken Hamric\n\nEnhancing Business Security and Compliance with Service Mesh\n\nApr 1st 2024 10:00am, by Ninad Desai\n\nSome Linkerd Users Must Pay: Fear and Anger Explained\n\nFeb 28th 2024 9:21am, by B. Cameron Gain\n\nBuoyant Revises Release Model for the Linkerd Service Mesh\n\nFeb 21st 2024 9:30am, by Joab Jackson\n\nIstio Advisor Plus GPT: Expert System Meets AI for Service Mesh\n\nDec 14th 2023 12:15pm, by Steven J. Vaughan-Nichols\n\nUsing JWTs to Authenticate Services Unravels API Gateways\n\nNov 8th 2023 6:53am, by Christian Posta and Peter Jausovec\n\n2024-04-16 11:00:59\n\nPython Tutorial: Use TensorFlow to Generate Predictive Text\n\nsponsor-nitric,sponsored-post-contributed,\n\nAI / Data / Python\n\n# Python Tutorial: Use TensorFlow to Generate Predictive Text\n\nThe tutorial will show you how to make a simple, serverless text-based\nprediction model based on Jane Austen\u2019s \"Pride and Prejudice.\"\n\nApr 16th, 2024 11:00am by Ryan Cartwright\n\nImage from C. Peiro on Shutterstock.\n\nVOXPOP\n\nTry our new 5 second poll. It's fast. And it's fun!\n\nTech Conferences: Does Your Employer Pay?\n\nDoes your employer pay for you to attend tech conferences?\n\nYes, registration and travel are comped.\n\nYes, just registration but not travel expenses.\n\nYes, travel expenses but not registration.\n\nOnly virtual conferences.\n\nNo reimbursement.\n\nWe'd love to hear what you think.\n\nNitric sponsored this post.\n\nPredictive text is something we use every day. We use it when we send text\nmessages, emails and anywhere else you might write. It has become so\ncommonplace that it\u2019s an expected feature across most platforms. Given its\nubiquity, I was curious to see how hard it was to create my own predictive\ntext model. I wasn\u2019t expecting it to be perfect, as not even the top\npredictive text models are, but I thought it would be a fun project to learn\nmore about machine learning and natural language processing.\n\nThe tutorial will show you how to make a simple text-based prediction model\nbased off of Jane Austen\u2019s \u201cPride and Prejudice.\u201d Due to the training data\nbeing based on a romantic novel, I was expecting that the resulting predictive\ntext would be very skewed towards the themes of love and marriage. We\u2019ll test\nthis theory at the end.\n\nThe interface for this will be an API. It will take prediction queries and\nreturn the three most likely words to come afterward. We\u2019ll deploy the API to\nthe cloud so that it can be used as a third-party API in other applications,\nlike a chat app or anywhere else you might want to embed predictive text. If\nyou want to skip to the end and deploy it yourself, you can find the full\nsource code in our examples repo.\n\nPython will be the base language because the machine learning (ML) ecosystem\naround Python is fantastic, enabling us to use tools like TensorFlow, Keras\nand NumPy. TensorFlow acts as a kind of ML toolbox. There are plenty of\noptions, but we should use the right tool for the job.\n\nUsing a bidirectional long short-term memory recurrent neural network (Bi-\nLSTM) is ideal for our predictive text problem. This type of neural network,\napart from having a very long name, also has the unique capability to store\nboth long- and short-term context. We\u2019ll need short-term memory to store the\nprevious words in the sentence and long-term memory to store the context of\nhow these words have been used in previous sentences.\n\nNitric is the cloud-aware framework that enhances developer productivity and\nops confidence, uniting backend and infrastructure code to build and ship\ncloud apps fast. Devs build your application, Platform determines the right\ninfrastructure and Nitric automates provisioning that works for both.\n\nLearn More\n\nThe latest from Nitric\n\nBuilding with Nitric - A Framework Demo\n\n29 March 2024\n\nCustomizing and Extending the Nitric Framework\n\n21 March 2024\n\nAchieve GitOps on Day One with IaC Automation\n\n20 March 2024\n\n## Step 1 \u2013 Set up the Project\n\nWe\u2019ll use the following tools:\n\n  * Pipenv for simplified dependency management\n  * The Nitric CLI for simple cloud backend infrastructure\n  * (optional) Your choice of an AWS, Google Cloud Platform (GCP) or Microsoft Azure account.\n\nStart by creating a new project for our API.\n\n1| nitric new prediction-api python-starter  \n---|---  \n  \nThen open the project in your editor of choice and resolve dependencies using\nPipenv.\n\n1| pipenv install --dev  \n---|---  \n  \n## Step 2 \u2013 Prepare the Data Set\n\nProject Gutenberg provides the \u201cPride and Prejudice\u201d text, so you can download\nthe file from there, or you can use the precleaned data from our example repo,\nwhich is the recommended approach. This text file will form the basis of our\ntraining data and will give our predictions a Jane Austen spin.\n\nTRENDING STORIES\n\n  1. Python Tutorial: Use TensorFlow to Generate Predictive Text\n  2. How (and When) to Use a Python While Loop\n  3. Insert Data into a MySQL Database via a Python Script\n  4. What Are Python Lambda Functions and How Do You Use Them?\n  5. MIT-Created Compiler Speeds up Python Code\n\nBefore we begin training our model, we want to make sure we explore and\npreprocess the training data to clean it up for quality training. Looking\nthrough the \u201cPride and Prejudice\u201d text, we find that Project Gutenberg adds a\nheader and a footer to the data. There are also volume headers, chapter\nheadings, punctuation and contractions that we\u2019ll remove. We\u2019ll also convert\nall the numbers to words \u2014 \u201c8\u201d to \u201ceight.\u201d This cleanup allows our training\ndata to be as versatile as possible, so predictions will be more cohesive.\n\nNow that we have our cleaned data, we\u2019ll tokenize the data so it can be\nprocessed by the model. To tokenize the data, we\u2019ll use Keras\u2019 preprocessing\nmodule, so we\u2019ll need to install the Keras module.\n\n1| pipenv install keras==2.15.0  \n---|---  \n  \nWe can then create and fit the tokenizer to the text. We\u2019ll initialize the Out\nof Vocabulary (OOV) token as <oov>. After it\u2019s fit to the text, we\u2019ll save it\nso we can use it later.\n\nimport pickle  \n---  \nfrom keras.preprocessing.text import Tokenizer  \n# Tokenize the data and fit it to the text  \ntokenizer = Tokenizer(oov_token='<oov>')  \ntokenizer.fit_on_texts(data.split())  \n# Save tokenizer  \nwith open('tokenizer.pickle', 'wb') as handle:  \npickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)  \n  \nview raw Nitric1.py hosted with \u2764 by GitHub\n\nNow we\u2019re ready to start training our model.\n\n## Step 3 \u2013 Train the Model\n\nTo train the model, we\u2019ll use a Bi-LSTM. This type of recurrent neural network\nis ideal for this problem since it enables the neural network to store the\ncontext of the previous words in the sentence.\n\nStart by loading the tokenizer we created in the preprocessing stage.\n\nimport pickle  \n---  \nwith open('tokenizer.pickle', 'rb') as handle:  \ntokenizer = pickle.load(handle)  \n  \nview raw Nitric2.py hosted with \u2764 by GitHub\n\nWe\u2019ll then create the input sequences to train our model. This works by\ngetting every six-word combination in the text. First, add NumPy as a\ndependency.\n\n1| pipenv install numpy  \n---|---  \n  \nThen we\u2019ll write the function to create the input sequences from the data.\n\nimport numpy as np  \n---  \nfrom keras.utils import pad_sequences  \ndef create_input_sequences(data: list[str], n_gram_size=6):  \n# Create n-gram input sequences based on an n-gram size of 6  \ninput_sequences = []  \ntoken_list = tokenizer.texts_to_sequences([data])[0]  \n# Sliding iteration which takes every 6 words in a row as an input sequence  \nfor i in range(1, len(token_list) - n_gram_size):  \nn_gram_sequence = token_list[i:i+n_gram_size]  \ninput_sequences.append(n_gram_sequence)  \n# Pad sequences  \nmax_sequence_len = max([len(x) for x in input_sequences])  \nreturn np.array(pad_sequences(input_sequences, maxlen=max_sequence_len,\npadding='pre')), max_sequence_len  \n  \nview raw nitric3.py hosted with \u2764 by GitHub\n\nWe\u2019ll then split the input sequences into labels, training and testing data.\n\nfrom keras.utils import to_categorical, pad_sequences  \n---  \nfrom sklearn.model_selection import train_test_split  \n# Create the features and labels and split the data into training and testing  \ndef create_training_data(input_sequences):  \n# Create features and labels  \nxs, labels = input_sequences[:,:-1], input_sequences[:,-1]  \nys = to_categorical(labels, num_classes=total_words)  \n# Split data  \nreturn train_test_split(xs, ys, test_size=0.1, shuffle=True)  \n  \nview raw Nitric4.py hosted with \u2764 by GitHub\n\nThe next part is fitting, compiling and training the model. We\u2019ll pass in the\ntraining data, which we have split into training and testing data. We can use\nthe model checkpoint callback, which will save the best iteration of our model\nat each epoch. To optimize our training speed, we\u2019ll also add an adaptive\nmoment estimation (ADAM) optimizer and a reduce learning rate on plateau\ncallback.\n\n# Create callbacks  \n---  \ncheckpoint = ModelCheckpoint(\"model.keras\", monitor='loss', verbose=1,\nsave_best_only=True, mode='auto')  \nreduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3,\nmin_lr=0.0001, verbose = 1)  \n# Create optimiser  \noptimizer = Adam(learning_rate=0.01)  \n  \nview raw Nitric5.py hosted with \u2764 by GitHub\n\nThen we\u2019ll add layers to the sequential model.\n\n# Create model  \n---  \nmodel = Sequential()  \nmodel.add(Embedding(total_words, 100, input_length=max_sequence_len-1))  \nmodel.add(Bidirectional(LSTM(512)))  \nmodel.add(Dense(total_words, activation='softmax'))  \nmodel.summary()  \n  \nview raw Nitric6.py hosted with \u2764 by GitHub\n\nFinally, we can put it all together and then compile the model using the\ntraining data.\n\nfrom keras.models import Sequential  \n---  \nfrom keras.layers import LSTM, Dense, Embedding, Bidirectional  \nfrom keras.optimizers import Adam  \nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau  \n# Train the model  \ndef train_model(X_train, y_train, total_words, max_sequence_len):  \n# Create callbacks  \ncheckpoint = ModelCheckpoint(\"model.keras\", monitor='loss', verbose=1,\nsave_best_only=True, mode='auto')  \nreduce = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3,\nmin_lr=0.0001, verbose = 1)  \n# Create optimiser  \noptimizer = Adam(learning_rate=0.01)  \n# Create model  \nmodel = Sequential()  \nmodel.add(Embedding(total_words, 100, input_length=max_sequence_len-1))  \nmodel.add(Bidirectional(LSTM(512)))  \nmodel.add(Dense(total_words, activation='softmax'))  \nmodel.summary()  \n# Compile model  \nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer,\nmetrics=['accuracy'])  \nmodel.fit(  \nX_train, y_train, epochs=20, batch_size=2000,  \ncallbacks=[  \ncheckpoint,  \nreduce,  \n]  \n)  \n  \nview raw Nitric7.py hosted with \u2764 by GitHub\n\nWith all the services defined, we can train our model with the cleaned data.\n\ndata = open('clean_data.txt', 'r').read().split(' ')  \n---  \ntotal_words = len(tokenizer.word_index) + 1  \ninput_sequences, max_sequence_len = create_input_sequences(data)  \nX_train, X_test, y_train, y_test = create_training_data(input_sequences)  \ntrain_model(X_train, y_train, total_words, max_sequence_len)  \n  \nview raw nitric8.py hosted with \u2764 by GitHub\n\nThe model checkpoint save callback will save the model as model.keras. We\u2019ll\nthen be able to load the model when we create our API.\n\n## Step 4 \u2013 Write the Text Prediction Function\n\nWe\u2019re ready to start predicting text. Starting with the hello.py file, we\u2019ll\nfirst write functions to load the model and tokenizer.\n\nimport pickle  \n---  \nfrom keras.models import load_model  \nmodel = None  \ntokenizer = None  \ndef load_tokenizer():  \nglobal tokenizer  \nif tokenizer is None:  \n# Load the tokenizer  \nwith open('tokenizer.pickle', 'rb') as handle:  \ntokenizer = pickle.load(handle)  \nreturn tokenizer  \ndef load_model():  \nglobal model  \nif model is None:  \n# Load the model  \nmodel = load_model('model.keras')  \nreturn model  \n  \nview raw Nitric9.py hosted with \u2764 by GitHub\n\nWe will then write a function to predict the next three most likely words.\nThis uses the tokenizer to create the same token list that was used to train\nthe model. We can then get a prediction of all the most likely words, which\nwe\u2019ll reduce down to three. We\u2019ll then get the actual word from the map of\ntokens by finding the word in the dictionary. The tokenizer word index is in\nthe form { \"word\": token_num }, such as { \"the\": 1, \"and\": 2 }. The\npredictions we receive will be an array of the token numbers.\n\n# Predict text based on a set of seed text  \n---  \n# Returns a list of 3 top choices for the next word  \ndef predict_text(seed_text: str) -> list[str]:  \n# Convert the seed text into a token list using the same process as the\nprevious tokenization  \nload_tokenizer()  \ntoken_list = tokenizer.texts_to_sequences([seed_text])[0]  \ntoken_list = pad_sequences([token_list], maxlen=5, padding='pre')  \n# Make the prediction  \nm = load_model()  \npredict_x = m.predict(token_list, batch_size=500, verbose=0)  \n# Find the top three words  \npredict_x = np.argpartition(predict_x, -3, axis=1)[0][-3:]  \n# Reverse the list so the most popular is first  \npredictions = list(predict_x)  \npredictions.reverse()  \n# Iterate over the predicted words, and find the word in the tokenizer\ndictionary that matches  \noutput_words = []  \nfor prediction in predictions:  \nfor word, index in tokenizer.word_index.items():  \nif prediction == index:  \noutput_words.append(word)  \nbreak  \nreturn output_words  \n  \nview raw Nitric10.py hosted with \u2764 by GitHub\n\n## Step 5 \u2013 Create the API\n\nUsing the predictive text function, we can create our API. I will be using the\nNitric framework for this, as it makes deploying our API very straightforward\nand gives us the choice of which cloud we want to use at the end.\n\nFirst, we will import the necessary modules for the Nitric SDK.\n\nfrom nitric.resources import api  \n---  \nfrom nitric.application import Nitric  \n  \nview raw Nitric11.py hosted with \u2764 by GitHub\n\nWe\u2019ll then define the API and our first route.\n\nmainApi = api(\"main\")  \n---  \n@mainApi.get(\"/prediction\")  \nasync def create_prediction(ctx) -> None:  \npass  \nNitric.run()  \n  \nview raw Nitric12.py hosted with \u2764 by GitHub\n\nWithin this function block, we want to define the code that will be run on a\nrequest. We\u2019ll accept the prompt to predict from via the query parameters.\nThis will mean that requests are in the form: /predictions?prompt=.\n\n@mainApi.get(\"/prediction\")  \n---  \nasync def create_prediction(ctx) -> None:  \nprompt = ctx.req.query.get(\"prompt\")  \nif prompt is None:  \nreturn  \nprompt = \" \".join(prompt)  \nNitric.run()  \n  \nview raw Nitric13.py hosted with \u2764 by GitHub\n\nNow that we have extracted the prompt from the user, we can pass this into the\nmodel for prediction. This will produce the three most likely next words and\nreturn them to the user.\n\n@mainApi.get(\"/prediction\")  \n---  \nasync def create_prediction(ctx) -> None:  \nprompt = ctx.req.query.get(\"prompt\")  \nif prompt is None:  \nreturn  \nprompt = \" \".join(prompt)  \nprediction = predict_text(prompt)  \nctx.res.body = f\"{prompt} {prediction}\"  \nNitric.run()  \n  \nview raw Nitric14.py hosted with \u2764 by GitHub\n\nThat\u2019s all there is to it. To test the function locally, we\u2019ll start the\nNitric server.\n\n1| nitric start  \n---|---  \n  \nYou can then make a request to the API using any HTTP client. Given the prompt\n\u201cWhat should I\u201d, it returns the most likely responses: \u201chave\u201d, \u201cthink\u201d and\n\u201csay\u201d.\n\ncurl \"http://localhost:4001/prediction?prompt=what%20should%20I\"  \n---  \nWhat should I ['have', 'think', 'say']  \n  \nview raw Nitric15.txt hosted with \u2764 by GitHub\n\nYou will find that the predictions have a lot of focus on family and weddings.\nThis shows that the training data, courtesy of Jane Austen, has a big effect\non the type of predictions that are produced. You can see these themes in the\nbelow examples where we start with a two-word sentence and see what the\npredictive text produces.\n\ngiven that [his, the, she]  \n---  \ngiven that his [two, being, sister]  \ngiven that his two [motives, days, dances]  \ngiven that his two sisters [and, the, were]  \ngiven that his two sisters were [engaged, the, in]  \ngiven that his two sisters were engaged [in, by, to]  \nyou must [be, now, feel]  \nyou must be [married, very, a]  \nyou must be married [and, said, to]  \nyou must be married and [i, you, at]  \nyou must be married and i [cannot, said flatter]  \nyou must be married and i cannot [pretend, help, be]  \n  \nview raw nitric16.py hosted with \u2764 by GitHub\n\n## Step 6 \u2013 Deploy to the Cloud\n\nYou can deploy to your cloud to enable use of the API by other projects.\nFirst, set up your credentials and any other cloud-specific configuration:\n\n  * AWS\n  * Azure\n  * GCP\n\nCreate your stack. This is an environment configuration file for the cloud\nprovider where your project will be deployed. For this project, I used Google\nCloud; however, it will work perfectly well if you prefer AWS or Azure.\n\n1| nitric stack new  \n---|---  \n  \nThis project will run as expected with a default memory configuration of\n512MB. However, to get instant predictions, we\u2019ll amend the memory to be 1GB.\nThis just means adding some config to the newly created stack file.\n\nprovider: nitric/gcp@1.3.1  \n---  \nregion: us-west2  \ngcp-project-id: gcp-project-123456  \nconfig:  \ndefault:  \ncloudrun:  \nmemory: 1024  \n  \nview raw Nitric17.py hosted with \u2764 by GitHub\n\nYou can then deploy using the following command:\n\n1| nitric up  \n---|---  \n  \nWhen deployment is finished, you\u2019ll get an endpoint so you can test your API\nin the cloud.\n\nIf you\u2019re just testing for now, you can tear down the stack with the following\ncommand:\n\n1| nitric down  \n---|---  \n  \nIf you want to learn more about using Nitric to quickly deploy Python and\nother language applications to your cloud, check out the session that Anmol\nKrishan Sachdeva and Kingsley Madikaegbu of Google are leading at Open Source\nSummit North America: \u201cThinking Beyond IaC: an OSS Approach to Cloud Agnostic\nInfra. Management Using Infra. from Code (IfC).\u201d\n\nRyan Cartwright, software engineer at Nitric, is passionate about learning and\nimproving the cloud development space for other developers. With skills across\nthe frontend and backend, Ryan embraces the challenges that the fast-paced\nstartup environment brings. Outside of work, he...\n\nRead more from Ryan Cartwright\n\nNitric sponsored this post.\n\nSHARE THIS STORY\n\nTRENDING STORIES\n\n  1. Python Tutorial: Use TensorFlow to Generate Predictive Text\n  2. How (and When) to Use a Python While Loop\n  3. Insert Data into a MySQL Database via a Python Script\n  4. What Are Python Lambda Functions and How Do You Use Them?\n  5. MIT-Created Compiler Speeds up Python Code\n\nSHARE THIS STORY\n\nTRENDING STORIES\n\n  1. Python Tutorial: Use TensorFlow to Generate Predictive Text\n  2. How (and When) to Use a Python While Loop\n  3. Insert Data into a MySQL Database via a Python Script\n  4. What Are Python Lambda Functions and How Do You Use Them?\n  5. MIT-Created Compiler Speeds up Python Code\n\nInsights From Our Sponsor\n\nNitric is the cloud-aware framework that enhances developer productivity and\nops confidence, uniting backend and infrastructure code to build and ship\ncloud apps fast. Devs build your application, Platform determines the right\ninfrastructure and Nitric automates provisioning that works for both.\n\nLearn More\n\nBuilding with Nitric - A Framework Demo\n\n29 March 2024\n\nCustomizing and Extending the Nitric Framework\n\n21 March 2024\n\nAchieve GitOps on Day One with IaC Automation\n\n20 March 2024\n\nCost Efficiencies with Azure and Serverless\n\n11 March 2024\n\nHow Nitric V1 Changes Cloud Development\n\n6 March 2024\n\n4 Lessons Learned from Building Microfrontends\n\n5 March 2024\n\nTNS DAILY NEWSLETTER Receive a free roundup of the most recent TNS articles in\nyour inbox each day.\n\nThe New Stack does not sell your information or share it with unaffiliated\nthird parties. By continuing, you agree to our Terms of Use and Privacy\nPolicy.\n\nARCHITECTURE\n\nCloud Native Ecosystem Containers Edge Computing Microservices Networking\nServerless Storage\n\nENGINEERING\n\nAI Large Language Models Frontend Development Software Development API\nManagement Python JavaScript TypeScript WebAssembly Cloud Services Data\nSecurity\n\nOPERATIONS\n\nPlatform Engineering Operations CI/CD Tech Careers Tech Culture DevOps\nKubernetes Observability Service Mesh\n\nCHANNELS\n\nPodcasts Ebooks Events Newsletter TNS RSS Feeds\n\nTHE NEW STACK\n\nAbout / Contact Sponsors Sponsorship Contributions\n\nroadmap.sh\n\nCommunity created roadmaps, articles, resources and journeys for developers to\nhelp you choose your path and grow in your career.\n\nFrontend Developer Roadmap Backend Developer Roadmap Devops Roadmap\n\n\u00a9 The New Stack 2024\n\nDisclosures Terms of Use Advertising Terms & Conditions Privacy Policy Cookie\nPolicy\n\nFOLLOW TNS\n\nFOLLOW TNS\n\nTNS DAILY\n\nSome TNS posts require third-party cookies to view embedded content (video,\naudio, technical & interactive content).\n\nBy clicking \u201cAccept\u201d you agree to our use of these cookies in accordance with\nour Cookie Notice.\n\nCookie Policy\n\n## The New Stack's Cookies Usage\n\nWhen you visit, the website may store or retrieve information on your browser,\nmostly in the form of cookies. This information might be about you, your\npreferences or your device, but does not usually directly identify you. The\ninformation is mostly used to make the website display the embedded content\nyou expect to see and work the way you expect it to. Cookie Policy\n\n### Manage Consent Preferences\n\n#### Strictly Necessary Cookies\n\nAlways Active\n\nThese cookies are necessary for the website to function and cannot be switched\noff in our systems. They are usually only set in response to actions made by\nyou which amount to a request for services, such as setting your privacy\npreferences, logging in or filling in forms. You can set your browser to block\nor alert you about these cookies, but some parts of the site will not then\nwork. These cookies do not store any personally identifiable information.\n\n#### Functional Cookies\n\nThese cookies enable the website to provide enhanced functionality and\npersonalisation. They may be set by us or by third party providers whose\nservices we have added to our pages. If you do not allow these cookies then\nsome or all of these services may not function properly.\n\n#### Performance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure\nand improve the performance of our site. They help us to know which pages are\nthe most and least popular and see how visitors move around the site. All\ninformation these cookies collect is aggregated and therefore anonymous. If\nyou do not allow these cookies we will not know when you have visited our\nsite, and will not be able to monitor its performance.\n\n#### Targeting Cookies\n\nThese cookies may be set through our site by our advertising partners. They\nmay be used by those companies to build a profile of your interests and show\nyou relevant adverts on other sites. If you do not allow these cookies, you\nwill experience less targeted advertising.\n\n### Vendors List\n\nlabel\n\nConsent Leg.Interest\n\nlabel\n\nlabel\n\nlabel\n\n", "frontpage": false}
