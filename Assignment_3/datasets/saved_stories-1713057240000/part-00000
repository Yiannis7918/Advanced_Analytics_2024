{"aid": "40025267", "title": "Intelligence is whatever machines cannot (yet) do", "url": "https://statmodeling.stat.columbia.edu/2024/04/13/intelligence-is-whatever-machines-cannot-yet-do/", "domain": "columbia.edu", "votes": 1, "user": "jyunwai", "posted_at": "2024-04-13 19:12:01", "comments": 0, "source_title": "Intelligence is whatever machines cannot (yet) do", "source_text": "Intelligence is whatever machines cannot (yet) do | Statistical Modeling, Causal Inference, and Social Science\n\nSkip to primary content\n\n# Statistical Modeling, Causal Inference, and Social Science\n\n# Intelligence is whatever machines cannot (yet) do\n\nPosted on April 13, 2024 3:00 PM by Bob Carpenter\n\nI had dinner a few nights ago with Andrew\u2019s former postdoc Aleks Jakulin, who\nleft the green fields of academia for entrepreneurship ages ago. Aleks was\ntelling me he was impressed by the new LLMs, but then asserted that they\u2019re\nclearly not intelligent. This reminded me of the old saw in AI that \u201cAI is\nwhatever a machine can\u2019t do.\u201d\n\nIn the end, the definition of \u201cintelligent\u201d is a matter of semantics.\nSemantics is defined by conventional usage, not by fiat (the exception seems\nto be an astronomical organization trying to change the definition of \u201cplanet\u201d\nto make it more astronomically precise). We do this all the time. If you think\nabout what \u201cwater\u201d means, it\u2019s incredibly vague. In the simplest case, how\nmany minerals can it contain before we call it \u201cmud\u201d rather than \u201cwater\u201d? Does\nit even have to be made of H20 if we can find a clear liquid on an alternative\nearth that will nourish us in the same way (this is a common example in\nphilosophy from Hilary Putnam, I believe)? When the word \u201cwater\u201d was first\nintroduced into English, let\u2019s just say that our understanding of chemistry\nwas less developed than it is now. The word \u201cintelligent\u201d is no different.\nWe\u2019ve been using the term since before computers, and now we have to rethink\nwhat it means. By convention, we could decide as a group of language users to\ndefine \u201cintelligent\u201d however we want. Usually such decisions are guided by\npragmatic considerations (or at least I\u2019d like to think so\u2014this is the\nstandard position of pragmatist philosophers of language, like Richard Rorty).\nFor instance, we could decide to exclude GPT because (a) it\u2019s not embodied in\nthe same way as a person, (b) it doesn\u2019t have long-term memory, (c) it runs on\nsilicon rather than cells, etc.\n\nIt would be convenient for benchmarking if we could fix a definition of\n\u201cintelligence\u201d to work with. What we do instead is just keep moving the bar on\nwhat counts as \u201cintelligent.\u201d I doubt people 50 years ago (1974) would have\nsaid you can play chess without being intelligent. But as soon as Deep Blue\nbeat the human chess champion, everyone changed their tune and the chorus\nbecame \u201cchess is just a game\u201d and \u201cit\u2019s finite\u201d and \u201cit has well defined\nrules, unlike real life.\u201d Then when IBM\u2019s Watson trounced the world champion\nat Jeopardy!, a language based game, it was dismissed as a parlor trick.\nObviously because a machine can play Jeopardy!, the reasoning went, it doesn\u2019t\nrequire intelligence.\n\nHere\u2019s the first hit on Google I found searching for something like [what\nmachines can\u2019t do]. This one\u2019s in a popular magazine, not the scientific\nliterature. It\u2019s the usual piece in the genre of \u201cML is amazing, but it\u2019s not\nintelligent because it can\u2019t do X\u201d.\n\n  * Rob Toews. 2021. What artificial intelligence still can\u2019t do. Forbes.\n\nLet\u2019s go over Toews\u2019s list of AI\u2019s failures circa 2021 (these are direct\nquotes).\n\n  1. Use \u201ccommon sense.\u201d A man went to a restaurant. He ordered a steak. He left a big tip. If asked what the man ate in this scenario, a human would have no problem giving the correct answer\u2014a steak. Yet today\u2019s most advanced artificial intelligence struggles with prompts like this.\n  2. Learn continuously and adapt on the fly. Today, the typical AI development process is divided into two distinct phases: training and deployment.\n  3. Understand cause and effect. Today\u2019s machine learning is at its core a correlative tool. It excels at identifying subtle patterns and associations in data. But when it comes to understanding the causal mechanisms\u2014the real-world dynamics\u2014that underlie those patterns, today\u2019s AI is at a loss.\n  4. \u201cReason ethically...In 2016, Microsoft debuted an AI personality on Twitter named Tay. The idea was for Tay to engage in online conversations with Twitter users as a fun, interactive demonstration of Microsoft\u2019s NLP technology. It did not go well. Within hours, Internet trolls had gotten Tay to tweet a wide range of offensive messages: for instance, \u201cHitler was right\u201d and \u201cI hate feminists and they should all die and burn in hell.\u201d\n\n(1) ChatGPT-4 gets these common-sense problems mostly right. But it\u2019s not\nlogic. The man may have ordered a steak, gotten it, sent it back, ordered the\nfish instead, and still left a big tip. This is a problem with a lot of the\nquestions posed to GPT about whether X follows from Y. It\u2019s not a sound\ninference, just the most likely thing to happen, or as we used to say, the\n\u201cdefault.\u201d Older AIs were typically designed around sound inference and\nweren\u2019t so much trying to emulate human imprecision (having said that, my grad\nschool admissions essay was about and my postdoc was funded by a grant on\ndefault logics back in the 1980s!).\n\n(2) You can do in-context learning with ChatGPT, but it doesn\u2019t retain\nanything long term without retraining/fine tuning. It will certainly adapt to\nits task/listener on the fly throughout a conversation (arguably the current\nsystems like ChatGPT adapt to their interlocuter too much\u2014it\u2019s what they were\ntrained to do via reinforcement learning). Long-term memory is perhaps the\nbiggest technical challenge to overcome, and it\u2019s been interesting to see\npeople going back to LSTM/recursive NN ideas (transformers, the neural net\narchitecture underlying ChatGPT, were introduced in a paper titled \u201cAttention\nis all you need\u201d, which used long, but finite memory).\n\n(3) ChatGPT 4 is pretty bad at causal inference. But it\u2019s probably above the\nbar for what Toews\u2019s complaints. It\u2019ll get simple \u201ccausal inference\u201d right the\nsame way people do. In general, humans are pretty bad at causal inference. We\nare way too prone to jump to causal conclusions based on insufficient\nevidence. Do we classify baseball announcers as not intelligent when they talk\nabout how a player struggles with high pressure situations after N = 10 plate\nappearances in the playoffs? We\u2019re also pretty bad at reasoning about things\nthat go against our preconceptions. Do we think Fisher was not intelligent\nbecause he argued that smoking didn\u2019t cause cancer? Do we think all the\nanthropogenic global warming deniers are not intelligent? Maybe they\u2019re right\nand it\u2019s just a coincidence that temps have gone up coinciding with\nindustrialization and carbon emissions. Seems like a highly suspicious\ncoincidence, but causation is really hard when you can\u2019t do randomized\ncontrolled trials (and even then it\u2019s not so easy because of all the possible\nmediation).\n\n(4) How you call this one depends on whether you think the front-line fine-\ntuning of ChatGPT made a reasonably helpful/harmless/truthful bot or not and\nwhether the \u201cethics\u201d it was trained with are yours. You can certainly\njailbreak even ChatGPT-4 to send it spiraling into hate land or fantasy land.\nYou can jailbreak some of my family in the same way, but I wouldn\u2019t go so far\nas to say they weren\u2019t intelligent. You can find lots of folks who think\nChatGPT is too \u201cwoke\u201d. This is a running theme on the GPT subreddit. It\u2019s also\na running theme among anti-woke billionaires, as reflected in the UK\u2019s Daily\nTelegraph article title, \u201cChatGPT may be the next big thing, but it\u2019s a biased\nwoke robot.\u201d\n\nI\u2019ve heard a lot of people say their dog is more intelligent than ChatGPT. I\nsuppose they would argue for a version of intelligence that doesn\u2019t require\n(1) or (4) and is very tolerant of poor performance in (2) and (3).\n\nThis entry was posted in Causal Inference, Zombies by Bob Carpenter. Bookmark\nthe permalink.\n\n## 3 thoughts on \u201cIntelligence is whatever machines cannot (yet) do\u201d\n\n  1. JimV on April 13, 2024 3:24 PM at 3:24 pm said:\n\nI was watching a \u201cclassic\u201d football game on the NFL channel, and blog-surfing\nduring the commercials, when I saw this post. Had to turn off the game to\nfocus on this since I found it absorbing.\n\nThe key point for me is to focus on the actual foibles of human brains when\ncomparing them to various AI programs. I think most if not all the people who\ncommunicate here are a couple standard deviations above the average IQ of 100.\n(Not that IQ is a great, determinative measurement, but for lack of a better\none.) There is not a general AI which can emulate them, but that does not mean\nthat no progress has been made.\n\nReply \u2193\n\n     * Joshua on April 13, 2024 3:30 PM at 3:30 pm said:\n\nFunny that you mention IQ.\n\nI was writing this comment as you posted yours.\n\nOn a more mundane level.\n\nI see a lot of arguments that \u201cintelligence\u201d is a clear and coherent concept,\nbasically because it can be measured by IQ tests. It\u2019s simply a fact, some\npeople say, that some people are more intelligent than others. IQ tests\npredict how well you\u2019ll do in life. Others say there are clear differences in\nintelligence among different groups, because intelligence is a clear and\ncoherent attribute that is largely (or I guess some say completely) an\ninherited attribute. It\u2019s a function of your generetic makeup.\n\nSo how well does ChatGPT do on IQ tests? Presumably it would get a result\nabove zero! So it must be intelligent by that logic. I just did a Google that\nsays ChatGPT\u2019s gets 155 on an IQ test, better than 99.9% of (human) test\ntakers. So then I guess anyone who argues that IQ validly measure\nintelligence, to be logically consistent would agree that AI is not only\nintelligent but is in fact basically Einstein intelligent.\n\nReply \u2193\n\n  2. Chris on April 13, 2024 4:15 PM at 4:15 pm said:\n\n> I see a lot of arguments that \u201cintelligence\u201d is a clear and coherent\n> concept, basically because it can be measured by IQ tests.\n\nThat\u2019s a dismal argument (not yours but the \u201carguments\u201d that \u201cyou see a lot\nof\u201d). What \u201ccan be measured by IQ tests\u201d is \u201cintelligence\u201d only if one asserts\nthat \u201cintelligence\u201d is \u201cwhat can be measured by IQ tests\u201d.\n\nThose arguments become somewhat self-serving since (like \u201carguments\u201d around\nthe existence of free will) their subject (\u201cintelligence\u201d/\u201dfree will\u201d) is\nmechanistically underdetermined and so pretty much all \u201carguments\u201d tend to\nbecome contrived in support of some sort of a \u201cposition\u201d and susceptible to\nsemantic confusion.\n\nReply \u2193\n\n### Leave a Reply Cancel reply\n\n  * Art\n  * Bayesian Statistics\n  * Causal Inference\n  * Decision Analysis\n  * Economics\n  * Jobs\n  * Literature\n  * Miscellaneous Science\n  * Miscellaneous Statistics\n  * Multilevel Modeling\n  * Papers\n  * Political Science\n  * Public Health\n  * Sociology\n  * Sports\n  * Stan\n  * Statistical Computing\n  * Statistical Graphics\n  * Teaching\n  * Zombies\n\n  1. Chris on Intelligence is whatever machines cannot (yet) doApril 13, 2024 4:15 PM\n\nI see a lot of arguments that \u201cintelligence\u201d is a clear and coherent concept,\nbasically because it can be measured...\n\n  2. Joshua on Intelligence is whatever machines cannot (yet) doApril 13, 2024 3:30 PM\n\nFunny that you mention IQ. I was writing this comment as you posted yours. On\na more mundane level. I...\n\n  3. JimV on Intelligence is whatever machines cannot (yet) doApril 13, 2024 3:24 PM\n\nI was watching a \"classic\" football game on the NFL channel, and blog-surfing\nduring the commercials, when I saw this...\n\n  4. John G Williams on Evidence, desire, supportApril 13, 2024 2:24 PM\n\nThe continental drift story is more complicated than most realize, as detailed\nby Naomi Oreskes in \"The Rejection of Continental...\n\n  5. JimV on What is the prevalence of bad social science?April 13, 2024 12:38 PM\n\nI thought (and subsequently got confirmation in a comment she made on another\nscience blog) that the specific academic disagreement...\n\n  6. Joshua on What is the prevalence of bad social science?April 13, 2024 11:44 AM\n\nchipmunk - changing how people are selected from a function-relevant\nperformance standard to a function-irrelevant social standard... You have\nan...\n\n  7. Seth Finkelstein on Evidence, desire, supportApril 13, 2024 11:36 AM\n\nUFOs/Space Aliens goes in cycles, and I'd say there's a clear process: 1) True\nBelievers make noise, get government interest...\n\n  8. Joshua on Evidence, desire, supportApril 13, 2024 11:18 AM\n\nI belive that chipmunk will translate any post on this blog into a rant\nagainst librulz\n\n  9. Joshua on What is the prevalence of bad social science?April 13, 2024 11:16 AM\n\nDunno. I'm not unsympathetic to some of her points about the industry of\nscience, but it's way too dichotomous and...\n\n  10. Dale Lehman on Evidence, desire, supportApril 13, 2024 11:08 AM\n\nThat's a very interesting idea and I hope Andrew takes you up on that. I\nthought about my answer to...\n\n  11. Joshua on Evidence, desire, supportApril 13, 2024 10:51 AM\n\nHmmm.. ... map nicely on to ... reasons to think ... not that old ....in\nthorough ...careful academics\n\n  12. Joshua on Evidence, desire, supportApril 13, 2024 10:47 AM\n\nDale - I agree. Social media reinforces and accelerates the process of\n\"support.\" Which enhances \"desire.\" And now it's so...\n\n  13. Anoneuoid on Evidence, desire, supportApril 13, 2024 10:41 AM\n\nWe need an example of something you do believe though.\n\n  14. Joshua on Evidence, desire, supportApril 13, 2024 10:34 AM\n\nI think there's pretty much (not 100% in all individual instances or 100% of\nthe time) a directional chain here....\n\n  15. Dale Lehman on Evidence, desire, supportApril 13, 2024 10:25 AM\n\nThis leads me to think about how technology is changing these three pillars:\nevidence is easily manufactured and support can...\n\n  16. Dale Lehman on What is the prevalence of bad social science?April 13, 2024 10:18 AM\n\nchipmunk As usual, your desire/need to make your usual political statements\nhas led you to oversimplify things. Yes, the history...\n\n  17. chipmunk on What is the prevalence of bad social science?April 13, 2024 9:44 AM\n\nI'll just also note that the funding scheme in science is analogous to the FHA\nthat created redlinging, right? A...\n\n  18. chipmunk on What is the prevalence of bad social science?April 13, 2024 9:39 AM\n\n15% overhead? Whoa, she is from the 90s! Overhead is 60% or more at most US\ninstitutions now init? It...\n\n  19. Gregory C. Mayer on Delayed retraction samplingApril 13, 2024 8:10 AM\n\nAre those articles reviewed by anyone other than the editors?\n\n  20. Paul Hayes on \u201cHe had acquired his belief not by honestly earning it in patient investigation, but by stifling his doubts. And although in the end he may have felt so sure about it that he could not think otherwise, yet inasmuch as he had knowingly and willingly worked himself into that frame of mind, he must be held responsible for it.\u201dApril 12, 2024 9:33 PM\n\nAnd of course Clifford's argument (and the ethical / moral aspects of inquiry\nand belief more generally) is also reasonably...\n\n  21. Ethan Bolker on Delayed retraction samplingApril 12, 2024 8:35 PM\n\nSo informally it's about halfway from 10,000 to 100,000 on the log scale.\n\n  22. Andrew on It\u2019s bezzle time: The Dean of Engineering at the University of Nevada gets paid $372,127 a year and wrote a paper that\u2019s so bad, you can\u2019t believe it.April 12, 2024 6:26 PM\n\nPresumably he's unavailable because he's busy doing research on train\naccidents and torment executioners.\n\n  23. Steve Haroz on Delayed retraction samplingApril 12, 2024 5:36 PM\n\nYes, but the journal pumping out a dozen new articles per week shows that the\neditors can find reviewers when...\n\n  24. Phil on Delayed retraction samplingApril 12, 2024 4:13 PM\n\nFew people realize \u201czillion\u201d means 3 x 10^4. Everyone assumes it somewhere up\nabove billions and trillions and quadrillions, but...\n\n  25. Adede on Delayed retraction samplingApril 12, 2024 3:02 PM\n\nIt's hard to find people to do a job when the pay is $0/hour.\n\n  26. Dale Lehman on What is the prevalence of bad social science?April 12, 2024 2:10 PM\n\nAnd I thought it was a plug for stand-up comedy to replace academia. I was\nprepared to make the switch.\n\n  27. Daniel Lakeland on What is the prevalence of bad social science?April 12, 2024 2:07 PM\n\nLoved seeing that video from Sabine Hossenfelder. It's a super personal\nintrospection on her career and the reasons why academia...\n\n  28. Daniel Lakeland on \u201cHe had acquired his belief not by honestly earning it in patient investigation, but by stifling his doubts. And although in the end he may have felt so sure about it that he could not think otherwise, yet inasmuch as he had knowingly and willingly worked himself into that frame of mind, he must be held responsible for it.\u201dApril 12, 2024 1:42 PM\n\nThere are a number of confusions going on here I guess. First off, the\nfoundation of Bayesian probability under Cox's...\n\n  29. somebody on What is the prevalence of bad social science?April 12, 2024 1:00 PM\n\nhttps://youtu.be/LKiBlGDfRU8?si=FjVO9trzR0LzWxw5 What is the prevalence of bad\nsocial science\n\n  30. Sara Lafrance on It\u2019s bezzle time: The Dean of Engineering at the University of Nevada gets paid $372,127 a year and wrote a paper that\u2019s so bad, you can\u2019t believe it.April 12, 2024 12:40 PM\n\nIndira Chatterjee, Associate Dean of Engineering, has been named as the Acting\nDean. She is listed as such on the...\n\n  31. Steve Haroz on Delayed retraction samplingApril 12, 2024 12:02 PM\n\nI've been involved in a case where there are GLARING statistical errors. I\nwrote to the journal (MDPI) about the...\n\n  32. Joshua on What is the prevalence of bad social science?April 12, 2024 11:29 AM\n\nDale - It is more about having a clear research record so that we can see how\nwork builds upon...\n\n  33. paul alper on Delayed retraction samplingApril 12, 2024 10:28 AM\n\nI have absolutely no expertise regarding \"Hepatic Fat Content and Visceral\nLipids in Hepatic Patients with Diabesity,\" but I am...\n\n  34. Ethan Bolker on Delayed retraction samplingApril 12, 2024 10:07 AM\n\nHow does one take \"literally zillions\" literally?\n\n  35. Lukas Lohse on \u201cHe had acquired his belief not by honestly earning it in patient investigation, but by stifling his doubts. And although in the end he may have felt so sure about it that he could not think otherwise, yet inasmuch as he had knowingly and willingly worked himself into that frame of mind, he must be held responsible for it.\u201dApril 12, 2024 5:44 AM\n\nI guess that makes sense in isolation, but it doesn't really gel with the\ndefinition of a probability measure as...\n\n  36. Daniel Lakeland on \u201cHe had acquired his belief not by honestly earning it in patient investigation, but by stifling his doubts. And although in the end he may have felt so sure about it that he could not think otherwise, yet inasmuch as he had knowingly and willingly worked himself into that frame of mind, he must be held responsible for it.\u201dApril 12, 2024 1:27 AM\n\nNo I mean a union of the set of facts, that is we are assuming all the facts\nare true...\n\n  37. Anoneuoid on How large is that treatment effect, really? (my talk at NYU economics department Thurs 18 Apr 2024, 12:30pm)April 11, 2024 11:09 PM\n\nI think it is worth it to look into how this equation was arrived at: CO =\nHR*SV Then think...\n\n  38. Anonymous Pigeon on Don\u2019t Call Me Shirley, Mr. Feynman!April 11, 2024 10:19 PM\n\n3075, a scientist is stuck in a room, flooding. He uses what he has (Maybe\ntech is so good it...\n\n  39. Dale Lehman on What is the prevalence of bad social science?April 11, 2024 7:31 PM\n\nJoshua I see some clear issues with both plagiarism and lying (you mention\neach of these). I'm not so concerned...\n\n  40. Raphael K on How large is that treatment effect, really? (my talk at NYU economics department Thurs 18 Apr 2024, 12:30pm)April 11, 2024 5:06 PM\n\nI think your criticism of 'personalised medicine research' is not inconsistent\nwith the message that the abstract says this talk...\n\n  41. Joshua on What is the prevalence of bad social science?April 11, 2024 4:58 PM\n\nDale - I don\u2019t know if you intended what sounded to me like a defense of\ncultural norms that don\u2019t...\n\n  42. Dale Lehman on What is the prevalence of bad social science?April 11, 2024 3:30 PM\n\nJoshua I don't know if you intended what sounded to me like a defense of\ncultural norms that don't consider...\n\n  43. Jay Patel on How large is that treatment effect, really? (my talk at NYU economics department Thurs 18 Apr 2024, 12:30pm)April 11, 2024 2:36 PM\n\nIt sounds like you're a fan of realist reviews, as described by Ray Pawson\n(https://guides.library.utoronto.ca/c.php?g=713309&p=5105450).\n\n  44. ES on How large is that treatment effect, really? (my talk at NYU economics department Thurs 18 Apr 2024, 12:30pm)April 11, 2024 2:22 PM\n\n\"But we typically care about individual effects (not \u201cDoes the treatment\nwork?\u201d but \u201cWhere and when does it work?\u201d and...\n\n  45. Angelo D'Ambrosio on blme: Bayesian Linear Mixed-Effects ModelsApril 11, 2024 2:06 PM\n\nActually I often find that blme + arm::sim() produce posteriors that are very\nsimilar to full stan sampling, at least...\n\n  46. Joshua on What is the prevalence of bad social science?April 11, 2024 1:29 PM\n\nchipmunk - > The fact that some sub-cultures deviate from the widely known and\nestablished rules doesn\u2019t mean they don\u2019t...\n\n  47. Dale Lehman on What is the prevalence of bad social science?April 11, 2024 12:26 PM\n\nchipmunk FYI, I don't follow Tucker Carlson and don't even know what that box\nactually means (other than I know...\n\n  48. Anonymous on How large is that treatment effect, really? (my talk at NYU economics department Thurs 18 Apr 2024, 12:30pm)April 11, 2024 11:56 AM\n\nCan I have a list of references?\n\n  49. Anonymous on How large is that treatment effect, really? (my talk at NYU economics department Thurs 18 Apr 2024, 12:30pm)April 11, 2024 11:49 AM\n\nIt would be great if this was recorded, and a link to the talk posted. It\nsounds very interesting.\n\n  50. chipmunk on What is the prevalence of bad social science?April 11, 2024 11:44 AM\n\nDale: I don't doubt that everything I write confirms the \"Tucker Carlson\" box\nyou've stuck me in.\n\nProudly powered by WordPress\n\n", "frontpage": false}
