{"aid": "40085641", "title": "Deploying an LLM app to AWS using open source tools", "url": "https://blog.digger.dev/deploy-a-llm-app-to-aws-using-open-source-tools/", "domain": "digger.dev", "votes": 1, "user": "iacguy", "posted_at": "2024-04-19 11:51:46", "comments": 0, "source_title": "Deploying an LLM App to AWS using Open Source Tools", "source_text": "Deploying an LLM App to AWS using Open Source Tools\n\nDigger.dev\n\nSign in Subscribe\n\n# Deploying an LLM App to AWS using Open Source Tools\n\n#### Utpal Nadiger\n\nApr 19, 2024 \u2022 7 min read\n\n## Overview\n\nIn this article, we will explore how to deploy a RAG chatbot app that\ninteracts with large language models(LLM\u2019s) to a cloud provider such as AWS\nusing GitHub Actions, OpenTofu, and Digger. We were extremely inspired by\nWenqi Glantz' article and thought of creating a version of our own, with\nOpenTofu & Digger.\n\n## Prerequisites\n\nBefore you begin setting up and deploying the LLM RAG Chatbot App , make sure\nyou have the following prerequisites in place:\n\n  * AWS Account: You'll need an active AWS account to provision and manage the cloud resources required by the Chatbot App.\n  * Github Account: Access to a Github account is necessary for implementing Github Actions and secrets for Chatbot App source code.\n  * Access to Chatbot App Source Code: Ensure you have access to the source code of the Chatbot App that you intend to deploy. We are using the source code available here.\n  * OpenTofu : OpenTofu will be used to automate AWS cloud infrastructure provisioning for the Chatbot App.\n  * Digger: Digger is used for orchestrating OpenTofu/Terraform within the Continuous Integration/Continuous Deployment (CI/CD) system.\n\n## Step by Step Instructions\n\n### Step 1: Set up AWS Account and Resources\n\n  1. Create an AWS Account: If you don't have one already, sign up for an AWS account using this link.\n  2. Set up AWS IAM User: Create an IAM user with appropriate permissions to deploy resources like EC2 instances, IAM roles for LLM app.\n\n  * Go to the AWS Management Console and sign in using your AWS account\n  * Once logged in, navigate to the IAM console. You can find this under by searching for IAM in the search bar.\n  * You will be redirected to IAM Dashboard where you'll see a menu. Click on \"Users\" under the \"Access management\" section. See screenshot below for reference.\n\n  * Create User: Click on the yellow \"Create user\" button on the upper right(see screenshot below) to start creating a new IAM user.\n\n  * Enter User Details: You'll be prompted to enter details for the new user. Provide a name for the user, set permissions(Add User to group). Once you're done, click \"Create user\" button on the lower right.See screenshot below for reference.\n\n  * Set EC2 permission for the user: Select the created user from the list and click on \"Add permissions\" button on the lower right. The button is highlighted in black box in screenshot below.\n\n  * Choose Add user to the group or create a group if there is no user group available.The \"Create group\" button is located on lower right in screenshot below.\n\n  * Clicking on Create Group button will ask you to provide group name for AWS resource access. Checkmark AmazonEC2ContainerRegistryFullAccess from Permission Policies list and click on \u2018Create user Group\u2019 button. See screenshot below for reference.\n\n3\\. Generate AWS Access Key and Secret Key: In the AWS IAM Console, Select the\ncreated user from the list and click on \"Create access key \" button to create\naccess key and secret key for the IAM user created earlier. The \"Create access\nkey\" button is highlighted in black box in screenshot below.\n\n4\\. Set up AWS CLI: Install AWS CLI on your local machine. For installation\ninstructions specific to your operating system check this link.\n\nOnce AWS CLI is installed, you need to configure it with your AWS credentials\nand set the default region specific to your AWS account. You can do this by\nrunning the aws configure command in your terminal or command prompt.\n\n  * Provide AWS Access Key ID and Secret Access Key: You'll be prompted to enter your AWS Access Key ID and Secret Access Key. These are credentials associated with your AWS account. You can find them in the AWS Management Console under IAM (Identity and Access Management).\n  * Set Default Region: After entering the credentials, you'll be prompted to enter the default region. For ex: ap-northeast-1.\n  * Set Default Output Format (Optional): Finally, you can choose the default output format. The default is usually JSON.\n\n### Step 2: Set up GitHub Secrets and Github Actions for the Repository\n\n  1. Go to your RAG chatbot example repository settings on GitHub, and navigate to the Secrets section. Add the AWS access key and secret key as repository secrets. See screenshot below for reference:\n\n2\\. In your repository, create .github/workflows directory with an empty\ndeploy.yaml file for implementing the GitHub Actions workflow later in the\narticle.\n\n### Step 3: Configure OpenTofu\n\n  1. Install OpenTofu CLI on your local machine using the instructions provided on the OpenTofu site (https://opentofu.org/docs/intro/install/).\n  2. Configure OpenTofu: Open Terminal/Command Prompt and Create a directory named tofudemo and navigate to that that directory using the commands below:\n\n    \n    \n    mkdir tofudemo cd tofudemo\n\n  3. Create a HCL configuration file named \u201cmain.tf\u201d file which contains declaration for launching AWS EC2 cloud instance on which LLM app will be deployed.\n\n    \n    \n    terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~> 4.0\" } } } provider \"aws\" { region = \"us-east-1\" access_key = \"AKIAXSPZ33SEY3IRIEW7\" secret_key = \"xxxx\" } resource \"aws_instance\" \"web\" { ami = \"ami-06e46074ae430fba6\" instance_type = \"t2.micro\" tags = { Name = \"hello-world\" } }\n\n4\\. To initalize the HCL configuration run the command below.\n\n    \n    \n    tofu init\n\nSee code snippet below for reference.\n\n5\\. Then run tofu plan command to ensure what AWS resources has to be created.\n\n    \n    \n    tofu plan\n\n6\\. Finally run \"tofu apply\" command to create AWS resources.\n\n7\\. Sign in to your AWS account and verify your AWS EC2 resources will be\ncreated with the provided specifications.\n\n  * Note: To terminate the AWS instance when it is not required just run the tofu destroy command.\n\n8\\. Now SSH into AWS instance and delpoy the LLM chatbot app.\n\n### Step 4: Setup Digger to automate OpenTofu pull requests\n\n  1. Push your OpenTofu Configuration to the LLM chatbot app repo .The OpenTofu configuration should be placed in the prod directory. Here\u2019s a demo repo with prod directory to give you a perspective.\n  2. Create a Digger token by signing up on cloud.digger.dev.\n\n  3. Add the token as secrets in your LLM app GitHub repository settings.\n\n  * Go to Secrets and Variables -> Actions -> New repository secret\n  * AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY (you can also use OIDC)\n  * DIGGER_TOKEN - your Digger token (cloud or self-hosted)\n\n4\\. Install the Digger GitHub App from cloud.digger.dev and give it access to\nyour repo.\n\n5\\. Create digger.yml file with code configuration below and place it at the\nroot level of your repository. Assuming your OpenTofu code is in the prod\ndirectory:\n\n    \n    \n    projects: - name: production dir: prod\n\n6\\. Now create a github actions workflow file named digger_workflow.yml (name\nis important!) with the configuration below and place it at\n.github/workflows/digger_workflow.yml\n\n    \n    \n    name: Digger Workflow on: workflow_dispatch: inputs: id: description: 'run identifier' required: false job: required: true comment_id: required: true jobs: digger-job: runs-on: ubuntu-latest permissions: contents: write # required to merge PRs actions: write # required for plan persistence id-token: write # required for workload-identity-federation pull-requests: write # required to post PR comments statuses: write # required to validate combined PR status steps: - uses: actions/checkout@v4 - uses: diggerhq/digger@v0.4.13 with: setup-aws: true aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} disable-locking: true digger-hostname: 'https://cloud.digger.dev' digger-organisation: 'digger' digger-token: ${{ secrets.DIGGER_TOKEN }} env: GITHUB_CONTEXT: ${{ toJson(github) }} GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\nThis file defines a simple workflow that\n\n  * Checks out repository using Github\u2019s official Checkout action\n  * Runs Digger. Note that DIGGER_TOKEN needs to be set as a secret in Actions (either repository secret, or environment secret), you also need to set AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY parameter. OIDC is also supported if you prefer that route\n\n7\\. Now to check whether digger is working correctly make any changes to\nOpenTofu code under prod directory and raise a PR. See screenshot below.\n\n8\\. An action run should start (you can see log output in Actions). After some\ntime you should see output of digger added as a comment to your PR.\n\nConclusion\n\nWe have explored the open-source GitOps for OpenTofu model via Digger for\ndeploying RAGs chatbot to AWS EC2 in this article. For automating and meeting\nAWS infrastructure demands for the app infrastructure as code model is\nimplemented via Opentofu which allows blueprint of your infrastructure to be\nshared and re-used.\n\nWe hope you find this article helpful. Thank you for reading until the end.\nBefore you go, we just wanted to share the following:We\u2019re building Digger as\nan Open Source Tool that helps you orchestrate Terraform and OpenTofu within\nCI/CD systems such as GitHub Actions while providing RBAC via OPA, Drift\nDetection and Concurrency with a self hostable orchestrator backend. Would\nlove your feedback!\n\n## Star us on GitHub | Check out Docs | Blog | Slack\n\n## Sign up for more like this.\n\nEnter your email\n\nSubscribe\n\n## Top self-hosted runner solutions for GitHub Actions.\n\nWhile talking to users using Digger in GitHub Actions, we see a lot of\ncompliance heavy enterprises relying on Self Hosted runners. We decided to\ncompile a list of available solutions out there, to help present the options\navailable before a decision is made. Let's dive in: Actions\n\nMar 13, 2024 3 min read\n\n## Digger's low-level CLI API\n\nThis was meant to be just another feature announcement post. Something along\nthe lines of \u201cyou can now run Digger CLI on your laptop; here\u2019s why this is\ncool\u201d kind of post. But as I started writing it I realised that why we built\nthis feature is just as\n\nFeb 6, 2024 5 min read\n\n## How to run Terraform in your Gitlab CI/CD pipeline?\n\nThis is something that we get asked very often. Integrating Terraform into\nGitLab CI clearly offers a streamlined approach to manage and automate\ninfrastructure deployment, and infra engineers are always curious and keen to\nPOC this to their peers. The reason is clear - cloud credentials never leave\nthe privileged\n\nJan 30, 2024 3 min read\n\nDigger.dev \u00a9 2024\n\nPowered by Ghost\n\n", "frontpage": false}
