{"aid": "40085642", "title": "Instinct.cpp is a toolkit for LLM-powered apps targeting edge computing", "url": "https://github.com/RobinQu/instinct.cpp", "domain": "github.com/robinqu", "votes": 1, "user": "RobinQu", "posted_at": "2024-04-19 11:51:53", "comments": 0, "source_title": "GitHub - RobinQu/instinct.cpp: instinct.cpp is a framework for developing AI Agent applications (RAG, Chatbot, Code interpreter) powered by language models.", "source_text": "GitHub - RobinQu/instinct.cpp: instinct.cpp is a framework for developing AI\nAgent applications (RAG, Chatbot, Code interpreter) powered by language\nmodels.\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nRobinQu / instinct.cpp Public\n\n  * Notifications\n  * Fork 0\n  * Star 4\n\ninstinct.cpp is a framework for developing AI Agent applications (RAG,\nChatbot, Code interpreter) powered by language models.\n\n### License\n\nApache-2.0 license\n\n4 stars 0 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# RobinQu/instinct.cpp\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n3 Branches\n\n1 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nRobinQuchores: update READMEApr 19, 2024875285d \u00b7 Apr 19, 2024Apr 19, 2024\n\n## History\n\n221 Commits  \n  \n### .github/workflows\n\n|\n\n### .github/workflows\n\n| Update cmake-multi-platform.yml| Apr 1, 2024  \n  \n### cmake\n\n|\n\n### cmake\n\n| chores: disable rpp in conanfile.py| Apr 1, 2024  \n  \n### conan\n\n|\n\n### conan\n\n| chores: more improvements for RAG evaluation| Apr 3, 2024  \n  \n### docs\n\n|\n\n### docs\n\n| chores: update components.md| Apr 3, 2024  \n  \n### modules\n\n|\n\n### modules\n\n| chores: clean notebook outputs| Apr 18, 2024  \n  \n### .devcontainer.json\n\n|\n\n### .devcontainer.json\n\n| chores: update .devcontainer.json| Apr 15, 2024  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| chores: add consistency test for text splitter| Apr 16, 2024  \n  \n### .gitmodules\n\n|\n\n### .gitmodules\n\n| chores: cleanup thirdparty| Mar 26, 2024  \n  \n### CMakeLists.txt\n\n|\n\n### CMakeLists.txt\n\n| test: FileSystemFileVault| Apr 18, 2024  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| chores: make build ok with gcc 13| Mar 18, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| chores: add docs for first release| Mar 29, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| chores: update README| Apr 19, 2024  \n  \n### conanfile.py\n\n|\n\n### conanfile.py\n\n| feat: FileSystemFileVault| Apr 18, 2024  \n  \n## Repository files navigation\n\n# \u2728 instinct.cpp\n\ninstinct.cpp is a toolkit for developing LLM-powered applications targeting\nedge computing.\n\n\ud83d\udea8 This project is under active development and has not reached to GA stage of\nfirst major release. See more at Roadmap section.\n\n## Features\n\nWhat instinct.cpp offer:\n\n  * Single-binary services that are working out-of-box.\n\n    * chat-agent: A CLI application that create knowledge index with your docs (PDF,TXT,MD,...) and launch an HTTP server that is fully compatible with OpenAI ChatCompletion.\n    * mini-assistant-api (WIP in Sprint v0.1.2): Agent service that is mostly compatible with OpenAI's Assistant API.\n  * Frameworks to build LLM-based applications\n\n    * Integration for privacy-first LLM providers: Built-in support for Ollama and other OpenAI compatible API services like nitro and more.\n    * Building blocks for common application patterns like Chatbot, RAG, LLM Agent.\n    * Functional chaining components for composable LLM pipelines.\n    * [WIP] Agent API service fully compatible with OpenAI's Assistant API, but with infinite scalability and security.\n\nWhat instinct.cpp cannot offer:\n\n  * A LLM Provider. instinct.cpp depends on existing local LLMs like Ollama, nitro, LLMStudio and API providers like OpenAI.\n  * A C++ version of langchain. While this project learns a lot from langchain including Prompt related classes and functional API designs, instinct.cpp will focus on opinionated components while providing extensive interfaces for vendor specific implementations. For example, there are tons of vector database integration available in langchain, but instinct.cpp will keep DuckDB implementation for single-node scenario and both Weaviate and milvus client integration for cloud scenario.\n  * End-to-end solution with user interfaces. We hope there will be downstream projects building Desktop or Webapps with instinct.cpp.\n\n## Getting started\n\n### Install from package manager\n\nWIP #1\n\n### Build from sources\n\nSystem Requirements:\n\n  * CMake 3.26+\n  * Compiler that supports C++ 20: GCC 13+ or Clang 15+\n  * Conan 2+\n\nThis project relies on conan to resolve dependencies. To build and install:\n\n    \n    \n    conan install . --build=missing --output-folder=build cd build cmake .. -DCMAKE_TOOLCHAIN_FILE=conan_toolchain.cmake -DCMAKE_BUILD_TYPE=Release cmake --build .\n\n### Quick start\n\nLet's build a simple text completion task using Ollama API.\n\n    \n    \n    #include \"chain/MessageChain.hpp\" #include \"input_parser/PromptValueVariantInputParser.hpp\" #include \"chat_model/OllamaChat.hpp\" #include \"output_parser/StringOutputParser.hpp\" #include \"prompt/PlainPromptTemplate.hpp\" int main() { using namespace INSTINCT_CORE_NS; using namespace INSTINCT_LLM_NS; const auto input_parser = CreatePromptVariantInputParser(); const auto string_prompt = CreatePlainPromptTemplate(\"Answer following question in one sentence: {question}\"); const auto output_parser = CreateStringOutputParser(); const auto chat_model = CreateOllamaChatModel(); const auto xn = input_parser | string_prompt | chat_model->AsModelFunction() | output_parser; const auto result = xn->Invoke(\"Why sky is blue?\"); std::cout << result <<std::endl; }\n\n### What's next\n\nYou can learn more about this frameworks by following links below:\n\n  * Chaining\n  * Built-in components\n  * Read more about single-binary services\n\n    * doc-agent : Chat with your docs locally with privacy.\n    * mini-assistant-api.\n\n## Roadmap\n\nComplete project plan is tracked at Github Project.\n\nMilestone| Features| DDL  \n---|---|---  \nv0.1.0| Long-short memory, PDF/TXT/DOCX ingestor, Chain programing paradigm,\nRAG reference app doc-agent| 3.29  \nv0.1.1| Performance tuning, RAG evaluation, Function calling agent| 4.16  \nv0.1.2| OpenAI Assistant API initial implementation, single-binary reference\napp mini-assistant| 4.30  \nv0.1.3| Benchmarks, packages.| 5.17  \nv0.2.0| Documentations. Features will be frozen.| 5.31  \n  \nContributions are welcomed! You can join discord server, or contact me via\nemail.\n\n## About\n\ninstinct.cpp is a framework for developing AI Agent applications (RAG,\nChatbot, Code interpreter) powered by language models.\n\n### Topics\n\nrag aigc llm langchain genai aiagent\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\n### Stars\n\n4 stars\n\n### Watchers\n\n1 watching\n\n### Forks\n\n0 forks\n\nReport repository\n\n## Releases\n\n1 tags\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Jupyter Notebook 62.5%\n  * C++ 35.4%\n  * CMake 1.5%\n  * Other 0.6%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
