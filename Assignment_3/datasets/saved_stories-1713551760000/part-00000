{"aid": "40086011", "title": "Mark Zuckerberg \u2013 Llama 3, Open Sourcing $10B Models, & Caesar Augustus", "url": "https://www.dwarkeshpatel.com/p/mark-zuckerberg", "domain": "dwarkeshpatel.com", "votes": 1, "user": "yarapavan", "posted_at": "2024-04-19 12:33:42", "comments": 0, "source_title": "Mark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus", "source_text": "Mark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus\n\n# Dwarkesh Podcast\n\nShare this post\n\n#### Mark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus\n\nwww.dwarkeshpatel.com\n\nDwarkesh Podcast\n\nMark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus\n\n15\n\nShare this post\n\n#### Mark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus\n\nwww.dwarkeshpatel.com\n\n3\n\n1\u00d7\n\n0:00\n\n-1:17:54\n\n## Mark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus\n\nCaeser Augustus, intelligence explosion, bioweapons, $10b models, & much more\n\nDwarkesh Patel\n\nApr 18, 2024\n\n15\n\nShare this post\n\n#### Mark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus\n\nwww.dwarkeshpatel.com\n\n3\n\nShare\n\nTranscript\n\n0:00\n\nMark, welcome to the podcast.\n\n0:01\n\nHey, thanks for having me.\n\n0:02\n\nBig fan of your podcast.\n\n0:03\n\nOh, thank you.\n\n0:04\n\nThat's very nice of you to say.\n\n0:06\n\nOkay, so let's start by talking about the releases that will go out when this\ninterview goes out.\n\n0:12\n\nTell me about the models.\n\n0:13\n\nTell me about Meta AI.\n\n0:14\n\nWhat's new?\n\n0:14\n\nWhat's exciting about them?\n\n0:15\n\nYeah, sure.\n\n0:16\n\nSo,\n\n0:16\n\nyou know,\n\n0:17\n\nI think the main thing that most people in the world are going to see is the\nnew\n\n0:19\n\nversion of Meta AI.\n\n0:21\n\nRight.\n\n0:21\n\nSo it's and, you know, the most important thing about what we're doing is the\nupgrade to the model.\n\n0:26\n\nWe're rolling out Lama 3.\n\n0:28\n\nWe're doing it both as open source for the dev community and it is now going\nto be powering Meta AI.\n\n0:33\n\nSo.\n\n0:35\n\nThere's a lot that I'm sure we'll go into around Llama 3,\n\n0:37\n\nbut I think the bottom line on this is that with Llama 3,\n\n0:40\n\nwe now think that Meta AI is the most intelligent AI assistant that people can\nuse\n\n0:45\n\nthat's freely available.\n\n0:47\n\nWe're also integrating Google and Bing for real-time knowledge.\n\n0:50\n\nWe're going to make it a lot more prominent across our apps.\n\n0:53\n\nSo basically, at the top of WhatsApp and Instagram and Facebook and Messenger,\n\n0:59\n\nUh, you'll just be able to, um, you know, use the search box right there to\nask, ask any question.\n\n1:03\n\nUm,\n\n1:04\n\nand there's a bunch of new creation features that we,\n\n1:06\n\nthat we added that I think are pretty cool that I think people enjoy.\n\n1:09\n\nUh, and I think animations is, is a good one.\n\n1:12\n\nUm, you can basically just take any image and animate it.\n\n1:15\n\nBut I think one that, that, uh, people are going to find pretty wild is, uh,\n\n1:20\n\nit now generates high quality images so quickly.\n\n1:24\n\nI don't know if you've gotten a chance to play with this,\n\n1:25\n\nthat it actually generates it as you're typing and updates it in real time.\n\n1:29\n\nSo you're like typing your query and it's kind of like honing in on,\n\n1:33\n\nand you know,\n\n1:34\n\nit's like,\n\n1:34\n\nokay,\n\n1:34\n\nhere,\n\n1:34\n\nyou know,\n\n1:35\n\nshow me a picture of a cow,\n\n1:38\n\nokay,\n\n1:38\n\nin a field with mountains in the background.\n\n1:40\n\nIt's just like everything's popular.\n\n1:41\n\nEating macadamia nuts, drinking beer.\n\n1:43\n\nAnd like, it's just like, it's updating the image in real time.\n\n1:47\n\nIt's pretty wild.\n\n1:48\n\nI think people are going to enjoy that.\n\n1:49\n\nSo, yeah, so that I think is that's what most people are going to see in the\nworld.\n\n1:53\n\nRight.\n\n1:53\n\nWe're rolling it out,\n\n1:55\n\nyou know,\n\n1:55\n\nnot everywhere,\n\n1:55\n\nbut we're starting in a handful of countries and we'll do more over the coming\n\n1:59\n\nweeks and months.\n\n2:02\n\nSo that's that I think is going to be a pretty big deal.\n\n2:04\n\nAnd I'm really excited to get that in people's hands.\n\n2:08\n\nit's a big step forward for Meta AI.\n\n2:12\n\nBut I think,\n\n2:12\n\nyou know,\n\n2:12\n\nif you want to get under the hood a bit,\n\n2:15\n\nthe Lama 3 stuff is obviously the most technically interesting.\n\n2:18\n\nSo,\n\n2:18\n\nyou know,\n\n2:19\n\nwe're basically,\n\n2:20\n\nfor the first version,\n\n2:20\n\nwe're training three versions,\n\n2:22\n\nyou know,\n\n2:23\n\nan 8 billion and a 70 billion,\n\n2:25\n\nwhich we're releasing today,\n\n2:27\n\nand a 405 billion dense model,\n\n2:29\n\nwhich is still training.\n\n2:31\n\nSo we're not releasing that today.\n\n2:32\n\nBut\n\n2:35\n\nThe 8 and 70, I'm pretty excited about how they turned out.\n\n2:41\n\nThey're leading for their scale.\n\n2:43\n\nWe'll release a blog post with all the benchmarks so people can check it out\nthemselves.\n\n2:50\n\nObviously, it's open source so people get a chance to play with it.\n\n2:54\n\nWe have a roadmap of new releases coming.\n\n2:57\n\nThat are going to bring multimodality, more multilinguality, bigger context\nwindows to those as well.\n\n3:04\n\nAnd then,\n\n3:05\n\nyou know,\n\n3:06\n\nhopefully sometime later in the year,\n\n3:08\n\nwe'll we'll get to roll out the four or five,\n\n3:10\n\nwhich I think is is in training.\n\n3:12\n\nIt's still training, but.\n\n3:15\n\nFor where it is right now in training, it is already at around 85 MMLU.\n\n3:22\n\nAnd we expect that it's going to have leading benchmarks on a bunch of the\nbenchmarks.\n\n3:29\n\nSo I'm pretty excited about all of that.\n\n3:31\n\nI mean, the $70 billion is...\n\n3:33\n\nis great too.\n\n3:35\n\nI mean, we're releasing that today.\n\n3:35\n\nIt's around 82 MMOU and has leading scores on math and reasoning.\n\n3:39\n\nSo I mean, I think just getting this in people's hands is going to be pretty\nwild.\n\n3:43\n\nOh, interesting.\n\n3:43\n\nYeah, that's the first I'm hearing this benchmark.\n\n3:44\n\nThat's super impressive.\n\n3:45\n\nYeah, the 8 billion is nearly as powerful as the biggest version of Llama 2\nthat we released.\n\n3:54\n\nSo it's like the smallest Llama 3 is basically as powerful as the biggest\nLlama 2.\n\n3:59\n\nOkay, so before we dig into these models, I actually want to go back in time.\n\n4:05\n\n2022 is, I'm assuming, when you started acquiring these H100s.\n\n4:09\n\nOr you can tell me when.\n\n4:11\n\nWe were like, stock price is getting hammered.\n\n4:12\n\nPeople are like, what's happening with all this CapEx?\n\n4:14\n\nPeople aren't buying the Metaverse.\n\n4:16\n\nAnd presumably you're spending that CapEx to get these H100s.\n\n4:19\n\nBack then, how did you know to get the H100s?\n\n4:21\n\nHow did you know we'll need the GPUs?\n\n4:23\n\nI think it was because we were working on Reels.\n\n4:26\n\nSo we got into this situation where we always want to have enough capacity to\nbuild\n\n4:35\n\nsomething that we can't quite see that we're on the horizon yet.\n\n4:40\n\nAnd we got into this position with Reels where we needed more GPUs to train\nthe models.\n\n4:47\n\nIt was this big evolution process.\n\n4:49\n\nFor our services,\n\n4:50\n\nwhere instead of just ranking content from people who you follow or your\nfriends\n\n4:54\n\nand whatever pages you follow,\n\n4:55\n\nwe made this big push to basically start recommending what we call unconnected\ncontent,\n\n5:03\n\nbasically content from people or pages that you're not following.\n\n5:07\n\nSo now kind of the...\n\n5:09\n\nthe corpus of content candidates that we could potentially show you expanded\nfrom\n\n5:14\n\non the order of thousands to on the order of hundreds of millions.\n\n5:19\n\nSo completely different infrastructure.\n\n5:21\n\nAnd we started working on doing that and we were constrained on basically the\n\n5:28\n\ninfrastructure that we had to catch up to what TikTok was doing as quickly as\nwe\n\n5:32\n\nwould have wanted to.\n\n5:33\n\nSo I basically looked at that and I was like, hey,\n\n5:36\n\nwe have to make sure that we're never in this situation again.\n\n5:39\n\nSo let's order enough GPUs to do what we need to do on reels and ranking\ncontent and feed.\n\n5:45\n\nBut let's also, let's double that, right?\n\n5:46\n\nBecause again,\n\n5:47\n\nlike our normal principle is there's going to be something on the horizon that\nwe\n\n5:50\n\ncan't see yet.\n\n5:51\n\nDid you know it would be AI?\n\n5:53\n\nUm,\n\n5:54\n\nWell,\n\n5:54\n\nwe thought it would be we thought it was going to be something that had to do\nwith\n\n5:57\n\ntraining large models.\n\n5:58\n\nRight.\n\n5:58\n\nI mean,\n\n5:59\n\nbut at the time,\n\n5:59\n\nI thought it was probably going to be more something that had to do with\ncontent.\n\n6:02\n\nBut I don't know.\n\n6:03\n\nI mean, it's almost just the pattern matching and running the company is\nthere's always another thing.\n\n6:10\n\nRight.\n\n6:10\n\nSo I'm not even sure I had at that time I was so deep and just.\n\n6:13\n\nyou know, trying to get, you know, the recommendations working for reels and\nother content.\n\n6:18\n\nCause I mean,\n\n6:19\n\nthat's just such a big unlock for Instagram and Facebook to now being able to\nshow\n\n6:22\n\npeople content that's interesting to them that they're from people that\nthey're not\n\n6:25\n\neven following.\n\n6:26\n\nBut yeah, I, that, that ended up being a very good decision in retrospect.\n\n6:32\n\nYeah.\n\n6:32\n\nYeah.\n\n6:33\n\nOkay.\n\n6:33\n\nAnd it came from being behind.\n\n6:34\n\nSo then it wasn't like I was, you know, it wasn't like, oh, I was so far\nahead.\n\n6:38\n\nActually,\n\n6:38\n\nmost of the times I think where we kind of make some decision that ends up\nseeming\n\n6:43\n\ngood is because we messed something up before and just didn't want to repeat\nthe mistake.\n\n6:47\n\nThis is a total detour, but I actually want to ask about this while we're on\nthis.\n\n6:50\n\nWe'll get back to AI in a second.\n\n6:52\n\nSo you didn't sell for $1 billion, but presumably there's some amount you\nwould have sold for, right?\n\n6:57\n\nDid you write down in your head,\n\n6:58\n\nlike,\n\n6:59\n\nI think the actual valuation of Facebook at the time is this,\n\n7:01\n\nand they're not actually getting the valuation right?\n\n7:03\n\nIf they offered you $5 trillion, of course you would have sold.\n\n7:05\n\nSo how did you think about that choice?\n\n7:09\n\nYeah, I don't know.\n\n7:10\n\nI mean, look, I think some of these things are just personal.\n\n7:12\n\nYeah.\n\n7:14\n\nI don't know at the time that I was sophisticated enough to do that analysis.\n\n7:18\n\nBut I had all these people around me who were making all these arguments for\nhow a\n\n7:24\n\nbillion dollars was...\n\n7:25\n\nIt's like,\n\n7:26\n\nhere's the revenue that we need to make and here's how big we need to be.\n\n7:29\n\nAnd it's clearly so many years in the future.\n\n7:31\n\nAnd it was very far ahead of where we were at the time.\n\n7:34\n\nAnd I don't know.\n\n7:35\n\nI didn't really have the financial sophistication to really even engage with\nthat kind of debate.\n\n7:42\n\nI just...\n\n7:43\n\nI think I sort of deep down believed in what we were doing.\n\n7:47\n\nAnd I did some analysis.\n\n7:48\n\nI was like, okay, well, what would I go do if I wasn't doing this?\n\n7:55\n\nIt's like,\n\n7:55\n\nwell,\n\n7:56\n\nI really like building things and I like helping people communicate and I like\n\n8:00\n\nunderstanding things.\n\n8:02\n\nwhat's going on with people and the dynamics between people.\n\n8:04\n\nSo I think if I sold this company, I'd just go build another company like\nthis.\n\n8:08\n\nAnd I kind of like the one I have.\n\n8:12\n\nSo I mean, why?\n\n8:15\n\nBut I don't know.\n\n8:17\n\nI think a lot of the biggest bets that people make\n\n8:21\n\nare often just based on conviction and values.\n\n8:26\n\nIt's actually usually very hard to do the analyses trying to connect the dots\nforward.\n\n8:31\n\nYeah.\n\n8:31\n\nSo you've had Facebook AI research for a long time.\n\n8:34\n\nNow it's become seemingly central to your company.\n\n8:39\n\nAt what point did making AGI or whatever,\n\n8:43\n\nhowever you consider that mission,\n\n8:44\n\nat what point is that like,\n\n8:45\n\nthis is a creek priority of what Meta is doing?\n\n8:49\n\nYeah, I mean, it's been a big deal for a while.\n\n8:51\n\nSo we started FAIR about 10 years ago.\n\n8:55\n\nAnd the idea was that along the way to general intelligence or AI,\n\n9:01\n\nlike full AI,\n\n9:02\n\nwhatever you want to call it,\n\n9:03\n\nthere can be all these different innovations and that's going to just improve\neverything that we do.\n\n9:08\n\nSo we didn't kind of conceive it as a product.\n\n9:11\n\nIt was more kind of a research group.\n\n9:14\n\nAnd over the last 10 years,\n\n9:17\n\nit has created a lot of different things that have basically improved all of\nour\n\n9:22\n\nproducts and advanced the field and allowed other people in the field to\ncreate\n\n9:26\n\nthings that have improved our products too.\n\n9:28\n\nSo I think that that's been great, but there's obviously a big change.\n\n9:32\n\nYeah.\n\n9:33\n\nIn the last few years, when ChatGPT comes out, the diffusion models around\nimage creation come out.\n\n9:39\n\nAnd this is some pretty wild stuff that I think is pretty clearly going to\naffect\n\n9:44\n\nhow people interact with every app that's out there.\n\n9:48\n\nSo at that point, we started a second group.\n\n9:54\n\num, the, the gen AI group, um, with the goal of basically bringing that stuff\ninto our product.\n\n10:00\n\nSo building leading foundation models that would, that would sort of power all\nthese different products.\n\n10:06\n\nAnd initially when we started doing that, um,\n\n10:10\n\nThe theory at first was, hey, a lot of the stuff that we're doing is pretty\nsocial, right?\n\n10:15\n\nSo it's helping people interact with creators,\n\n10:18\n\nhelping people interact with businesses so the businesses can sell things or\ndo\n\n10:23\n\ncustomer support or basic assistant functionality for whether it's for apps or\nthe\n\n10:30\n\nsmart glasses or VR,\n\n10:32\n\nlike all these different things.\n\n10:34\n\nSo initially,\n\n10:35\n\nit wasn't completely clear that you were going to need kind of full AGI to be\nable\n\n10:42\n\nto support those use cases.\n\n10:44\n\nBut then through working on them,\n\n10:46\n\nI think it's actually become clear that you do in all these subtle ways.\n\n10:49\n\nSo for example, for Llama 2, when we were working on it, we didn't prioritize\ncoding.\n\n10:53\n\nAnd the reason why we didn't prioritize coding is because people aren't going\nto\n\n10:56\n\nask Meta AI a lot of coding questions in WhatsApp.\n\n10:59\n\nNow they will.\n\n11:00\n\nWell, I don't know.\n\n11:01\n\nI'm not sure that WhatsApp is like the UI that people are going to be doing a\nlot of coding questions.\n\n11:05\n\nSo we're like,\n\n11:05\n\nall right,\n\n11:06\n\nlook,\n\n11:06\n\nin terms of the things that,\n\n11:07\n\nyou know,\n\n11:08\n\nor Facebook or Instagram or,\n\n11:09\n\nyou know,\n\n11:09\n\nthose different services,\n\n11:10\n\nmaybe the website or metadata.ai that we're launching,\n\n11:13\n\nI think.\n\n11:15\n\nBut the thing that was sort of,\n\n11:17\n\nI think,\n\n11:18\n\nhas been a somewhat surprising result over the last 18 months is that\n\n11:23\n\nIt turns out that coding is important for a lot of domains, not just coding,\nright?\n\n11:28\n\nSo even if people aren't asking coding questions to the models,\n\n11:32\n\ntraining the models on coding helps them just be more rigorous and answer the\n\n11:37\n\nquestion and kind of help reason across a lot of different types of domains.\n\n11:41\n\nOkay,\n\n11:41\n\nso that's one example where it's like,\n\n11:43\n\nall right,\n\n11:43\n\nso for Llama 3,\n\n11:43\n\nwe like really focused on training it with a lot of coding because it's like,\n\n11:46\n\nall right,\n\n11:46\n\nthat's gonna make it better on all these things,\n\n11:48\n\neven if people aren't asking primarily coding questions.\n\n11:52\n\nReasoning, I think, is another example.\n\n11:54\n\nIt's like,\n\n11:55\n\nokay,\n\n11:56\n\nyeah,\n\n11:56\n\nmaybe you want to chat with a creator or you're a business and you're trying\nto\n\n12:00\n\ninteract with a customer.\n\n12:01\n\nThat interaction is not just like, okay, the person sends you a message and\nyou just reply.\n\n12:06\n\nIt's like a multi-step interaction where you're trying to think through how do\nI\n\n12:11\n\naccomplish the person's goals.\n\n12:12\n\nAnd a lot of times when a customer comes, they don't necessarily respond.\n\n12:16\n\nknow exactly what they're looking for or how to ask their questions.\n\n12:19\n\nSo it's not really the job of the AI to just respond to the question.\n\n12:22\n\nIt's like you need to kind of think about it more holistically.\n\n12:25\n\nIt's really becomes a reasoning problem, right?\n\n12:26\n\nSo if someone else solves reasoning or makes good advances on reasoning and\nwe're\n\n12:31\n\nsitting here with a basic chat bot,\n\n12:33\n\nthen like our product is lame compared to what other people are building.\n\n12:36\n\nSo it's like,\n\n12:37\n\nso okay,\n\n12:38\n\nso at the end of the day,\n\n12:39\n\nwe've got we,\n\n12:40\n\nyou know,\n\n12:40\n\nwe basically realized,\n\n12:42\n\nwe've got to solve general intelligence.\n\n12:44\n\nAnd we just kind of upped the ante and the investment to make sure that we\ncould do that.\n\n12:49\n\nSo the version of Lama that that that's going to solve all these use cases for\nusers,\n\n12:57\n\nis that the version that will be powerful enough to like replace a programmer\nyou\n\n13:01\n\nmight have in this building?\n\n13:03\n\nI mean, I just think that all this stuff is going to be progressive over time.\n\n13:05\n\nBut in case, La Matin.\n\n13:10\n\nI think that there's a lot baked into that question.\n\n13:12\n\nI'm not sure that we're replacing people as much as giving people tools to do\nmore stuff.\n\n13:18\n\nIs the programmer in this building 10x more productive?\n\n13:20\n\nI would hope more.\n\n13:23\n\nBut no,\n\n13:23\n\nI mean,\n\n13:23\n\nlook,\n\n13:24\n\nI don't believe that there's a single threshold of intelligence for humanity\n\n13:29\n\nbecause people have different skills.\n\n13:31\n\nAt some point,\n\n13:31\n\nI think that AI is probably going to surpass people at most of those things,\n\n13:37\n\ndepending on how powerful the models are.\n\n13:39\n\nBut\n\n13:40\n\nUm, but I think it's progressive and I don't think AGI is one thing.\n\n13:44\n\nI think it's, you're basically adding different capabilities.\n\n13:47\n\nSo multimodality is,\n\n13:49\n\nis kind of a key one that we're focused on now,\n\n13:51\n\ninitially with photos and images and text,\n\n13:54\n\nbut eventually with videos.\n\n13:55\n\nAnd then because we're so focused on the metaverse kind of 3d type stuff is\nimportant.\n\n13:59\n\nUm, one modality that I'm pretty focused on that I haven't seen as many other\npeople in the\n\n14:08\n\nemotional understanding.\n\n14:10\n\nSo much of the human brain is just dedicated to understanding people and\n\n14:16\n\nunderstanding your expressions and emotions.\n\n14:19\n\nThat's its own whole modality.\n\n14:22\n\nYou could say,\n\n14:22\n\nokay,\n\n14:22\n\nmaybe it's just video or image,\n\n14:24\n\nbut it's clearly a very specialized version of those too.\n\n14:27\n\nThere's all these different capabilities that I think you want to\n\n14:31\n\nbasically train the models to focus on as well as getting a lot better at\nreasoning\n\n14:36\n\ngetting a lot better at memory which i think is is kind of its own whole thing\nit's\n\n14:39\n\ni mean i don't think we're going to be you know primarily shoving context or\nor\n\n14:43\n\nkind of things into a query context window um in the future to ask more\ncomplicated\n\n14:48\n\nquestions i think that there will be kind of different stores of memory or\n\n14:51\n\ndifferent custom models that um that are maybe more personalized to people but\n\n14:56\n\nI don't know.\n\n14:57\n\nI think that these are all just different capabilities and then obviously\nmaking them big and small.\n\n15:00\n\nWe care about both because,\n\n15:02\n\nyou know,\n\n15:02\n\nwe want to,\n\n15:02\n\nyou know,\n\n15:03\n\nif you're running something like Meta AI,\n\n15:05\n\nthen we have the ability to,\n\n15:06\n\nthat's pretty server based.\n\n15:08\n\nBut we also want it running on smart glasses and, you know, there's not a lot\nof space in smart glasses.\n\n15:13\n\nSo you want to have something that's very efficient for that.\n\n15:16\n\nWhat is the use case that if you're doing tens of billions of dollars worth of\ninference,\n\n15:20\n\nor even eventually hundreds of billions of dollars worth of inference,\n\n15:23\n\nusing intelligence in an industrial scale,\n\n15:25\n\nwhat is the use case?\n\n15:26\n\nIs it simulations?\n\n15:27\n\nIs it the AIs that will be in the metaverse?\n\n15:29\n\nWhat will we be using the data centers for?\n\n15:35\n\nI mean, our bet is that it's going to, this is basically going to change all\nof the products, right?\n\n15:39\n\nSo I think that there's going to be a kind of meta AI general assistant\nproduct.\n\n15:45\n\nAnd I think that that will shift from something that feels more like a chat\nbot\n\n15:50\n\nwhere it's like you just ask a question that kind of formulates an answer to\nthings\n\n15:54\n\nwhere you're increasingly giving it more complicated tasks and that goes away\nand\n\n15:57\n\ndoes them.\n\n15:58\n\nSo that's going to take a lot of inference.\n\n16:00\n\nIt's going to take a lot of compute in other ways too.\n\n16:02\n\nYeah.\n\n16:04\n\nThen I think that there's a big part of what we're going to do that is like\n\n16:09\n\ninteracting with other agents for other people.\n\n16:13\n\nSo whether it's businesses or creators,\n\n16:15\n\nI guess a big part of my theory on this is that there's not just going to be\nlike\n\n16:19\n\none singular AI that you interact with,\n\n16:21\n\nbecause I think,\n\n16:22\n\nyou know,\n\n16:23\n\nevery business is going to like,\n\n16:24\n\nwant an ai that represents their interests they're not going to like want to\n\n16:28\n\nprimarily interact with you through an ai that is going to sell their\ncompetitors\n\n16:31\n\ncustomers so sorry their competitors products um so um uh so yeah so i think\n\n16:39\n\ncreators is going to be a big one i mean there are about 200 million creators\non\n\n16:43\n\nour platforms they all basically have the pattern where um\n\n16:48\n\nThey want to engage their community, but they're limited by hours in the day.\n\n16:51\n\nAnd their community generally wants to engage them, but they're limited by\nhours in the day.\n\n16:56\n\nSo if you could create something where that creator can basically own the AI\nand\n\n17:03\n\ntrain it in the way that they want and can engage their community,\n\n17:08\n\nI think that that's going to be super powerful,\n\n17:09\n\ntoo.\n\n17:10\n\nSo I think that there's going to be a ton of engagement across all these\nthings.\n\n17:16\n\nbut these are just the consumer use cases.\n\n17:17\n\nI mean, I think when you think about stuff like, I mean, you know, I run like\nour foundation, right.\n\n17:23\n\nA Chan Zuckerberg initiative with my wife and,\n\n17:25\n\nyou know,\n\n17:26\n\nwe're doing a bunch of stuff on science and,\n\n17:27\n\nand there's obviously a lot of AI work that,\n\n17:30\n\nwhere I,\n\n17:30\n\nthat I think is going to advance science and healthcare and all these things\ntoo.\n\n17:34\n\nSo I think that it's like,\n\n17:35\n\nthere's a,\n\n17:35\n\nthis is,\n\n17:36\n\nI think it ended up affecting basically every area of the products and,\n\n17:39\n\nand,\n\n17:40\n\nand the,\n\n17:40\n\nand the,\n\n17:41\n\nthe economy.\n\n17:41\n\nThe thing you mentioned about an AI that can just go out and do something for\nyou\n\n17:45\n\nthat's multi-step,\n\n17:46\n\nis that a bigger model?\n\n17:48\n\nThere'll be a version that's still 70B,\n\n17:52\n\nbut you'll just turn it on the right data and that will be super powerful.\n\n17:56\n\nWhat does the progression look like?\n\n17:57\n\nIs it scaling?\n\n17:58\n\nIs it just same size, but different banks like you were talking about?\n\n18:05\n\nI don't know that we know the answer to that.\n\n18:08\n\nSo I think one thing that seems to be a pattern is that you have the LAMA\nmodel,\n\n18:16\n\nand then you build some kind of other application-specific code around it.\n\n18:22\n\nSo some of it is the fine-tuning for the use case,\n\n18:25\n\nbut some of it is just logic for how MetAI should integrate\n\n18:33\n\nthat should work with tools like Google or Bing to bring in real-time\nknowledge.\n\n18:36\n\nI mean, that's not part of the base Llama model.\n\n18:38\n\nThat's like part of a, okay.\n\n18:39\n\nSo for Llama 2, we had some of that and it was a little more kind of hand\nengineered.\n\n18:45\n\nAnd then part of our goal for Llama 3 was to bring more of that into the model\nitself.\n\n18:51\n\nAnd but for Lama three,\n\n18:52\n\nas we start getting into more of these agent like behaviors,\n\n18:56\n\nI think some of that is going to be more hand engineered.\n\n18:59\n\nAnd then I think our goal for Lama four will be to bring more of that into the\nmodel.\n\n19:03\n\nSo I think at each point, like at each step along the way, you kind of have a\nsense of\n\n19:08\n\nof what's going to be possible on the horizon.\n\n19:10\n\nYou start messing with it and hacking around it.\n\n19:13\n\nAnd then I think that that helps you hone your intuition for what you want to\ntry\n\n19:17\n\nto train into the next version of the model itself.\n\n19:19\n\nInteresting.\n\n19:20\n\nWhich makes it more general because obviously anything that you're hand coding\nis,\n\n19:24\n\nyou know,\n\n19:25\n\nyou can unlock some use cases,\n\n19:26\n\nbut it's just inherently brittle and non-general.\n\n19:30\n\nHey everybody, real quick, I want to tell you about a tool that I wish more\napplications used.\n\n19:35\n\nSo obviously you've noticed every single company is trying to add an AI\nchatbot to their website.\n\n19:41\n\nBut as a user,\n\n19:43\n\nI usually find them really annoying because they give these long,\n\n19:46\n\ngeneric,\n\n19:46\n\noften useless answers.\n\n19:48\n\nCommandBar is a user assistant that you can just embed into your website or\napplication.\n\n19:54\n\nAnd it feels like you're talking to a friendly human support agent who is\nbrowsing with you and for you.\n\n20:00\n\nAnd it's much more personalized than a regular chatbot.\n\n20:04\n\nIt can actually look up users' history and respond differently based on that.\n\n20:08\n\nIt can use APIs to perform actions.\n\n20:11\n\nIt can even proactively nudge users to explore new features.\n\n20:15\n\nOne thing that I think is really cool is that instead of just outputting text,\n\n20:19\n\nCommandBar can kind of just say,\n\n20:20\n\nhere,\n\n20:21\n\nlet me show you and start browsing alongside the user.\n\n20:25\n\nAnyways, they're in a bunch of great products already.\n\n20:27\n\nYou can learn more about them at commandbar.com.\n\n20:32\n\nThanks to them for sponsoring this episode.\n\n20:34\n\nAnd now back to Mark.\n\n20:35\n\nWhen you say into the model itself, you train it on the thing that you want in\nthe model itself?\n\n20:40\n\nWhat do you mean by into the model itself?\n\n20:42\n\nWell,\n\n20:43\n\nI mean,\n\n20:43\n\nI think like the example that I gave for Lama 2,\n\n20:46\n\nwhere,\n\n20:46\n\nyou know,\n\n20:48\n\nwe really,\n\n20:49\n\nI mean,\n\n20:49\n\nfor Lama 2,\n\n20:50\n\nthe tool use was very,\n\n20:52\n\nvery specific.\n\n20:54\n\nWhereas Lama 3 has the ability to, has much better tool use, right?\n\n20:57\n\nSo we don't have to like,\n\n20:59\n\nhand code all the stuff to have it use google to to go do a search um it just\nkind\n\n21:05\n\nof can do that um so and similarly for coding and and kind of running code and\njust\n\n21:12\n\na bunch of stuff like that and um but i think once you kind of get that\ncapability\n\n21:18\n\nthen you get a peak of, okay, well, what can we start doing next?\n\n21:21\n\nOkay,\n\n21:21\n\nwell,\n\n21:21\n\nI don't necessarily wanna wait until Llama 4 is around to start building those\ncapabilities,\n\n21:25\n\nso let's start hacking around it.\n\n21:27\n\nAnd so you do a bunch of hand coding and that makes the products better for\nthe interim,\n\n21:32\n\nbut then that also helps show the way of what we wanna try to build into the\nnext\n\n21:36\n\nversion of the model.\n\n21:37\n\nWhat is the community fine tune of Llama 3 you're most excited by?\n\n21:41\n\nMaybe not the one that will be most useful to you, but just you will just\nenjoy playing it with the most.\n\n21:46\n\nThey'll fine tune it on antiquity and you'll just be talking to Virgil or\nsomething.\n\n21:49\n\nWhat are you excited about?\n\n21:50\n\nI don't know.\n\n21:53\n\nI think the nature of the stuff is it's like you get surprised.\n\n21:57\n\nSo I think any specific thing that I sort of\n\n22:03\n\nthought would be valuable, we'd probably be building.\n\n22:07\n\nBut I think you'll get distilled versions.\n\n22:11\n\nI think you'll get kind of smaller versions.\n\n22:13\n\nI mean, one thing that I think is\n\n22:17\n\n8 billion, I don't think is quite small enough for a bunch of use cases,\nright?\n\n22:21\n\nI think like over time,\n\n22:23\n\nI'd love to get,\n\n22:24\n\nyou know,\n\n22:24\n\na billion parameter model or a 2 billion parameter model,\n\n22:28\n\nor even like a,\n\n22:28\n\nI don't know,\n\n22:29\n\nmaybe like a 500 million parameter model and see what you can do with that.\n\n22:32\n\nBecause I mean, as they start getting...\n\n22:34\n\nIf with 8 billion parameters,\n\n22:36\n\nwe're basically nearly as powerful as the largest Lama 2 model,\n\n22:39\n\nthen with a billion parameters,\n\n22:41\n\nwe should be able to do something that's interesting,\n\n22:43\n\nright?\n\n22:43\n\nAnd faster,\n\n22:45\n\ngood for classification or a lot of kind of like basic things that people do\nbefore\n\n22:50\n\nkind of understanding the intent of a user query and feeding it to the most\n\n22:55\n\npowerful model to kind of hone what the prompt should be.\n\n22:59\n\nSo I don't know.\n\n23:01\n\nI think that's one thing that maybe the community can help fill in.\n\n23:03\n\nBut I mean, we're also thinking about getting around to distilling some of\nthese ourselves.\n\n23:08\n\nBut right now, the GPUs are training the 405.\n\n23:11\n\nOkay, so you have all these GPUs.\n\n23:16\n\nI think you said 350,000 by the end of the year.\n\n23:18\n\nThat's the whole fleet.\n\n23:19\n\nI mean, we built two...\n\n23:23\n\nI think it's like 22,\n\n23:25\n\n24,000 clusters that are kind of the single clusters that we have for training\nthe\n\n23:29\n\nbig models.\n\n23:30\n\nI mean,\n\n23:30\n\nobviously across a lot of the stuff that we do,\n\n23:32\n\na lot of our stuff goes towards training like reels models and like Facebook\nnews\n\n23:37\n\nfeed and Instagram feed.\n\n23:38\n\nAnd then inference is a huge thing for us because we serve a ton of people,\nright?\n\n23:41\n\nSo our ratio of inference is,\n\n23:45\n\ncompute required to training is probably much higher than most other companies\nthat\n\n23:51\n\nare doing this stuff just because of the sheer volume of the community that\nwe're serving.\n\n23:55\n\nYeah.\n\n23:55\n\nYeah.\n\n23:56\n\nYeah.\n\n23:56\n\nThat was really interesting in the material they shared with me before that\nyou\n\n23:59\n\ntrained it on more data than is compute optimal just for training because the\n\n24:03\n\ninference is such a big deal for you guys and also for the community that it\nmakes\n\n24:06\n\nsense to just have this thing and have trillions of tokens in there.\n\n24:09\n\nYeah.\n\n24:09\n\nYeah.\n\n24:10\n\nAlthough in one of the interesting things about it that we saw even with the\n70\n\n24:13\n\nbillion is we we thought it would get more saturated at,\n\n24:18\n\nyou know,\n\n24:18\n\nit's like we trained it on around 15 trillion tokens.\n\n24:21\n\nYeah.\n\n24:22\n\nI guess our prediction going in was that it was going to asymptote more.\n\n24:27\n\nBut even by the end, it was...\n\n24:29\n\nstill learning right it's like we probably could have fed it more tokens and\nit\n\n24:34\n\nwould have gotten somewhat better but i mean at some point you know you're\nrunning\n\n24:37\n\na company you need to do these meta reasoning questions of like all right how\ndo i\n\n24:41\n\nwant to spend our gpus on like training this 70 billion model further do we\nwant to\n\n24:46\n\nkind of get on with it so we can start testing hypotheses for llama 4 so we\nkind of\n\n24:51\n\nneeded to to make um to make that call and i think we got it we i think we got\nto a\n\n24:55\n\nreasonable balance for for this version of the 70 billion um\n\n24:59\n\nThere will be others in the future where,\n\n25:00\n\nyou know,\n\n25:01\n\nthe 70 billion multimodal one that'll come over the next period.\n\n25:05\n\nBut yeah, I mean, that was fascinating that the architectures at this point\ncan just take so much data.\n\n25:11\n\nYeah, that's really interesting.\n\n25:13\n\nSo what does this imply about future models?\n\n25:15\n\nYou mentioned that the LAMA-3 8B is better than the LAMA-2 70B, right?\n\n25:20\n\nNo, no, no.\n\n25:20\n\nIt's nearly as good.\n\n25:21\n\nOkay.\n\n25:22\n\nI don't overstate.\n\n25:22\n\nBut does that mean like the LAMA-4?\n\n25:23\n\nIn the same order of magnitude.\n\n25:24\n\nDoes that mean the Lama 470B will be as good as the Lama 3405B?\n\n25:27\n\nWhat is the future of this?\n\n25:29\n\nThis is one of the great questions that I think no one knows.\n\n25:37\n\nIt's one of the trickiest things in the world to plan around is when you have\nan\n\n25:40\n\nexponential curve,\n\n25:41\n\nhow long does it keep going for?\n\n25:43\n\nYeah.\n\n25:45\n\nI think it's likely enough that it will keep going,\n\n25:48\n\nthat it is worth investing the tens or 100 billion plus in building the\n\n25:55\n\ninfrastructure to assume that if that kind of keeps going,\n\n25:58\n\nyou're going to get some really amazing things that are just going to make\namazing products.\n\n26:03\n\nBut.\n\n26:05\n\nI don't think anyone in the industry can really tell you that it will continue\n\n26:09\n\nscaling at that rate for sure.\n\n26:11\n\nIn general, in history, you hit bottlenecks at certain points.\n\n26:15\n\nAnd now there's so much energy on this that maybe those bottlenecks get\nknocked over pretty quickly.\n\n26:20\n\nBut I don't know.\n\n26:22\n\nI think that's an interesting question.\n\n26:24\n\nWhat does the world look like where there aren't these bottlenecks?\n\n26:27\n\nYou know, suppose like progress just continues at this pace, which seems like\nplausible.\n\n26:33\n\nLike zooming out.\n\n26:34\n\nThey're going to be different bottlenecks.\n\n26:37\n\nRight.\n\n26:37\n\nSo if not training, then like, oh yeah, go ahead.\n\n26:40\n\nWell, I think at some point,\n\n26:42\n\nOver the last few years, I think there's this issue of GPU production, right?\n\n26:48\n\nSo even companies that had the models,\n\n26:51\n\nsorry,\n\n26:51\n\nthat had the money to pay for the GPUs couldn't necessarily get as many as\nthey\n\n26:56\n\nwanted because there were all these supply constraints.\n\n26:59\n\nNow I think that's sort of getting less.\n\n27:02\n\nSo now I think you're seeing a bunch of companies think about,\n\n27:06\n\nwow,\n\n27:07\n\nwe should just like really invest a lot of money in building out these things.\n\n27:10\n\nAnd I think that that will go for some period of time.\n\n27:13\n\nI think there is a capital question of like, okay,\n\n27:19\n\nat what point does it stop being worth it to put the capital in but i actually\n\n27:23\n\nthink before we hit that you're going to run into energy constraints right\nbecause\n\n27:28\n\num i just i mean i don't think anyone's built a gigawatt single training\ncluster\n\n27:35\n\nyet right and um and then you run into these things that just end up being\nslower\n\n27:39\n\nin the world like\n\n27:40\n\ngetting energy permitted is like a very heavily regulated government function,\nright?\n\n27:47\n\nSo you're going from, on the one hand, software, which is somewhat regulated.\n\n27:53\n\nI'd argue that it is more regulated than I think a lot of people in the tech\n\n27:56\n\ncommunity feel,\n\n27:57\n\nalthough it's obviously different.\n\n27:59\n\nIf you're starting a small company, maybe you feel that less.\n\n28:01\n\nIf you're a big company, we just interact with people.\n\n28:04\n\nDifferent governments and regulators are, you know, we have kind of...\n\n28:08\n\nLots of rules that we need to follow and make sure we do a good job with\naround the world.\n\n28:13\n\nBut I think that there's no doubt that energy,\n\n28:14\n\nand if you're talking about building large new power plants or large build-\nouts and\n\n28:20\n\nthen building transmission lines that cross\n\n28:24\n\nother private or public land, that is just a heavily regulated thing.\n\n28:28\n\nSo you're talking about many years of lead time.\n\n28:30\n\nSo if we wanted to stand up just some massive facility to power that, I think\nthat that is...\n\n28:40\n\nThat's that's a very long term project.\n\n28:43\n\nRight.\n\n28:43\n\nAnd so I don't know.\n\n28:45\n\nI think that that's I think people do it.\n\n28:47\n\nBut I don't think that this is like something that can be quite as magical as\njust like,\n\n28:51\n\nOK,\n\n28:52\n\nyou get a level of AI and you get a bunch of capital and you put it in and\nthen\n\n28:55\n\nlike all of a sudden the models are just going to kind of like it just like I\nthink\n\n28:58\n\nyou do hit different bottlenecks along the way.\n\n29:00\n\nYeah.\n\n29:00\n\nIs there something,\n\n29:01\n\na project,\n\n29:02\n\nmaybe AI related,\n\n29:03\n\nmaybe not,\n\n29:04\n\nthat even a company like Meta doesn't have the resources for?\n\n29:07\n\nLike if your R&D budget or CapEx budget was 10x what it is now, then you could\npursue it.\n\n29:12\n\nLike it's in the back of your mind.\n\n29:13\n\nBut Meta today, and maybe you could like, even you can't even issue a stock or\nbond for it.\n\n29:18\n\nIt's like just 10x bigger than your budget.\n\n29:20\n\nwell i think energy is one piece yeah right um i think we would probably build\nout\n\n29:25\n\nbigger clusters than we currently can if we could get the energy to do it so i\n\n29:32\n\nthink that that's um that's fundamentally money bottlenecked in the limit like\nif\n\n29:38\n\nyou had a trillion dollars it's time yeah right um\n\n29:42\n\nWell, if you look at it in terms of, but it depends on how far the exponential\ncurves go, right?\n\n29:47\n\nLike I think a number of companies are working on,\n\n29:50\n\nyou know,\n\n29:50\n\nright now I think,\n\n29:51\n\nyou know,\n\n29:51\n\nlike a lot of data centers are on the order of 50 megawatts or a hundred\nmegawatts\n\n29:55\n\nor like a big one might be 150 megawatts.\n\n29:57\n\nOkay.\n\n29:58\n\nSo you take a whole data center and you fill it up with just all the stuff\nthat you\n\n30:01\n\nneed to do for training and you build the biggest cluster you can.\n\n30:04\n\nI think that's kind of, I think a bunch of companies are running at stuff like\nthat.\n\n30:08\n\num but then when you start getting into building a data center that's like 300\n\n30:16\n\nmegawatts or 500 megawatts or a gigawatt i just i mean just no one has built a\n\n30:21\n\nsingle gigawatt data center yet so i think it will happen right i mean this is\nonly\n\n30:24\n\na matter of time but it's it's not going to be like next year right it's um i\nthink\n\n30:29\n\nthat some of these things will take i don't know some some number of years to\nbuild\n\n30:35\n\nout and then the question is okay well if you\n\n30:39\n\ni mean just i guess put this in perspective i think a gigawatt it's like\naround the\n\n30:45\n\nsize of like a meaningful nuclear power plant only going towards training a\nmodel\n\n30:51\n\ndidn't it didn't amazon do this there's like they have a 950 gig a megawatt uh\nyeah\n\n30:55\n\ni'm not exactly sure what you did you'd have to what they did you'd have to\nask\n\n30:58\n\nthem um\n\n31:00\n\nBut it doesn't have to be in the same place, right?\n\n31:01\n\nIf distributed training works, it can be distributed.\n\n31:03\n\nThat I think is a big question, is basically how that's going to work.\n\n31:06\n\nAnd I do think in the future,\n\n31:07\n\nit seems quite possible that more of what we call training for these big\nmodels is actually...\n\n31:17\n\nmore along the lines of inference generating synthetic data to then go feed\ninto the model.\n\n31:23\n\nSo I don't know what that ratio is going to be,\n\n31:25\n\nbut I consider the generation of synthetic data to be more inference than\ntraining today.\n\n31:31\n\nBut obviously, if you're doing it in order to train a model, it's part of the\nbroader training process.\n\n31:35\n\nSo I don't know,\n\n31:38\n\nthat's an open question is to kind of where what the balance of that and how\nthat\n\n31:42\n\nplays out.\n\n31:43\n\nIf that's the case, would that potentially also be the case with Lama 3?\n\n31:47\n\nAnd maybe like Lama 4 onwards,\n\n31:49\n\nwhere you put this out and if somebody has a ton of compute,\n\n31:52\n\nthen using the models that you've put out,\n\n31:54\n\nyou can just keep making these things arbitrarily smarter.\n\n31:57\n\nLike some Kuwait or UAE or some random country has a ton of compute and they\ncan\n\n32:02\n\njust actually just use Lama 4 to just make something much smarter.\n\n32:08\n\nI do think that there are going to be dynamics like that.\n\n32:12\n\nBut I also think that there is a fundamental limitation on...\n\n32:20\n\non kind of the network architecture, right?\n\n32:22\n\nOr the kind of model architecture, right?\n\n32:24\n\nSo I think like a 70 billion model that kind of we trained with the Llama 3\n\n32:30\n\narchitecture can get better,\n\n32:31\n\nright?\n\n32:32\n\nIt can keep going.\n\n32:33\n\nLike I was saying,\n\n32:34\n\nit's,\n\n32:34\n\nyou know,\n\n32:34\n\nwe felt like if we kept on feeding it more data or rotated the high value\ntokens\n\n32:40\n\nthrough again,\n\n32:40\n\nthen,\n\n32:41\n\nyou know,\n\n32:41\n\nit would continue getting better.\n\n32:43\n\nBut\n\n32:46\n\nAnd we've seen a bunch of other people around the world,\n\n32:49\n\ndifferent companies basically take the Lama 2,\n\n32:51\n\n70 billion base,\n\n32:53\n\ntake that model architecture and then build a new model.\n\n32:57\n\nIt's still the case that when you make a generational improvement to the kind\nof\n\n33:01\n\nLama 3 $70 billion or the Lama 3 $405 billion,\n\n33:03\n\nthere's nothing open source,\n\n33:04\n\nanything like that today.\n\n33:06\n\nI think that it's a big step function and what people are going to be able to\nbuild\n\n33:12\n\non top of that I don't think can go infinitely from there.\n\n33:16\n\nI think there can be some optimization in that until you get to the next step\nfunction.\n\n33:21\n\nYeah.\n\n33:21\n\nOkay,\n\n33:22\n\nso let's zoom out a little bit from specific models and even the many years\nlead\n\n33:27\n\ntimes you would need to get energy approvals and so on.\n\n33:30\n\nLike big picture, these next couple of decades, what's happening with AI?\n\n33:34\n\nDoes it feel like another technology like metaverse or social or does it feel\nlike\n\n33:38\n\na fundamentally different thing in the course of human history?\n\n33:45\n\nI think it's gonna be pretty fundamental.\n\n33:47\n\nI think it's gonna be more like the creation of computing in the first place,\nright?\n\n33:53\n\nSo you'll get all these new apps\n\n33:58\n\nin the same way that when you got the web or you got mobile phones you got\nlike\n\n34:04\n\npeople basically rethought all these experiences and a lot of things that\nweren't\n\n34:07\n\npossible before now became possible um something that will happen but i think\nit's\n\n34:12\n\na much lower level innovation it's um it's it's going to be more like going\nfrom\n\n34:18\n\npeople didn't have computers to people have computers is my my sense um\n\n34:24\n\nBut it's also... I don't know.\n\n34:30\n\nIt's very hard to reason about exactly how this goes.\n\n34:33\n\nI tend to think that in the cosmic scale,\n\n34:37\n\nobviously,\n\n34:38\n\nit'll happen quickly over a couple of decades or something.\n\n34:42\n\nBut I do think that there is some set of people who are afraid of...\n\n34:47\n\nyou know,\n\n34:47\n\nit really just kind of spins and goes from being like somewhat intelligent to\n\n34:50\n\nextremely intelligent overnight.\n\n34:52\n\nAnd I just think that there's all these physical constraints that make that so\nthat\n\n34:55\n\nthat's unlikely to happen.\n\n34:56\n\nI just don't, I don't really see that playing out.\n\n35:00\n\nSo I think you'll have,\n\n35:01\n\nI think we'll have time to kind of acclimate a bit,\n\n35:04\n\nbut it will really change the way that we work and give people all these\ncreative\n\n35:08\n\ntools to do different things that they\n\n35:12\n\nYeah, I think it's going to really enable people to do the things that they\nwant a lot more, is my view.\n\n35:20\n\nOkay,\n\n35:20\n\nso maybe not overnight,\n\n35:21\n\nbut is it your view that on a cosmic scale,\n\n35:24\n\nif you think humans evolved,\n\n35:26\n\nand then AI happened,\n\n35:27\n\nand then they went out through the galaxy?\n\n35:29\n\nOr maybe it takes many decades,\n\n35:31\n\nmaybe it takes a century,\n\n35:32\n\nbut is that the grand scheme of what's happening right now in history?\n\n35:37\n\nYeah.\n\n35:39\n\nSorry, in what sense?\n\n35:40\n\nIn the sense that there are other technologies like computers and even like\nfire,\n\n35:43\n\nbut the AI happening is as significant as humans evolving in the first place.\n\n35:49\n\nI think that's tricky.\n\n35:50\n\nI think people like to...\n\n35:54\n\nThe history of humanity,\n\n35:55\n\nI think,\n\n35:56\n\nhas been people basically thinking that certain aspects of humanity are like\n\n36:06\n\nreally unique in different ways.\n\n36:08\n\nAnd then coming to grips with the fact that that's not true,\n\n36:13\n\nbut humanity is actually still super special,\n\n36:15\n\nright?\n\n36:15\n\nSo it's,\n\n36:16\n\num,\n\n36:18\n\nit's like,\n\n36:19\n\nwe thought that the earth was the center of the universe and it's like,\n\n36:22\n\nit's not,\n\n36:22\n\nbut like,\n\n36:24\n\nit's like humans are still pretty awesome.\n\n36:26\n\nRight.\n\n36:26\n\nAnd pretty unique.\n\n36:28\n\nUm, I think that another bias that people tend to have is thinking that\nintelligence is somehow\n\n36:36\n\nkind of fundamentally connected to life and it's not actually clear that it is\n\n36:43\n\nright i think like like people think that um i mean i don't know that we have\na\n\n36:49\n\nclear enough definition of consciousness or um or or life to kind of fully um\n\n36:55\n\ninterrogate this but\n\n36:58\n\nI know there's all this science fiction about,\n\n36:59\n\nokay,\n\n37:00\n\nyou create intelligence and now it starts taking on all these human-like\nbehaviors\n\n37:05\n\nand things like that.\n\n37:06\n\nBut I actually think that the current incarnation of all this stuff,\n\n37:09\n\nat least,\n\n37:10\n\nkind of feels like it's going in a direction where intelligence can be pretty\n\n37:13\n\nseparated from consciousness and agency and things like that.\n\n37:17\n\nThat...\n\n37:19\n\nI think just makes it a super valuable tool.\n\n37:21\n\nSo I don't know.\n\n37:22\n\nI mean,\n\n37:22\n\nobviously it's very difficult to predict what direction this stuff goes in\nover time,\n\n37:26\n\nwhich is why I don't think anyone should be dogmatic about how they plan to\ndevelop\n\n37:32\n\nit or what they plan to do.\n\n37:33\n\nI think you want to kind of look at each release.\n\n37:36\n\nIt's like we're obviously very pro-open source,\n\n37:38\n\nbut I haven't committed that we're going to release every single thing that we\ndo.\n\n37:41\n\nBut it's basically, I'm just generally very inclined to thinking that open\nsourcing it is going to be\n\n37:47\n\ngood for the community and also good for us, right?\n\n37:50\n\nBecause we'll benefit from the innovations.\n\n37:54\n\nBut if at some point there's some qualitative change in what the thing is\ncapable\n\n37:58\n\nof and we feel like it's just not responsible to open source it,\n\n38:01\n\nthen we won't.\n\n38:02\n\nSo I don't know.\n\n38:06\n\nIt's all very difficult to predict.\n\n38:07\n\nYeah.\n\n38:08\n\nWhat is a kind of qualitative change, like a specific thing?\n\n38:11\n\nYou're training Lama 5, Lama 4, and you've seen this.\n\n38:16\n\nYou know what?\n\n38:16\n\nI'm not sure about open sourcing it.\n\n38:20\n\nI think that it's a little hard to answer that in the abstract because there\nare\n\n38:25\n\nnegative behaviors that any product can exhibit that as long as you can\nmitigate it,\n\n38:31\n\nit's okay.\n\n38:35\n\nThere's bad things about social media that we work to mitigate.\n\n38:38\n\nThere's bad things about Lama 2 that we spend a lot of time trying to make\nsure that it's not like...\n\n38:44\n\nhelping people commit violent acts or things like that, right?\n\n38:46\n\nI mean, that doesn't mean that it's like a kind of autonomous or intelligent\nagent.\n\n38:52\n\nIt just means that it's learned a lot about the world and it can answer a set\nof\n\n38:55\n\nquestions that we think it would be unhelpful for it to answer.\n\n38:59\n\nSo I don't know.\n\n39:03\n\nI think the question isn't really what behaviors would it\n\n39:07\n\nshow, it's what things would we not be able to mitigate after it shows that.\n\n39:11\n\nAnd I don't know.\n\n39:15\n\nI think that there's so many ways in which something can be good or bad that\nit's\n\n39:20\n\nhard to actually enumerate them all up front.\n\n39:21\n\nIf you even look at what we've had to deal with in\n\n39:25\n\nin social media and the different types of harms.\n\n39:28\n\nWe've basically gotten to, there's like 18 or 19 categories of harmful things\nthat people do.\n\n39:34\n\nAnd we've basically built AI systems to try to go identify what those things\nare\n\n39:38\n\nthat people are doing and try to make sure that that doesn't happen on our\nnetwork\n\n39:42\n\nas much as possible.\n\n39:42\n\nSo yeah, over time, I think you'll be able to break down this into more of a\ntaxonomy too.\n\n39:49\n\nAnd I think this is a thing that we spend time researching too,\n\n39:52\n\nbecause we want to make sure that we understand that.\n\n39:54\n\nSo one of the things I asked Mark is what industrial scale use of LLMs would\nlook like.\n\n40:00\n\nYou see this in previous technological revolutions where at first they're\nthinking\n\n40:03\n\nin a very small scale way about what's enabled.\n\n40:06\n\nAnd I think that's what chatbots might be for LLMs.\n\n40:08\n\nAnd I think the large scale use case might look something like what v7 Go is.\n\n40:13\n\nAnd by the way, it's made by v7 Labs who's sponsoring this episode.\n\n40:16\n\nSo it's like a spreadsheet.\n\n40:18\n\nYou put in raw information like documents,\n\n40:21\n\nimages,\n\n40:21\n\nwhatever,\n\n40:22\n\nand they become rows and the columns are populated by an LLM of your choice.\n\n40:27\n\nAnd in fact, I used it to prepare for Mark.\n\n40:30\n\nSo I fed in a bunch of blog posts and papers from Meta's AI research.\n\n40:34\n\nAnd as you can see,\n\n40:35\n\nif you're on YouTube,\n\n40:36\n\nit summarizes and extracts exactly the information I want as columns.\n\n40:40\n\nAnd obviously mine is a small use case, but you can imagine, for example, a\ncompany like FedEx.\n\n40:46\n\nhas to process half a million documents a day, obviously a chatbot can't do\nthat.\n\n40:50\n\nA spreadsheet can, because this is just like a fire hose of intelligence in\nthere, right?\n\n40:55\n\nAnyways, you can learn more about them at v7labs.com slash go, or the link in\nthe description.\n\n41:00\n\nBack to Mark.\n\n41:01\n\nYeah, like it seems to me it would be a good idea.\n\n41:04\n\nI would be disappointed in a future where AI systems aren't broadly deployed\nand\n\n41:08\n\neverybody doesn't have access to them.\n\n41:10\n\nAt the same time, I want to better understand the mitigations.\n\n41:14\n\nBecause if the mitigation is the fine tuning,\n\n41:17\n\nwell,\n\n41:17\n\nthe whole thing about open weights is that you can then\n\n41:20\n\num remove the fine-tuning which is often superficial on top of these\ncapabilities\n\n41:24\n\nlike if it's like talking on slack with a biology researcher and again i think\nlike\n\n41:29\n\nmodels are very far from this they're right now they're like google search um\nbut\n\n41:33\n\nit's like i can show them my petri dish and they can explain like here's why\nyou're\n\n41:36\n\na smallpox sample didn't grow um here's what to change um how do you mitigate\nthat\n\n41:41\n\nbecause somebody can just like fine-tune that in there right yeah i mean\n\n41:46\n\nThat's true.\n\n41:46\n\nI think a lot of people will basically use the off-the-shelf model.\n\n41:51\n\nAnd some people who have basically bad faith are going to try to strip out all\nthe bad stuff.\n\n41:57\n\nSo I do think that that's an issue.\n\n41:58\n\nThe...\n\n42:01\n\nThe flip side of this is that,\n\n42:03\n\nand this is one of the reasons why I'm kind of philosophically so pro open\nsource,\n\n42:08\n\nis I do think that a concentration of AI in the future has the potential to be\nas\n\n42:16\n\ndangerous as kind of it being widespread.\n\n42:20\n\nSo I think a lot of people are,\n\n42:21\n\nthey think about the questions of,\n\n42:23\n\nokay,\n\n42:24\n\nwell,\n\n42:24\n\nif we can do this stuff,\n\n42:24\n\nis it bad for it to be out wild?\n\n42:26\n\nLike just in kind of widely available.\n\n42:31\n\nI think another version of this is like,\n\n42:33\n\nokay,\n\n42:33\n\nwell,\n\n42:34\n\nit's probably also pretty bad for one institution to have an AI that is way\nmore\n\n42:42\n\npowerful than everyone else's AI,\n\n42:44\n\nright?\n\n42:44\n\nSo if you look at like, I guess one security analogy that I think of is, you\nknow, it doesn't take AI...\n\n42:54\n\nto basically, okay, there's security holes in so many different things.\n\n42:57\n\nAnd if you could travel back in time a year or two years, right?\n\n43:01\n\nIt's like, that's not AI.\n\n43:03\n\nIt's like you just,\n\n43:04\n\nlet's say you just have like one year or two years more knowledge of the\nsecurity holes.\n\n43:08\n\nYou can pretty much hack into like any system, right?\n\n43:10\n\nSo it's not that far fetched to believe,\n\n43:13\n\nthat a very intelligent AI would probably be able to identify some holes and\n\n43:19\n\nbasically be like a human who could potentially go back in time a year or two\nand\n\n43:22\n\ncompromise all these systems.\n\n43:23\n\nOkay, so how have we dealt with that as a society?\n\n43:26\n\nWell,\n\n43:27\n\nOne big part is open source software that makes it so that when improvements\nare\n\n43:31\n\nmade to the software,\n\n43:32\n\nit doesn't just kind of get stuck in one company's products,\n\n43:35\n\nbut it can kind of be broadly deployed to a lot of different systems,\n\n43:39\n\nwhether it's banks or hospitals or government stuff.\n\n43:42\n\nAnd like just everyone can kind of like as the software gets hardened.\n\n43:46\n\nwhich happens because more people can see it and more people can bang on it\nand\n\n43:50\n\nthere are standards on how this stuff works,\n\n43:53\n\nthe world can kind of get upgraded together pretty quickly.\n\n43:56\n\nAnd I kind of think that a world where AI is very widely deployed in a way\nwhere\n\n44:02\n\nit's gotten hardened progressively over time and is one where all the\ndifferent\n\n44:09\n\nsystems will be in check in a way that seems like it is fundamentally more\nhealthy\n\n44:13\n\nto me than one where this is more concentrated.\n\n44:16\n\nSo there are risks on all sides,\n\n44:19\n\nbut I think that that's one risk that I think people,\n\n44:24\n\nI don't hear them talking about quite as much.\n\n44:25\n\nI think like there's sort of the risk of like, okay, well, what if the AI\nsystem does something bad?\n\n44:30\n\nI am more like, you know, I stay up at night more worrying.\n\n44:34\n\nWell, what if like,\n\n44:36\n\nsome actor that whatever it's like from wherever you sit there's going to be\nsome\n\n44:40\n\nactor who you don't trust if they're the ones who have like the super strong\nai\n\n44:44\n\nwhether it's some like other government that we that that is sort of like an\n\n44:47\n\nopponent of of our country or some company that you don't trust or whatever it\nis\n\n44:52\n\num\n\n44:54\n\nI think that that's potentially a much bigger risk.\n\n44:59\n\nAs in they could overthrow our government because they have a weapon that\nnobody else has?\n\n45:05\n\nIt would just cause a lot of mayhem.\n\n45:08\n\nI think it's like...\n\n45:10\n\nI mean,\n\n45:11\n\nI think the intuition is that this stuff ends up being pretty kind of\nimportant and\n\n45:16\n\nvaluable for both kind of economic and kind of security and other things.\n\n45:21\n\nAnd I don't know.\n\n45:22\n\nI just think,\n\n45:23\n\nyeah,\n\n45:24\n\nif someone who you don't trust or is an adversary of you gets something that\nis\n\n45:28\n\nmore powerful than...\n\n45:30\n\nI think that that could be an issue.\n\n45:31\n\nAnd I think probably the best way to mitigate that is to have good open source\nAI\n\n45:36\n\nthat basically becomes the standard and in a lot of ways kind of can become\nthe leader.\n\n45:42\n\nAnd in that way, it just ensures that it's a much more kind of even and\nbalanced playing field.\n\n45:49\n\nYeah, that seems plausible to me.\n\n45:50\n\nAnd if that works out, that would be the future I prefer.\n\n45:53\n\nI guess I want to understand mechanistically how if somebody was going to\ncause a\n\n45:58\n\nmayhem with AI systems,\n\n46:00\n\nhow the fact that there are other open source systems in the world prevents\nthat.\n\n46:04\n\nLike the specific example of somebody coming with a bioweapon.\n\n46:08\n\nIs it just that we'll do a bunch of R&D in the rest of the world to figure out\nvaccines really fast?\n\n46:13\n\nWhat's happening?\n\n46:13\n\nIf you take the computer, the security one that I was talking about,\n\n46:17\n\nI think someone with a weaker AI trying to hack into a system that is like\n\n46:21\n\nprotected by a stronger AI will succeed less.\n\n46:24\n\nRight.\n\n46:24\n\nSo so I think that that's I mean,\n\n46:27\n\nthat's like in terms of how do you know everything in the world is like that?\n\n46:29\n\nLike what if bioweapons aren't like that?\n\n46:32\n\nNo, I mean, I don't know that everything in the world is like that.\n\n46:35\n\nUm,\n\n46:36\n\num,\n\n46:38\n\nI,\n\n46:38\n\nI think that that's,\n\n46:40\n\nI guess one of the bioweapons are one of the areas where I think the people\nwho are\n\n46:44\n\nmost worried about this stuff are focused.\n\n46:46\n\nAnd, and I think that that's, uh, I think it makes a lot of sense to think\nabout that.\n\n46:51\n\nUm,\n\n46:53\n\nI mean, I think that there are certain mitigations.\n\n46:55\n\nYou can try to not train certain knowledge into the model, right?\n\n47:00\n\nThere's different things.\n\n47:00\n\nBut yeah,\n\n47:02\n\nI mean,\n\n47:03\n\nat some level,\n\n47:04\n\nI mean,\n\n47:05\n\nif you get a sufficiently bad actor and you don't have other AI that can sort\nof\n\n47:10\n\nbalance them and understand what's going on and what the threats are,\n\n47:14\n\nthen that could be a risk.\n\n47:17\n\nSo I think that that's one of the things that we need to watch out for.\n\n47:19\n\nYeah.\n\n47:21\n\nUm,\n\n47:21\n\nis there something you could see in the deployment of these systems where,\n\n47:24\n\nuh,\n\n47:26\n\nyou,\n\n47:26\n\nyou observe like you're training llama for,\n\n47:28\n\nand it's like lie to you because it thought you weren't noticing or something.\n\n47:31\n\nAnd you're like, Whoa, I, uh, what's going on here?\n\n47:34\n\nUm,\n\n47:35\n\nnot that you,\n\n47:35\n\nthis is probably not likely with alarm for test system,\n\n47:37\n\nbut is there something you can imagine like that,\n\n47:39\n\nwhere you'd like be really concerned about deceptiveness and if like billions\nof\n\n47:44\n\ncopies of things are out in the wild?\n\n47:46\n\nUm,\n\n47:48\n\nYeah.\n\n47:48\n\nI mean,\n\n47:49\n\nI think that that's not necessarily,\n\n47:50\n\nI mean,\n\n47:51\n\nright now it's,\n\n47:52\n\nwe see a lot of hallucinations,\n\n47:54\n\nright?\n\n47:54\n\nSo I think it's more,\n\n47:55\n\nmore that,\n\n47:56\n\num,\n\n47:57\n\num,\n\n47:57\n\nI think it's an,\n\n47:58\n\nit's an interesting question how you would tell the difference between a\n\n48:01\n\nhallucination and deception,\n\n48:02\n\nbut yeah,\n\n48:03\n\nI'm not,\n\n48:03\n\nlook,\n\n48:03\n\nI mean,\n\n48:04\n\nI think that there's a lot of risks and things to think about the,\n\n48:06\n\num,\n\n48:08\n\nThe flip side of all this is that there are also a lot of...\n\n48:11\n\nI try to,\n\n48:13\n\nin running our company at least,\n\n48:16\n\nbalance what I think of as these longer-term theoretical risks with...\n\n48:23\n\nWith what I actually think are quite real risks that exist today.\n\n48:27\n\nSo when you talk about deception,\n\n48:30\n\nthe form of that that I worry about most is people using this to generate\n\n48:33\n\nmisinformation and then pump that through,\n\n48:36\n\nwhether it's our networks or others.\n\n48:38\n\nSo the way that we've basically...\n\n48:41\n\ncombated a lot of this type of harmful content is by building AI systems that\nare\n\n48:46\n\nsmarter than the adversarial ones.\n\n48:49\n\nThis kind of informs part of my theory on this.\n\n48:52\n\nIf you look at the different types of harm that people do or try to do through\nsocial networks...\n\n49:00\n\nThere are ones that are not very adversarial.\n\n49:03\n\nSo for example,\n\n49:04\n\nlike hate speech,\n\n49:08\n\nI would say is not super adversarial in the sense that like people aren't\ngetting\n\n49:13\n\nbetter at being racist,\n\n49:15\n\nright?\n\n49:15\n\nThey're just like,\n\n49:16\n\nit's,\n\n49:17\n\nyou just like,\n\n49:17\n\nokay,\n\n49:18\n\nif you kind of,\n\n49:19\n\nthat's one where I think the AIs are generally just getting way more\nsophisticated\n\n49:24\n\nfaster than people are at those issues.\n\n49:26\n\nSo we have, and we have issues both ways.\n\n49:27\n\nIt's like,\n\n49:28\n\nPeople do bad things, whether they're trying to incite violence or something.\n\n49:34\n\nBut we also have a lot of false positives, right?\n\n49:36\n\nSo where we basically censor stuff that we shouldn't and I think\nunderstandably\n\n49:40\n\nmake a lot of people annoyed.\n\n49:41\n\nSo I think having an AI that just gets increasingly precise on that, that's\ngoing to be good over time.\n\n49:47\n\nBut let me give you another example, which is like nation states trying to\ninterfere in elections.\n\n49:51\n\nThat's an example where they're absolutely they have cutting edge technology\nand\n\n49:55\n\nabsolutely get better each year.\n\n49:57\n\nSo we block some technique.\n\n49:59\n\nThey learn what we did.\n\n50:01\n\nThey come at us with a different technique.\n\n50:03\n\nRight.\n\n50:03\n\nIt's not like a person trying to, you know, say mean things.\n\n50:08\n\nRight.\n\n50:08\n\nIt's like it's it's there.\n\n50:10\n\nThey're basically they have a goal.\n\n50:11\n\nThey're sophisticated.\n\n50:12\n\nThey have a lot of technology.\n\n50:13\n\nRight.\n\n50:14\n\nIn those cases,\n\n50:15\n\nI still think the ability to kind of have our AI systems grow in\nsophistication at\n\n50:21\n\na faster rate than theirs have,\n\n50:23\n\nit's an arms race.\n\n50:24\n\nBut I think we're at least currently winning that arms race.\n\n50:28\n\nSo I don't know.\n\n50:30\n\nBut this is like a lot of the stuff that I spend time thinking about is like,\n\n50:33\n\nokay,\n\n50:34\n\nyes,\n\n50:35\n\nit is possible that...\n\n50:37\n\nwhether it's Lama four or Lama five or Lama six.\n\n50:40\n\nYeah.\n\n50:40\n\nWe need to think about like what behaviors we're, we're observing.\n\n50:43\n\nAnd it's not just us.\n\n50:43\n\nI think part of the reason why you make this open source is that there are a\nlot of\n\n50:45\n\nother people who study this too.\n\n50:47\n\nSo yeah,\n\n50:48\n\nwe want to see what other people are observing,\n\n50:50\n\nwhat we're observing,\n\n50:52\n\nwhat we can mitigate,\n\n50:53\n\nand then we'll make our assessment on whether we can make it,\n\n50:56\n\num,\n\n50:57\n\nopen source.\n\n50:58\n\nBut yeah,\n\n50:59\n\nI think for the foreseeable future, I'm optimistic we will be able to.\n\n51:03\n\nAnd in the near term,\n\n51:05\n\nI don't want to take our eye off the ball of what are actual bad things that\npeople\n\n51:09\n\nare trying to use the models for today,\n\n51:11\n\neven if they're not existential,\n\n51:12\n\nbut they're like they're like pretty bad kind of day to day harms that we're\n\n51:17\n\nfamiliar with and running our services.\n\n51:21\n\nThat's actually a lot of what we have to, I think, spend our time on as well.\n\n51:24\n\nYeah.\n\n51:24\n\nActually, I found the synthetic data thing really curious.\n\n51:29\n\nI'm actually interested in why you don't think,\n\n51:32\n\nlike current models,\n\n51:32\n\nit makes sense why there might be an asymptote with just doing the synthetic\ndata\n\n51:36\n\nagain and again.\n\n51:36\n\nIf they get smarter and you use the kind of techniques you talk about in the\npaper\n\n51:40\n\nor the blog post that's coming out on the day this will be released,\n\n51:43\n\nwhere it goes to the thought chain that is the most correct and\n\n51:49\n\nWhy this wouldn't lead to a loop that...\n\n51:52\n\nOf course,\n\n51:53\n\nit wouldn't be overnight,\n\n51:53\n\nbut over many months or years of training potentially with a smarter model,\n\n51:56\n\nit gets smarter,\n\n51:57\n\nmakes better output,\n\n51:58\n\ngets smarter,\n\n51:58\n\nand so forth.\n\n52:01\n\nWell, I think it could within the parameter of whatever the model architecture\nis.\n\n52:06\n\nIt's just that at some level...\n\n52:10\n\nI don't know.\n\n52:11\n\nI think like today is eight billion parameter models.\n\n52:15\n\nI just don't think you're going to be able to get to be as good as the state\nof the\n\n52:21\n\nart multi hundred billion parameter models that are incorporating new research\ninto\n\n52:25\n\nthe architecture itself.\n\n52:29\n\nBut those will be open source as well, right?\n\n52:31\n\nWell, yeah, but I think that that's, I mean, subject to all the questions that\nwe just talked about.\n\n52:38\n\nBut yes, I mean, we would hope that that'll be the case.\n\n52:40\n\nBut I think that at each point, I don't know, it's like,\n\n52:44\n\nyou're building software there's like a ton of stuff that you can do with\nsoftware\n\n52:48\n\nbut then at some level you're constrained by the chips that it's running on\nright\n\n52:53\n\nso there are always going to be different physical constraints and it's like\nhow\n\n52:59\n\nbig are the models is going to be constrained by how much energy you can get\nand um\n\n53:04\n\nand use for inference um so\n\n53:10\n\nI guess I'm simultaneously very optimistic that this stuff will continue to\nimprove\n\n53:14\n\nquickly and also a little more measured than I think some people are about\n\n53:25\n\nI just don't think the runaway case is a particularly likely one.\n\n53:32\n\nI think it makes sense to keep your options open.\n\n53:34\n\nThere's so much we don't know.\n\n53:37\n\nThere's a case in which it's really important to keep the balance of power so\nwhen\n\n53:39\n\nnobody becomes a totalitarian dictator,\n\n53:41\n\nthere's a case in which you don't want to open source the architecture because\n\n53:45\n\nChina can use it to catch up to America's AIs and there is an intelligence\n\n53:49\n\nexplosion and they win that.\n\n53:51\n\nA lot of things seem possible, just like\n\n53:54\n\nkeeping your options open considering all of them seems reasonable.\n\n53:57\n\nYeah.\n\n53:58\n\nLet's talk about some other things.\n\n54:00\n\nGo for it.\n\n54:00\n\nOkay.\n\n54:01\n\nMetaverse, what time period in human history would you be most interested in\ngoing into?\n\n54:06\n\n100,000 BCE to now.\n\n54:09\n\nYou just want to see what it was like.\n\n54:10\n\nIt has to be the past?\n\n54:11\n\nHuh?\n\n54:11\n\nIt has to be the past?\n\n54:12\n\nOh, yeah.\n\n54:12\n\nIt has to be the past.\n\n54:13\n\nUm,\n\n54:18\n\nI don't know.\n\n54:18\n\nI mean, I have the periods of time that I'm interested in.\n\n54:21\n\nI'm really interested in American history and classical history.\n\n54:23\n\nAnd I'm really interested in the history of science, too.\n\n54:28\n\nSo I actually think seeing and trying to understand more\n\n54:35\n\nbut how some of the big advances came about.\n\n54:37\n\nI mean, all we have are like somewhat limited writings about some of that\nstuff.\n\n54:42\n\nI'm not sure the metaverse is going to let you do that.\n\n54:44\n\nCause I mean,\n\n54:44\n\nit's,\n\n54:44\n\num,\n\n54:44\n\nyou know,\n\n54:45\n\nwe can't,\n\n54:46\n\nit's going to be hard to,\n\n54:46\n\nto kind of go back in time for things that we don't have records of.\n\n54:51\n\nBut, uh,\n\n54:54\n\nactually not sure that going back in time is going to be that that that\nimportant\n\n54:57\n\nof a thing for them i mean i think it's gonna be cool for like history classes\nand\n\n55:00\n\nstuff but um that's probably not the use case that i'm most excited about for\nthe\n\n55:05\n\nfor the metaverse overall i mean it's um i think the main thing is just the\nability\n\n55:09\n\nto feel present with people no matter where you are i think that's gonna be\nkiller\n\n55:13\n\ni mean there's um i mean in the ai conversation that we that we're having i\nmean\n\n55:19\n\nit's uh\n\n55:20\n\nyou know, so much of it is about physical constraints that kind of underlie\nall, all of this.\n\n55:25\n\nRight.\n\n55:25\n\nAnd you want to move,\n\n55:26\n\nI think one lesson of technology is you want to move things from the physical\n\n55:31\n\nconstraint realm into software as much as possible because software is so much\n\n55:34\n\neasier to build and,\n\n55:36\n\nand evolve.\n\n55:37\n\nAnd like,\n\n55:38\n\nyou can democratize it more because like not everyone is going to have a data\ncenter,\n\n55:42\n\nbut like a lot of people can,\n\n55:44\n\ncan kind of write code and take open source code and modify it.\n\n55:47\n\nUm,\n\n55:49\n\nThe metaverse version of this is,\n\n55:51\n\nI think,\n\n55:52\n\nenabling realistic digital presence is going to be just an absolutely huge\n\n55:59\n\ndifference for making it so that people don't feel like they have to\nphysically be\n\n56:05\n\ntogether for as many things.\n\n56:07\n\nNow, I mean, I think that there are gonna be things that are better about\nbeing physically together.\n\n56:12\n\nSo it's not I mean, these things aren't binary.\n\n56:14\n\nIt's not going to be like, OK, now it's you don't need to do that anymore.\n\n56:17\n\nBut but overall,\n\n56:21\n\nI mean,\n\n56:21\n\nI think that this it's just gonna be really powerful for socializing,\n\n56:26\n\nfor feeling connected with people,\n\n56:28\n\nfor working,\n\n56:29\n\nfor.\n\n56:31\n\nI don't know, parts of industry, for medicine, for like so many things.\n\n56:36\n\nI want to go back to something you said at the beginning of the conversation\nwhere\n\n56:39\n\nyou didn't sell the company for a billion dollars and like the metaverse,\n\n56:42\n\nyou knew we were going to do this even though the market was hammering you for\nit.\n\n56:46\n\nAnd then I'm actually curious, like what is the source of that edge?\n\n56:49\n\nAnd you said like, oh, values, I have this intuition.\n\n56:51\n\nBut like everybody says that, right?\n\n56:53\n\nLike if you had to say something that's specific to you, how would you express\nwhat that is?\n\n56:57\n\nLike why were you so convinced about the metaverse?\n\n57:06\n\nWell, I think that those are different questions.\n\n57:07\n\nSo, I mean, what are the things that kind of power me?\n\n57:13\n\nI think we've talked about a bunch of the themes.\n\n57:16\n\nSo, I mean, I just really like building things.\n\n57:21\n\nI specifically like building things around how people communicate and sort of\n\n57:26\n\nunderstanding how people express themselves and how people work,\n\n57:29\n\nright?\n\n57:29\n\nWhen I was in college, I was...\n\n57:31\n\nI studied computer science and psychology.\n\n57:32\n\nI think a lot of other people in the industry studied computer science, right?\n\n57:35\n\nSo it's always been sort of the intersection of those two things for me.\n\n57:41\n\nBut I think it's also sort of this like,\n\n57:46\n\nreally deep drive.\n\n57:48\n\nI don't know how to explain it,\n\n57:49\n\nbut I just feel like in the constitutionally,\n\n57:53\n\nlike I'm doing something wrong if I'm not building something new.\n\n57:58\n\nRight.\n\n57:59\n\nAnd so I think that there's like,\n\n58:06\n\neven when we're putting together the business case for investing like $100\nbillion\n\n58:12\n\nin AI or some huge amount in the metaverse,\n\n58:15\n\nit's like,\n\n58:16\n\nyeah,\n\n58:16\n\nI mean,\n\n58:17\n\nwe have plans that I think make it pretty clear that if our stuff works,\n\n58:20\n\nit'll be a good investment.\n\n58:21\n\nBut you can't know for certain from the outset.\n\n58:25\n\nAnd so there's all these arguments that people have, whether it's like,\n\n58:30\n\nyou know, with advisors or, or different folks.\n\n58:32\n\nIt's like, well, how, how could you like, it's a, how are you confident enough\nto do this?\n\n58:36\n\nAnd it's like, well, the day I stopped trying to build new things, I'm just\ndone.\n\n58:42\n\nI'm going to go build new things somewhere else.\n\n58:44\n\nRight.\n\n58:44\n\nIt's like, um, it's like, it is, I I'm fundamentally incapable of\n\n58:52\n\nrunning something or in my own life and like not trying to build new things\nthat i\n\n58:58\n\nthink are are interesting it's like that's not even a question for me right\nit's\n\n59:01\n\nlike whether like whether we're going to go take a swing at like building the\nnext\n\n59:05\n\nthing it's like it's like i'm i'm just incapable of not doing that um and i\ndon't\n\n59:14\n\nknow i and i'm kind of like this in like all the different aspects of my life\nright\n\n59:18\n\nit's like we built this like\n\n59:20\n\nMy family built this ranch in Kauai, and I just worked to design all these\nbuildings.\n\n59:30\n\nWe started raising cattle, and I'm like, all right, well, I want to make the\nbest cattle in the world.\n\n59:34\n\nSo it's like,\n\n59:35\n\nhow do we architect this so that way we can figure this out and build all the\nstuff\n\n59:40\n\nup that we need to try to do that?\n\n59:41\n\nSo I don't know.\n\n59:44\n\nThat's me.\n\n59:46\n\nWhat was the other part of the question?\n\n59:48\n\nLook, Meta is just a really amazing tech company, right?\n\n59:51\n\nThey have all these great software engineers and even they work with Stripe to\nhandle payments.\n\n59:56\n\nAnd I think that's just a really notable fact that Stripe's ability to\nengineer\n\n60:00\n\nthese checkout experiences is so good that big companies like Ford,\n\n60:04\n\nZoom,\n\n60:04\n\nMeta,\n\n60:05\n\neven OpenAI,\n\n60:06\n\nthey work with Stripe to handle payments.\n\n60:08\n\nBecause just think about how many different possibilities you have to handle.\n\n60:11\n\nIf you're in a different country, you'll pay a different way.\n\n60:13\n\nAnd if you're buying a certain kind of item, that might affect how you decide\nto pay.\n\n60:16\n\nAnd Stripe is able to test these fine-grained optimizations across tens of\nbillions\n\n60:21\n\nof transactions a day to figure out what will convert people.\n\n60:25\n\nAnd obviously conversion means more revenue for you.\n\n60:27\n\nAnd look,\n\n60:28\n\nI'm not a big company like Meta or anything,\n\n60:30\n\nbut I've been using Stripe since long before they were advertisers.\n\n60:33\n\nStripe Atlas was just the easiest way for me to set up an LLC.\n\n60:36\n\nAnd they have these payments and invoicing features that make it super\nconvenient\n\n60:39\n\nfor me to get money from advertisers.\n\n60:42\n\nAnd obviously without that, it would have been much harder for me to earn\nmoney from the podcast.\n\n60:46\n\nAnd so it's been great for me.\n\n60:48\n\nGo to stripe.com to learn more.\n\n60:50\n\nThanks to them for sponsoring the episode.\n\n60:52\n\nNow back to Mark.\n\n60:53\n\nI'm not sure,\n\n60:54\n\nbut I'm actually curious about something else,\n\n60:55\n\nwhich is,\n\n60:56\n\nso a 19-year-old Mark reads a bunch of antiquity and classics,\n\n61:02\n\nhigh school,\n\n61:03\n\ncollege.\n\n61:04\n\nWhat important lesson did you learn from it?\n\n61:06\n\nNot just interesting things you found,\n\n61:07\n\nbut there aren't that many tokens you consume by the time you're 19.\n\n61:10\n\nA bunch of them were about the classics.\n\n61:12\n\nClearly, that was important in some way.\n\n61:13\n\nYeah.\n\n61:22\n\nI don't know.\n\n61:22\n\nThat's a good question.\n\n61:23\n\nI mean, one of the things that I thought was really fascinating is so when\nAugustus\n\n61:33\n\nwas first, so he became emperor, and he was trying to establish peace.\n\n61:42\n\nThere was no real conception of peace at the time.\n\n61:47\n\nPeople's understanding of peace was it is the temporary time between when your\n\n61:52\n\nenemies will inevitably attack you again,\n\n61:55\n\nso you get a short rest.\n\n61:58\n\nAnd he had this view,\n\n61:59\n\nwhich is like,\n\n61:59\n\nlook,\n\n61:59\n\nlike we want to change the economy from instead of being so mercenary and like\nin\n\n62:05\n\nkind of militaristic to like actually this positive something.\n\n62:11\n\nIt's like a very novel idea at the time.\n\n62:18\n\nI don't know.\n\n62:19\n\nI think that there's like something that's just really fundamental about that.\n\n62:22\n\nIt's like in terms of the,\n\n62:23\n\nthe bounds on like what people can conceive at the time of like,\n\n62:27\n\nwhat are rational ways to work.\n\n62:30\n\nAnd, um,\n\n62:32\n\nI'm going back to like,\n\n62:33\n\nI mean,\n\n62:33\n\nthis applies to both the metaverse and the AI stuff,\n\n62:36\n\nbut like a lot of investors and just different people just can't wrap their\nhead\n\n62:39\n\naround why we would open source this.\n\n62:42\n\nAnd it's like, are you like, like, I don't understand.\n\n62:45\n\nIt's like open source.\n\n62:46\n\nThat must just be like the temporary time between which you're making things\nproprietary.\n\n62:51\n\nRight.\n\n62:51\n\nAnd it's, but, but I actually think it's like this very profound thing in tech\nthat it's\n\n62:59\n\nhas actually, it creates a lot of winners, right?\n\n63:03\n\nAnd it's,\n\n63:03\n\nand so I don't know,\n\n63:05\n\nI don't want to strain the analogy too much,\n\n63:07\n\nbut I do think that there's,\n\n63:10\n\nthere's a lot of times I think ways where you can,\n\n63:15\n\nthat are just like models for building things that people can't even like,\n\n63:21\n\nthey just like often can't wrap their head around how that would be a valuable\n\n63:25\n\nthing for people to go do or like a reasonable state of the world that it's,\n\n63:31\n\nI mean,\n\n63:31\n\nit's,\n\n63:32\n\nuh,\n\n63:33\n\nI think that there's more reasonable things than people think.\n\n63:36\n\nThat's super fascinating.\n\n63:38\n\nCan I give you my answer of what I was thinking?\n\n63:40\n\nSure.\n\n63:40\n\nYou might have gotten from it.\n\n63:42\n\nThis is probably totally off,\n\n63:43\n\nbut just how young some of these people are who have very important roles in\nthe empire.\n\n63:49\n\nCaesar Augustus,\n\n63:50\n\nby the time he's 19,\n\n63:50\n\nhe's actually incredibly one of the most prominent people in Roman politics.\n\n63:54\n\nHe's leading battles and forming the second triumvirate.\n\n63:57\n\nI wonder if you're like the 19 year old is like,\n\n63:59\n\nI can actually do this because like,\n\n64:00\n\nI think that's an interesting example,\n\n64:03\n\nboth from a lot of history and American history.\n\n64:06\n\nYeah.\n\n64:07\n\nI mean,\n\n64:07\n\nit's,\n\n64:07\n\nI mean,\n\n64:09\n\none of my favorite quotes is it's this Picasso quote that all children are\nartists\n\n64:14\n\nand the challenge is how do you remain an artist when you grow up?\n\n64:17\n\nAnd it's like, basically I think, cause when you're younger, I think it's just\neasier to,\n\n64:23\n\nhave kind of wild ideas and you're not,\n\n64:26\n\nyou know,\n\n64:27\n\nyou have no,\n\n64:27\n\nthere are all these analogies to the innovators dilemma that exist in your\nlife as\n\n64:33\n\nwell as your company or whatever you've built.\n\n64:36\n\nRight.\n\n64:36\n\nSo, you know, you're kind of earlier on your trajectory.\n\n64:38\n\nIt's easier to pivot and take in new ideas without it disrupting other\ncommitments\n\n64:43\n\nthat you've made to,\n\n64:44\n\nto different things.\n\n64:45\n\nAnd, um, so I don't know.\n\n64:48\n\nI think that that's an interesting part of,\n\n64:49\n\nof running a company is like,\n\n64:51\n\nhow do you,\n\n64:52\n\nhow do you kind of stay dynamic?\n\n64:55\n\nGoing back to the investors in open source, the $10 billion model, suppose\nit's totally safe.\n\n65:00\n\nYou've done these evaluations.\n\n65:02\n\nAnd unlike in this case,\n\n65:03\n\nthe evaluators can also fine tune the model,\n\n65:06\n\nwhich hopefully will be the case in future models.\n\n65:09\n\nWould you open source that, the $10 billion model?\n\n65:11\n\nWell, I mean, as long as it's helping us, then yeah.\n\n65:13\n\nBut would it?\n\n65:14\n\nLike to $10 billion of R&D and then now it's like open source for anybody?\n\n65:17\n\nWell, I think here's, I think, a question which we'll have to evaluate this as\ntime goes on too.\n\n65:22\n\nBut...\n\n65:26\n\nWe have a long history of open sourcing software, right?\n\n65:29\n\nWe don't tend to open source our product, right?\n\n65:32\n\nSo it's not like we don't take like the code for Instagram and make it open\nsource, but we take like...\n\n65:37\n\na lot of the low-level infrastructure, and we make that open source, right?\n\n65:41\n\nProbably the biggest one in our history was Open Compute Project,\n\n65:46\n\nwhere we took the designs for kind of all of our servers and network switches\nand\n\n65:52\n\ndata centers and made it open source and ended up being super helpful because,\n\n65:55\n\nyou know,\n\n65:56\n\nI mean,\n\n65:56\n\na lot of people can design servers,\n\n65:58\n\nbut now,\n\n65:58\n\nlike,\n\n65:58\n\nthe industry standardized on our design,\n\n66:00\n\nwhich meant that the supply chains...\n\n66:02\n\nbasically all got built out around our design.\n\n66:04\n\nThe volumes went up, so it got cheaper for everyone and saved us billions of\ndollars.\n\n66:08\n\nSo awesome, right?\n\n66:09\n\nOkay, so there's multiple ways where open source, I think, could be helpful\nfor us.\n\n66:14\n\nOne is if people figure out how to run the models more cheaply.\n\n66:17\n\nWell, we're going to be spending tens or like $100 billion or more over time\non all this stuff.\n\n66:24\n\nSo if we can do that 10% more effectively, we're saving billions or tens of\nbillions of dollars.\n\n66:29\n\nOkay, that's probably worth a lot by itself.\n\n66:32\n\nEspecially if there's other competitive models out there.\n\n66:34\n\nIt's not like our thing is giving away some kind of crazy advantage.\n\n66:39\n\nSo is your view that the trading will be commodified?\n\n66:42\n\nI think there's a bunch of ways that this could play out.\n\n66:47\n\nThat's one.\n\n66:47\n\nThe other is...\n\n66:52\n\nis that so commodity kind of implies that it's going to get very cheap because\num\n\n66:57\n\nbecause there's lots of options the other direction that this could go in is\n\n67:02\n\nqualitative improvements so um so you mentioned fine tuning right it's like\nright\n\n67:06\n\nnow it's it's um you know it's pretty limited what you can do with fine tuning\n\n67:10\n\nmajor other models out there and there are some options but generally not for\nthe\n\n67:13\n\nbiggest models um\n\n67:16\n\nSo I think being able to do that and be able to kind of do different app-\nspecific\n\n67:22\n\nthings or use case-specific things or build them into specific tool chains,\n\n67:25\n\nI think will not only enable kind of more efficient development,\n\n67:32\n\nit could enable qualitatively different things.\n\n67:35\n\nHere's one analogy on this.\n\n67:38\n\nSo one thing that I think generally sucks about the mobile ecosystem is that\nyou\n\n67:44\n\nhave these two gatekeeper companies,\n\n67:46\n\nApple and Google,\n\n67:47\n\nthat can tell you what you're allowed to build.\n\n67:49\n\nAnd there are lots of times in our history...\n\n67:52\n\nSo there's the economic version of that,\n\n67:53\n\nwhich is like,\n\n67:53\n\nall right,\n\n67:53\n\nwe build something and they're just like,\n\n67:54\n\nI'm going to take a bunch of your money.\n\n67:56\n\nBut then there's the...\n\n67:59\n\nThe qualitative version,\n\n68:00\n\nwhich is actually what kind of upsets me more,\n\n68:02\n\nwhich is there's a bunch of times when we've launched or wanted to launch\nfeatures,\n\n68:07\n\nand then Apple's just like,\n\n68:08\n\nnope,\n\n68:08\n\nyou're not launching that.\n\n68:09\n\nI was like, that sucks, right?\n\n68:12\n\nAnd so...\n\n68:14\n\nThe question is,\n\n68:16\n\nare we kind of set up for a world like that with AI,\n\n68:21\n\nwhere you're going to get a handful of companies that run these closed models\nthat\n\n68:25\n\nare going to be in control of the APIs and therefore going to be able to tell\nyou\n\n68:28\n\nwhat you can build?\n\n68:30\n\nWell, for one, I can say for us,\n\n68:32\n\nit is worth it to go build a model ourselves to make sure that we're not in\nthat position, right?\n\n68:37\n\nLike I don't want any of those other companies telling us what we can build.\n\n68:41\n\nUm,\n\n68:42\n\nbut from an open source perspective,\n\n68:44\n\nI think a lot of developers don't want those companies telling them what they\ncan\n\n68:47\n\nbuild either.\n\n68:47\n\nUm, so the question is what is the ecosystem that gets built out around that?\n\n68:53\n\nWhat are interesting new things?\n\n68:54\n\nHow much does that improve our products?\n\n68:57\n\nUm,\n\n68:59\n\nI know there's a lot of cases where if this ends up being like,\n\n69:01\n\nyou know,\n\n69:02\n\nlike our databases or caching systems or architecture,\n\n69:07\n\nwe'll get valuable contributions from the community that will make our stuff\nbetter.\n\n69:10\n\nAnd then our app specific work that we do will still be so differentiated that\nit won't really matter.\n\n69:15\n\nRight.\n\n69:15\n\nIt's like, well, we'll be able to do what we do.\n\n69:17\n\nWe'll benefit in all the systems, ours and the communities will be better\nbecause it's open source.\n\n69:22\n\nThere is one world where, um,\n\n69:26\n\nMaybe it's not that.\n\n69:26\n\nI mean, maybe the model just ends up being more of the product itself.\n\n69:29\n\nIn that case,\n\n69:30\n\nthen I think it's a trickier economic calculation about whether you open\nsource\n\n69:36\n\nthat because then you are kind of commoditizing yourself a lot.\n\n69:39\n\nBut from what I can see so far, it doesn't seem like we're in that zone.\n\n69:43\n\nDo you expect to earn significant revenue from licensing your model to the\ncloud\n\n69:46\n\nproviders so they have to pay you a fee to actually serve the model?\n\n69:49\n\nYeah.\n\n69:52\n\nWe want to have an arrangement like that, but I don't know how significant\nit'll be.\n\n69:57\n\nAnd we have this... This is basically our license for Llama.\n\n70:01\n\nYeah.\n\n70:02\n\nYou know,\n\n70:03\n\nin a lot of ways,\n\n70:04\n\nit's like a very permissive open source license,\n\n70:07\n\nexcept that we have a limit for the largest companies using it.\n\n70:09\n\nAnd this is why we put that limit in, is we're not trying to prevent them from\nusing it.\n\n70:15\n\nWe just want them to come talk to us because if they're going to just\nbasically\n\n70:17\n\ntake what we built and resell it and make money off of it,\n\n70:20\n\nthen it's like,\n\n70:20\n\nokay,\n\n70:20\n\nwell...\n\n70:22\n\nIf you're like Microsoft Azure or Amazon,\n\n70:25\n\nthen yeah,\n\n70:26\n\nif you're going to be reselling the model,\n\n70:27\n\nthen we should have some revenue share on that.\n\n70:29\n\nSo just come talk to us before you go do that.\n\n70:31\n\nAnd that's how that's played out.\n\n70:32\n\nSo for Lama 2,\n\n70:33\n\nI mean,\n\n70:34\n\nwe basically just have deals with all these major cloud companies and Lama 2\nis\n\n70:39\n\navailable as a hosted service on all those clouds and everything.\n\n70:45\n\nI assume that as we release bigger and bigger models, that'll become a bigger\nthing.\n\n70:48\n\nIt's not the main thing that we're doing,\n\n70:49\n\nbut I just think if those companies are going to be selling our models,\n\n70:53\n\nit makes sense that we should share the upside of that somehow.\n\n70:56\n\nYeah.\n\n70:57\n\nWith regards to the other open source dangers,\n\n70:58\n\nI think I have genuine legitimate points about the balance of power stuff and\n\n71:03\n\npotentially the harms you can get rid of because we have better alignment\n\n71:06\n\ntechniques or something.\n\n71:08\n\nI wish there was some sort of framework that Meta had.\n\n71:11\n\nOther labs have this where they say,\n\n71:12\n\nif we see this concrete thing,\n\n71:14\n\nthen that's a no-go on the open source or even potentially on deployment.\n\n71:19\n\nJust writing it down so the company is ready for it, people have expectations\naround it and so forth.\n\n71:25\n\nYeah, no, I think that that's a fair point on the existential risk side.\n\n71:28\n\nRight now, we focus more on the types of risks that we see today, which are\nmore of these content risks.\n\n71:34\n\nSo we have lines on we don't want the model to be basically doing things that\nare\n\n71:42\n\nhelping people commit violence or fraud or just harming people in different\nways.\n\n71:46\n\nSo\n\n71:49\n\nIn practice for today's models,\n\n71:51\n\nand I would guess the next generation and maybe even the generation after\nthat,\n\n71:56\n\nI think while...\n\n71:58\n\nIt is somewhat more maybe intellectually interesting to talk about the\nexistential risks.\n\n72:04\n\nI actually think the real harms that need more energy being mitigated are\nthings\n\n72:10\n\nthat are going to have someone take a model and do something to hurt a person\nwith\n\n72:16\n\ntoday's parameters and the types of more mundane harms that we see today.\n\n72:21\n\nLike people...\n\n72:22\n\nkind of committing fraud against each other or things like that.\n\n72:25\n\nSo that I just don't want to shortchange that.\n\n72:29\n\nI think we have a responsibility to make sure we do a good job on that.\n\n72:33\n\nMeta is a big company.\n\n72:34\n\nYou can handle both.\n\n72:35\n\nYeah.\n\n72:37\n\nokay so as far as the open source goes I'm actually curious if you think the\nimpact\n\n72:41\n\nof the open source from PyTorch React Open Compute these things has been\nbigger for\n\n72:45\n\nthe world than even the social media aspects of meta because I've like talked\nto\n\n72:49\n\npeople who use these services who think like it's plausible because a big part\nof\n\n72:52\n\nthe internet runs on these things um\n\n72:55\n\nIt's an interesting question.\n\n72:56\n\nI mean, I think almost half the world uses our... Yeah.\n\n73:03\n\nSo I think it's hard to beat that.\n\n73:06\n\nBut no, I think open source is... It's really powerful as a new way of\nbuilding things.\n\n73:13\n\nAnd yeah, I mean, it's possible.\n\n73:18\n\nI mean, it may be one of these things where...\n\n73:22\n\nI don't know, like Bell Labs, right?\n\n73:25\n\nWhere they,\n\n73:25\n\nyou know,\n\n73:26\n\nit's like they were working on the transistor because they wanted to enable\nlong\n\n73:31\n\ndistance calling.\n\n73:32\n\nAnd they did.\n\n73:33\n\nAnd it ended up being really profitable for them that they were able to enable\nlong distance calling.\n\n73:37\n\nAnd if you ask them,\n\n73:39\n\nfive to ten years out from that um what was the most useful thing that they\n\n73:45\n\ninvented it's like okay well we enabled long distance calling and now all\nthese\n\n73:48\n\npeople are long distance calling but if you ask a hundred years later maybe\nit's a\n\n73:51\n\ndifferent question so um i think that that's true of a lot of the things that\nwe're\n\n73:57\n\nbuilding right reality labs\n\n73:59\n\num some of the ai stuff some of the open source stuff i think it's like the\n\n74:03\n\nspecific products evolve and to some degree come and go but i think like the\n\n74:07\n\nadvances for humanity persist and that's like a i don't know a cool part of\nwhat we\n\n74:13\n\nall get to do um by when will the llama models be trained on your own custom\n\n74:17\n\nsilicon um\n\n74:23\n\nSoon.\n\n74:24\n\nNot Lama 4.\n\n74:26\n\nThe approach that we took is first we basically built custom silicon that\ncould\n\n74:32\n\nhandle inference for our ranking and recommendation type stuff.\n\n74:36\n\nSo reels, newsfeed, ads.\n\n74:39\n\nAnd that was consuming a lot of GPUs.\n\n74:44\n\nBut when we were able to move that to our own silicon,\n\n74:47\n\nwe now were able to use the more expensive NVIDIA GPUs only for training.\n\n74:53\n\nSo at some point,\n\n74:57\n\nwe will hopefully have silicon ourselves that we can be using for probably\nfirst\n\n75:03\n\ntraining some of the simpler things,\n\n75:05\n\nthen eventually training these really large models.\n\n75:11\n\nBut in the meantime,\n\n75:12\n\nI'd say the program is going quite well and we're just rolling it out\nmethodically\n\n75:16\n\nand have a long-term roadmap for it.\n\n75:19\n\nFinal question.\n\n75:19\n\nThis is totally out of left field, but if you were made CEO of Google+, could\nyou have made it work?\n\n75:25\n\nGoogle+, oof.\n\n75:27\n\nWell, I don't know.\n\n75:30\n\nI don't know.\n\n75:31\n\nThat's a very difficult, very difficult counterfactual.\n\n75:36\n\nOkay,\n\n75:36\n\nthen the real final question will be when Gemini was launched,\n\n75:39\n\nwas there any chance that somebody in the office uttered Carthaga Delinda Est?\n\n75:44\n\nNo.\n\n75:44\n\nI think we're tamer now.\n\n75:47\n\nCool, cool.\n\n75:48\n\nAwesome, Mark.\n\n75:52\n\nYeah, I don't know.\n\n75:53\n\nIt's a good question.\n\n75:53\n\nI don't know.\n\n75:55\n\nThe problem is there was no CEO of Google+.\n\n75:57\n\nIt was just like a division within a company.\n\n76:00\n\nI think it's like,\n\n76:01\n\nand you asked before about what are the kind of scarcest commodities,\n\n76:05\n\nbut you asked about it in terms of dollars.\n\n76:07\n\nAnd I actually think for most companies, it's of this scale, at least, it's\nfocus, right?\n\n76:13\n\nIt's like when you're a startup, maybe you're more constrained on capital,\nright?\n\n76:17\n\nUm, you know, you, you just are working on one idea and you, you might not\nhave all the resources.\n\n76:21\n\nI think you cross some threshold at some point where the nature of what you're\ndoing,\n\n76:26\n\nyou,\n\n76:26\n\nyou're building multiple things and you're creating more value across them,\n\n76:29\n\nbut you become more constrained on what can you direct and to go well.\n\n76:35\n\nAnd like, there's always the cases where something just random awesome happens\nin the organization.\n\n76:41\n\nI don't even know about it.\n\n76:42\n\nAnd those are, that's great.\n\n76:44\n\nBut like, but I think in general,\n\n76:47\n\norganization's capacity is largely limited by what like the ceo and the and\nthe\n\n76:54\n\nmanagement team are able to kind of oversee and and kind of manage it's i\nthink\n\n76:59\n\nthat that's just been a a big focus for us it's like all right keep the as as\ni\n\n77:04\n\nguess ben horowitz says keep the main thing the main thing right and and\n\n77:10\n\ntry to kind of stay focused on your key priorities.\n\n77:14\n\nYeah.\n\n77:15\n\nAll right.\n\n77:15\n\nAwesome.\n\n77:16\n\nThat was excellent, Mark.\n\n77:16\n\nThanks so much.\n\n77:17\n\nThat was a lot of fun.\n\n77:18\n\nYeah, really fun.\n\n77:19\n\nThanks for having me.\n\n77:20\n\nAbsolutely.\n\n77:21\n\nHey, everybody.\n\n77:22\n\nI hope you enjoyed that episode with Mark.\n\n77:24\n\nAs you can see, I'm now doing ads.\n\n77:26\n\nSo if you're interested in advertising on the podcast, go to the link in the\ndescription.\n\n77:31\n\nOtherwise,\n\n77:31\n\nas you know,\n\n77:32\n\nthe most helpful thing you can do is just share the podcast with people who\nyou\n\n77:36\n\nthink might enjoy it.\n\n77:37\n\nYou know, your friends, group chats, Twitter, I guess threads.\n\n77:41\n\nYeah, I hope you enjoyed and I'll see you on the next one.\n\nMark Zuckerberg on:\n\n  * Llama 3\n\n  * open sourcing towards AGI\n\n  * custom silicon, synthetic data, & energy constraints on scaling\n\n  * Caesar Augustus, intelligence explosion, bioweapons, $10b models, & much more\n\nEnjoy!\n\nWatch on YouTube. Listen on Apple Podcasts, Spotify, or any other podcast\nplatform. Human edited transcript with helpful links here.\n\n##\n\nTimestamps\n\n(00:00:00) - Llama 3\n\n(00:08:32) - Coding on path to AGI\n\n(00:25:24) - Energy bottlenecks\n\n(00:33:20) - Is AI the most important technology ever?\n\n(00:37:21) - Dangers of open source\n\n(00:53:57) - Caesar Augustus and metaverse\n\n(01:04:53) - Open sourcing the $10b model & custom silicon\n\n(01:15:19) - Zuck as CEO of Google+\n\n##\n\nSponsors\n\nIf you\u2019re interested in advertising on the podcast, fill out this form.\n\n  * This episode is brought to you by Stripe, financial infrastructure for the internet. Millions of companies from Anthropic to Amazon use Stripe to accept payments, automate financial processes and grow their revenue. Learn more at stripe.com.\n\n  * V7 Go is a tool to automate multimodal tasks using GenAI, reliably and at scale. Use code DWARKESH20 for 20% off on the pro plan. Learn more here.\n\n  * CommandBar is an AI user assistant that any software product can embed to non-annoyingly assist, support, and unleash their users. Used by forward-thinking CX, product, growth, and marketing teams. Learn more at commandbar.com.\n\n##\n\nTranscript\n\nThanks to Graham Bessellieu for editing this podcast. Transcript with lots of\nhelpful links by Teddy Kim.\n\n###\n\n00:00:00 - Llama 3\n\nDwarkesh Patel 00:00:00\n\nMark, welcome to the podcast.\n\nMark Zuckerberg 0:00:01\n\nThanks for having me. Big fan of your podcast.\n\nDwarkesh Patel 00:00:03\n\nThank you, that's very nice of you to say. Let's start by talking about the\nreleases that will go out when this interview goes out. Tell me about the\nmodels and Meta AI. What\u2019s new and exciting about them?\n\nMark Zuckerberg 00:00:15\n\nI think the main thing that most people in the world are going to see is the\nnew version of Meta AI. The most important thing that we're doing is the\nupgrade to the model. We're rolling out Llama-3. We're doing it both as open\nsource for the dev community and it is now going to be powering Meta AI.\nThere's a lot that I'm sure we'll get into around Llama-3, but I think the\nbottom line on this is that we think now that Meta AI is the most intelligent,\nfreely-available AI assistant that people can use. We're also integrating\nGoogle and Bing for real-time knowledge.\n\nWe're going to make it a lot more prominent across our apps. At the top of\nFacebook and Messenger, you'll be able to just use the search box right there\nto ask any question. There's a bunch of new creation features that we added\nthat I think are pretty cool and that I think people will enjoy. I think\nanimations is a good one. You can basically take any image and just animate\nit.\n\nOne that people are going to find pretty wild is that it now generates high\nquality images so quickly that it actually generates it as you're typing and\nupdates it in real time. So you're typing your query and it's honing in. It\u2019s\nlike \u201cshow me a picture of a cow in a field with mountains in the background,\neating macadamia nuts, drinking beer\u201d and it's updating the image in real\ntime. It's pretty wild. I think people are going to enjoy that. So I think\nthat's what most people are going to see in the world. We're rolling that out,\nnot everywhere, but we're starting in a handful of countries and we'll do more\nover the coming weeks and months. I think that\u2019s going to be a pretty big deal\nand I'm really excited to get that in people's hands. It's a big step forward\nfor Meta AI.\n\nBut I think if you want to get under the hood a bit, the Llama-3 stuff is\nobviously the most technically interesting. We're training three versions: an\n8 billion parameter model and a 70 billion, which we're releasing today, and a\n405 billion dense model, which is still training. So we're not releasing that\ntoday, but I'm pretty excited about how the 8B and the 70B turned out. They're\nleading for their scale. We'll release a blog post with all the benchmarks so\npeople can check it out themselves. Obviously it's open source so people get a\nchance to play with it.\n\nWe have a roadmap of new releases coming that are going to bring\nmultimodality, more multi-linguality, and bigger context windows as well.\nHopefully, sometime later in the year we'll get to roll out the 405B. For\nwhere it is right now in training, it is already at around 85 MMLU and we\nexpect that it's going to have leading benchmarks on a bunch of the\nbenchmarks. I'm pretty excited about all of that. The 70 billion is great too.\nWe're releasing that today. It's around 82 MMLU and has leading scores on math\nand reasoning. I think just getting this in people's hands is going to be\npretty wild.\n\nDwarkesh Patel 00:03:42\n\nOh, interesting. That's the first I\u2019m hearing of it as a benchmark. That's\nsuper impressive.\n\nMark Zuckerberg 00:03:45\n\nThe 8 billion is nearly as powerful as the biggest version of Llama-2 that we\nreleased. So the smallest Llama-3 is basically as powerful as the biggest\nLlama-2.\n\nDwarkesh Patel 00:03:59\n\nBefore we dig into these models, I want to go back in time. I'm assuming 2022\nis when you started acquiring these H100s, or you can tell me when. The stock\nprice is getting hammered. People are asking what's happening with all this\ncapex. People aren't buying the metaverse. Presumably you're spending that\ncapex to get these H100s. How did you know back then to get the H100s? How did\nyou know that you\u2019d need the GPUs?\n\nMark Zuckerberg 00:04:22\n\nI think it was because we were working on Reels. We always want to have enough\ncapacity to build something that we can't quite see on the horizon yet. We got\ninto this position with Reels where we needed more GPUs to train the models.\nIt was this big evolution for our services. Instead of just ranking content\nfrom people or pages you follow, we made this big push to start recommending\nwhat we call unconnected content, content from people or pages that you're not\nfollowing.\n\nThe corpus of content candidates that we could potentially show you expanded\nfrom on the order of thousands to on the order of hundreds of millions. It\nneeded a completely different infrastructure. We started working on doing that\nand we were constrained on the infrastructure in catching up to what TikTok\nwas doing as quickly as we wanted to. I basically looked at that and I was\nlike \u201chey, we have to make sure that we're never in this situation again. So\nlet's order enough GPUs to do what we need to do on Reels and ranking content\nand feed. But let's also double that.\u201d Again, our normal principle is that\nthere's going to be something on the horizon that we can't see yet.\n\nDwarkesh Patel 00:05:51\n\nDid you know it would be AI?\n\nMark Zuckerberg 00:05:52\n\nWe thought it was going to be something that had to do with training large\nmodels. At the time I thought it was probably going to be something that had\nto do with content. It\u2019s just the pattern matching of running the company,\nthere's always another thing. At that time I was so deep into trying to get\nthe recommendations working for Reels and other content. That\u2019s just such a\nbig unlock for Instagram and Facebook now, being able to show people content\nthat's interesting to them from people that they're not even following.\n\nBut that ended up being a very good decision in retrospect. And it came from\nbeing behind. It wasn't like \u201coh, I was so far ahead.\u201d Actually, most of the\ntimes where we make some decision that ends up seeming good is because we\nmessed something up before and just didn't want to repeat the mistake.\n\nDwarkesh Patel 00:06:47\n\nThis is a total detour, but I want to ask about this while we're on this.\nWe'll get back to AI in a second. In 2006 you didn't sell for $1 billion but\npresumably there's some amount you would have sold for, right? Did you write\ndown in your head like \u201cI think the actual valuation of Facebook at the time\nis this and they're not actually getting the valuation right\u201d? If they\u2019d\noffered you $5 trillion, of course you would have sold. So how did you think\nabout that choice?\n\nMark Zuckerberg 00:07:08\n\nI think some of these things are just personal. I don't know that at the time\nI was sophisticated enough to do that analysis. I had all these people around\nme who were making all these arguments for a billion dollars like \u201chere's the\nrevenue that we need to make and here's how big we need to be. It's clearly so\nmany years in the future.\u201d It was very far ahead of where we were at the time.\nI didn't really have the financial sophistication to really engage with that\nkind of debate.\n\nDeep down I believed in what we were doing. I did some analysis like \u201cwhat\nwould I do if I weren\u2019t doing this? Well, I really like building things and I\nlike helping people communicate. I like understanding what's going on with\npeople and the dynamics between people. So I think if I sold this company, I'd\njust go build another company like this and I kind of like the one I have. So\nwhy?\u201d I think a lot of the biggest bets that people make are often just based\non conviction and values. It's actually usually very hard to do the analyses\ntrying to connect the dots forward.\n\n###\n\n00:08:32 - Coding on path to AGI\n\nDwarkesh Patel 00:08:32\n\nYou've had Facebook AI Research for a long time. Now it's become seemingly\ncentral to your company. At what point did making AGI, or however you consider\nthat mission, become a key priority of what Meta is doing?\n\nMark Zuckerberg 00:08:49\n\nIt's been a big deal for a while. We started FAIR about 10 years ago. The idea\nwas that, along the way to general intelligence or whatever you wanna call it,\nthere are going to be all these different innovations and that's going to just\nimprove everything that we do. So we didn't conceive of it as a product. It\nwas more of a research group. Over the last 10 years it has created a lot of\ndifferent things that have improved all of our products. It\u2019s advanced the\nfield and allowed other people in the field to create things that have\nimproved our products too. I think that that's been great.\n\nThere's obviously a big change in the last few years with ChatGPT and the\ndiffusion models around image creation coming out. This is some pretty wild\nstuff that is pretty clearly going to affect how people interact with every\napp that's out there. At that point we started a second group, the gen AI\ngroup, with the goal of bringing that stuff into our products and building\nleading foundation models that would power all these different products.\n\nWhen we started doing that the theory initially was that a lot of the stuff\nwe're doing is pretty social. It's helping people interact with creators,\nhelping people interact with businesses, helping businesses sell things or do\ncustomer support. There\u2019s also basic assistant functionality, whether it's for\nour apps or the smart glasses or VR. So it wasn't completely clear at first\nthat you were going to need full AGI to be able to support those use cases.\nBut in all these subtle ways, through working on them, I think it's actually\nbecome clear that you do. For example, when we were working on Llama-2, we\ndidn't prioritize coding because people aren't going to ask Meta AI a lot of\ncoding questions in WhatsApp.\n\nDwarkesh Patel 00:10:59\n\nNow they will, right?\n\nMark Zuckerberg 00:11:00\n\nI don't know. I'm not sure that WhatsApp, or Facebook or Instagram, is the UI\nwhere people are going to be doing a lot of coding questions. Maybe the\nwebsite, meta.ai, that we\u2019re launching. But the thing that has been a somewhat\nsurprising result over the last 18 months is that it turns out that coding is\nimportant for a lot of domains, not just coding. Even if people aren't asking\ncoding questions, training the models on coding helps them become more\nrigorous in answering the question and helps them reason across a lot of\ndifferent types of domains. That's one example where for Llama-3, we really\nfocused on training it with a lot of coding because that's going to make it\nbetter on all these things even if people aren't asking primarily coding\nquestions.\n\nReasoning is another example. Maybe you want to chat with a creator or you're\na business and you're trying to interact with a customer. That interaction is\nnot just like \u201cokay, the person sends you a message and you just reply.\u201d It's\na multi-step interaction where you're trying to think through \u201chow do I\naccomplish the person's goals?\u201d A lot of times when a customer comes, they\ndon't necessarily know exactly what they're looking for or how to ask their\nquestions. So it's not really the job of the AI to just respond to the\nquestion.\n\nYou need to kind of think about it more holistically. It really becomes a\nreasoning problem. So if someone else solves reasoning, or makes good advances\non reasoning, and we're sitting here with a basic chat bot, then our product\nis lame compared to what other people are building. At the end of the day, we\nbasically realized we've got to solve general intelligence and we just upped\nthe ante and the investment to make sure that we could do that.\n\nDwarkesh Patel 00:12:48\n\nSo the version of Llama that's going to solve all these use cases for users,\nis that the version that will be powerful enough to replace a programmer you\nmight have in this building?\n\nMark Zuckerberg 00:13:03\n\nI just think that all this stuff is going to be progressive over time.\n\nDwarkesh Patel 00:13:05\n\nBut in the end case: Llama-10.\n\nMark Zuckerberg 00:13:10\n\nI think that there's a lot baked into that question. I'm not sure that we're\nreplacing people as much as we\u2019re giving people tools to do more stuff.\n\nDwarkesh Patel 00:13:18\n\nIs the programmer in this building 10x more productive after Llama-10?\n\nMark Zuckerberg 00:13:20\n\nI would hope more. I don't believe that there's a single threshold of\nintelligence for humanity because people have different skills. I think that\nat some point AI is probably going to surpass people at most of those things,\ndepending on how powerful the models are. But I think it's progressive and I\ndon't think AGI is one thing. You're basically adding different capabilities.\nMultimodality is a key one that we're focused on now, initially with photos\nand images and text but eventually with videos. Because we're so focused on\nthe metaverse, 3D type stuff is important too. One modality that I'm pretty\nfocused on, that I haven't seen as many other people in the industry focus on,\nis emotional understanding. So much of the human brain is just dedicated to\nunderstanding people and understanding expressions and emotions. I think\nthat's its own whole modality, right? You could say that maybe it's just video\nor image, but it's clearly a very specialized version of those two.\n\nSo there are all these different capabilities that you want to train the\nmodels to focus on, in addition to getting a lot better at reasoning and\nmemory, which is its own whole thing. I don't think in the future we're going\nto be primarily shoving things into a query context window to ask more\ncomplicated questions. There will be different stores of memory or different\ncustom models that are more personalized to people. These are all just\ndifferent capabilities. Obviously then there\u2019s making them big and small. We\ncare about both. If you're running something like Meta AI, that's pretty\nserver-based. We also want it running on smart glasses and there's not a lot\nof space in smart glasses. So you want to have something that's very efficient\nfor that.\n\nDwarkesh Patel 00:15:16\n\nIf you're doing $10Bs worth of inference or even eventually $100Bs, if you're\nusing intelligence in an industrial scale what is the use case? Is it\nsimulations? Is it the AIs that will be in the metaverse? What will we be\nusing the data centers for?\n\nMark Zuckerberg 00:15:32\n\nOur bet is that it's going to basically change all of the products. I think\nthat there's going to be a kind of Meta AI general assistant product. I think\nthat that will shift from something that feels more like a chatbot, where you\nask a question and it formulates an answer, to things where you're giving it\nmore complicated tasks and then it goes away and does them. That's going to\ntake a lot of inference and it's going to take a lot of compute in other ways\ntoo.\n\nThen I think interacting with other agents for other people is going to be a\nbig part of what we do, whether it's for businesses or creators. A big part of\nmy theory on this is that there's not going to be just one singular AI that\nyou interact with. Every business is going to want an AI that represents their\ninterests. They're not going to want to primarily interact with you through an\nAI that is going to sell their competitors\u2019 products.\n\nI think creators is going to be a big one. There are about 200 million\ncreators on our platforms. They basically all have the pattern where they want\nto engage their community but they're limited by the hours in the day. Their\ncommunity generally wants to engage them, but they don't know that they're\nlimited by the hours in the day. If you could create something where that\ncreator can basically own the AI, train it in the way they want, and engage\ntheir community, I think that's going to be super powerful. There's going to\nbe a ton of engagement across all these things.\n\nThese are just the consumer use cases. My wife and I run our foundation, Chan\nZuckerberg Initiative. We're doing a bunch of stuff on science and there's\nobviously a lot of AI work that is going to advance science and healthcare and\nall these things. So it will end up affecting basically every area of the\nproducts and the economy.\n\nDwarkesh Patel 00:17:41\n\nYou mentioned AI that can just go out and do something for you that's multi-\nstep. Is that a bigger model? With Llama-4 for example, will there still be a\nversion that's 70B but you'll just train it on the right data and that will be\nsuper powerful? What does the progression look like? Is it scaling? Is it just\nthe same size but different banks like you were talking about?\n\nMark Zuckerberg 00:18:02\n\nI don't know that we know the answer to that. I think one thing that seems to\nbe a pattern is that you have the Llama model and then you build some kind of\nother application specific code around it. Some of it is the fine-tuning for\nthe use case, but some of it is, for example, logic for how Meta AI should\nwork with tools like Google or Bing to bring in real-time knowledge. That's\nnot part of the base Llama model. For Llama-2, we had some of that and it was\na little more hand-engineered. Part of our goal for Llama-3 was to bring more\nof that into the model itself. For Llama-3, as we start getting into more of\nthese agent-like behaviors, I think some of that is going to be more hand-\nengineered. Our goal for Llama-4 will be to bring more of that into the model.\n\nAt each step along the way you have a sense of what's going to be possible on\nthe horizon. You start messing with it and hacking around it. I think that\nhelps you then hone your intuition for what you want to try to train into the\nnext version of the model itself. That makes it more general because obviously\nfor anything that you're hand-coding you can unlock some use cases, but it's\njust inherently brittle and non-general.\n\nDwarkesh Patel 00:20:35\n\nWhen you say \u201cinto the model itself,\u201d you train it on the thing that you want\nin the model itself? What do you mean by \u201cinto the model itself\u201d?\n\nMark Zuckerberg 00:20:42\n\nFor Llama- 2, the tool use was very specific, whereas Llama-3 has much better\ntool use. We don't have to hand code all the stuff to have it use Google and\ngo do a search. It can just do that. Similarly for coding and running code and\na bunch of stuff like that. Once you kind of get that capability, then you get\na peek at what we can start doing next. We don't necessarily want to wait\nuntil Llama-4 is around to start building those capabilities, so we can start\nhacking around it. You do a bunch of hand coding and that makes the products\nbetter, if only for the interim. That helps show the way then of what we want\nto build into the next version of the model.\n\nDwarkesh Patel 00:21:37\n\nWhat is the community fine tune of Llama-3 that you're most excited for? Maybe\nnot the one that will be most useful to you, but the one you'll just enjoy\nplaying with the most. They fine-tune it on antiquity and you'll just be\ntalking to Virgil or something. What are you excited about?\n\nMark Zuckerberg 00:21:50\n\nI think the nature of the stuff is that you get surprised. Any specific thing\nthat I thought would be valuable, we'd probably be building. I think you'll\nget distilled versions. I think you'll get smaller versions. One thing is that\nI think 8B isn\u2019t quite small enough for a bunch of use cases. Over time I'd\nlove to get a 1-2B parameter model, or even a 500M parameter model and see\nwhat you can do with that.\n\nIf with 8B parameters we\u2019re nearly as powerful as the largest Llama-2 model,\nthen with a billion parameters you should be able to do something that's\ninteresting, and faster. It\u2019d be good for classification, or a lot of basic\nthings that people do before understanding the intent of a user query and\nfeeding it to the most powerful model to hone in on what the prompt should be.\nI think that's one thing that maybe the community can help fill in. We're also\nthinking about getting around to distilling some of these ourselves but right\nnow the GPUs are pegged training the 405B.\n\nDwarkesh Patel 00:23:12\n\nSo you have all these GPUs. I think you said 350,000 by the end of the year.\n\nMark Zuckerberg 00:23:18\n\nThat's the whole fleet. We built two, I think 22,000 or 24,000 clusters that\nare the single clusters that we have for training the big models, obviously\nacross a lot of the stuff that we do. A lot of our stuff goes towards training\nReels models and Facebook News Feed and Instagram Feed. Inference is a huge\nthing for us because we serve a ton of people. Our ratio of inference compute\nrequired to training is probably much higher than most other companies that\nare doing this stuff just because of the sheer volume of the community that\nwe're serving.\n\nDwarkesh Patel 00:23:56\n\nIn the material they shared with me before, it was really interesting that you\ntrained it on more data than is compute optimal just for training. The\ninference is such a big deal for you guys, and also for the community, that it\nmakes sense to just have this thing and have trillions of tokens in there.\n\nMark Zuckerberg 00:24:08\n\nAlthough one of the interesting things about it, even with the 70B, is that we\nthought it would get more saturated. We trained it on around 15 trillion\ntokens. I guess our prediction going in was that it was going to asymptote\nmore, but even by the end it was still learning. We probably could have fed it\nmore tokens and it would have gotten somewhat better.\n\nAt some point you're running a company and you need to do these meta reasoning\nquestions. Do I want to spend our GPUs on training the 70B model further? Do\nwe want to get on with it so we can start testing hypotheses for Llama-4? We\nneeded to make that call and I think we got a reasonable balance for this\nversion of the 70B. There'll be others in the future, the 70B multimodal one,\nthat'll come over the next period. But that was fascinating that the\narchitectures at this point can just take so much data.\n\nDwarkesh Patel 00:25:11\n\nThat's really interesting. What does this imply about future models? You\nmentioned that the Llama-3 8B is better than the Llama-2 70B.\n\nMark Zuckerberg 00:25:19\n\nNo, no, it's nearly as good. I don\u2019t want to overstate it. It\u2019s in a similar\norder of magnitude.\n\n###\n\n00:25:24 - Energy bottlenecks\n\nDwarkesh Patel 00:25:24\n\nDoes that mean the Llama-4 70B will be as good as the Llama-3 405B? What does\nthe future of this look like?\n\nMark Zuckerberg 00:25:30\n\nThis is one of the great questions, right? I think no one knows. One of the\ntrickiest things in the world to plan around is an exponential curve. How long\ndoes it keep going for? I think it's likely enough that we'll keep going. I\nthink it\u2019s worth investing the $10Bs or $100B+ in building the infrastructure\nand assuming that if it keeps going you're going to get some really amazing\nthings that are going to make amazing products. I don't think anyone in the\nindustry can really tell you that it will continue scaling at that rate for\nsure. In general in history, you hit bottlenecks at certain points. Now\nthere's so much energy on this that maybe those bottlenecks get knocked over\npretty quickly. I think that\u2019s an interesting question.\n\nDwarkesh Patel 00:26:24\n\nWhat does the world look like where there aren't these bottlenecks? Suppose\nprogress just continues at this pace, which seems plausible. Zooming out and\nforgetting about Llamas...\n\nMark Zuckerberg 00:26:33\n\nWell, there are going to be different bottlenecks. Over the last few years, I\nthink there was this issue of GPU production. Even companies that had the\nmoney to pay for the GPUs couldn't necessarily get as many as they wanted\nbecause there were all these supply constraints. Now I think that's sort of\ngetting less. So you're seeing a bunch of companies thinking now about\ninvesting a lot of money in building out these things. I think that that will\ngo on for some period of time. There is a capital question. At what point does\nit stop being worth it to put the capital in?\n\nI actually think before we hit that, you're going to run into energy\nconstraints. I don't think anyone's built a gigawatt single training cluster\nyet. You run into these things that just end up being slower in the world.\nGetting energy permitted is a very heavily regulated government function.\nYou're going from software, which is somewhat regulated and I'd argue it\u2019s\nmore regulated than a lot of people in the tech community feel. Obviously it\u2019s\ndifferent if you're starting a small company, maybe you feel that less. We\ninteract with different governments and regulators and we have lots of rules\nthat we need to follow and make sure we do a good job with around the world.\nBut I think that there's no doubt about energy.\n\nIf you're talking about building large new power plants or large build-outs\nand then building transmission lines that cross other private or public land,\nthat\u2019s just a heavily regulated thing. You're talking about many years of lead\ntime. If we wanted to stand up some massive facility, powering that is a very\nlong-term project. I think people do it but I don't think this is something\nthat can be quite as magical as just getting to a level of AI, getting a bunch\nof capital and putting it in, and then all of a sudden the models are just\ngoing to... You do hit different bottlenecks along the way.\n\nDwarkesh Patel 00:29:00\n\nIs there something, maybe an AI-related project or maybe not, that even a\ncompany like Meta doesn't have the resources for? Something where if your R&D\nbudget or capex budget were 10x what it is now, then you could pursue it?\nSomething that\u2019s in the back of your mind but with Meta today, you can't even\nissue stock or bonds for it? It's just like 10x bigger than your budget?\n\nMark Zuckerberg 00:29:19\n\nI think energy is one piece. I think we would probably build out bigger\nclusters than we currently can if we could get the energy to do it.\n\nDwarkesh Patel 00:29:34\n\nThat's fundamentally money-bottlenecked in the limit? If you had $1\ntrillion...\n\nMark Zuckerberg 00:29:39\n\nI think it\u2019s time. It depends on how far the exponential curves go. Right now\na lot of data centers are on the order of 50 megawatts or 100MW, or a big one\nmight be 150MW. Take a whole data center and fill it up with all the stuff\nthat you need to do for training and you build the biggest cluster you can. I\nthink a bunch of companies are running at stuff like that.\n\nBut when you start getting into building a data center that's like 300MW or\n500MW or 1 GW, no one has built a 1GW data center yet. I think it will happen.\nThis is only a matter of time but it's not going to be next year. Some of\nthese things will take some number of years to build out. Just to put this in\nperspective, I think a gigawatt would be the size of a meaningful nuclear\npower plant only going towards training a model.\n\nDwarkesh Patel 00:30:51\n\nDidn't Amazon do this? They have a 950MW\u2013\n\nMark Zuckerberg 00:30:55\n\nI'm not exactly sure what they did. You'd have to ask them.\n\nDwarkesh Patel 00:31:00\n\nBut it doesn\u2019t have to be in the same place, right? If distributed training\nworks, it can be distributed.\n\nMark Zuckerberg 00:31:03\n\nWell, I think that is a big question, how that's going to work. It seems quite\npossible that in the future, more of what we call training for these big\nmodels is actually more along the lines of inference generating synthetic data\nto then go feed into the model. I don't know what that ratio is going to be\nbut I consider the generation of synthetic data to be more inference than\ntraining today. Obviously if you're doing it in order to train a model, it's\npart of the broader training process. So that's an open question, the balance\nof that and how that plays out.\n\nDwarkesh Patel 00:31:44\n\nWould that potentially also be the case with Llama-3, and maybe Llama-4\nonwards? As in, you put this out and if somebody has a ton of compute, then\nthey can just keep making these things arbitrarily smarter using the models\nthat you've put out. Let\u2019s say there\u2019s some random country, like Kuwait or the\nUAE, that has a ton of compute and they can actually just use Llama-4 to make\nsomething much smarter.\n\nMark Zuckerberg 00:32:08\n\nI do think there are going to be dynamics like that, but I also think there is\na fundamental limitation on the model architecture. I think like a 70B model\nthat we trained with a Llama-3 architecture can get better, it can keep going.\nAs I was saying, we felt that if we kept on feeding it more data or rotated\nthe high value tokens through again, then it would continue getting better.\nWe've seen a bunch of different companies around the world basically take the\nLlama-2 70B model architecture and then build a new model. But it's still the\ncase that when you make a generational improvement to something like the\nLlama-3 70B or the Llama-3 405B, there isn\u2019t anything like that open source\ntoday. I think that's a big step function. What people are going to be able to\nbuild on top of that I think can\u2019t go infinitely from there. There can be some\noptimization in that until you get to the next step function.\n\n###\n\n00:33:20 - Is AI the most important technology ever?\n\nDwarkesh Patel 00:33:20\n\nLet's zoom out a little bit from specific models and even the multi-year lead\ntimes you would need to get energy approvals and so on. Big picture, what's\nhappening with AI these next couple of decades? Does it feel like another\ntechnology like the metaverse or social, or does it feel like a fundamentally\ndifferent thing in the course of human history?\n\nMark Zuckerberg 00:33:43\n\nI think it's going to be pretty fundamental. I think it's going to be more\nlike the creation of computing in the first place. You'll get all these new\napps in the same way as when you got the web or you got mobile phones. People\nbasically rethought all these experiences as a lot of things that weren't\npossible before became possible. So I think that will happen, but I think it's\na much lower-level innovation. My sense is that it's going to be more like\npeople going from not having computers to having computers.\n\nIt\u2019s very hard to reason about exactly how this goes. In the cosmic scale\nobviously it'll happen quickly, over a couple of decades or something. There\nis some set of people who are afraid of it really spinning out and going from\nbeing somewhat intelligent to extremely intelligent overnight. I just think\nthat there's all these physical constraints that make that unlikely to happen.\nI just don't really see that playing out. I think we'll have time to acclimate\na bit. But it will really change the way that we work and give people all\nthese creative tools to do different things. I think it's going to really\nenable people to do the things that they want a lot more.\n\nDwarkesh Patel 00:35:18\n\nSo maybe not overnight, but is it your view that on a cosmic scale we can\nthink of these milestones in this way? Humans evolved, and then AI happened,\nand then they went out into the galaxy. Maybe it takes many decades, maybe it\ntakes a century, but is that the grand scheme of what's happening right now in\nhistory?\n\nMark Zuckerberg 00:35:38\n\nSorry, in what sense?\n\nDwarkesh Patel 00:35:40\n\nIn the sense that there were other technologies, like computers and even fire,\nbut the development of AI itself is as significant as humans evolving in the\nfirst place.\n\nMark Zuckerberg 00:35:48\n\nI think that's tricky. The history of humanity has been people basically\nthinking that certain aspects of humanity are really unique in different ways\nand then coming to grips with the fact that that's not true, but that humanity\nis actually still super special. We thought that the earth was the center of\nthe universe and it's not, but humans are still pretty awesome and pretty\nunique, right?\n\nI think another bias that people tend to have is thinking that intelligence is\nsomehow fundamentally connected to life. It's not actually clear that it is. I\ndon't know that we have a clear enough definition of consciousness or life to\nfully interrogate this. There's all this science fiction about creating\nintelligence where it starts to take on all these human-like behaviors and\nthings like that. The current incarnation of all this stuff feels like it's\ngoing in a direction where intelligence can be pretty separated from\nconsciousness, agency, and things like that, which I think just makes it a\nsuper valuable tool.\n\n###\n\n00:37:21 - Dangers of open source\n\nObviously it's very difficult to predict what direction this stuff goes in\nover time, which is why I don't think anyone should be dogmatic about how they\nplan to develop it or what they plan to do. You want to look at it with each\nrelease. We're obviously very pro open source, but I haven't committed to\nreleasing every single thing that we do. I\u2019m basically very inclined to think\nthat open sourcing is going to be good for the community and also good for us\nbecause we'll benefit from the innovations. If at some point however there's\nsome qualitative change in what the thing is capable of, and we feel like it's\nnot responsible to open source it, then we won't. It's all very difficult to\npredict.\n\nDwarkesh Patel 00:38:07\n\nWhat is a kind of specific qualitative change where you'd be training Llama-5\nor Llama-4, and if you see it, it\u2019d make you think \u201cyou know what, I'm not\nsure about open sourcing it\u201d?\n\nMark Zuckerberg 00:38:17\n\nIt's a little hard to answer that in the abstract because there are negative\nbehaviors that any product can exhibit where as long as you can mitigate it,\nit's okay. There\u2019s bad things about social media that we work to mitigate.\nThere's bad things about Llama-2 where we spend a lot of time trying to make\nsure that it's not like helping people commit violent acts or things like\nthat. That doesn't mean that it's a kind of autonomous or intelligent agent.\nIt just means that it's learned a lot about the world and it can answer a set\nof questions that we think would be unhelpful for it to answer. I think the\nquestion isn't really what behaviors would it show, it's what things would we\nnot be able to mitigate after it shows that.\n\nI think that there's so many ways in which something can be good or bad that\nit's hard to actually enumerate them all up front. Look at what we've had to\ndeal with in social media and the different types of harms. We've basically\ngotten to like 18 or 19 categories of harmful things that people do and we've\nbasically built AI systems to identify what those things are and to make sure\nthat doesn't happen on our network as much as possible. Over time I think\nyou'll be able to break this down into more of a taxonomy too. I think this is\na thing that we spend time researching as well, because we want to make sure\nthat we understand that.\n\nDwarkesh Patel 00:41:04\n\nIt seems to me that it would be a good idea. I would be disappointed in a\nfuture where AI systems aren't broadly deployed and everybody doesn't have\naccess to them. At the same time, I want to better understand the mitigations.\nIf the mitigation is the fine-tuning, the whole thing about open weights is\nthat you can then remove the fine-tuning, which is often superficial on top of\nthese capabilities. If it's like talking on Slack with a biology researcher...\nI think models are very far from this. Right now, they\u2019re like Google search.\nBut if I can show them my Petri dish and they can explain why my smallpox\nsample didn\u2019t grow and what to change, how do you mitigate that? Because\nsomebody can just fine-tune that in there, right?\n\nMark Zuckerberg 00:41:44\n\nThat's true. I think a lot of people will basically use the off-the-shelf\nmodel and some people who have basically bad faith are going to try to strip\nout all the bad stuff. So I do think that's an issue. On the flip side, one of\nthe reasons why I'm philosophically so pro open source is that I do think that\na concentration of AI in the future has the potential to be as dangerous as it\nbeing widespread. I think a lot of people think about the questions of \u201cif we\ncan do this stuff, is it bad for it to be out in the wild and just widely\navailable?\u201d I think another version of this is that it's probably also pretty\nbad for one institution to have an AI that is way more powerful than everyone\nelse's AI.\n\nThere\u2019s one security analogy that I think of. There are so many security holes\nin so many different things. If you could travel back in time a year or two\nyears, let's say you just have one or two years more knowledge of the security\nholes. You can pretty much hack into any system. That\u2019s not AI. So it's not\nthat far-fetched to believe that a very intelligent AI probably would be able\nto identify some holes and basically be like a human who could go back in time\na year or two and compromise all these systems.\n\nSo how have we dealt with that as a society? One big part is open source\nsoftware that makes it so that when improvements are made to the software, it\ndoesn't just get stuck in one company's products but can be broadly deployed\nto a lot of different systems, whether they\u2019re banks or hospitals or\ngovernment stuff. As the software gets hardened, which happens because more\npeople can see it and more people can bang on it, there are standards on how\nthis stuff works. The world can get upgraded together pretty quickly.\n\nI think that a world where AI is very widely deployed, in a way where it's\ngotten hardened progressively over time, is one where all the different\nsystems will be in check in a way. That seems fundamentally more healthy to me\nthan one where this is more concentrated. So there are risks on all sides, but\nI think that's a risk that I don't hear people talking about quite as much.\nThere's the risk of the AI system doing something bad. But I stay up at night\nworrying more about an untrustworthy actor having the super strong AI, whether\nit's an adversarial government or an untrustworthy company or whatever. I\nthink that that's potentially a much bigger risk.\n\nDwarkesh Patel 00:44:59\n\nAs in, they could overthrow our government because they have a weapon that\nnobody else has?\n\nMark Zuckerberg 00:45:06\n\nOr just cause a lot of mayhem. I think the intuition is that this stuff ends\nup being pretty important and valuable for both economic and security reasons\nand other things. If someone whom you don't trust or an adversary gets\nsomething more powerful, then I think that that could be an issue. Probably\nthe best way to mitigate that is to have good open source AI that becomes the\nstandard and in a lot of ways can become the leader. It just ensures that it's\na much more even and balanced playing field.\n\nDwarkesh Patel 00:45:49\n\nThat seems plausible to me. If that works out, that would be the future I\nprefer. I want to understand mechanistically how the fact that there are open\nsource AI systems in the world prevents somebody causing mayhem with their AI\nsystem? With the specific example of somebody coming with a bioweapon, is it\njust that we'll do a bunch of R&D in the rest of the world to figure out\nvaccines really fast? What's happening?\n\nMark Zuckerberg 00:46:13\n\nIf you take the security one that I was talking about, I think someone with a\nweaker AI trying to hack into a system that is protected by a stronger AI will\nsucceed less. In terms of software security\u2013\n\nDwarkesh Patel 00:46:28\n\nHow do we know everything in the world is like that? What if bioweapons aren't\nlike that?\n\nMark Zuckerberg 00:46:32\n\nI mean, I don't know that everything in the world is like that. Bioweapons are\none of the areas where the people who are most worried about this stuff are\nfocused and I think it makes a lot of sense. There are certain mitigations.\nYou can try to not train certain knowledge into the model. There are different\nthings but at some level if you get a sufficiently bad actor, and you don't\nhave other AI that can balance them and understand what the threats are, then\nthat could be a risk. That's one of the things that we need to watch out for.\n\nDwarkesh Patel 00:47:19\n\nIs there something you could see in the deployment of these systems where\nyou're training Llama-4 and it lied to you because it thought you weren't\nnoticing or something and you're like \u201cwhoa what's going on here?\u201d This is\nprobably not likely with a Llama-4 type system, but is there something you can\nimagine like that where you'd be really concerned about deceptiveness and\nbillions of copies of this being out in the wild?\n\nMark Zuckerberg 00:47:46\n\nI mean right now we see a lot of hallucinations. It's more so that. I think\nit's an interesting question, how you would tell the difference between\nhallucination and deception. There are a lot of risks and things to think\nabout. I try, in running our company at least, to balance these longer-term\ntheoretical risks with what I actually think are quite real risks that exist\ntoday. So when you talk about deception, the form of that that I worry about\nmost is people using this to generate misinformation and then pump that\nthrough our networks or others. The way that we've combated this type of\nharmful content is by building AI systems that are smarter than the\nadversarial ones.\n\nThis informs part of my theory on this. If you look at the different types of\nharm that people do or try to do through social networks, there are ones that\nare not very adversarial. For example, hate speech is not super adversarial in\nthe sense that people aren't getting better at being racist. That's one where\nI think the AIs are generally getting way more sophisticated faster than\npeople are at those issues. And we have issues both ways. People do bad\nthings, whether they're trying to incite violence or something, but we also\nhave a lot of false positives where we basically censor stuff that we\nshouldn't. I think that understandably makes a lot of people annoyed. So I\nthink having an AI that gets increasingly precise on that is going to be good\nover time.\n\nBut let me give you another example: nation states trying to interfere in\nelections. That's an example where they absolutely have cutting edge\ntechnology and absolutely get better each year. So we block some technique,\nthey learn what we did and come at us with a different technique. It's not\nlike a person trying to say mean things, They have a goal. They're\nsophisticated. They have a lot of technology. In those cases, I still think\nabout the ability to have our AI systems grow in sophistication at a faster\nrate than theirs do. It's an arms race but I think we're at least winning that\narms race currently. This is a lot of the stuff that I spend time thinking\nabout.\n\nYes, whether it's Llama-4 or Llama-6, we need to think about what behaviors\nwe're observing and it's not just us. Part of the reason why you make this\nopen source is that there are a lot of other people who study this too. So we\nwant to see what other people are observing, what we\u2019re observing, what we can\nmitigate, and then we'll make our assessment on whether we can make it open\nsource. For the foreseeable future I'm optimistic we will be able to. In the\nnear term, I don't want to take our eye off the ball in terms of what are\nactual bad things that people are trying to use the models for today. Even if\nthey're not existential, there are pretty bad day-to-day harms that we're\nfamiliar with in running our services. That's actually a lot of what we have\nto spend our time on as well.\n\nDwarkesh Patel 00:51:24\n\nI found the synthetic data thing really curious. With current models it makes\nsense why there might be an asymptote with just doing the synthetic data again\nand again. But let\u2019s say they get smarter and you use the kinds of\ntechniques\u2014you talk about in the paper or the blog posts that are coming out\non the day this will be released\u2014where it goes to the thought chain that is\nthe most correct. Why do you think this wouldn't lead to a loop where it gets\nsmarter, makes better output, gets smarter and so forth. Of course it wouldn't\nbe overnight, but over many months or years of training potentially with a\nsmarter model.\n\nMark Zuckerberg 00:52:00\n\nI think it could, within the parameters of whatever the model architecture is.\nIt's just that with today's 8B parameter models, I don't think you're going to\nget to be as good as the state-of-the-art multi-hundred billion parameter\nmodels that are incorporating new research into the architecture itself.\n\nDwarkesh Patel 00:52:28\n\nBut those will be open source as well, right?\n\nMark Zuckerberg 00:52:31\n\nWell yeah, subject to all the questions that we just talked about but yes. We\nwould hope that that'll be the case. But I think that at each point, when\nyou're building software there's a ton of stuff that you can do with software\nbut then at some level you're constrained by the chips that it's running on.\nSo there are always going to be different physical constraints. How big the\nmodels are is going to be constrained by how much energy you can get and use\nfor inference. I'm simultaneously very optimistic that this stuff will\ncontinue to improve quickly and also a little more measured than I think some\npeople are about it. I don\u2019t think the runaway case is a particularly likely\none.\n\nDwarkesh Patel 00:53:32\n\nI think it makes sense to keep your options open. There's so much we don't\nknow. There's a case in which it's really important to keep the balance of\npower so nobody becomes a totalitarian dictator. There's a case in which you\ndon't want to open source the architecture because China can use it to catch\nup to America's AIs and there is an intelligence explosion and they win that.\nA lot of things seem possible. Keeping your options open considering all of\nthem seems reasonable.\n\nMark Zuckerberg 00:53:57\n\nYeah.\n\n###\n\n00:53:57 - Caesar Augustus and metaverse\n\nDwarkesh Patel 00:53:57\n\nLet's talk about some other things. Metaverse. What time period in human\nhistory would you be most interested in going into? 100,000 BCE to now, you\njust want to see what it was like?\n\nMark Zuckerberg 00:54:09\n\nIt has to be the past?\n\nDwarkesh Patel 00:54:12\n\nOh yeah, it has to be the past.\n\nMark Zuckerberg 00:54:13\n\nI'm really interested in American history and classical history. I'm really\ninterested in the history of science too. I actually think seeing and trying\nto understand more about how some of the big advances came about would be\ninteresting. All we have are somewhat limited writings about some of that\nstuff. I'm not sure the metaverse is going to let you do that because it's\ngoing to be hard to go back in time for things that we don't have records of.\nI'm actually not sure that going back in time is going to be that important of\na thing. I think it's going to be cool for like history classes and stuff, but\nthat's probably not the use case that I'm most excited about for the metaverse\noverall.\n\nThe main thing is just the ability to feel present with people, no matter\nwhere you are. I think that's going to be killer. In the AI conversation that\nwe were having, so much of it is about physical constraints that underlie all\nof this. I think one lesson of technology is that you want to move things from\nthe physical constraint realm into software as much as possible because\nsoftware is so much easier to build and evolve. You can democratize it more\nbecause not everyone is going to have a data center but a lot of people can\nwrite code and take open source code and modify it. \u03a4he metaverse version of\nthis is enabling realistic digital presence. That\u2019s going to be an absolutely\nhuge difference so people don't feel like they have to be physically together\nfor as many things. Now I think that there can be things that are better about\nbeing physically together. These things aren't binary. It's not going to be\nlike \u201cokay, now you don't need to do that anymore.\u201d But overall, I think it's\njust going to be really powerful for socializing, for feeling connected with\npeople, for working, for parts of industry, for medicine, for so many things.\n\nDwarkesh Patel 00:56:32\n\nI want to go back to something you said at the beginning of the conversation.\nYou didn't sell the company for a billion dollars. And with the metaverse, you\nknew you were going to do this even though the market was hammering you for\nit. I'm curious. What is the source of that edge? You said \u201coh, values, I have\nthis intuition,\u201d but everybody says that. If you had to say something that's\nspecific to you, how would you express what that is? Why were you so convinced\nabout the metaverse?\n\nMark Zuckerberg 00:57:02\n\nI think that those are different questions. What are the things that power me?\nWe've talked about a bunch of the themes. I just really like building things.\nI specifically like building things around how people communicate and\nunderstanding how people express themselves and how people work. When I was in\ncollege I studied computer science and psychology. I think a lot of other\npeople in the industry studied computer science. So, it's always been the\nintersection of those two things for me.\n\nIt\u2019s also sort of this really deep drive. I don't know how to explain it but I\njust feel constitutionally that I'm doing something wrong if I'm not building\nsomething new. Even when we were putting together the business case for\ninvesting a $100 billion in AI or some huge amount in the metaverse, we have\nplans that I think made it pretty clear that if our stuff works, it'll be a\ngood investment. But you can't know for certain from the outset. There are all\nthese arguments that people have, with advisors or different folks. It's like,\n\u201chow are you confident enough to do this?\u201d Well the day I stop trying to build\nnew things, I'm just done. I'm going to go build new things somewhere else.\nI'm fundamentally incapable of running something, or in my own life, and not\ntrying to build new things that I think are interesting. That's not even a\nquestion for me, whether we're going to take a swing at building the next\nthing. I'm just incapable of not doing that. I don't know.\n\nI'm kind of like this in all the different aspects of my life. Our family\nbuilt this ranch in Kauai and I worked on designing all these buildings. We\nstarted raising cattle and I'm like \u201calright, I want to make the best cattle\nin the world so how do we architect this so that way we can figure this out\nand build all the stuff up that we need to try to do that.\u201d I don't know,\nthat's me. What was the other part of the question?\n\nDwarkesh Patel 01:00:54\n\nI'm not sure but I'm actually curious about something else. So a 19-year-old\nMark reads a bunch of antiquity and classics in high school and college. What\nimportant lesson did you learn from it? Not just interesting things you found,\nbut there aren't that many tokens you consume by the time you're 19. A bunch\nof them were about the classics. Clearly that was important in some way.\n\nMark Zuckerberg 01:01:15\n\nThere aren't that many tokens you consume... That's a good question. Here\u2019s\none of the things I thought was really fascinating. Augustus became emperor\nand he was trying to establish peace. There was no real conception of peace at\nthe time. The people's understanding of peace was peace as the temporary time\nbetween when your enemies inevitably attack you. So you get a short rest. He\nhad this view of changing the economy from being something mercenary and\nmilitaristic to this actually positive-sum thing. It was a very novel idea at\nthe time.\n\nThat\u2019s something that's really fundamental: the bounds on what people can\nconceive of at the time as rational ways to work. This applies to both the\nmetaverse and the AI stuff. A lot of investors, and other people, can't wrap\ntheir head around why we would open source this. It\u2019s like \u201cI don't\nunderstand, it\u2019s open source. That must just be the temporary time between\nwhich you're making things proprietary, right?\u201d I think it's this very\nprofound thing in tech that it actually creates a lot of winners.\n\nI don't want to strain the analogy too much but I do think that a lot of the\ntime, there are models for building things that people often can't even wrap\ntheir head around. They can\u2019t understand how that would be a valuable thing\nfor people to do or how it would be a reasonable state of the world. I think\nthere are more reasonable things than people think.\n\nDwarkesh Patel 01:03:36\n\nThat's super fascinating. Can I give you what I was thinking in terms of what\nyou might have gotten from it? This is probably totally off, but I think it\u2019s\njust how young some of these people are, who have very important roles in the\nempire. For example, Caesar Augustus, by the time he\u2019s 19, is already one of\nthe most important people in Roman politics. He's leading battles and forming\nthe Second Triumvirate. I wonder if the 19-year-old you was thinking \u201cI can do\nthis because Caesar Augustus did this.\u201d\n\nMark Zuckerberg 01:04:01\n\nThat's an interesting example, both from a lot of history and American history\ntoo. One of my favorite quotes is this Picasso quote that all children are\nartists and the challenge is to remain an artist as you grow up. When you\u2019re\nyounger, it\u2019s just easier to have wild ideas. There are all these analogies to\nthe innovator\u2019s dilemma that exist in your life as well as for your company or\nwhatever you\u2019ve built. You\u2019re earlier on in your trajectory so it's easier to\npivot and take in new ideas without disrupting other commitments to different\nthings. I think that's an interesting part of running a company. How do you\nstay dynamic?\n\n###\n\n01:04:53 - Open sourcing the $10b model & custom silicon\n\nDwarkesh Patel 01:04:53\n\nLet\u2019s go back to the investors and open source. The $10B model, suppose it's\ntotally safe. You've done these evaluations and unlike in this case the\nevaluators can also fine-tune the model, which hopefully will be the case in\nfuture models. Would you open source the $10 billion model?\n\nMark Zuckerberg 01:05:11\n\nAs long as it's helping us then yeah.\n\nDwarkesh Patel 01:05:13\n\nBut would it? $10 billion of R&D and now it's open source.\n\nMark Zuckerberg 01:05:17\n\nThat\u2019s a question which we\u2019ll have to evaluate as time goes on too. We have a\nlong history of open sourcing software. We don\u2019t tend to open source our\nproduct. We don't take the code for Instagram and make it open source. We take\na lot of the low-level infrastructure and we make that open source. Probably\nthe biggest one in our history was our Open Compute Project where we took the\ndesigns for all of our servers, network switches, and data centers, and made\nit open source and it ended up being super helpful. Although a lot of people\ncan design servers the industry now standardized on our design, which meant\nthat the supply chains basically all got built out around our design. So\nvolumes went up, it got cheaper for everyone, and it saved us billions of\ndollars which was awesome.\n\nSo there's multiple ways where open source could be helpful for us. One is if\npeople figure out how to run the models more cheaply. We're going to be\nspending tens, or a hundred billion dollars or more over time on all this\nstuff. So if we can do that 10% more efficiently, we're saving billions or\ntens of billions of dollars. That's probably worth a lot by itself. Especially\nif there are other competitive models out there, it's not like our thing is\ngiving away some kind of crazy advantage.\n\nDwarkesh Patel 01:06:38\n\nSo is your view that the training will be commodified?\n\nMark Zuckerberg 01:06:44\n\nI think there's a bunch of ways that this could play out and that's one. So\n\u201ccommodity\u201d implies that it's going to get very cheap because there are lots\nof options. The other direction that this could go in is qualitative\nimprovements. You mentioned fine-tuning. Right now it's pretty limited what\nyou can do with fine-tuning major other models out there. There are some\noptions but generally not for the biggest models. There\u2019s being able to do\nthat, different app specific things or use case specific things or building\nthem into specific tool chains. I think that will not only enable more\nefficient development, but it could enable qualitatively different things.\n\nHere's one analogy on this. One thing that I think generally sucks about the\nmobile ecosystem is that you have these two gatekeeper companies, Apple and\nGoogle, that can tell you what you're allowed to build. There's the economic\nversion of that which is like when we build something and they just take a\nbunch of your money. But then there's the qualitative version, which is\nactually what upsets me more. There's a bunch of times when we've launched or\nwanted to launch features and Apple's just like \u201cnope, you're not launching\nthat.\u201d That sucks, right? So the question is, are we set up for a world like\nthat with AI? You're going to get a handful of companies that run these closed\nmodels that are going to be in control of the APIs and therefore able to tell\nyou what you can build?\n\nFor us I can say it is worth it to go build a model ourselves to make sure\nthat we're not in that position. I don't want any of those other companies\ntelling us what we can build. From an open source perspective, I think a lot\nof developers don't want those companies telling them what they can build\neither. So the question is, what is the ecosystem that gets built out around\nthat? What are interesting new things? How much does that improve our\nproducts? I think there are lots of cases where if this ends up being like our\ndatabases or caching systems or architecture, we'll get valuable contributions\nfrom the community that will make our stuff better. Our app specific work that\nwe do will then still be so differentiated that it won't really matter. We'll\nbe able to do what we do. We'll benefit and all the systems, ours and the\ncommunities\u2019, will be better because it's open source.\n\nThere is one world where maybe that\u2019s not the case. Maybe the model ends up\nbeing more of the product itself. I think it's a trickier economic calculation\nthen, whether you open source that. You are commoditizing yourself then a lot.\nBut from what I can see so far, it doesn't seem like we're in that zone.\n\nDwarkesh Patel 01:09:42\n\nDo you expect to earn significant revenue from licensing your model to the\ncloud providers? So they have to pay you a fee to actually serve the model.\n\nMark Zuckerberg 01:09:49\n\nWe want to have an arrangement like that but I don't know how significant\nit'll be. This is basically our license for Llama. In a lot of ways it's a\nvery permissive open source license, except that we have a limit for the\nlargest companies using it. This is why we put that limit in. We're not trying\nto prevent them from using it. We just want them to come talk to us if they're\ngoing to just basically take what we built and resell it and make money off of\nit. If you're like Microsoft Azure or Amazon, if you're going to be reselling\nthe model then we should have some revenue share on that. So just come talk to\nus before you go do that. That's how that's played out.\n\nSo for Llama-2, we just have deals with basically all these major cloud\ncompanies and Llama-2 is available as a hosted service on all those clouds. I\nassume that as we release bigger and bigger models, that will become a bigger\nthing. It's not the main thing that we're doing, but I think if those\ncompanies are going to be selling our models it just makes sense that we\nshould share the upside of that somehow.\n\nDwarkesh Patel 01:10:55\n\nRegarding other open source dangers, I think you have genuine legitimate\npoints about the balance of power stuff and potentially the harms you can get\nrid of because we have better alignment techniques or something. I wish there\nwere some sort of framework that Meta had. Other labs have this where they say\n\u201cif we see this concrete thing, then that's a no go on the open source or even\npotentially on deployment.\u201d Just writing it down so the company is ready for\nit and people have expectations around it and so forth.\n\nMark Zuckerberg 01:11:25\n\nThat's a fair point on the existential risk side. Right now we focus more on\nthe types of risks that we see today, which are more of these content risks.\nWe don't want the model to be doing things that are helping people commit\nviolence or fraud or just harming people in different ways. While it is maybe\nmore intellectually interesting to talk about the existential risks, I\nactually think the real harms that need more energy in being mitigated are\nthings where someone takes a model and does something to hurt a person. In\npractice for the current models, and I would guess the next generation and\nmaybe even the generation after that, those are the types of more mundane\nharms that we see today, people committing fraud against each other or things\nlike that. I just don't want to shortchange that. I think we have a\nresponsibility to make sure we do a good job on that.\n\nDwarkesh Patel 01:12:33\n\nMeta's a big company. You can handle both.\n\nAs far as open source goes, I'm actually curious if you think the impact of\nopen source, from PyTorch, React, Open Compute and other things, has been\nbigger for the world than even the social media aspects of Meta. I've talked\nto people who use these services and they think that it's plausible because a\nbig part of the internet runs on these things.\n\nMark Zuckerberg 01:12:55\n\nIt's an interesting question. I mean almost half the world uses our consumer\nproducts so it's hard to beat that. But I think open source is really powerful\nas a new way of building things. I mean, it's possible. It may be one of these\nthings like Bell Labs, where they were working on the transistor because they\nwanted to enable long-distance calling. They did and it ended up being really\nprofitable for them that they were able to enable long-distance calling. 5 to\n10 years out from that, if you asked them what was the most useful thing that\nthey invented it's like \u201cokay, we enabled long distance calling and now all\nthese people are long-distance calling.\u201d But if you asked a hundred years\nlater maybe it's a different answer.\n\nI think that's true of a lot of the things that we're building: Reality Labs,\nsome of the AI stuff, some of the open source stuff. The specific products\nevolve, and to some degree come and go, but the advances for humanity persist\nand that's a cool part of what we all get to do.\n\nDwarkesh Patel 01:14:14\n\nBy when will the Llama models be trained on your own custom silicon?\n\nMark Zuckerberg 01:14:19\n\nSoon, not Llama-4. The approach that we took is we first built custom silicon\nthat could handle inference for our ranking and recommendation type stuff, so\nReels, News Feed ads, etc. That was consuming a lot of GPUs. When we were able\nto move that to our own silicon, we're now able to use the more expensive\nNVIDIA GPUs only for training. At some point we will hopefully have silicon\nourselves that we can be using for at first training some of the simpler\nthings, then eventually training these really large models. In the meantime,\nI'd say the program is going quite well and we're just rolling it out\nmethodically and we have a long-term roadmap for it.\n\n###\n\n01:15:19 - Zuck as CEO of Google+\n\nDwarkesh Patel 01:15:19\n\nFinal question. This is totally out of left field. If you were made CEO of\nGoogle+ could you have made it work?\n\nMark Zuckerberg 01:15:24\n\nGoogle+? Oof. I don't know. That's a very difficult counterfactual.\n\nDwarkesh Patel 01:15:35\n\nOkay, then the real final question will be: when Gemini was launched, was\nthere any chance that somebody in the office uttered: \u201cCarthago delenda est\u201d.\n\nMark Zuckerberg 01:15:43\n\nNo, I think we're tamer now. It's a good question. The problem is there was no\nCEO of Google+. It was just a division within a company. You asked before\nabout what are the scarcest commodities but you asked about it in terms of\ndollars. I actually think for most companies, of this scale at least, it's\nfocus. When you're a startup maybe you're more constrained on capital. You\u2019re\njust working on one idea and you might not have all the resources. You cross\nsome threshold at some point with the nature of what you're doing. You're\nbuilding multiple things. You're creating more value across them but you\nbecome more constrained on what you can direct to go well.\n\nThere are always the cases where something random awesome happens in the\norganization and I don't even know about it. Those are great. But I think in\ngeneral, the organization's capacity is largely limited by what the CEO and\nthe management team are able to oversee and manage. That's been a big focus\nfor us. As Ben Horowitz says \u201ckeep the main thing, the main thing\u201d and try to\nstay focused on your key priorities.\n\nDwarkesh Patel 01:17:14\n\nAwesome, that was excellent, Mark. Thanks so much. That was a lot of fun.\n\nMark Zuckerberg 01:17:17\n\nYeah, really fun. Thanks for having me.\n\nDwarkesh Patel 01:17:19\n\nAbsolutely.\n\n15 Likes\n\nShare this discussion\n\n#### Mark Zuckerberg - Llama 3, Open Sourcing $10b Models, & Caesar Augustus\n\nwww.dwarkeshpatel.com\n\n3 Comments\n\n  * New First\n  * Top First\n  * Chronological\n\nNathan LambertInterconnects20 hrs agoLiked by Dwarkesh PatelWow huge\nsnagExpand full commentLike (1)ReplyShare  \n---  \n  \nPeter13 hrs agoMark Zuckerberg is wearing a wig, look at the line on his\nforeheadExpand full commentLike (1)ReplyShare  \n---  \n  \nDanielle NewnhamDanielle Newnham17 hrs agoAMAZING - so it wasn't an April\nFool's joke? Listening now - very good! Will recommend in my newsletter\ntomorrowExpand full commentLikeReplyShare  \n---  \n  \nDwarkesh Podcast\n\nDeeply researched interviews\n\nhttps://link.chtbl.com/dwarkesh\n\nDeeply researched interviews https://link.chtbl.com/dwarkesh\n\nListen on\n\nSubstack App\n\nSpotify\n\nRSS Feed\n\nAppears in episode\n\nDwarkesh Patel\n\nRecent Episodes\n\nSholto Douglas & Trenton Bricken - How to Build & Understand GPT-7's Mind\n\nMar 28 \u2022 Dwarkesh Patel\n\nDemis Hassabis - Scaling, Superhuman AIs, AlphaZero atop LLMs, Rogue Nations\nThreat\n\nFeb 28 \u2022 Dwarkesh Patel\n\nPatrick Collison (Stripe CEO) - Craft, Beauty, & The Future of Payments\n\nFeb 21 \u2022 Dwarkesh Patel\n\nTyler Cowen - Hayek, Keynes, & Smith on AI, Animal Spirits, Anarchy, & Growth\n\nJan 31 \u2022 Dwarkesh Patel\n\nLessons from The Years of Lyndon Johnson by Robert Caro [Narration]\n\nJan 23 \u2022 Dwarkesh Patel\n\nWill scaling work? [Narration]\n\nJan 19 \u2022 Dwarkesh Patel\n\nJung Chang - Living through Cultural Revolution and the Crimes of Mao\n\nNov 29, 2023 \u2022 Dwarkesh Patel\n\nReady for more?\n\n\u00a9 2024 Dwarkesh Patel\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
