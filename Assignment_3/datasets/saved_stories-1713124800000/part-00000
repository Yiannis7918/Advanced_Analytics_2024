{"aid": "40031074", "title": "Fun with AI Embeddings in Go", "url": "https://cybernetist.com/2024/01/07/fun-with-embeddings/", "domain": "cybernetist.com", "votes": 1, "user": "breck", "posted_at": "2024-04-14 13:58:33", "comments": 0, "source_title": "Fun With AI Embeddings in Go", "source_text": "Fun With AI Embeddings in Go - Cybernetist\n\n# Fun With AI Embeddings in Go\n\n| 21 minutes | 4330 words | Milos Gajdos\n\nUpdate 9th January, 2024: Changed the title to \u201cFun With AI Embeddings in Go\u201d\n\nBefore the end of last year, I visited San Francisco (SF) for a few weeks. It\nfelt great meeting some old friends and ex-colleagues face-to-face after a\nlong hiatus. There is something incredibly refreshing about being in the same\nroom with the folks you\u2019ve spent chatting to so much time over the past few\nyears on Zoom or Slack. Real-life connections remain undefeated and I hope it\nwill stay that way.\n\nI knew AI has taken the world by storm in the past year but I was still taken\naback by the sheer energy the folks I met in SF radiate with. Crazy ideas were\nflying at me from literally everywhere. The nerd populace of the city felt\nrejuvenated in comparison to how I remember my last visit there a few years\nago. The enthusiasm of the folks I met was very infectious! Not to mention the\nimpromptu Open AI mini-conference followed by a wild rave DJ-ed by Grimes fell\nsomehow randomly on my second day in the city!\n\nSimilarly, entirely coincidentally, without my realizing it GitHub Universe\nwas also happening at the same time in SF which made things even more fun for\nme because I got to catch up with some of my GitHub friends, too.\nUnsurprisingly the main theme of the Universe was Generative AI. In GtHub\u2019s\ncase it was mildly disappointing because there is still so much work GH should\ndo to make the existing product so much better than it is now before throwing\nmost of its weight behind GenAI. I mean, have you ever reviewed a large PR\nthat turned into a mass conversation of 5 people? But I digress...\n\n# The motivation\n\nAt one of the dinners I had with my friends we got to talk about non-tech\nthings like TV shows, movies, and music. And naturally, at some point, the\nconversation turned to Taylor Swift. I know what you\u2019re thinking, but no this\nisn\u2019t one of those posts by a middle-aged man that piles on Taylor.\n\nAnyway, I\u2019m not a Swifty and have nothing against the church of Taylor Swift,\nbut I\u2019ve always wondered how she managed to become such a conglomerate that\npeople literally go to cinemas to watch [the replays of] her live shows,\nbeating the box office number of some of the Hollywood movies. I\u2019ve listened\nto a few songs by her in the past but none of them resonated with me, so...I\nremain curious.\n\nThe friends I was sharing a delicious dinner with on that night on the other\nhand could probably be qualified as Swifties. At least to some extent, anyway.\nI mean how do you react to someone summarising her lyrics as: \u201cTaylor speaks\nthe truth\u201d. Sarcasm or not, this sentence stuck with me for whatever reason,\nthough I didn\u2019t expect it\u2019d lead to some fun hacks in the weeks that\nfollowed...\n\nOver the past year or so I\u2019ve mostly listened to white noise on Spotify - no,\nreally - though every once in a while I\u2019d put on some of my favourite metal\nbands. Metal is not the only genre of music I like but I grew up listening to\nit and old habits and tastes die hard.\n\nOn the flight back from the west of the USA I somewhat randomly started\nthinking about that dinner conversation with my friends. I became curious\nabout how the lyrics in Taylor Swift songs compare to the lyrics of one of my\nfavourite heavy metal bands. Yes, I occasionally listen to heavy metal and yes\nI could spend my flight reading through every song I\u2019d find on the internet\nand come up with some sort of comparison in my head that\u2019d justify my saying:\n\u201cMy band is better than yours\u201d. But that\u2019s not how I roll which is where the\ntitle of this blog post starts becoming a bit clearer, hopefully.\n\n# The task\n\nThough one might argue that art is subjective and therefore hard to quantify I\nfigured I\u2019d still try and compare the two artists. Given my contracting the AI\nvirus the best way I could think of doing the comparison was by leveraging\nembeddings. The LLMs got pretty good at generating text recently which makes\nthe text embeddings a pretty good tool for the task of comparing the lyrics.\nMaybe. Probably. But you know...\n\n> Mathematics is the language of the universe\n\nThough Python is [still] arguably the uncontested language of AI/ML \u2013 and I\ncan\u2019t see that changing anytime soon \u2013 there is a sizeable Go community out\nthere which I figured could be interested in how to to do some of this\nanalysis in Go. Plus I enjoy working on hard problems and doing some of this\nstuff in Go pretty much checked all the boxes for me.\n\nNOTE: It\u2019s much \u201ceasier\u201d to accomplish what I\u2019ll describe in this post in\nPython. Pick your battles, folks!\n\n# The embeddings\n\nI rolled up my sleeves and charged forward. First I had to scrape the lyrics.\nI used the gocolly framework for this because I was already familiar with it.\nThere is also geziyor which would\u2019ve probably been a good tool for the job,\ntoo, and probably many others I\u2019m not even aware of. Pick whatever tool gets\nthe job done and move on \u2013 especially when it comes to tedious tasks like\nscraping the web!\n\nWith all the data scraped down the next task was to generate the lyrics\nembeddings. I wanted to make my life as easy as possible so I opted to use the\nOpenAI Ada model. The most popular OpenAI Go module kinda melted my face a bit\nwith how much redundant code it contained (it doesn\u2019t use generics so it\ncontains a boatload of similar code) \u2013 I didn\u2019t want to pull all that stuff\ninto my hack. Besides, the modules provide quite comprehensive OpenAI API\ncoverage and all I wanted was the embeddings.\n\nSo the idiot I am I hacked up a small embeddings Go module. Part of it was\nthat I wanted something slim but I also wanted to learn about these Gen AI\nAPIs. The module currently supports the OpenAI embeddings API but also Cohere\nAI and the Google Vertex AI embeddings APIs.\n\nGetting the embeddings for any text content with the new Go module is quite\nsimple:\n\n    \n    \n    c := openai.NewClient() embReq := &openai.EmbeddingRequest{ Input: input, Model: openai.TextAdaV2, EncodingFormat: openai.EncodingFloat, } embs, err := c.Embed(context.Background(), embReq) if err != nil { log.Fatal(err) }\n\nNow, I should clarify the methodology here a bit. I wanted to zoom in on both\nthe individual song lyrics but also on the albums as a whole. So I generated\nembeddings for each individual song lyrics of each artist, first: the input\nvariable in the code above code would contain the lyrics of the whole song\nwhich would be turned into a single embedding vector. When it comes to\ncomparing the albums as wholes, I\u2019ve simply calculated average embeddings\nacross all songs in each individual album. This is just to save some time as\nthis was mostly a fun hack rather than a rigorous study.\n\nThe alternative way could be chunking the lyrics in both the songs and albums\nand do some clever things with the chunks before using the final embeddings.\nIf you are into that then you can have a look at the text package in the above\nmentioned Go module that implements simple document splitters heavily inspired\nby the popular Langchain framework. The splitters are basically a Go rewrite\nof the character and recursive character langchain splitters. Using the text\npackage you could split the songs (or concatenated songs of each album) and\ncalculate averages across the generated embeddings and use those instead of\nthe full song string as I did.\n\n# The projections\n\nNow, we could come up with some wild frameworks for \u201ccomparing\u201d the two\nartists like whose songs are sadder: in this case, I\u2019d just grab a bunch of\nsad sentences from the interwebzzz, generate the embeddings for them and then\ncalculate the average distance from each song to these sentences. The smaller\nthe average distance would be the sadder the artist\u2019s songs.\n\nBut I wanted something quick and dirty, something I wouldn\u2019t need to break my\nhead over too much. Ideally, it\u2019d be something visual that\u2019d make things more\nobvious from the get-go. I remember a while ago I played around with the\nawesome go-echarts Go module which is able to generate different types of\ncharts using the Go programming language. It\u2019s a port of the fantastic Apache\necharts library which actually generates an HTML file that bundles the JS\nlibrary into it which you can then open in your browser. Exactly what I\nneeded!\n\nBut before I could do that I had to massage the embeddings a bit. See, the\nembeddings are wild beasts i.e. large vectors whose size often exceeds 1k\nelements. How does one display a 1K dimensional vector in a chart? How does\none even imagine one for that sake!\n\nThe solution here is projecting the large dimensional data into lower\ndimension(s). This leads to losing some context but generally does a pretty\ngood job of visualizing high-dimensional data to wrap your head around.\n\nThere are probably more options out there but I opted to generate 2D and 3D\ndimensional projections using the Principal component analysis (PCA) and\nt-SNE. I actually wrote a two-part blog post series many moons ago about the\nbeauty behind PCA. If you are into practical applications you can go to the\nsecond part and check out how the PCA can be applied to a very rudimentary\ndigital image compression if you scroll at the bottom of the second post.\n\nIn order to project high dimensional data to lower dimension in Go I had to\nrevisit some previously acquired knowledge of the wonderful gonum framework.\nIt\u2019s got all the pieces we need to get the PCA vectors so we can use them for\ngenerating 2D/3D projections. Specifically, we need the mat package for matrix\noperations and the stat package for the PCA algorithm implementation. As for\nthe t-SNE, there is actually a dedicated Go module which is referenced by the\nt-SNE project as an official Go implementation.\n\nNow I had to piece these things together. Here\u2019s a simple Go snippet that\ndemonstrates how to generate the PCA projections in Go:\n\n    \n    \n    // Vector stores embeddings for each song type Vector struct { // Name is the name of the song. Name string `json:\"name\"` // Values are embeddings elements. Values []float64 `json:\"vector\"` } // Data is used to store artist albums. type Data struct { // Name of the album. Name string `json:\"name\"` // Vectors stores embeddings for each song. Vectors []Vector `json:\"embeddings\"` } func getPCA(embs []Data, dim int) ([]Data, error) { pcas := make([]Data, 0, len(embs)) for _, e := range embs { items := make([]Vector, 0, len(e.Vectors)) // embMx: each row is a song whose dimension is the length of its embedding embMx := mat.NewDense(len(e.Vectors), len(e.Vectors[0].Values), nil) for i, t := range e.Vectors { embMx.SetRow(i, t.Values) } r, _ := embMx.Dims() if r == 1 { log.Printf(\"skipping data %s due to low number of items: %d\", e.Name, len(e.Vectors)) continue } var pc stat.PC ok := pc.PrincipalComponents(embMx, nil) if !ok { log.Printf(\"failed pca for %s\", e.Name) continue } var proj mat.Dense var vec mat.Dense pc.VectorsTo(&vec) proj.Mul(embMx, vec.Slice(0, len(e.Vectors[0].Values), 0, dim)) for i := range e.Vectors { items = append(items, Vector{ Name: e.Vectors[i].Name, Values: proj.RawRowView(i), }) } pcas = append(pcas, Data{ Name: e.Name, Vectors: items, }) } return pcas, nil }\n\nWe use this func to generate embedding projections for both 2D and 3D charts.\nNote that calculating PCA for a single vector does not make any sense so we\nskip those cases.\n\nThe t-SNE code looks quite similar:\n\n    \n    \n    func getTSNE(embs []Data, dim int) ([]Data, error) { tsnes := make([]Data, 0, len(embs)) perplexity, learningRate := float64(30), float64(200) if dim == 3 { perplexity, learningRate = float64(30), float64(200) } for _, e := range embs { items := make([]Vector, 0, len(e.Vectors)) // embMx: each row is a song whose dimension is the length of its embedding embMx := mat.NewDense(len(e.Vectors), len(e.Vectors[0].Values), nil) for i, t := range e.Vectors { embMx.SetRow(i, t.Values) } t := tsne.NewTSNE(dim, perplexity, learningRate, 3000, true) resMat := t.EmbedData(embMx, nil) d := mat.DenseCopyOf(resMat) for i := range e.Vectors { items = append(items, Vector{ Name: e.Vectors[i].Name, Values: d.RawRowView(i), }) } tsnes = append(tsnes, Data{ Name: e.Name, Vectors: items, }) } return tsnes, nil }\n\nI should point out the t-SNE has two hyperparameters: perplexity and learing\nrate, which means if you are going to use it you need to tune them a bit for\nyour use case. You can learn more about them in this wonderful post.\n\nNow that we have the projections calculated for all of our data it\u2019s time to\ngenerate some charts.\n\n# The charts\n\nAs I mentioned above, I opted to use the go-echarts Go module, though another\noption would be to use one of the plot package from the Gonum framework. It\ndoesnt generate the HTML files though and the charts generated by the go-\necharts module are just too beautiful to pass on, so I went with that.\n\nThere are truckload of examples in the examples repository that I checked out\nbeforehand. Specifically, I was after the 2D and 3D charts; the scatter and\nscatter3D charts checked all the boxes for my requirements. They provide\noptions for displaying labels and tooltips which was a very nice cherry on the\ncake.\n\nHere\u2019s a sample code for the global chart config\n\n    \n    \n    chartOptions := []charts.GlobalOpts{ charts.WithTitleOpts(opts.Title{ Title: title, Subtitle: \"Lyrics Embeddings\", }), charts.WithTooltipOpts(opts.Tooltip{ Show: true, Formatter: \"{a}: {b}\", }), charts.WithToolboxOpts(opts.Toolbox{ Show: true, Orient: \"horizontal\", Left: \"right\", Feature: &opts.ToolBoxFeature{ SaveAsImage: &opts.ToolBoxFeatureSaveAsImage{ Show: true, Title: \"Save as image\"}, Restore: &opts.ToolBoxFeatureRestore{ Show: true, Title: \"Reset\"}, }}), }\n\nYou then need to generate time series which are then rendered into a chart.\nHere\u2019s one way to do that:\n\n    \n    \n    func add2DSeries(artist string, data []Data, chart *charts.Scatter) error { var chartData []opts.ScatterData for _, d := range data { for _, p := range d.Vectors { vals := make([]interface{}, len(p.Values)) for i := range p.Values { vals[i] = p.Values[i] } chartData = append(chartData, opts.ScatterData{ Name: fmt.Sprintf(\"%s (%s)\", p.Name, d.Name), Value: vals, Symbol: \"roundRect\", }, ) } } chart.AddSeries(artist, chartData) return nil } func add3DSeries(artist string, data []Data, chart *charts.Scatter3D, grad bool) error { var chartData []opts.Chart3DData for i, d := range data { for _, p := range d.Vectors { vals := make([]interface{}, len(p.Values)) for i := range p.Values { vals[i] = p.Values[i] } chartData = append(chartData, opts.Chart3DData{ Name: fmt.Sprintf(\"%s (%s)\", p.Name, d.Name), Value: vals, ItemStyle: &opts.ItemStyle{Color: colors[i]}, }, ) } } chart.AddSeries(artist, chartData) return err } r := charts.NewScatter() // or charts.NewScatter3D() if err := add2DSeries(swift, swiftPcas, scatter); err != nil { log.Fatal(err) } f, err := os.Create(\"chart.html\") if err != nil { panic(err) } if err := r.Render(io.MultiWriter(f)); err != nil { log.Fatal(err) }\n\nAs I said earlier this will spit out an HTML file you can then open in the\nbrowser. And with this, we\u2019re pretty much done. We finally have something we\ncan look over and see what we can make of it.\n\n# The Results\n\nLet\u2019s have a look at the 2D chart of the song lyrics projections to see if we\ncan spot any discernible difference between the two artists.\n\nNOTE: all the charts discussed in this post are ineractive\n\nFrom the first look at the PCA projections, it would appear that they\u2019re\npretty equally.....eclectic? Perfect. Or not. It depends. PCA kinda takes my\nside which is: whatever, both artists sing about more or less the same kinda\nthings and the contents of their lyrics are pretty diverse.\n\nIf we look at the t-SNE projections things are a bit different. It\u2019s worth\nmentioning that t-SNE is [generally] better at generating lower dimensional\nprojections (at least the 3D ones, anyway) because PCA assumes the data you\nare projecting are linear; which very roughly means that you can generate any\nvector (song lyrics) in the data by a linear combination of the vector basis\n(nerd alert!). Or put it in layman\u2019s terms: any song lyrics is a rehash of\nother songs in the same data set \u2013 or something like that. Now, this is a very\nstrong assumption as you can imagine \u2013 at least for a lot of artists this\nusually isn\u2019t the case (though I imagine there are some that wouldn\u2019t surprise\nme if this held true).\n\nt-SNE does not make this assumption. It uses a clever way to calculate the\nprobabilities the two pieces of data are [somehow] related \u2013 this is quite\ndifferent from PCA. I\u2019d encourage you to read about it on its wiki page and\naccompanying references as the algorithm itself are pretty fascinating and has\nbecome pretty much the standard way to visualise high-dimensional data.\n\nBecause of these useful properties, from now on we\u2019ll be using t-SNE when\ndoing our analysis.\n\nt-SNE has a couple of hyperparameters so you need to play around with them to\nget somewhat reasonable results. What that means is a bit hazy to guess but I\nguess in our case we would be looking for some patterns like, say, clustering\nof songs with similar content (context) or some such.\n\nNow, what I find interesting in the t-SNE projection is how eclectic my fav\nband lyrics are: you can see how more spread around the songs are in\ncomparison to Taylor Swift songs. I have a theory about this but I dont dare\nto anger Swifties so I shall keep it to myself :-)\n\nI think it\u2019s fairly safe to assume from the 2D projections the songs don\u2019t\ntell us much about how different the lyrics are: maybe Masterplan \u201cspeak the\ntruth\u201d as well. Probably. Most definitely.\n\nLet\u2019s have a look at the albums though. Let\u2019s recap what I did to generate the\nembeddings for each album: take the embeddings of all individual songs in each\nalbum and calculate the average vector from them; use that vector as an\nembedding that represents the whole album \u2013 we are making an assumption that\neach album attempts to convey somewhat consistent message throughout all the\nsongs it contains. This is a reasonable assumption that gives us a rough\napproximation of the content of each album.\n\nTo make things more interesting I\u2019ve also decided to pull in the embeddings of\nbasic human emotions: happy, sad, surprised, angry, disgusted, and fear. The\nway I went about it was somewhat similar to what I did with the album\nembeddings: I grabbed some (10ish) sentences for each emotion from the\ninternet, got embeddings for each of them, and once again averaged them into a\nsingle vector that \u201crepresents\u201d the specific emotion.\n\nThen I calculated projections for each emotion vector using PCA and t-SNE. I\nfigured this could give me a very rough idea about the general sentiment of\neach album. Again, I shall stress we are comparing averages with averages of\nlyrics of various sizes so take this with a major pinch of salt! This will do\njust fine for this hack.\n\nThe t-SNE 2D projection suggests that Taylor Swift seems to write happier\nsongs than the Masterplan. Go figure! Also, it would appear nobody seems to be\nsinging about disgust \u2013 not even the metal band! How peculiar. Still, this\ndoes not seem quite what I\u2019d expect and there is not much I could assume from\nthis. It also goes to show how easy it is to fool oneself by very questionable\nanalysis applied to wild approximations of raw data.\n\nNow, if we zoom in on the 3D projection things are a bit more interesting.\nWhilst the 2D projections made us believe that some of the lyrics of both\nartists are quite similar if we play around with the 3D chart we get to see\nthat that\u2019s not quite the case for quite a few songs which is totally not\nobvious from the 2D chart. This again goes to show how easy it is to get\nplayed by lower dimensional data. There is a lesson here hiding along the\nlines of \u201clook for models that are as simple as possible but not simpler\u201d \u2013 2D\nis simpler than 3D but it can fool you if you are not careful enough.\n\nIt goes without saying that the higher dimensional data carry more context\n(information) and therefore should lead to better analysis and less flawed\nresults. Another lesson here is, I suppose, always try to project the data\ninto 3 dimensions before dropping one level below. The latter is not entirely\nuseless though, if you are aware of what\u2019s happening. Also, sometimes you\nmight not be able to display the 3D charts so it\u2019s nice to have some option\nthat lets us view the data at least in 2D.\n\n# The embeddings again\n\nEmbeddings are one of the most fascinating artifacts of AI/ML. They allow us\nto represent any piece of data as numerical vectors that capture the context\nof the data within the domain the embeddings were trained on. This is why\nfine-tuning your embedding models should theoretically yield better results\nfor the given domain than simply reusing the \u201cgeneric\u201d embedding vectors. I\u2019d\nwager if we fine-tuned the Open AI model on all of the lyrics and emotion-\ncapturing data we would get a way better idea about what\u2019s going on in the\nlyrics of both artists. As an aside, one of my good friends just started a new\ncompany that lets you fine-tune models and some! Go check it out here.\n\nEmbeddings open an awful lot of opportunities that haven\u2019t been explored\nentirely, yet. From what I\u2019ve seen the predominant use case at the moment is\nusing embeddings in unison with some context addressable stores a.k.a. vector\ndatabases where one stores knowledge bases and does quick look-up in them over\nsome content and uses the returned results as an additional context when\ntalking to LLMs. This increases the accuracy of RAG results and helps with\npreventing LLM hallucinations.\n\nThis is cute, but it\u2019s the most obvious use case which barely scratches the\nsurface of what embeddings could be capable of! The mere fact that an\nembedding provides a numerical representation of a thing in some domain is a\nvery powerful notion. You can assign numbers to any (not necessarily) textual\ncontent!\n\nWhy is that powerful? Anything that can be represented as a numerical vector\ncan have a whole class of mathematical opertions applied on them; some of\nwhich may feel like nonsense \u2013 what does adding \u201ccar\u201d vector with \u201cevil clown\u201d\nresult in? \u2013 others less so. Imagine recommendation engines that leverage the\ncontext of a piece of data within a domain (yes I am familiar with\ncollaborative filtering), classifying similar data through clustering, etc.\n\n> EMBEDDINGS GIVE YOU SUPERPOWERS!\n\nAnd you can take it much further e.g. if you think of each vector as a node in\na network you can analyse contextual relationships between the nodes (say, in\nour case, the lyrics) \u2013 \u201csingle dimensionality\u201d of networks has always been a\nhuge problem in network analysis and it actually recently lead to the creation\nof theory og hypergraphs which once again, opens a whole another avenue\ntowards an understanding of the world and developing better products.\n\nIt gets better still. The Open AI CLIP model lets you generate multimodal\nembeddings, in fact so does the Vertex AI (FYI: support for these is built\ninto the go-embeddings Go module used in this hack). This creates a link\nbetween the images and text and lets you do all kindsa crazy things with image\nsearch or whatnot. I\u2019ve seen someone blogging about splitting an image into\npatches of identified objects in the image, then generating embeddings for\neach of them and storing them in a vector store for querying \u2013 that lets you\nsearch for content inside images not just for the \u201caverage\u201d image content per\nse!\n\nOne of the more interesting use cases I learnt about recently from one of my\nbest friends, Dan, was about using embeddings in reverse engineering. Dan is\nthe CTO of Teller, the best API provider for connecting your app to banking\ninstitutions. Teller do a lot of reverse-engineering, which is some of the\nmost fascinating things but sometimes it can become a rather tedious activity.\nNow, imagine you could build a knowledge base of some frequently appearing\npseudo code snippets you\u2019ve seen before whilst reversing some other apps \u2013\nthis is not an unreasonable assumption given a lot of companies reuse lots of\nlibraries in their code \u2013 and then cross-reference/match them to a new freshly\ndecompiled program you get access to. This can vastly simplify and speed up\nyour work. You could even take it further, by building full ASTs using\nsomething like a graph DB, etc.\n\n# Conclusion\n\nWhilst Python is and will remain the dominant language in the AI/ML space,\nthere are plenty of Go modules that let you do some interesting things with\ndata and vector embeddings.\n\nHappily \u2013 or sadly, depending on whose side you are on \u2013 my quick Go hacks\nhavent uncovered much difference between Taylor Swift and Masterplan lyrics. I\nam going to assume if Taylor speaks the truth then so does Masterplan and will\ncontinue to listen to whatever comes my way.\n\nIn the future, I\u2019d like to take this a bit further, still. The recent\nannouncement by Google brain team introduced the Gemini project which promises\nmultimodal embeddings that include audio data. It\u2019d be great to sample the\nsongs and inspect their projections and maybe see how much our taste in the\nactual music differs, instead of focusing just on a single dimension: lyrics.\n\nIf you have any fun ideas about how embeddings can be used or simply want to\nshare how you leveraged them i whatever use-case you had, please let me know\nin the comments. See you in another post!\n\nYou can find [most of] the code used in this hack on GitHub.\n\nGo embeddings golang ai\n\n#### See also\n\n  * Circular Buffer Performance Trick\n  * A Small Tool for Exploring Text Embeddings\n  * Getting Started With LDAP in Go\n  * Build a Graph of Kubernetes API Objects in Go\n  * Breadth-first search using Go standard library\n\n  * \u2190 Previous Post\n  * Next Post \u2192\n\nMilos Gajdos \u2022 \u00a9 2024 \u2022 Cybernetist\n\nHugo v0.124.1 powered \u2022 Theme Beautiful Hugo adapted from Beautiful Jekyll\n\n", "frontpage": false}
