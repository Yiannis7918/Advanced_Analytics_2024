{"aid": "40086181", "title": "Where do all those colors in space telescope images come from?", "url": "https://www.popsci.com/science/telescope-images/", "domain": "popsci.com", "votes": 2, "user": "geox", "posted_at": "2024-04-19 12:51:07", "comments": 0, "source_title": "Where do all those colors in space telescope images come from?", "source_text": "Where do all those colors in space telescope images come from? | Popular Science\n\nSOCIAL\n\nNewsletter Sign-Up\n\n# Where do all those colors in space telescope images come from?\n\nHow scientists make vibrant spectacles out of grayscale blobs.\n\nBy Briley Lewis | Published Apr 18, 2024 10:28 AM EDT\n\n  * Science\n\nCassiopeia A (Cas A) is a supernova remnant located about 11,000 light-years\nfrom Earth in the constellation Cassiopeia. It spans approximately 10 light-\nyears. This image uses data from Webb\u2019s Mid-Infrared Instrument (MIRI) to\nreveal Cas A in a new light. This image combines various filters with the\ncolor red assigned to 25.5 microns (F2550W), orange-red to 21 microns\n(F2100W), orange to 18 microns (F1800W), yellow to 12.8 microns (F1280W),\ngreen to 11.3 microns (F1130W), cyan to 10 microns (F1000W), light blue to 7.7\nmicrons (F770W), and blue to 5.6 microns (F560W). NASA, ESA, CSA, Danny\nMilisavljevic (Purdue University), Tea Temim (Princeton University), Ilse De\nLooze (UGent) / Image Processing: Joseph DePasquale (STScI)\n\nSHARE\n\nWe\u2019ve all seen beautiful images of outer space, with vivid swirls and bright\nstars resting on a black abyss. With how quick it is to snap a color photo on\nan iPhone, you might think that sophisticated space telescopes churn out color\nphotos automatically, too.\n\nHowever, all digital cameras\u2014from your phone to the James Webb Space\nTelescope\u2014can\u2019t actually see in color. Digital cameras record images as a\nbunch of ones and zeros, counting the amount of light hitting their sensors.\nEach pixel has a colored filter over it (either red, green, or blue), which\nonly allows specific wavelengths of light to go through. The filters are\narranged in a specific pattern (typically a four-pixel repeating square known\nas the Bayer pattern), which allows the camera\u2019s computing hardware to combine\nthe captured data into a full-colored image. Some digital cameras spread the\ncolored filters out across three individual sensors, the data from which can\nsimilarly combine into a full-color image. Telescope cameras, however, have to\ntake images with one filter at a time, such that they have to be combined by\nexperts later into a composite image.\n\n> Processing scientific data into beautiful color images is actually a full-\n> time job.\n\nApproximate outlines help to define the features in the Sagittarius C (Sgr C)\nregion. Astronomers are studying data from NASA\u2019s James Webb Space Telescope\nto understand the relationship between these features, as well as other\ninfluences in the chaotic galaxy center. Credits: NASA, ESA, CSA, STScI,\nSamuel Crowe (UVA)\n\nIn our smartphones, the combination of layers happens incredibly fast\u2014but\ntelescopes are complicated scientific behemoths, and it takes a bit more\neffort to get the stunning results we know and love. Plus, when we\u2019re looking\nat the cosmos, astronomers use wavelengths of light that our eyes can\u2019t even\nsee (e.g. infrared and X-rays), so those also need to be represented with\ncolors in the rainbow. There are lots of decisions to be made about how to\ncolorize space images, which begs the question: who is making these images,\nand how do they make them?\n\nFor the spectacular results we\u2019ve been seeing from JWST, processing scientific\ndata into beautiful color images is actually a full-time job. Science\nvisualization specialists at the Space Telescope Science Institute in\nBaltimore stack images together and stitch observations from different\ninstruments on the telescope. They also remove artifacts, or things in the\nimage that aren\u2019t actually real, but instead just results of the telescope\nequipment and how digital data is processed. These could be streaks from stray\ncosmic rays, oversaturation of the brightest stars, or noise from the detector\nitself.\n\n## Black and white to color\n\nBefore they even think about color, these specialists need to balance out the\ndark and light values in the image. Scientific cameras are meant to record a\nwide range of brightnesses beyond what our eyes can pick up on. This means\nthat the raw images from telescopes often look very dark to our eyes, and you\nhave to brighten up the image to see anything.\n\nOnce they have black and white images where the details are visible, they\nstart adding color. \u201cDifferent telescopes have filters that are made to be\nsensitive to only certain wavelengths of light, and the colorful space images\nwe see are combinations of separate exposures taken in these different\nfilters\u201d similar to the earlier description of a phone camera, explains Katya\nGozman, an astronomer at the University of Michigan. \u201cWe can assign each\nfilter to a separate color channel\u2014red, green or blue, the primary colors of\nvisible light. When stacked on top of each other, we get the spectacular\ntextbook color image that we\u2019re used to seeing in the media,\u201d she adds.\n\n> This is where it becomes a bit of an art, choosing colors based on not only\n> scientific accuracy, but also what looks best. For JWST and Hubble, the\n> usual routine is to use blue for the shortest wavelengths, green for in\n> between, and red for the longest wavelengths.\n\nThe end result, of course, also depends on what kind of data the image\nspecialists have to work with in the first place. The team often chooses\ndifferent colors to highlight the fact that NIRCam and MIRI\u2014two of Webb\u2019s\ninfrared cameras\u2014are looking at different wavelengths (near-infrared and mid-\ninfrared, respectively), and therefore different physical structures. For\nexample, in the Cassiopeia A supernova remnant, JWST\u2019s observations revealed a\nbubble of something emitting a specific wavelength of light, colored as green\nin the MIRI image and resultantly known as the \u201cGreen Monster.\u201d Without this\nvisualization, astronomers may not have noticed such a curious feature that\nprovides insight into how giant stars die\u2014and after some investigation, they\nfigured out the Green Monster is a region of debris disturbed by the huge\nblast from the supernova explosion.\n\nThis image provides a side-by-side comparison of supernova remnant Cassiopeia\nA (Cas A) as captured by NASA\u2019s James Webb Space Telescope\u2019s NIRCam (Near-\nInfrared Camera) and MIRI (Mid-Infrared Instrument). Credits: NASA, ESA, CSA,\nSTScI, Danny Milisavljevic (Purdue University), Ilse De Looze (UGent), Tea\nTemim (Princeton University)\n\n## Invisible to visible\n\nGenerally, image specialists try to keep things as close to reality as\npossible. For example, if a telescope is observing in visible light,\nwavelengths can directly map to colors we\u2019re used to seeing. But for those\nparts of the spectrum invisible to our eyes, they have to make choices about\nwhich visible colors to use. This is where it becomes a bit of an art,\nchoosing colors based on not only scientific accuracy, but also what looks\nbest. For JWST and Hubble, the usual routine is to use blue for the shortest\nwavelengths, green for in between, and red for the longest wavelengths. If\nthere are more than three different filters to choose from (as is often the\ncase with JWST, especially when using more than one of its high tech\ninstruments), sometimes they\u2019ll add in purple, teal, and orange for other\nwavelengths in between the red, green, and blue.\n\nWebb\u2019s raw telescope images initially appear almost completely black (left).\nThey are initially transformed by image processors into crisp black-and-white\nimages (center) and then full-color composites (right). Credit: JWST\n\nColor images are far more than a pretty picture, though\u2014they\u2019re actually quite\nuseful for science. The human brain is excellent at picking up patterns in\ncolor, such as parsing a map with color-coded subway lines or recognizing that\n\u201ca red light is stop, green is go,\u201d says Mark Popinchalk, an astronomer at the\nAmerican Museum of Natural History. \u201cThese are daily examples where societal\ninformation is presented and processed quickly through color. Scientists want\nto use the same tool,\u201d he adds. \u201cBut instead of societal information, it\u2019s\nscientific. If X-rays are red, and ultraviolet is blue, we can very quickly\ninterpret energetic light beyond what humans are capable of.\u201d The result is a\nvisual representation of an intense amount of data\u2013much more than can be\nprocessed with the naked eye, or in black and white alone.\n\nFor example, Gozman describes how images have helped recognize \u201cwhere\ndifferent physical processes are happening in an object, such as seeing where\nstar formation is happening in a galaxy or where different elements are\nlocated around a nebula.\u201d Color images with light beyond the visible spectrum\nhave even revealed dark matter around galaxies, such as in the bullet cluster.\n\n[ Related: This is what Uranus and Neptune may really look like ]\n\nAnother particularly recent and interesting example of image coloration is the\ncase of Neptune. The dark blue photo of the icy world from the Voyager mission\ndoesn\u2019t actually reflect its true color, as if we were looking at it with our\nown eyes\u2014instead, it\u2019s more similar to the pale face of Uranus. \u201cBack in the\n80s, astronomers actually stretched and modified the images of Neptune to\nbring out more contrast in some of its fainter features, leading it to have\nthat deep blue hue which made it look very different compared to Uranus,\u201d\nexplains Gozman. \u201cThough astronomers were aware of this, the public was not.\nThis is one good example of how reprocessing the same data in different ways\ncan lead to completely different representations.\u201d\n\nImage analysis is, and always has been, a huge part of astronomy, finding ways\nto see the cosmos beyond the limitations of our very limited human eyes. You\ncan even try your own hand at it\u2014JWST data is available to the public from\nNASA, and they even run an astrophotography challenge open to anyone. Now,\nwhen you see a beautiful image of space, perhaps you can think of it as a\nwonderful melding of science and art.\n\nDeep Space\n\nSpace\n\nSpace Telescope\n\nLike science, tech, and DIY projects?\n\nSign up to receive Popular Science's emails and get the highlights.\n\nLET'S GO\n\nLinks\n\nFollow us\n\nDISCLAIMER(S)\n\nArticles may contain affiliate links which enable us to share in the revenue\nof any purchases made.\n\nRegistration on or use of this site constitutes acceptance of our Terms of\nService.\n\n\u00a9 2024 Recurrent. All rights reserved.\n\n", "frontpage": false}
