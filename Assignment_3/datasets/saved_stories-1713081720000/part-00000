{"aid": "40028039", "title": "Performance inching isn't a strategy, even for AI models", "url": "https://github.com/getlago/lago/wiki/Performance-inching-isn%27t-a-strategy,-and-AI-models-aren%27t-exceptions", "domain": "github.com/getlago", "votes": 1, "user": "jdenquin", "posted_at": "2024-04-14 02:00:09", "comments": 0, "source_title": "Performance inching isn't a strategy, and AI models aren't exceptions", "source_text": "Performance inching isn't a strategy, and AI models aren't exceptions \u00b7\ngetlago/lago Wiki \u00b7 GitHub\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ngetlago / lago Public\n\n  * Notifications\n  * Fork 243\n  * Star 6k\n\n# Performance inching isn't a strategy, and AI models aren't exceptions\n\nJump to bottom\n\nAnh-Tho Chuong edited this page Apr 14, 2024 \u00b7 1 revision\n\nWhen touting their product against competitors, developers often use\nperformance as the core criteria. Assuming you\u2019re a developer, you\u2019ve\ndefinitely seen the slogans. \u201cOur framework is 40% more efficient than its\npredecessor\u201d. \u201cReach 2x faster speeds than Y library\u201d. Etc. Etc.\n\nIt\u2019s a fair thing to care about. Notably, performance woes with an existing\nsolution often prompt a search for an upgrade. If your application can\u2019t\nhandle your users\u2019 needs, then something needs to change. For most companies,\nhowever, that search doesn\u2019t result in a solution with peak performance.\nInstead, organizations often choose something with satisfactory performance\nthat has other markers of success, such as a great community.\n\nIn short, we believe that performance is rarely more than a checkbox.\n\n## Our personal experience\n\nAbout a year ago, we were running up against the wall with our database setup.\nWe used Postgres for everything, but the general-purpose database was failing\nour analytical needs. The analytical queries were hogging up our database\u2019s\nCPU and memory, clogging the database\u2019s availability for other business-\ncritical processes.\n\nWe eventually made a decision. Postgres\u2019s efficiency in answering analytical\nqueries wasn\u2019t cutting it. We needed a more efficient solution\u2014an analytics-\nfriendly OLAP database, to be specific. And we had tons of options. Pinot.\nApache Druid. Timescale.\n\nWe ended up choosing ClickHouse. ClickHouse was blazing fast and definitely\nabove the threshold needed to rectify our problem. However, while our search\nwas prompted by speed issues, we didn\u2019t choose ClickHouse because it was the\nfastest. It was technically slower than [QuestDB](https://questdb.io/time-\nseries-benchmark-suite/) for instance. What mattered was that it was fast\nenough. Other highlights sealed the deal: (i) an amazing community and (ii) a\nstrong managed offering.\n\nLet\u2019s back up and look at this story a bit more holistically.\n\n## Performance is a heavy-weighted checkbox\n\nIn general, developers tend to take a holistic approach when choosing\nproducts. And there are many checkboxes. For some teams, products need to be\nopen source. Other teams need explicit compatibility with their other tools.\n\nTypically, performance is another one of these checkboxes. A product simply\nneeds to be fast enough, compressed enough, and economical enough.\n\nFor instance, we had two requirements for our new analytical database: (i)\nanalytical queries couldn\u2019t lock up the server, and (ii) queries had to be\nanswered in a sub-second time. Technically, we could\u2019ve achieved the first\ntenet by reading from a Postgres replica alone, but never the second. We\nneeded a new product, and ClickHouse solved both. And while <>, <>, and\nTimescale were technically faster, our quest wasn\u2019t returning the fastest\nresult to the user. Our users waiting a heartbeat for the loaders to disappear\nwas A-OK. So, once we checked the box, we opted for other considerations\n(which, for us, was community).\n\n## There are exceptions\n\nAs with any mantra, there are exceptions. In certain cases, performance is the\nmost important consideration, particularly if the sought product is closely\ntied to the business\u2019s value prop. For instance, Dropbox\u2014a company in the\nbusiness of storing things\u2014may care about achieving peak compression, given\nthat it\u2019s directly tied to Dropbox\u2019s profit margin. Likewise, a team such as\nAWS S3 may care about optimal servers to serve its CDN content faster than\ncompetitors.\n\nBut even here, there are holdouts. PostHog is in the business of storing and\ndisplaying website analytical data but still opted for ClickHouse for similar\nreasons to ours.\n\nIn a nutshell, performance is about crossing a threshold, not pushing a\nboundary. But, if it\u2019s critical to an organization\u2019s core offering, the\nreverse may be applicable.\n\n## Community is an underrated marker\n\nThe real reason we chose ClickHouse was its massive community of adopters.\nThese were builders who were dealing with similar analytical problems. While\nClickHouse has plenty of competitors, it\u2019s a rather old tool, one of the first\nOLAP databases in the modern era of big data processing. Its long, battle-\ntested age has very effectively activated developers.\n\nCommunity is a big deal. And I\u2019m not referencing a heap of available Stack\nOverflow posts. It\u2019s more that products with big communities naturally flesh\nout. Big communities mean more online guides. Big communities mean more\nbattle-tested pairings with other common frameworks. Big communities create a\nmarket for commercially-driven managed solutions to launch, scale, and\nmaintain the product (e.g., Altinity Cloud for ClickHouse). And, as icing on\nthe cake, adopting a popular project makes it easy to attract engineering\ntalent.\n\nToday, we have a relatively popular stack at Lago. We would like to think of\nit as a fancy, bespoke solution, but frankly, Postgres + ClickHouse has grown\ninto quite a common database split. We needed to do very little in the\ncreative wheelhouse when implementing it. Scaling it was easy with Altinity.\nConnecting it was simplified by prebuilt Kafka connectors. This was all made\npossible due to ClickHouse\u2019s popularity.\n\n## Open source plays a role here\n\nMany developer tools\u2014especially tools shaped around performance\u2014are open\nsource. And, for open-source tools, community is inherently important. A\nstrong community means more third-party plugins built for tools. It means more\nmembers auditing code, flagging bugs, and preventing security issues. In\nshort, community activation by open-source projects means better projects in\nthe long run.\n\nThis is a slightly self-fulfilling point because open source attracts avid\ncommunities because of its free and open nature. There\u2019s no chance that\nClickHouse would\u2019ve gotten its modern adoption had it been closed source.\n\n## Often, cost precedes performance\n\nAssuming all contenders have satisfactory performance, another common tie-\nbreaker is cost. A product that is twice as fast might cost twice as much.\nEven if it costs 50% as much, it\u2019s likely not the ideal choice if the slower\nproduct\u2019s performance is satisfactory.\n\nFor us, cost wasn\u2019t a major consideration given that all databases are priced\nwith scale, and projecting scale was a tricky thing to begin with. Other\ncompanies may be satisfied with the Porsche, not the Bugatti.\n\n## What does this mean for performance-inching?\n\nThe intention of this article isn\u2019t to shame folks working on performance-\ninching tools (e.g., something with a 10-100% improvement on the previous\nleader). The development ecosystem moves forward because of small projects\nthat aspire to push the needle.\n\nInstead, the message here is that those projects are not going to succeed\nbecause of broad adoption, assuming there\u2019s a widely popular incumbent. This\nis, more or less, an engineering version of the VC \u201c10x or bust\u201d mentality.\nFrankly, a 20-30% improvement isn\u2019t going to convince organizations to move\nover from a significantly more popular tool.\n\nAt the same time, that\u2019s not a death sentence for projects with marginal\nperformance improvements. Instead of succeeding with broad adoption, they can\ncharge more and cater to organizations whose bottom-line business is directly\nattached to underlying performance. For instance, a project that scores a\nmarginally faster AI training score may find serious, lucrative success with\norganizations that do AI training as a service. It just may not succeed with\ncompanies that need it as a subprocess.\n\n## Closing thoughts\n\nPerformance might not be a common north star, but it is still important.\nWhat\u2019s more important, however, is projects building well-rounded\nqualities\u2014including amazing communities, extensions, pricing plans, and code\ndisclosures. Of course, some companies may see performance as a be-all and\nend-all factor, but it\u2019s increasingly rare!\n\n##### Clone this wiki locally\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
