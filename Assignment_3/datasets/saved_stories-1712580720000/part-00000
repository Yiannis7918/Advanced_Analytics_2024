{"aid": "39966918", "title": "Just How Much Faster Are the Gnome 46 Terminals?", "url": "https://bxt.rs/blog/just-how-much-faster-are-the-gnome-46-terminals/", "domain": "bxt.rs", "votes": 39, "user": "janvdberg", "posted_at": "2024-04-08 06:49:59", "comments": 12, "source_title": "Just How Much Faster Are the GNOME 46 Terminals?", "source_text": "Just How Much Faster Are the GNOME 46 Terminals? | Ivan Molodetskikh\u2019s Webpage\n\n# Just How Much Faster Are the GNOME 46 Terminals?\n\nApr 6, 2024 12:00 \u00b7 2408 words \u00b7 12 minute read\n\nVTE (Virtual TErminal library) is the library underpinning various GNOME\nterminal emulators. It provides a GTK widget that shows a terminal view, which\nis used in apps like GNOME Terminal, Console, Black Box, Tilix, Terminator,\nPtyxis, and others. It also powers embedded terminals in Builder and\nWorkbench.\n\nOver the GNOME 46 cycle, VTE has seen a lot of performance improvements.\nChristian Hergert mentioned some of them in his blog posts about VTE and about\nhis work in GNOME 46. But how much did the performance actually improve? What\nshould you, the user, expect to feel after installing a fresh Fedora 40 update\nand launching your favorite terminal?\n\nLet\u2019s measure and find out! If you don\u2019t have time for measuring, you can skip\nstraight to the finding out.\n\n## What Are We Measuring? #\n\nThere is no shortage of ways to define \u201cperformance\u201d, especially when it comes\nto terminal emulators. One of the more tangible metrics is input latency.\nRoughly, it describes how quickly the program reacts to your actions: how much\ntime passes from the moment you press a key on your keyboard to the change in\ncolor of the pixels on your monitor. Apps with low input latency feel snappy,\nwhereas apps with high input latency can feel sluggish.\n\nWhen the input latency is small-ish, you can get used to it and think it feels\nfine. However, comparing lower and higher input latency together (for example,\nby switching between two apps and typing in both) can make it quite\nnoticeable. If you\u2019ve ever heard people say they can\u2019t go back to a 60 Hz\nmonitor after trying out 144 Hz, that\u2019s a similar effect (and input latency is\npartially responsible).\n\nSo, how do you measure it?\n\n### Measuring Input Latency #\n\nThere are tools like Typometer that measure the input latency in software by\ndetecting key press events and recording the screen to detect a change in\npixel color. This can work reasonably well but requires fiddling with your\nsetup to make sure you\u2019re not accidentally introducing any biases. For\nexample, a screen capture API may return the new pixel colors a few\nmilliseconds before or after they are shown on the monitor, depending on the\nsystem setup, and you need to be aware of this when trying to measure\nsomething to a millisecond precision.\n\nI\u2019ve got something more interesting, a hardware input latency tester! It\nconsists of a light sensor attached to a Teensy board, which in turn is\nplugged into the computer via USB.\n\nI should really get around to writing a full blog post about this latency\ntester, but for now, you should read this post by Tristan Hume about building\na similar device.^1 I used that post as a reference for building mine, but I\nwrote my own firmware and analysis scripts (these I am not sharing until they\nare less of an utter mess).\n\nThe main benefit of such a device is that it allows you to measure a full end-\nto-end input latency, including processing time in the kernel, the compositor,\nthe application, and then the response time of the monitor itself. You are\nmeasuring what you really see and feel, excluding only the keyboard firmware\n(since the latency tester sends key press events directly over USB). There\u2019s\nalso very little extra load on the system, especially compared to using\nsomething like a screen capture API.\n\nHere\u2019s a gist of how it works. The light sensor is aimed at a specific, small\narea on the monitor, which will be affected by the key press (in our case, a\nspecific character cell in the terminal). The board sends a key press over USB\n(for example, Space) and starts monitoring the light sensor readings. As soon\nas it detects a jump in the light amount, it releases the key. Then, it\npresses a second key (for example, Backspace) and waits for the light to\nchange back. Now we\u2019re back to square one; the firmware waits a randomized\namount (to prevent \u201csnapping\u201d to the monitor refresh rate) and repeats the\nexperiment.\n\nDuring all of this process, the board dumps light sensor readings over a\nserial port as fast as it can manage (I\u2019m getting about 35,500 readings per\nsecond with my current board and firmware). On the computer, I save all of\nthis data into a file for offline analysis with Python code. This analysis\ncode finds the timestamp where the light starts to change, and subtracts it\nfrom the timestamp of the key press, to get one input latency measurement.\n\nI then aggregate the measurements and plot them with seaborn. Here\u2019s an\nexample of what the result looks like:\n\n### Input Latency Plots #\n\nLet\u2019s explore what you can find on this latency plot.\n\nThe small black dots represent the individual measurements. As in, every dot\nshows a real amount of time that had passed between one key press and the\ncorresponding change in light on the sensor. There are 120 of these dots since\nI repeat each test 120 times.\n\nLooking at the dots can confirm that the data is sensible. We expect the bulk\nof the measurements to be spread uniformly across an interval roughly the size\nof one monitor repaint cycle. This is because monitors generally repaint at a\nconstant rate, and pressing a key at a random point in time should land us in\na random point of the repaint cycle. We get the lowest latency if the\napplication renders a new frame in response right in time for the monitor to\nshow it. And we get the highest latency when the application finishes\nrendering a new frame just missing the monitor deadline, having to wait one\nextra repaint cycle for the pixel colors to change.\n\nIn the example above, the dots are spread over 7\u20138 ms, which is about equal to\nthe ~6.94 ms refresh cycle of my 144 Hz monitor.\n\nHigh outliers in the dots, or a larger spread, indicate lag or slowness of the\napplication under test: some key presses are taking longer than others to\nprocess.\n\nWe do not expect to see any gaps between dot clusters. They would usually\nindicate aliasing with the monitor repaint cycle, or some frame scheduling bug\nin the compositor.^2\n\nThe box shows statistics over the individual measurements:\n\n  * median (a measurement perfectly \u201cin the middle\u201d with half of the measurements lower and half of the measurements higher),\n  * lowest and highest measurement,\n  * 25th and 75th percentiles (with 25% and 75% of the measurements lower than the line, respectively).\n\nAll in all, you can compare applications by their spread, then by the median\nlatency, and also look if there are any outliers.\n\nWith all that said, we\u2019re almost ready to look at some results. I just need to\ntell you what exactly I was measuring the latency of.\n\n## Test Setup #\n\nI did all tests on this system:\n\n  * Lenovo Legion 7 Gen 7 AMD with Ryzen 7 6800H CPU and Radeon RX 6700M dGPU (using the dGPU exclusively via the MUX switch).\n  * Monitor: Acer Nitro XV320QU, 2560\u00d71440, 144 Hz, using 100% scale.\n  * Host: Fedora 40 Silverblue Beta, Mesa 24.0.4.\n  * Compositor: raw Mutter 46.0.\n\nWhat is raw Mutter, you may ask? Well, Mutter is the compositor that GNOME\nShell builds on top of. Turns out, you can start Mutter on its own, without\nGNOME Shell, by switching to a different VT and running a command like mutter\n--display-server -- alacritty. This gives you a very bare-bones environment\nthat is only really meant for testing. It is, however, quite useful for\nbenchmarking, as it represents something close to a zero-overhead GNOME Shell\nideal case.\n\nI\u2019m testing several terminal applications. In the order of appearance on the\nplots, they are:\n\n  * Alacritty: not VTE-based; serves as a baseline of sorts, because it is consistently one of the fastest terminals according to all of my prior tests.\n  * Console: GTK 4, the default terminal in GNOME.^3\n  * VTE Test App: GTK 4, a test terminal that lives in the VTE repository.\n  * GNOME Terminal: GTK 3,^4 used to be the default in GNOME, and is still shipped out of the box in several distributions.\n\nSince the intention is to compare GNOME 45 to GNOME 46, I used toolb\\0x\ncontainers with Fedora 39 and Fedora 40 to install and run all terminals\nabove, as packaged by Fedora with no extra tweaks.\n\nI ran the terminals one by one and put their windows in the top left corner of\nthe monitor. The mouse cursor was outside the window for all tests.^5\n\n## Input Latency Tests #\n\nThe first test is simple: I run cat > /dev/null to get an input field with no\nreadline or similar processing, and then I measure how long it takes for the\nterminal to move its block cursor one cell to the right after pressing Space.\n\nThis is meant to test the best possible scenario for the terminal, with the\nleast overhead.\n\nThis is what the test process looks like:\n\nAnd here are the results:\n\nAlacritty, which is our baseline, did not change from F39 to F40, as expected.\n\nBut look at the massive improvement on all of the VTE terminals! They went\nfrom quite bad to pretty much on par with Alacritty, even the GTK 3 GNOME\nTerminal is very close.\n\nThe main change that caused this much improvement is likely this one by\nChristian that moves away from a 40 Hz VTE repaint timer to drawing every\nframe, synchronized with the monitor, as any self-respecting GTK widget should\ndo.\n\nConsole has a few outliers which are maybe caused by its process tracking, but\nthose are nothing new (they may be looked into for GNOME 47).\n\nFor the next test, I constructed a more realistic case. I took a snapshot of\nmy neovim setup and opened the README from Ptyxis. I then strategically\nreplaced a square of text with Unicode full-block characters to provide a\nbright \u201clanding pad\u201d for the light sensor.\n\nThe test consists of repeatedly pressing Ctrl+D and Ctrl+U to scroll the text\nbuffer down and up in neovim. The light sensor alternates between an empty\nline (dark) and the full-block landing pad (bright). The neovim setup has a\nbunch of bells and whistles, so the terminal gets to have fun drawing the\nvarious underlines, undercurls, gutter icons, and the statusline.\n\nThis is what the test process looks like:\n\nHere are the results:\n\nThe massive improvement is clear on this test too, and our GNOME 46 terminals\nare still pretty much on par with Alacritty!\n\nFinally, let\u2019s take a closer look at all Fedora 40 results on one plot:\n\nThis plot shows how much of a latency toll the neovim test takes compared to a\nsimple cat, but the latency increase is similar across all terminals.\n\n## vtebench #\n\nI also ran Alacritty\u2019s vtebench suite across the same set of applications and\nconfigurations. This is a fully automated benchmark that measures something\ncompletely different from input latency: PTY read and parsing performance. It\nhas also proven quite capable at finding crashes in VTE.\n\nHere\u2019s what vtebench\u2019s README has to say:\n\n> This benchmark is not sufficient to get a general understanding of the\n> performance of a terminal emulator. It lacks support for critical factors\n> like frame rate or latency. The only factor this benchmark stresses is the\n> speed at which a terminal reads from the PTY. If you do not understand what\n> this means, please do not jump to any conclusions from the results of this\n> benchmark.\n\nThe repaint duration can and does affect the results of this test, especially\nfor terminals that read and parse PTY on the same thread as they run their\nrepaint logic, like VTE.\n\nThis is what one of the vtebench benchmarks looks like:\n\nAnd here are the results:\n\nTo avoid making this plot even busier, I drew the green arrows on only one of\nthe benchmarks. As you can see, other benchmarks show a similar trend.\n\nVTE from GNOME 46 shows some welcome improvements here too, although a lot\nmore varied, and not quite on par with Alacritty (which renders in a separate\nthread from reading and parsing). These improvements likely come from the many\nother optimizations that happened in VTE during the GNOME 46 cycle.\n\nNote that I omitted two benchmarks from these results: dense_cells and\nunicode. They are the main stress tests of vtebench that hit the terminal\nreally hard. Unfortunately, VTE still struggles with them and shows a huge\nspread, which pushes the rest of the results down and makes the plot less\nreadable.\n\n## Conclusion #\n\nVTE had a round of massive performance improvements in GNOME 46 which manifest\nas something you can really feel during normal terminal use. The input latency\nis down to almost matching the fastest terminals, even in a non-trivial neovim\nsetup with lots of complexity on screen.\n\nThe remaining difference, at least on these test cases, is close to\nnegligible. Some of it can be explained by VTE doing a bit more extra work for\naccessibility (enabled in GNOME Terminal and currently disabled in the GTK 4\nterminals), scrollbar calculations, and other features.\n\nIf you\u2019ve been avoiding VTE-based terminals due to sluggishness and input lag,\nnow is the time to give them another chance. Just make sure you\u2019re running VTE\n0.76, which includes all of this goodness.\n\nHuge thanks to the VTE maintainers and contributors for making this a reality,\nand congratulations on an awesome release!\n\nP.S. If you\u2019re curious about Ptyxis or the behavior of GTK\u2019s NGL vs. NVK vs.\nGL renderers, they all perform similarly to the F40 VTE Test App results shown\nabove. I did more extensive benchmarks of these a month ago, you can find them\nhere.\n\n  1. As you can tell from the photo, I did not follow Tristan\u2019s advice to make something fancier than just dangling wires. \u21a9\ufe0e\n\n  2. Just a few weeks ago some measurements I took showed a suspicious one-frame-long gap in the dots. And guess what, it was a frame scheduling bug in my compositor, with none other than myself to blame for it. Thankfully, it wasn\u2019t hard to fix, and easy to verify afterward by redoing the same test. \u21a9\ufe0e\n\n  3. Your distribution may have a different idea of which terminal should be the default in its GNOME spin. For example, Fedora still ships GNOME Terminal by default. \u21a9\ufe0e\n\n  4. GNOME Terminal is being ported to GTK 4 for GNOME 47, but in GNOME 46 it is still a GTK 3 application. \u21a9\ufe0e\n\n  5. To avoid the link-under-cursor detection logic skewing the results. \u21a9\ufe0e\n\ngnome planet-gnome profiling latency\n\nBased on Hugo Theme By nodejh\n\n", "frontpage": true}
