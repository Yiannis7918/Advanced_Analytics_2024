{"aid": "40077704", "title": "ELF, Part 2", "url": "http://kestrelcomputer.github.io/kestrel/2018/02/01/on-elf-2", "domain": "kestrelcomputer.github.io", "votes": 1, "user": "danny00", "posted_at": "2024-04-18 16:12:17", "comments": 0, "source_title": "Kestrel", "source_text": "Kestrel\n\nView on GitHub\n\n# Kestrel Computer Project\n\n#### Aiming to build a full-stack, open source, and open hardware home\ncomputer.\n\n## On ELF, Part 2\n\n01 Feb 2018\n\n## Abstract\n\nThe Executable and Linkable Format, ELF, is too complex. I firmly feel it was\ncreated without critically thinking about the ramifications it would have on\nfuture tool chains. In this article, I show how ELF-like features can be\nsafely retrofitted onto executable formats contemporary with ELF\u2019s debut.\nHopefully, future executable format authors will reconsider their needs more\ncritically in the future before committing to something as complicated as ELF.\n\n## Basic Principles\n\nBefore writing this installment, I had a realization. One of the big mistakes\nfrom Unix, besides the X Window System, was the ld linker. At the time, it\nmust have seemed like a great idea! Put yourself in the original authors\u2019\nshoes: why should the kernel spend so much effort relocating a binary when\nthat image will just appear at the same place in every process? So, why not\njust relocate any linked executable at that point before the kernel ever gets\na chance to see it? The kernel can be made much simpler (just read in an\nopaque binary blob, then call a specified address), and as a nice side-effect,\nit\u2019s faster to load the programs as well, which was probably noticeable on\ntimesharing systems of that era.\n\nBut, as we\u2019ve seen in the previous article, this can open a can of worms from\nthe security point of view as well as constrain new features, such as the new\nhotness at about this time, component-oriented programming (what eventually\nled to CORBA and DCOM). It turns out that program relocation at load-time is a\ngood thing.^1 The design of ELF, in part, reflects the realization that\nmistakes were made in the past, and AT&T wanted to both move forward with new\nfeatures while preserving at least some of their initial investment. (Aside:\nI, personally, have mixed feelings about this; but, this article is not about\nthose specific feelings.)\n\nSo, why is ld such a big mistake? Bluntly, it\u2019s a tool which, like ELF, fails\nto adhere to the Unix philosophy of doing one thing well. See, ld is\nresponsible for at least two services:\n\n  * Linking multiple compiler artifacts into a single artifact for later re-use in the construction of software, and,\n  * Producing a loadable binary from one or more of these re-usable artifacts.\n\nWhile these two concepts are clearly related, they are most definitely not the\nsame thing. We see that the Plan 9 compiler toolchain partially remedies this\npast oversight by keeping software in a binary representation of an assembly\nlanguage listing for as long as possible before the very last step of\nproducing the final binary executable.\n\nBasically, there are two principles involved.\n\nPrinciple of Linking. A linker\u2019s job is to coalesce, merge, and perhaps even\nsort sections of equivalent type. If it helps you, think of it as a merge-sort\nfor related code. A typical program might have hundreds of sections, which a\nlinker might reduce to a smaller, perhaps still quite numerous, quantity.\nUltimately, by the time you yield a final executable, it\u2019s been massaged down\nto a much smaller set (typically, text, data, and BSS).\n\nPrinciple of Loading. A loader\u2019s job is to unmarshall the concrete program\nrepresentation in memory from an off-line representation. This prepares a\nprogram for execution. In the case of dynamic linking, a loader may perform\nsome basic relocations, but it never merges sections of comparable types. It\njust lays them out in the address space somehow. This can be seen on any Linux\ninstallation by looking at a process\u2019 memory map layout (sudo cat\n/proc/$PID/maps, which will show each dynamically loaded module\u2019s text, data,\nBSS, and stack segments). I\u2019m sure BSD and Plan 9 have similarly accessible\nmethods of showing this information.\n\nWhere ld goes wrong, then, is that it attempts to both link and load in one\nstep. The limitations of this approach do not become visible as long as\n\n  * Your runtime environment is isolated via a page-capable MMU, and,\n  * You have no need whatsoever for dynamic linking.\n\nViolate any of these assumptions, and ld\u2019s approach breaks down hard. This is\nwhy ld requires so many horrible-looking arguments when linking code together:\none set of options intends to put a choke-hold on ld from building an\nexecutable or shared object when all you want is a relocatable module, while\nanother set is often to do just the opposite.\n\nI mention this only because I want this article to focus exclusively on\nprogram loading. That is, nothing I write in this article is intended to\nrelate to linking at all. The formats below may or may not make suitable\ntargets for linkers. In fact, there\u2019s a great chance that they won\u2019t at all.\nPlan 9 accepts this. There\u2019s no reason why the progeny of Unix can\u2019t either.\n\nSo, with the full understanding that we\u2019re talking exclusively about loading\nprograms, let us now tear ELF a new hole in its address space by illustrating\nviable alternatives to it.\n\n## ELF versus GEMDOS PRG Format\n\nIn the previous article, I had stated that the a.out format was one of the\nearliest and most portable of executable formats around. To illustrate this\npoint, let\u2019s compare Unix\u2019s original a.out format to an OS where you might not\nhave expected it to show up: Atari TOS and GEMDOS, the two components that\nmake up the Atari ST/TT\u2019s operating system.\n\nPDP-11 Unix\n\n    \n    \n    struct aout_unix { short a_magic; // 0x0085 short a_textsz; // Size of .text segment short a_symsz; // Size of symbol tables short a_relocsz; // Size of fixups short a_datasz; // Size of .data segment short a_padding; };\n\nAtari TOS\n\n    \n    \n    typedef struct { WORD ph_branch; /* Branch to start of the program */ /* (must be 0x601a!) */ LONG ph_tlen; /* Length of the TEXT segment */ LONG ph_dlen; /* Length of the DATA segment */ LONG ph_blen; /* Length of the BSS segment */ LONG ph_slen; /* Length of the symbol table */ LONG ph_res1; /* Reserved, should be 0; */ /* Required by PureC */ LONG ph_prgflags; /* Program flags */ WORD ph_absflag; /* 0 = Relocation info present */ } PH;\n\nSome observations:\n\n  * The respective fields appear in different places depending on which header is used. But, that\u2019s OK; ELF 32-bit and 64-bit structures also have fields which move about to support different processor alignment restrictions.\n  * TOS supports an explicit .bss segment, while the original Unix loader did not. BSS was just a pre-zeroed bunch of bytes tacked onto the end of .data, and accounted for in a_datasz.\n  * Interestingly, both the PDP-11 and the 68000 formats supported fixups to resolve code and data references. This suggests there was a time when Unix did not run with a page-based MMU.\n\nAfter the file header, you\u2019ll find the actual executable artifacts:\n\n    \n    \n    +-------------------------------+ | PH header | +-------------------------------+ | TEXT segment | +-------------------------------+ | DATA segment | +-------------------------------+ | Symbol table | +-------------------------------+ | Relocation table | +-------------------------------+\n\nThat\u2019s it: there are no tables containing pointers to segments, there are no\ncomplex graphs to traverse to get at some piece of information, there exists\nno reason to invest more than a handful of printed pages to describe the\nentire structure. Despite this minimalism, the a.out format is surprisingly\nversatile. It supported TOS applications in a single address space, it\nsupported MultiTOS applications in a single address space, and it later\nsupported MultiTOS applications in separate address spaces as well. Clearly,\nwe see that a.out is quite adept at handling both DOS-like and Unix-like\nenvironments with equal facility.\n\nNote that some details differ between the two a.out headers. That\u2019s perfectly\nOK. Exact layout doesn\u2019t matter, what matters are the concepts supported. It\ngives the loader just enough information to allocate a chunk of memory for\ncode, a chunk of memory for data and BSS, to locate the relevant data in the\nfiles and load them into the allocated memory, and then apply fixups to\nresolve broken references. The a.out binaries were self-contained and self-\nconsistent otherwise: it was not possible to legally create an a.out file\nwhich referred to an undefined symbol. Intra-segment relocations (for\ninstance, where a symbol in module A\u2019s .text segment refers to a symbol in the\n.text segment in module B) are resolved by the linker prior to emitting the\nfinal a.out, often relying upon PC-relative or register-relative addressing.\nAbsolute references (e.g., with JSR or JMP instructions, or when storage in\n.data was referenced from a location in .text) were resolved using the bundled\nfixups. The reason for this is that there was little to no guarantee that\n.data and .text would remain adjacent in the computer\u2019s address space,\nparticularly for single-address space environments.\n\nIn my previous article, I\u2019d stated that a.out was intended to be loaded/mapped\nblindly as an opaque blob. This is especially evident in the original Unix\nheader, as the \u201cmagic\u201d field, used to identify executables from other file\ntypes, is literally a PDP-11 machine language instruction that jumps over the\nheader. The Atari TOS program header continues this tradition.\n\n### Extending to Support Dynamic Linking\n\nOK, so now that we\u2019ve seen how trivial a.out is, how do we extend it to\nsupport dynamic linking? Pretend, for a moment, that you were in charge of\nadding dynamic linking to MultiTOS for its next release. How would you\nretrofit this loader format to do so? Here is how I would handle the task.\n\n### Required Extensions\n\nThe first task would be to identify what additional support is required to\nhandle the job.\n\nFirst and foremost, a statically linked binary is expected to be self-\ncontained. Dynamic linking throws that assumption out the door; therefore, we\nneed a way for a module to identify its dependencies. So, we need to introduce\na segment that lists library dependencies. Let\u2019s not concern ourselves with\nprecise layout at this point; we only need to know that it consumes space in\nthe file, and thus, has a size field associated with it.\n\nSecond, we observe that dynamically linked modules may require symbols defined\nin the executable. It turns out a.out has us covered here, as both PDP-11 and\nTOS versions of the file support a symbol table explicitly. Convenient! So\nout-bound definitions are taken care of; however, in-bound relocations are\nnot. There are two ways to handle this: first, we can extend the existing\nsymbol table definition to support both symbol definitions and symbol\nreferences, or we can introduce a separate symbol table segment just for in-\nbound references. Just to make things harder and for the sake of illustration,\nwe\u2019ll assume the latter. In the real-world, I\u2019d probably shoot for the former.\n\nTo support in-bound symbol relocations, we will also need to extend our\nrelocation records. Atari TOS uses a very simplistic model: every N bytes, add\nthe base address of the appropriate segment to the 32-bit word at that current\nlocation. Again, the assumption is that references are self-consistent/self-\ncontained, so this is fine if all you\u2019re doing is relocating a microcosm of\ncode. For dynamic linking, however, we need to know not only where to perform\nthe relocations, but also against what symbol. For this reason, I would\nreplace individual bytes in the relocation segment with 32-bit words, with a\nlayout along these lines:\n\n    \n    \n    3 2 2 0 1 4 3 0 +---+-----------+ | D | d | Type 1 +---+-----------+ +---+-----------+ | D | S | Type 2 +---+-----------+\n\nThis makes for a larger executable file, but is also substantially more\nflexible. The rules are as follows:\n\n  * If D=255, then we have a type-1 relocation record, which basically says, \u201cThere\u2019s no relocation at this point; however, the next relocation record is going apply d bytes from here in the file.\u201d\n  * If D<255, then we have a type-2 relocation record. This says to the loader, \u201cFix up the current 32-bit word with the value of the S-th symbol in the symbol table, then advance D (capital!) bytes in the program image.\u201d\n\nIn both cases, we know if we\u2019re making a code or data segment reference based\nboth on the value of the referenced symbol, and on the relative offset we\u2019re\npatching in the a.out file.\n\nSo far as I\u2019m aware, this is all that is required to make the format support\ndynamic linking. Now let\u2019s lay this stuff out into something that makes the\ntask of loading it easy.\n\n### Refined Header Structures\n\nSince the initial ph_branch is a 68000 BRA instruction that skips over the\nlength of the program header, it follows that if we append our extra fields\nonto the program header, then we must adjust the branch offset as well. This\nimplies we create a new magic cookie for ph_branch which the loader can use to\ndetermine if the binary is dynamically linked or not.\n\nJust in case some other file type uses this same magic value, we\u2019re going to\nuse an unused ph_prgflags bit to identify a dynamically linked artifact. Let\u2019s\ncall it PRGF_DYNAMIC.\n\nIf ph_branch is correct yet PRGF_DYNAMIC is not set, then we either have a\ncorrupt program header, or the file is not actually a dynamically linked\nexecutable. Thus, we reject the file.\n\nThe following fields can appear immediately after the ABSFLAG field:\n\n    \n    \n    typedef struct { WORD ph_branch; // Magic: 0x6022 LONG ph_tlen; // as before. LONG ph_dlen; // as before. LONG ph_blen; // as before. LONG ph_slen; // as before. LONG ph_res1; // as before. LONG ph_prgflags; // Make sure PRGF_DYNAMIC is set! WORD ph_absflag; // as before. LONG phx_deplen; // Length of dependencies. LONG phx_implen; // Length of imported symbols. } PHDYN;\n\nObserve that loading the module\u2019s code and data segments is meaningless if we\ncan determine ahead of time that we cannot satisfy this module\u2019s dependencies.\nFor this reason, we need only insert our list of dependencies and symbol\nimports, in that order, ahead of the code segment. In this way, you can still\ncompute the offsets of everything without having to provide explicit pointers.\nThis keeps the size of the header down. We also take care to order the\nsegments we\u2019ll need in the order we\u2019ll use them.\n\n  * We first find exported symbols, since it\u2019s possible that dependencies may require a symbol defined by the executable itself. So, the loader must process locally defined symbols first.\n  * Then, we transitively load dependencies using a depth-first traversal of the dependency tree.\n  * Once all dependencies have been loaded, then we can resolve imported symbols for this module. If any are left unresolved, then we abort further loading with an undefined symbol error.\n  * At this point, we can finally handle loading our TEXT, DATA, and BSS segments, along with any relocations they may require.\n\nBy doing things in this order, we minimize unnecessary seeking through the\nfile.\n\n    \n    \n    +-------------------------------+ | PHDYN header | +-------------------------------+ | exported symbols (new) | | (replaces old symbol table) | +-------------------------------+ | dependencies (new) | +-------------------------------+ | imported symbols (new) | +-------------------------------+ | TEXT segment | +-------------------------------+ | DATA segment | +-------------------------------+ | Relocation table (new) | | (replaces old reloc table) | +-------------------------------+\n\n### Normative Procedures\n\nHere, we get to the basic algorithm of loading and relocating a dynamic\nexecutable using this format.\n\nYou\u2019ll notice a reference to a global context. This is some arbitrary data\nstructure that serves as a global record-keeping device keeping track of\nresources allocated and/or files opened. In Unix, this would be the process\nitself. For something like TOS, this structure would need to exist separately.\nEither way, it\u2019s required if we want to properly track resources in the event\nwe return with an error. Otherwise, resources will be allocated but unable to\nbe freed, since we wouldn\u2019t have a long-standing reference to them. The\ncontext also serves as a rendezvous point for symbols, where they\u2019re defined,\nand what value they equate to.\n\nFirst, we start out at the top level: when loading a PRG, we dispatch to the\nappropriate loader based on ph_branch values.\n\n    \n    \n    PROCEDURE LoadPRG(filename) BEGIN Read first two bytes of file. IF ph_branch == 0x601A THEN Load statically linked PRG file. ELSIF ph_branch == 0x6022 THEN Create global loader context. LoadDynamicPRG(filename, context) ELSE Return with an unrecognized file type error. END END\n\nThe legacy loader, as defined in GEMDOS, can be used to load the statically-\nlinked executable, so I won\u2019t repeat its pseudo-code here. Instead, let\u2019s\nfocus on the dynamic loader.\n\n    \n    \n    PROCEDURE LoadDynamicPRG(filename, context) BEGIN Read rest of the PHDYN header. IF PRGF_DYNAMIC not in ph_prgflags THEN Return with an unrecognized file type error. END // Process locally defined symbols so that any dependencies // can find them and use them. FOR ALL s IN locally defined symbols DO Create symbol descriptor for s in the context. END // Transitively load all dependencies. FOR ALL d IN dependencies DO Resolve dependency d to library filename. LoadDynamicPRG(Filename(dependency), context) IF not successful THEN Free all allocated or opened resources so far. Return with an error code. END END // We've just loaded all of our dependencies, and they are // happy with the symbols we've exported. Let's now resolve // our own symbol imports. This can potentially take some // amount of time; O(n^2) algorithm. FOR ALL s IN imported symbols DO FOR all dependencies we loaded above DO IF dependency contains symbol THEN Create descriptor for s in the context. Exit this loop and continue outer loop. END END // No dependency claims to define the symbol. // Abort with an undefined symbol error. Free all allocated or opened resources so far. Return with an error code. END // We transitively loaded our dependencies. We've resolved // all of our symbols. Now it's time to load our text and data // segments and apply relocations to them. AllocateTextSegment() ReadTextSegment() AllocateDataSegment() ReadDataSegment() AllocateBssSegment() ZeroBssSegment() offset = 0 segment = TextSegment IF length(relocations) > 0 THEN FOR ALL r IN relocations DO IF offset >= length(TextSegment) AND segment = TextSegment THEN segment = DataSegment offset = offset - length(TextSegment) END IF offset >= length(DataSegment) AND segment = DataSegment THEN segment = BssSegment offset = offset - length(DataSegment) END IF IsType2(r) THEN x = GetWord(segment+offset) v = SymbolValue(SymbolDescriptorFor(r)) PutWord(segment+offset, x+v) END offset = offset + displacement(r) END END END\n\nThis pseudo-code is more or less representative of the actions that must be\ntaken for someone to extend GEM\u2019s PRG format to include dynamic linking\nabilities. Actual code is straight-forward, the code follows the layout of the\ndata as found in the executable file, and should be easily maintained as\nfuture requirements dictate.\n\nThis pseudo-code does not handle the case where a shared library is already\nresident in memory. However, with a small change to the calling convention of\nthe LoadDynamicPRG procedure, it should be possible to short-circuit the\nloading process for resident libraries.\n\n### Handling Other Processor Architectures\n\nThe pseudo-code above assumes the same 680x0 processor family that drives the\nAtari ST/TT line. As written, it won\u2019t scale to newer architectures. Many RISC\nprocessors requires multiple kinds of relocations to resolve references, since\ninstructions rarely can pack a full word\u2019s worth of bits in an instruction.\nFor example, a RISC-V processor can only address +/- 2KiB from some base\naddress. For a 32-bit address, then, you need to break the reference up across\ntwo instructions: a LUI instruction to load the upper 20 bits of the address,\nand an addition to contribute the lower 12 bits. Worse still, the addition is\nsign-extended, which must be accounted for in the upper portion of the\naddress.\n\nA 64-bit RISC-V implementation can\u2019t even use this approach, for there is no\nway to embed the upper 32-bits of an address directly into the instruction\nstream. You end up loading addresses indirectly from a code or data word of\nmemory, and that is what receives the relocation. Alternatively, if the value\nhas lots of binary 0s in it, you can load a portion of the address in the low-\norder bits and then shift up appropriately. As you can see, resolving a 64-bit\naddress on RISC-V can potentially be messy.\n\nAssuming a 64-bit RISC-V target, the loader will need to understand how to\nperform a minimum of four different kinds of relocations:\n\n  * Absolute 32-bit relocation\n  * Absolute 64-bit relocation\n  * Upper 20-bits for LUI\n  * Lower 12-bits for ADDI\n\nThis can be encoded easily enough in the relocation segment of the file. You\njust need to make the relocation record format known to the loader somehow,\neither implicitly through the ph_branch magic cookie, or via additional header\nfields.\n\n### Handling Initializations and Finalizations\n\nSome languages, like Modula-2 and C++, often require objects to be pre-\ninitialized via \u201cconstructors\u201d before the main program begins. In the case of\nModula-2 and Oberon, the \u201cconstructor\u201d is the global body of a module\ndefinition. In C++, D, Sather, et. al., these are provided through more\nexplicit programming constructs on classes. Either way, they must be invoked\nfor the main program to run correctly. After all, the executable might be\nwritten in plain-vanilla C, while the library you\u2019re depending upon could very\nwell be written in C++!\n\nIn a statically linked executable, this is not a problem, since the linker is\ngiven libraries which are capable of handling this issue. It has compile-time\n(at best) or link-time (at worst) knowledge of which routines to call and\nwhen. Thus, it can provide supporting code in the .text segment, and the day\nis saved.\n\nFor dynamically linked executables, however, it\u2019s not as simple. Since the\nlinker and loader both have no idea what languages modules are written in, the\nloader must support a means of calling constructors independently of the main\nprogram\u2019s entry point. The ELF .init, .fini, and related sections all exist to\nsupport languages which require global constructors to be called before\ninvoking the main program.\n\nWe map this to the a.out file by requiring initializers and finalizers to\nexist in the .text segment. Further, instead of providing a single routine to\ncall, we express requirements as a vector of routines to call. These can be\nhandled by extending the a.out header once more with the following fields:\n\n    \n    \n    LONG phx_ivecbase; // Offset to base of initializer vector LONG phx_ivecsize; // Number of initializers to call LONG phx_fvecbase; // Offset to base of finalizer vector LONG phx_fvecsize; // Number of finalizers to call\n\nFrom the loader\u2019s point of view, there\u2019s nothing special about these vectors.\nThe linker must provide zero or more such vector entries for each module it\nhelps produce. The loader, then, must take on the responsibility of invoking\nthem as it loads module dependencies.\n\n## ELF versus Hunk Format\n\nFirst, I want to get this off my chest. There is no such thing as the Amiga\nHunk Format. It\u2019s just ... Hunk Format. Remember, AmigaDOS is just a port of\nthe Tripos operating system to run under the exec.library kernel. You can find\nmore about Commodore-Amiga\u2019s rebranding of Tripos at this Page Table article.\nI highly recommend it; it\u2019s actually quite fascinating.\n\nNow that that\u2019s cleared up, let\u2019s talk about hunks. Big hunks, heavy hunks,\nsmall hunks, hot hunks, however you prefer them to be. A hunk is nothing more\nthan a self-identifying, often explicitly length-delimited, array of integers.\nLike so:\n\n    \n    \n    +-----------------------------+ | Hunk Type ID | +-----------------------------+ | # of words (4 in this case) | +-----------------------------+ | 1 | +-----------------------------+ | 2 | +-----------------------------+ | 3 | +-----------------------------+ | 4 | +-----------------------------+\n\nIn the Amiga\u2019s case, these words are always, always, 32-bits wide. That\u2019s\nbecause dos.library (a.k.a. Tripos) was written in a 32-bit dialect of BCPL.\nIn STS\u2019s case, these words were always 16-bits wide. For a 64-bit RISC-V port,\nthey could well be 64-bits wide. I think you get the idea.\n\nA hunk formatted file, then, is just a file with an array of hunks in it.\nThat\u2019s it. You now understand the structure of a hunk formatted file.\n\nYou\u2019ll notice that there\u2019s no mention of text, data, or BSS segments. No\nrelocations. No symbol definitions or imports. That\u2019s because hunk format is a\ncontainer format, just as MP3 is a container for audio, MP4 for different\nkinds of video, etc.\n\nNext step, then, is to learn how dos.library and Tripos actually used it to\nstore executable artifacts.\n\n### Amiga and Tripos Binary Files\n\nThe Hunk Format executable is naturally multi-processor capable. Metacomco\ndefined it for the Motorola 68000 processor originally, the details of which\nyou can read in the Amiga Binary File Specification. Since then, however, the\nAmiga community moved to support the PowerPC processor architecture. Although\nmodern versions of AmigaOS support ELF, originally, they simply adopted the\nHunk Format to include PowerPC-specific hunks.\n\nSo, right out of the gate, we plainly see hunk format supports multiple\nprocessors. The fact that I used the basic concepts in a 16-bit OS of my own\ndesign also illustrates that hunk format is not constrained to just AmigaOS.\nSo multi-processor and platform independence have never been unique selling\npoints for ELF. And we haven\u2019t even begun to look at the details of hunk\nformat yet.\n\nFor the purposes of this article, however, I will once again concentrate just\non the 68000 version of the file.\n\nThe large-scale structure of an Amiga executable looks more or less like this:\n\n    \n    \n    +---------------+ | HUNK_HEADER | +---------------+ | HUNK_CODE | +---------------+ | HUNK_RELOC* | +---------------+ | HUNK_DATA | +---------------+ | HUNK_RELOC* | +---------------+ | HUNK_BSS | +---------------+ | HUNK_END | +---------------+\n\nThe layout of a hunk file is intended to be processed with an \u201cevent-driven\u201d\nparser, which looks more or less like this skeleton pseudo-code:\n\n    \n    \n    f = open(\"hunkfile\",\"rb\"); size = read(f, &id, 4); done = FALSE; do { size = read(f, &id, 4); if(size < 4) goto done_loading; switch(id) { case HUNK_HEADER: ... case HUNK_CODE: ... case HUNK_DATA: ... case HUNK_BSS: ... ...etc... case HUNK_END: done = TRUE; break; default: // unknown hunk type? OK, skip it. read(f, &size, 4); seek(f, size*4, SEEK_OFFSET); break; } done_loading: } while(!done && (size >= 4)); close(f);\n\nAs you can see, the very structure of a hunk file is intended to simplify the\nloader a great deal.\n\n### Header Hunk\n\nHUNK_HEADER hunks identify the file as an executable as well as gives due\nwarning to the loader on the number of segments to allocate and how big they\nare. But, hark, look what else it provides!\n\n    \n    \n    +-----------------+ | HUNK_HEADER | +-----------------+ -+ | N1 | | Names of shared library +-----------------+ | dependencies. | N1 name words | | +-----------------+ | | N2 | | +-----------------+ | | N2 name words | | +-----------------+ | | ... | | +-----------------+ -+ | 0 | +-----------------+ | Hunk Table Size | +-----------------+ | First hunk | +-----------------+ | Last hunk | +-----------------+ | | | L-F+1 Sizes | | | +-----------------+\n\nThis hunk includes the names of shared library dependencies. The loader is\nresponsible for opening (and loading if not already in memory) each specified\nlibrary prior to loading the rest of the binary. In this way, transitive\ndependencies are satisfied.\n\nAssuming this has been done successfully, the next step is to allocate an\narray of segment descriptors, whose size is specified by the hunk table size\nfield. It then copies the libraries\u2019 hunk descriptors into this image\u2019s\ndescriptor table. From the loader\u2019s perspective, all your shared libraries\nhave been included in this image\u2019s hunk table as if the contents of those\nlibraries came from this executable file. This greatly eases relocating hunks\nwithout having to traverse a complex graph of dependencies.\n\n(Aside: at this point, if you wanted to, you could theoretically deallocate\nindividual library segment tables, since the relevant references are now\nincluded in this executable\u2019s segment table. But, it\u2019s not worth it; if these\nare reusable libraries, they\u2019ll be referenced again later.)\n\nOnce all the libraries have been opened and their segment tables merged into\nthis executable\u2019s segment table, then the fun part happens: the loader reads\nthe remainder of the hunk to get at the list of hunk sizes. This gives the\nloader an opportunity to pre-allocate all the segments it needs to hold the\nbinary in memory. These segments will take their place sequentially in the\nhunk table starting at the First hunk index, and continuing until the Last\nhunk index, inclusive.\n\nSo, if we have a clock executable that includes (for sake of argument) libc.so\nand libX11.so, then the loader\u2019s segment table could well look a lot like\nthis:\n\n    \n    \n    +----------------+ 0 | libc.so CODE |----> +----------------+ points into 1 | libc.so DATA |----> libc.so's +----------------+ segments 2 | libc.so BSS |----> +----------------+ 3 | libX11.so CODE |----> +----------------+ points into 4 | libX11.so DATA |----> libX11.so's +----------------+ segments 5 | libX11.so BSS |----> +----------------+ 6 | clock CODE |----> +----------------+ allocated, 7 | clock DATA |----> but not yet +----------------+ loaded. 8 | clock BSS |----> +----------------+\n\nGosh, this looks an awful lot like the information made accessible in Linux\n/proc/$PID/maps files, wouldn\u2019t you agree?\n\nThe actual HUNK_HEADER will look vaguely like this in the file:\n\n    \n    \n    +-----------------+ | HUNK_HEADER | +-----------------+ | 2 | Shared object dependencies +-----------------+ start here. | 'l' 'i' 'b' 'c' | | '.' 's' 'o' 0 | +-----------------+ | 3 | +-----------------+ | 'l' 'i' 'b' 'X' | | '1' '1' '.' 's' | | 'o' 0 0 0 | +-----------------+ | 0 | +-----------------+ | 9 | Total hunk table size. +-----------------+ | 6 | Clock's first segment start at 6, ... +-----------------+ | 8 | and ends at segment 8. +-----------------+ | seg 6's size | Clock's code segment. +-----------------+ | seg 7's size | Clock's data segment. +-----------------+ | seg 8's size | Clock's BSS segment. +-----------------+\n\nAfter processing the header, the loader now has a complete description of a\nprogram image in memory. It just doesn\u2019t have any of the specific details\nhammered out yet. For that, we need to load our segments with data.\n\n### Hunks for Code and Data\n\nHUNK_CODE hunks are for providing what would be considered .text or .rodata\ncontent in other formats. This is where your executable ... well, code goes.\nSimilarly, HUNK_DATA hunks provide statically allocated/initialized data that\nwould fall in a .data section in other formats.\n\n    \n    \n    +------------------+ | HUNK_CODE | +------------------+ | # words in image | +------------------+ | | | code | | | +------------------+ +------------------+ | HUNK_DATA | +------------------+ | # words in image | +------------------+ | | | data | | | +------------------+\n\nA BSS segment is specified in a similar manner; however, since its content is\nimplicitly undefined, we only need to specify how big it is.^2\n\n    \n    \n    +--------------------+ | HUNK_BSS | +--------------------+ | # words in segment | +--------------------+\n\nNote that, just like ELF but unlike a.out, you can have any number of code,\ndata, or BSS segments. This was useful for earlier versions of AmigaOS, which\ndid not automatically defragment free chunks of memory. As a result, there was\nan incentive to have many smaller code, data, or BSS segments as a means of\nworking around the memory fragmentation that would inevitably build up like a\nlayer of mold. You had to be careful though; too many small segments would\nactually exacerbate the problem, especially after you ran and quit an\nexecutable linked in this manner several times on a 256KB or 512KB Amiga!\n(Thankfully, I believe this issue was fixed with AmigaOS 2.0 or 3.0, so the\nincentive to coalesce like-typed sections became much stronger.)\n\nAnyway, back to the hot hunks.\n\nThe very first code, data, or BSS hunk that the loader encounters in the file\nwill obviously be used to load the very first hunk that is defined to belong\nto this file. Recall in the header that this was specified by the First hunk\nfield. Each subsequent code or data hunk would fill subsequent hunk in the\nhunk table. Any code or data hunks that would exceed the table would be\nignored.\n\n### Relocations\n\nRelocation hunks come in many varieties. I\u2019m only going to illustrate one:\nHUNK_RELOC32.^3 As with the GEMDOS file format, relocations are to 32-bit\nabsolute addresses only. By the time you\u2019re loading something into memory, all\nPC-relative or base address-relative offsets should have been resolved by the\nlinker first. There also is a HUNK_PPC_RELOC26 for PowerPC branch relocations\nas well.\n\nThe HUNK_RELOC32 hunk looks like this on disk:\n\n    \n    \n    +----------------+ | HUNK_RELOC32 | +----------------+ | N1 | +----------------+ | Segment 1 | +----------------+ | | | N1 offsets | | | +----------------+ | N2 | +----------------+ | Segment 2 | +----------------+ | | | N2 offsets | | | +----------------+ : : +----------------+ | 0 | +----------------+\n\nBasically, this is saying:\n\n  * Apply N_1 relocations to the most recently loaded segment by adding the base address of segment 1 to the 32-bit values at all these offsets,\n  * Apply N_2 relocations to the most recently loaded segment by adding the base address of segment 2 to the 32-bit values at all these offsets,\n  * and so on.\n\nThis happens until we reach the end of the list of relocations, identified by\nthe final 0 value.\n\nRemember that relocations always apply to the most recently loaded segment.\nThis is why relocations for a segment always follows the segment to which it\napplies. You can have any number of different types of relocations following a\ncode or data hunk.^4\n\nAlso note that it\u2019s perfectly OK to refer to a segment which hasn\u2019t been\nloaded yet. Recall that while processing the HUNK_HEADER, the loader knows how\nbig each segment will be and can thus pre-allocate them. Obviously, you can\nalso refer to segments which belong to shared libraries.\n\n### Tripos Shared Libraries\n\nWe\u2019ve seen that Hunk Format executables share just about every major feature\nwith ELF out of the box. It\u2019s fully capable of supporting ASLR, and there\u2019s\nnothing which prevents it from being used in either single- or multiple-\naddress spaces. The only thing it doesn\u2019t support is statically linked\nexecutables pre-designated for a specific load address. Further, it supports\ndynamic linking.\n\nJust not the way AT&T specified with ELF.\n\nSee, there\u2019s a frailty with how Tripos handles shared objects: the executable\nneeds to know at link-time where the library\u2019s assets are located (which\nsegment and the offset within that segment). On its own, this places a hard\ndependency on a specific version of a library. Change the library to a newer\nversion, and those assumptions could well break.\n\nFor this reason, AmigaOS does not support Tripos-style shared libraries.\nInstead, it uses its own library system which exec.library provides, which\naddresses this exact issue by using well-defined offsets on a jump table,\nitself relative to a kind of handle to the library. This lets specific\naddresses of various assets float within their respective binaries, with only\nthe relative offsets being well-known at compile-time.\n\nExec\u2019s jump table is exactly like ELF\u2019s PLT (Procedure Linkage Table) segment,\nonly instead of your program constructing it, it\u2019s part of the library you\u2019re\ntrying to call. Any publicly available data is similarly made available\nrelative to this library base pointer. This has several advantages over ELF:\n\n  * No need to keep symbol tables around, so it uses less memory.\n  * Loading is much faster without having to scan for symbols all the time.\n  * It\u2019s faster than the ELF-style PLT. You\u2019re jumping to an unconditional jump instruction, which modern CPU pipelines handle quite elegantly.\n\nOf course, it comes at a cost: you can\u2019t just use dlsym() to resolve a symbol\non a library.\n\n### How to Make Tripos Shared Libraries Work Like ELF\u2019s\n\nYou can definitely get some great milage out of Tripos\u2019 approach to shared\nlibraries, despite the aforementioned limitations. Tripos, circa 1981, was\nsuccessfully using them to make command-line tools as small as 512 bytes,\nwhile comparable tools in Linux, even with ELF\u2019s shared objects, require\ncloser to 20KB. Even accounting for binary size differences of 16-bit and\n32-bit platforms, we\u2019re still looking at an order of magnitude smaller\nexecutables for Tripos than we are seeing for Linux. Arguably, Tripos wins at\nshared libraries.\n\nBut, OK, we want the ability to use C++, and we want unique data segments per\nprocess. How do we get these?\n\nRelieve the linker of detailed knowledge of dependencies. This is not a\nprerequisite for normal, day to day use of Tripos shared libraries. But, it is\ndefinitely a requirement if you want symbols defined in the executable to be\nusable by those libraries. There are two ways of resolving this issue. Either\nintroduce a replacement hunk type for HUNK_HEADER that implies the new\nsemantics, or specify the use of negative hunk indices as a flag to the\nloader. For instance, you can declare bit 31 of First hunk field to be set for\n\u201cmodule-relative\u201d hunk indices or some such. That way, the loader can\nreference library hunks when that bit is clear, and module-relative hunks when\nset. This would apply to all hunk indices, including inside relocations. The\nprobability of exceed two billion hunks is asymptotically zero on 32-bit\nsystems, and particularly so on 64-bit systems, so this is a pretty safe\nextension.\n\nRetain symbol imports and exports from the linker stage. This is a requirement\nthat\u2019s been discussed above under the GEMDOS section; it\u2019s required if you\nwant to allow libraries to bind to symbols you create in your executable.^5\nThe loader of a module would need, then, not only to maintain hunk tables, but\nalso symbol tables. This would enable, in turn, the next item.\n\nAllocate new data segments on each successful load. Since libraries and\nexecutables are statically linked in Tripos, code hunks can freely reference\ndata hunks, thus eliminating completely the need for GOTs. This implies that\nTripos libraries (as with Exec-style libraries) maintain a shared body of data\nacross all clients of the library. ELF mandates this cannot happen. By\ndefinition, each new program is in its own address space, so each library\nshares only its code; and at that, this code can appear anywhere in the\nprocess\u2019 address space. All data hunks must be remapped for each address\nspace, uniquely. To enable this to happen, the loader must recreate data and\nBSS hunks for each client use-case.\n\nPage aligned code and data segments. This is not a hard requirement; don\u2019t let\nanyone tell you otherwise. Even given an executable with non-aligned segments,\nyou can still mmap them into memory. You need only give special consideration\nto the leading and trailing pages, which may have to be loaded by copying from\nthe file if their boundaries aren\u2019t page aligned. Given a 4KB page size, this\nmeans that you end up transferring no more than 8KB of content. For larger\nbinaries (which are everywhere on my Linux box, by the way), the overhead of\nthis would be immeasurable, as the overwhelming bulk of binary content would\nbe memory-mapped as normal. However, if this is such an important feature to\nhave, then one could introduce two new hunk types:\n\n  * HUNK_NULL, which is a null hunk. It consists only of the HUNK_NULL ID. No size or payload field follows.\n  * HUNK_SKIP, which contains a size field. It\u2019s sole purpose is to cause the loader to skip ahead in the file. The following hunk, presumably a code or data hunk, can then be placed such that its content is page aligned, and so can be mmaped per normal Unix conventions.\n\nThe HUNK_SKIP hunk allows for coarse-grained alignment control within the\nexecutable, while HUNK_NULL provides alignment control at individual word\ngranularity.\n\nSupport for initializers and finalizers. This can be supported fairly easily\nusing two new hunk types: HUNK_INIT and HUNK_FINI. As with my GEMDOS\nmodifications above, these would contain vectors of initialization functions\nto call. Unlike GEMDOS, however, these would not occupy any code or data\nspace. Rather, the loader would read in a set of hunk and offset pairs,\nintended to point at initialization and/or finalization functions, and call\nthem sequentially in the order provided.\n\n    \n    \n    +-------------------+ +-------------------+ | HUNK_INIT | | HUNK_FINI | +-------------------+ +-------------------+ | N | | N | +-------------------+ +-------------------+ | Code Segment 0 | | Code Segment 0 | +-------------------+ +-------------------+ | Code Offset 0 | | Code Offset 0 | +-------------------+ +-------------------+ | Code Segment 1 | | Code Segment 1 | +-------------------+ +-------------------+ | Code Offset 1 | | Code Offset 1 | +-------------------+ +-------------------+ : : : : +-------------------+ +-------------------+ | Code Segment N-1 | | Code Segment N-1 | +-------------------+ +-------------------+ | Code Offset N-1 | | Code Offset N-1 | +-------------------+ +-------------------+\n\nSo far as I am aware, this is all that is required for Hunk Format to attain\nparity with ELF. Arguably, it is simpler to get Hunk Format working like ELF\nthan it is for GEMDOS, particularly since the whole arrangement is built to be\nextensible via an event-driven loader.\n\nAs with the GEMDOS loader, these new semantics can be selected by altering\nwhich kind of header hunk appears at the head of the file. If you want the\nolder-style, Tripos semantics, use HUNK_HEADER. For the newer, ELF-like\nsemantics, use (just inventing a name here) HUNK_HEADER_MAS (for multiple\naddress space support).\n\nThough, honestly, considering Tripos libraries overwhelmingly superior memory\nsavings over ELF-style, I\u2019m not sure why you\u2019d ever want to.\n\n## Conclusion\n\nI\u2019ve shown how one can build a dynamic loader for the a.out format. It\ninvolves adding a few missing fields and pseudo-segments to the file, but it\nis not impossible, and it\u2019s patently much simpler than ELF\u2019s current file\nstructure.\n\nI\u2019ve shown how Hunk Format executables already implements the vast majority of\nELF\u2019s more salient features. It should be noted that Hunk Format predates ELF\nby almost two decades. It is possible to retrofit ELF-like behavioral patterns\nonto Hunk Format, but it\u2019s not clear to me that this delivers a technical win.\nThe memory savings one gets with a Tripos-style shared library is rather\nsignificant, even after accounting for instruction set density differences\nbetween processors contemporary in 1978, 1988, and 1998.\n\nThe one thing I would consider unconditionally retrofitting onto Hunk Format\nloaders, though, is the use of negative indices to the hunk table to refer to\nmodule-local hunks. It will make life easier for anyone looking to\nindependently upgrade libraries from their clients. Knowing that your module\u2019s\nhunks starts at offset 6 in the hunk table (e.g., as in our clock example\nabove) seems klunky to me, and to an extent breaches the encapsulation the\nloader\u2019s intended to provide. I\u2019ll need to research this further some day.\n\nAs well, I would continue to provide mezzanine documentation on conventions to\nhelp ameliorate versioning-related incompatibilities. This documentation would\ninclude, for instance, how to discover where a library\u2019s jump table resides,\netc. However, these things are complimentary to Tripos-style libraries, and do\nnot replace them.\n\nPersonally, I think Unix System V Release 4 would have been a lot better off\nif they\u2019d built on top of Hunk Format executables instead of relying on ELF.\nThere\u2019s definite memory-savings potential from not having everything and their\ngrandmother embedding a symbol table, the lack of a (or at least a smaller)\nGOT means programs run faster since fewer indirection is happening all the\ntime, and, allowing a library to keep shared state across all its clients is a\nreally useful thing to have, enabling libraries to offer first-class, system-\nwide services. While not intending to serve as a complete replacement, there\nwould be reduced pressure for the use of kernel modules, which are platform-\nspecific and often with strange interface requirements, to serve these needs.\nThis, in turn, would lead to a more modular and robust user-land experience\nwithout sacrificing the architectural benefits that a monolithic kernel can\nprovide.\n\nAnyway, there you have it: not just one; but, two technologies which existed\nat the time ELF was invented, which with a little bit of thought could have\neasily subsumed all the use-cases of ELF, and which didn\u2019t require 186 pages\nof documentation to describe poorly. It\u2019s regrettable that neither of these\ntechnologies had the weight of AT&T backing them.^6\n\n1: For a quite compelling argument against this point of view, please read\nthis collection of quotes against dynamic linking in general, and a uniquely\nELF-related concept of versioned symbols.\n\n2: It is interesting that we must give a hunk size for HUNK_BSS, even though\nnothing actually follows it. The authors of Tripos\u2019 loader could have just as\neasily declared HUNK_BSS to just be a null hunk, but instead chose an\nextraneous size word to follow. Please note, however, that the BSS size\nspecified in the HUNK_HEADER takes priority over the supplied size in the\nHUNK_BSS hunk.\n\n3: Starting with AmigaOS 2.0, you can also use HUNK_RELOC32SHORT hunks to\nbasically include the exact same information as above, but more compactly,\nusing 16-bit words instead of 32-bit words. This is a space saving measure,\nsince most segments for AmigaOS tend to be 64KiB or smaller.\n\n4: It is technically illegal to place relocations after a BSS hunk. I\u2019m not\npersonally aware of any version of AmigaOS which will throw out such a binary,\nhowever. I suppose, if you\u2019re crafty enough, you can use these relocations to\npre-load pointers placed in BSS. I don\u2019t recommend this, for obvious reasons;\nyour program could well break on any revision of the operating system\u2019s\nloader.\n\n5: I think this is one of ELF\u2019s worst features. A library should always be\nsomething that you depend upon; the library should never have to depend on\nyou. When the latter happens, you really have a degenerate framework, and as\nwe all know, frameworks are evil.\n\n6: AT&T certainly did have control over the a.out header format for their Unix\ndistributions prior to their switch to COFF with Unix System V Release 1.\nHowever, looking at the Wikipedia article on COFF, I\u2019m utterly bamboozled as\nto why AT&T even bothered with it, when even a little bit of research in the\nmatter would have shown hunk format to have both existed and to have met most\nof their needs at the time. As I\u2019ve illustrated above, adding a few different\nhunk types would have added the remaining semantics that it was missing. For\nsome reason, this never crossed anyone\u2019s mind. Why? I can only think that,\nlike so many other computer-related companies at the time, AT&T Bell Labs\nsuffered dearly from Not Invented Here Syndrome.\n\nSamuel A. Falvo II Twitter: @SamuelAFalvoII Google+: +Samuel A. Falvo II\n\n#### About the Author\n\nSoftware engineer by day. Amateur computer engineer by night. Founded the\nKestrel Computer Project as a proof-of-concept back in 2007, with the\nKestrel-1 computer built around the 65816 CPU. Since then, he's evolved the\ndesign to use a simple stack-architecture CPU with the Kestrel-2, and is now\nin the process of refining the design once more with a 64-bit RISC-V\ncompatible engine in the Kestrel-3.\n\nSamuel is or was:\n\n  * a Forth, Oberon, J, and Go enthusiast.\n  * an amateur radio operator (KC5TJA/6).\n  * an amateur photographer.\n  * an intermittent amateur astronomer, astrophotographer.\n  * a student of two martial arts (don't worry; he's still rather poor at them, so you're still safe around him. Or not, depending on your point of view).\n  * a former semiconductor verification technician for the HIPP-II and HIPP-III line of Hifn, Inc. line-speed compression and encryption VLSI chips.\n  * the co-founder of Armored Internet, a small yet well-respected Internet Service Provider in Carlsbad, CA that, sadly, had to close its doors after three years.\n  * the author of GCOM, an open-source, Microsoft COM-compatible component runtime environment. I also made a proprietary fork named Andromeda for Amiga, Inc.'s AmigaDE software stack. It eventually influenced AmigaOS 4.0's bizarre \"interface\" concept for exec libraries. (Please accept my apologies for this architectural blemish; I warned them not to use it in AmigaOS, but they didn't listen.)\n  * the former maintainer and contributor to Gophercloud.\n  * a contributor to Mimic.\n\nSamuel seeks inspirations in many things, but is particularly moved by those\nthings which moved or enabled him as a child. These include all things\nCommodore, Amiga, Atari, and all those old Radio-Electronics magazines he used\nto read as a kid.\n\nToday, he lives in the San Francisco Bay Area with his beautiful wife, Steph,\nand four cats; 13, 6.5, Tabitha, and Panther.\n\nKestrel maintained by the Kestrel Computer Project. Published with GitHub\nPages. Theme redesigned around Bootstrap 3.0.2.\n\n", "frontpage": false}
