{"aid": "40086107", "title": "Pgvector-remote: connect Postgres pgvector with other vector stores", "url": "https://github.com/georgia-tech-db/pgvector-remote", "domain": "github.com/georgia-tech-db", "votes": 1, "user": "gk1", "posted_at": "2024-04-19 12:44:02", "comments": 0, "source_title": "GitHub - georgia-tech-db/pgvector-remote", "source_text": "GitHub - georgia-tech-db/pgvector-remote\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ngeorgia-tech-db / pgvector-remote Public\n\n  * Notifications\n  * Fork 4\n  * Star 12\n\n### License\n\nView license\n\n12 stars 4 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# georgia-tech-db/pgvector-remote\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n12 Branches\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\noscarlairdpush distance sorting to postgres' reorderApr 18, 2024abbc6c7 \u00b7 Apr\n18, 2024Apr 18, 2024\n\n## History\n\n1,459 Commits  \n  \n### .github/workflows\n\n|\n\n### .github/workflows\n\n| Merge commit '301c8083f50b3b9bbacc57fce2c2c95813ac542e' into pgvr/main| Apr\n17, 2024  \n  \n### .vscode\n\n|\n\n### .vscode\n\n| add debug flags to Makefile| Mar 14, 2024  \n  \n### sql\n\n|\n\n### sql\n\n| Fix function parameter type in pinecone.c and pinecone.h| Apr 17, 2024  \n  \n### src\n\n|\n\n### src\n\n| push distance sorting to postgres' reorder| Apr 18, 2024  \n  \n### test\n\n|\n\n### test\n\n| Merge commit '301c8083f50b3b9bbacc57fce2c2c95813ac542e' into pgvr/main| Apr\n17, 2024  \n  \n### .dockerignore\n\n|\n\n### .dockerignore\n\n| Added dockerignore [skip ci]| May 6, 2021  \n  \n### .editorconfig\n\n|\n\n### .editorconfig\n\n| Use consistent indentation [skip ci]| Dec 23, 2022  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Add test SQL file to gitignore| Apr 1, 2024  \n  \n### CHANGELOG.md\n\n|\n\n### CHANGELOG.md\n\n| Added support for bit to IVFFlat| Apr 17, 2024  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| added missing curl library in Dockerfile| Apr 2, 2024  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Updated license year [skip ci]| Feb 29, 2024  \n  \n### META.json\n\n|\n\n### META.json\n\n| Version bump to 0.6.2 [skip ci]| Mar 18, 2024  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| Merge commit '301c8083f50b3b9bbacc57fce2c2c95813ac542e' into pgvr/main| Apr\n17, 2024  \n  \n### Makefile.win\n\n|\n\n### Makefile.win\n\n| Fixed regression test list for Windows [skip ci]| Apr 14, 2024  \n  \n### README.md\n\n|\n\n### README.md\n\n| Add Milvus installation instructions to README.md| Apr 17, 2024  \n  \n### comparison.html\n\n|\n\n### comparison.html\n\n| Create comparison.html| Apr 17, 2024  \n  \n### test.ipynb\n\n|\n\n### test.ipynb\n\n| jupyter notebook demonstrating connection pooling| Feb 24, 2024  \n  \n### vector.control\n\n|\n\n### vector.control\n\n| update version to remote0.1.0| Apr 8, 2024  \n  \n## Repository files navigation\n\n# pgvector-remote\n\nintroduction\n\npgvector-remote is a fork of pgvector which combines the simplicity of\npgvector with the power of remote vector databases, by introducing a new\nremote vector index type. Currently, pgvector-remote only supports pinecone ,\nbut we plan to support other vendors in the future.\n\n  * Short Version\n  * Use Cases\n  * Installation\n  * Configuration\n  * Index Creation\n  * Performance Considerations\n  * Docker\n  * Credits\n\nBenchmarks for a 10M filtered search workload. https://big-ann-\nbenchmarks.com/neurips23.html#tracks. Results for pgvector are shown for a\ntuned hnsw index on a t2.2xlarge (32GB RAM). Results for pinecone are for a\np2.x8 pod.\n\n## Short Version\n\n    \n    \n    CREATE TABLE products (name text, embedding vector(1536), price float); CREATE INDEX my_remote_index ON products USING pinecone (embedding, price) with (host = 'my-pinecone-index.pinecone.io'); -- [insert, update, and delete billions of records in products] SELECT * FROM products WHERE price < 40.0 ORDER BY embedding <-> '[...]' LIMIT 10; -- pinecone performs this query, including the price predicate\n\n## Use Cases\n\n### Benefits of using pgvector-remote for pinecone users\n\n  * Vector databases like pinecone aren't docstores (and they shouldn't try to be). That means your document and its embedding live in separate databases. pgvector-remote lets you keep your metadata in postgres and your embeddings in pinecone, while hiding this complexity from the user by presenting a unified sql interface to creating, querying, and updating pinecone indexes.\n  * Control your data. Using pgvector-remote means that all your vectors are in postgres. This makes it easy to test out a different index type (like hnsw) and drop pinecone in favor of a different vendor.\n\n### Benefits of using pinecone for pgvector users\n\n  * Scalability: Pinecone is designed to scale to billions of vectors. pgvector does not easily accomodate such large datasets. Large vector indexes are incredibly highly memory intensive and therefore it makes sense to separate this from the main database. For example indexing 200M vectors of 1536 dimensions would require 1.2TB of memory.\n\n### Benefits of using pgvector-remote for users who already use pinecone and\npgvector\n\n  * Seamless integration: You don't need to write a line of pinecone application logic. Use a unified sql interface to leverage pinecone as if it were any other postgres index type.\n  * Synchronization: pgvector-remote ensures that the data in pinecone and postgres are always in sync. For example, if your postgres transaction rolls back you don't need to worry about cleaning up the data in pinecone.\n\n### Why is this integration better than confluent's kafka-connect?\n\n  * Liveness and correctness: pgvector-remote sends inserted vectors to pinecone in batches and locally scans unflushed records, guaranteeing that all data is always visible to index queries.\n  * Query and integration logic: traditional ETL won't help you write queries like the one above. pgvector-remote translates select predicates to pinecone filters.\n\n### When should I just use pgvector?\n\n  * Small datasets: If you have a small to medium dataset (10M vectors at 768 dimensions), you can use pgvector without a remote vector store. The local hnsw indexes will be sufficient.\n  * Minimal metadata: You aren't performing metadata filtering. Currently, pgvector does not handle metadata filtering, meaning that queries like the one above can sometimes be inefficient and inaccurate.\n\n## Installation\n\nInstall libcurl headers. For example,\n\n    \n    \n    sudo apt-get install libcurl4-openssl-dev\n\nThen follow the installation instructions for pgvector, using the\nfeature/remote_indexes of this repository.\n\n### Milvus Installation\n\n  * build the milvus c++ sdk\n  * git clone https://github.com/oscarlaird/milvus-sdk-cpp\n  * sudo apt install libgrpc++-dev libgrpc-dev libprotobuf-dev\n  * git submodule update --init\n  * make && sudo make install\n\n## Configuration\n\nSet the pinecone API key in the postgres configuration. For example,\n\n    \n    \n    ALTER DATABASE mydb SET pinecone.api_key = 'xxxxxxxx-xxxx-xxxx-xxxx\u2013xxxxxxxxxxxx';\n\n## Index Creation\n\nThere are two ways to specify the pinecone index:\n\n  * By providing the host of an existing pinecone index. For example,\n\n    \n    \n    CREATE INDEX my_remote_index ON products USING pinecone (embedding) with (host = 'example-23kshha.svc.us-east-1-aws.pinecone.io');\n\n  * By specifying the spec of the pinecone index. For example,\n\n    \n    \n    CREATE INDEX my_remote_index ON products USING pinecone (embedding) with (spec = '\"spec\": { \"serverless\": { \"region\": \"us-west-2\", \"cloud\": \"aws\" } }');\n\nAll spec options can be found here\n\n## Performance Considerations\n\n  * Place your pinecone index in the same region as your postgres instance to minimize latency.\n  * Make use of connection pooling to run queries in postgres concurrently. For example, use asyncpg in python.\n  * Records are sent to the remote index in batches. Therefore pgvector-remote performs a local scan of the unflushed records before every query. To disable this set pinecone.max_buffer_scan to 0. For example,\n\n    \n    \n    ALTER DATABASE mydb SET pinecone.max_buffer_scan = 0;\n\n  * You can adjust the number of vectors sent in each request and the number of concurrent requests per batch using pinecone.vectors_per_request and pinecone.requests_per_batch respectively. For example,\n\n    \n    \n    ALTER DATABASE mydb SET pinecone.vectors_per_request = 100; --default ALTER DATABASE mydb SET pinecone.requests_per_batch = 40; --default\n\n  * You can control the number of results returned by pinecone using pinecone.top_k. Lowering this parameter can decrease latencies, but keep in mind that setting this too low could cause fewer results to be returned than expected.\n\n## Docker\n\nAn example docker image can be obtained with,\n\n    \n    \n    docker pull kslohith17/pgvector-remote:latest\n\nThis contains postgres along with pgvector-remote configured to run on it.\n\n## Credits\n\nWe give special thanks to these projects, which enabled us to develop our\nextension:\n\n  * pgvector: Open-source vector similarity search for Postgres\n  * PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension\n  * Faiss: A Library for Efficient Similarity Search and Clustering of Dense Vectors\n  * Using the Triangle Inequality to Accelerate k-means\n  * k-means++: The Advantage of Careful Seeding\n  * Concept Decompositions for Large Sparse Text Data using Clustering\n  * Efficient and Robust Approximate Nearest Neighbor Search using Hierarchical Navigable Small World Graphs\n  * Pinecone: Vector database and search service designed for real-time applications\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\nReadme\n\n### License\n\nView license\n\nActivity\n\nCustom properties\n\n### Stars\n\n12 stars\n\n### Watchers\n\n4 watching\n\n### Forks\n\n4 forks\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Contributors 20\n\n\\+ 6 contributors\n\n## Languages\n\n  * C 82.5%\n  * Perl 12.3%\n  * C++ 3.0%\n  * Jupyter Notebook 0.9%\n  * HTML 0.7%\n  * Makefile 0.5%\n  * Other 0.1%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
