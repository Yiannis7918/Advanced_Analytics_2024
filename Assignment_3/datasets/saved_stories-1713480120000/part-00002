{"aid": "40078091", "title": "Can generative AI only get better from here? It's complicated", "url": "https://community.aws/content/2ey0aCSXGcC2WRdHshVNvv3WBfy/can-generative-ai-only-improve-from-here-it-s-complicated", "domain": "community.aws", "votes": 1, "user": "damonk10", "posted_at": "2024-04-18 16:40:47", "comments": 0, "source_title": "Can generative AI only improve from here? It's complicated", "source_text": "Community | Can generative AI only improve from here? It's complicated\n\n## Select your cookie preferences\n\nWe use essential cookies and similar tools that are necessary to provide our\nsite and services. We use performance cookies to collect anonymous statistics\nso we can understand how customers use our site and make improvements.\nEssential cookies cannot be deactivated, but you can click \u201cCustomize cookies\u201d\nto decline performance cookies.\n\nIf you agree, AWS and approved third parties will also use cookies to provide\nuseful site features, remember your preferences, and display relevant content,\nincluding relevant advertising. To continue without accepting these cookies,\nclick \u201cContinue without accepting.\u201d To make more detailed choices or learn\nmore, click \u201cCustomize cookies.\u201d\n\n## Customize cookie preferences\n\nWe use cookies and similar tools (collectively, \"cookies\") for the following\npurposes.\n\n### Essential\n\nEssential cookies are necessary to provide our site and services and cannot be\ndeactivated. They are usually set in response to your actions on the site,\nsuch as setting your privacy preferences, signing in, or filling in forms.\n\n### Performance\n\nPerformance cookies provide anonymous statistics about how customers navigate\nour site so we can improve site experience and performance. Approved third\nparties may perform analytics on our behalf, but they cannot use the data for\ntheir own purposes.\n\nAllowed\n\n### Functional\n\nFunctional cookies help us provide useful site features, remember your\npreferences, and display relevant content. Approved third parties may set\nthese cookies to provide certain site features. If you do not allow these\ncookies, then some or all of these services may not function properly.\n\nAllowed\n\n### Advertising\n\nAdvertising cookies may be set through our site by us or our advertising\npartners and help us deliver relevant marketing content. If you do not allow\nthese cookies, you will experience less relevant advertising.\n\nAllowed\n\nBlocking some types of cookies may impact your experience of our sites. You\nmay review and change your choices at any time by clicking Cookie preferences\nin the footer of this site. We and selected third-parties use cookies or\nsimilar technologies as specified in the AWS Cookie Notice.\n\n## Unable to save cookie preferences\n\nWe will only store essential cookies at this time, because we were unable to\nsave your cookie preferences.\n\nIf you want to change your cookie preferences, try again later using the link\nin the AWS console footer, or contact support if the problem persists.\n\nHomeTags\n\nFeatured Spaces\n\nCost Optimization\n\nDevOps\n\nGenerative AI\n\nKubernetes\n\nLivestreams\n\nResilience\n\nTraining and Certification\n\nCommunity Programs\n\nAWS Heroes\n\nAWS Community Builders\n\nAWS User Groups\n\nStudent Communities\n\n# Can generative AI only improve from here? It's complicated\n\n## I asked machine learning experts about the future of AI and LLMs. Their\nanswers made me realize I was focusing on the wrong questions.\n\ngenerative-aillmdataresponsible-ai\n\nDavid Priest\n\nAmazon Employee\n\nPublished Apr 18, 2024\n\nComments\n\nComputers will only get better. Our hardware is continually becoming more\nefficient, our storage more expansive, our software more powerful. Cars will\nonly get better, too: more fuel efficient, safer, smarter. The same is true\nwith almost all technology; if we set aside business-driven enshittification\nfor the moment, technological improvement in the 21st century seems to be\nabout as dependable as death and taxes.\n\nBut what about generative AI? Will it only improve? I\u2019ve heard countless\nexperts say so, as though it\u2019s all but guaranteed. But the answer doesn\u2019t seem\nso clear to me. Generative AI isn\u2019t just software plus hardware. It\u2019s also\ndata. And while the hardware (think of data storage and computation cost) will\nalmost certainly improve, and the software (think of semantic mapping) will\nalmost certainly improve, the data (think of all the written language ingested\nby LLMs) will almost certainly not.\n\nSo will generative AI only get better from here? Probably... but it\u2019s more\ncomplicated than you might think.\n\n##\n\nHardware + Software + Data\n\nLet\u2019s get more specific: is the software and hardware undergirding AI really\nimproving? We constantly read, after all, about the massive cost of generative\nAI. But those costs are also quickly improving. Transformer models, introduced\nin 2017, use GPUs far more efficiently than previous generations of encoder-\ndecoder models (like RNN, LSTM, etc.) did, even if we\u2019re rapidly increasing\nhow many GPUs we\u2019re using for these models. Look at cloud services in general:\nthe tech industry generally improves performance over time, lowering prices\nrelative to that performance in the process \u2014 and there\u2019s little reason to\nthink generative AI will be any different.\n\nCustomer-facing costs will almost certainly go down, too. Amazon Bedrock, for\nexample, recently cut costs to people testing and developing on it by as much\nas 75%. That was a material improvement based simply on service offering\noptimization.\n\nThe same pattern holds true for the software \u2014 that is, the mechanisms that\nare taking raw data (billions of words) and using them to answer your random\nqueries on ChatGPT. Just look at the recent improvements in language\ngeneration: ten years ago, tools were available that would take a word and\nstart spinning out a sentence by guessing the next word \u2014 based simply on the\nprevious word (or perhaps the previous few words). The result was a stream-of-\nconsciousness meandering that could be intriguing, but wasn\u2019t particularly\nuseful.\n\nWhat followed was many smart people working to capture the context of language\nmore effectively \u2014 and the resulting emergence of self-attention, a concept\nthat allowed models to pay, well, attention to the context not simply of the\nlast word, but of many words together. (As an example, self-attention allows\nmodels to more reliably make sense of the pronouns in a sentence like, \u201cJake\nlent Bob his jacket because he was cold,\u201d by paying attention to the whole\nthing together.)\n\nOne way to think about self-attention is that it is a \"mirror\" for LLMs to\nunderstand their context.\n\nJump forward a few more years, to 2017, and a bunch of Google engineers\nrealize that attention isn\u2019t just useful in conjunction with other tools, like\nrecurrence and convolutions, but on its own. They publish one of the most\nimportant recent papers on machine learning, aptly titled, \u201cAttention Is All\nYou Need.\u201d\n\nAnd within a few years, we land at gpt-3 and other decoder-only models that\nstring words together in exactly the same way as those old, meandering tools.\nThey don\u2019t guess the next word based only on the last word to be generated,\nthough. Instead they guess based on the hidden context of all the words\nwritten so far \u2014 creating incredibly cogent, essay-length responses to\nquestions (even if they sometimes hallucinate along the way).\n\nIf you only tracked with 50% of that, don\u2019t worry. The important fact to\nunderstand for our purposes is this: we are still very much learning about how\nto create effective large language models, and that means our ability to\nleverage our massive datasets is only improving over time.\n\n##\n\nThe Data Problem\n\nHardware and software may be improving, but the story of the data itself isn\u2019t\nquite as clear. Let\u2019s pretend that our dataset is the internet: that includes\nmost of what\u2019s been written (or at least published) in human history, or\nthousands of years of written words. A year from now, we will have exactly one\nmore year of data. That's not insignificant; we are creating a massive amount\nof data online every year, so one year of written-language data in the 2020s\nis far larger than one year of written language data from even a hundred years\nago \u2014 let alone a thousand years ago.\n\nOkay, we\u2019re creating a lot of data, so our dataset (the internet) should be\ngetting bigger \u2014 and that means better, right? Well... maybe not. After all,\npopular generative AI tools like ChatGPT are now live and being used widely.\nThat means the input data is quickly being tainted by outputs from previous\niterations of generative AI. (This isn\u2019t intentional, to be clear; it\u2019s just\nincidental to everyone suddenly publishing AI-generated content all over the\ninternet.)\n\nThis sort of corruption matters for a few reasons. First, it contributes to\nwhat one group of machine learning experts, in a research paper published last\nyear, called \"model collapse.\" Essentially, as models approximate the\ndistribution of a large dataset, some of that data is inevitably lost \u2014\nmeaning the approximated distribution changes over time. Feed the outputs into\nthe model, and a problem emerges: the more models approximate based upon their\nown approximates, the more their outputs will diverge from the original\ndataset.\n\nA screenshot from \"The Curse of Recursion: Training on Generated Data Makes\nModels Forget\"\n\nNot only will this data corruption lead to model collapse, but outright errors\nin model outputs will also propagate across generations of generative AI\ntools, further degrading their performance over time.\n\nIn other words, generative AI ingesting its own outputs is very bad for its\nreliability.\n\n##\n\nWhat are the solutions?\n\nResearchers aren\u2019t ignorant of these data challenges. For extra perspective, I\nreached out to Mark Kon, a professor of mathematics and statistics at Boston\nUniversity, and an expert on machine learning and neural networks.\n\n\u201cThe danger is not apparent yet,\u201d he said. \u201cYou\u2019re looking ahead a few years,\nwhere... AI-based content becomes the majority of internet content. And the\nquestion is, will this lead to an iterated corruption of information?\u201d\n\nKon said the answer to that question is yes \u2014 as long as the spread of AI-\ngenerated content remains unchecked. In essence, the so called dead internet\ntheory would in such a case become a reality. But Kon says there are\nsolutions.\n\n\u201cIt\u2019s going to be... a \u2018better mousetrap, better mouse\u2019 situation,\" he said,\n\"in that human safeguards against the iteration of AI generated content will\niteratively be defeated by stronger and more powerful AI content, which will\nlead to better human safeguards, and so on.\u201d\n\nWe\u2019ll need to build features, explained Kon, to \u201cestablish the authenticity of\na piece of information based on verifiable human authorship.\u201d Plenty of AI\ntools, like Amazon Titan, are already making impressive efforts to watermark\nAI-generated images (better mousetraps). Of course, as we use artificial\nintelligence more and more, the line between human-created content and AI-\ngenerated content will become blurrier (better mice).\n\n\"I think we're going to need a bigger mousetrap\"\n\nMy colleague Mike Chambers, an AI Specialist and Developer Advocate at AWS,\nwas more hopeful about LLM improvements when I spoke to him. He pointed out\nthat we\u2019ve already taken steps to improve model performance through \u201ctidying\u201d\nexisting datasets, which indicates that we need to clean our data as much as\nor more than we need to increase it. Generative AI itself might even be able\nto assist with this cleaning process.\n\nLikewise, he said active research into the use of alignment and fine tuning,\nalong with regular discoveries in the area of prompting techniques, are\nimproving how we leverage existing data \u2014 even if we don\u2019t always have great\nvisibility into said research. (Research and development for such high-value,\ncutting-edge technology remains highly secretive.)\n\n\u201cWill generative AI only improve?\u201d asked Chambers. \u201cAbsolutely yes! As an\nindustry, we are floundering around in the dark near the very beginning of\nthis technology. We are just waiting on the next small discovery, the next\nstep change discovery, or for someone to invent a torch.\u201d\n\nKon and Chambers both are getting at the fact that there are different kinds\nof \u201cbetter\u201d when it comes to data; it doesn't always come down to \"more.\"\n\nI was reminded of a recent conversation I had with a scientist who likened our\ncurrent data situation to the pre-war steel problem. Essentially, after\nnuclear bombs were detonated in 1940s and 1950s, atmospheric radiation\nresulted in newly produced steel having higher radioactivity \u2014 making it less\nsuitable for a variety of purposes. That raised the value of pre-war steel\n(and, more specifically, pre-war steel shielded from the effects of radiation\nby, for example, being in a shipwreck at the bottom of the sea), which was\ncrucial to the production of Geiger-counters and various scientific\ninstruments.\n\nPerhaps the fallout of ChatGPT is too universal to be contained, and saved\ncopies of the internet pre-2020 will be the new pre-war steel \u2014 with a level\nof purity we won\u2019t ever achieve again. And as Chambers argued, our task is to\nclean that data and optimize our use of it. Or as Kon argued, perhaps tools to\nfilter out AI-generated content will help preserve the value of newer online\ndata as it is created.\n\nTo me, either option feels useful. LLMs really do seem almost certain to\nimprove, but how exactly they improve remains to be seen \u2014 and no matter the\nanswer, that improvement will require significant investment on our part.\n\n##\n\nThe Bigger Picture of Data\n\nTalking with experts like Kon and Chambers made me realize I might have been\nasking the wrong question in the first place. Will generative AI get better?\nSure. But there\u2019s a bigger question about data here.\n\nTidying older data and labeling newer data are important strategies, but they\nmostly apply to our same old categories of data: text, images, and videos. The\nfuture of AI will likely also involve finding new types data to ingest. I\u2019ve\nwritten about the perception problem of generative AI before: that everything\nan LLM generates is a hallucination insofar as it is an expression of a\nreality the LLM cannot itself perceive. Well, one solution to the data problem\nis giving models more means of perception.\n\nThink about the transition from paper maps to satellite-enabled navigation\nsystems. We went from millennia of cartographic practices to something\nradically new: camera-equipped satellites that were able to map the earth \u2014\nand see our exact locations on it \u2014 in a way never before achieved. Within a\nfew years of GPS navigation, cars with 360-degree cameras strapped to their\nroofs began to roam the world, capturing street views. Digital photography in\nits various implementations created a completely new category of data for maps\nto use, from the clouds to the streets.\n\nNew categories of data have radically reshaped how we think about maps and\nnavigation.\n\nGenerative AI is looking for that new category of data.\n\nIn much the same way scientists have discovered how to more effectively\n\u201cunderstand\u201d and leverage the data of written language through vector\nembedding, I believe we will begin to \u201cunderstand\u201d and leverage new categories\nof data, be it spacial, visual, or even socio-cultural. It might sound like\nscience fiction, but the apparatus is already in development: both new devices\nfor gathering data and new methods of gathering data from existing devices are\non the way. In other words, the camera-equipped satellites and cars of the AI\nage aren\u2019t so far away from launching.\n\nGenerative AI will improve because of our efforts to better leverage or\npreserve existing data. But in the long run, it will get more powerful because\nit will begin to access whole new categories of data. After all, the best\nsource for understanding reality isn\u2019t the internet; it\u2019s reality itself.\n\nAny opinions in this post are those of the individual author and may not\nreflect the opinions of AWS.\n\nComments\n\n## Comments\n\nLog in to comment\n\n", "frontpage": false}
