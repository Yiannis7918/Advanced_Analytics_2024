{"aid": "40030259", "title": "The Integers in Our Continuum", "url": "https://kylehovey.github.io/blog/the-integers-in-our-continuum", "domain": "kylehovey.github.io", "votes": 1, "user": "speleo", "posted_at": "2024-04-14 11:01:13", "comments": 0, "source_title": "The Integers In Our Continuum", "source_text": "The Integers In Our Continuum \u00b7 Kyle Hovey\n\nHere you will find occasional musings I have on math, science, and other\nthings. Portfolio Mathstodon\n\n\u00a9 2024. All rights reserved.\n\n### Kyle Hovey\n\n# The Integers In Our Continuum\n\nArtwork by my good friend Sophia Wood\n\n# On Physics\n\nRecently, I was surprised to learn that the existence of quanta is not\nfundamental in our current understanding of physics. In other words, none of\nour models of physics begin with quantizations or discrete entities, they only\nend up with them after examination. David Tong, a mathematical physicist at\nthe University of Cambridge, wrote a thought-provoking essay elucidating this\nironic nuance in our models of physics. Quantum mechanics, for instance,\nbegins with a continuous-valued wave equation describing the evolution of a\nwave packet from which measurements are taken by utilizing the convenient\nproperties of Hilbert Spaces to allow proejction of the wavefunction onto\nanother analytic object like a Hamiltonian. Many versions of this wave\nequation can be constructed given your baseline assumptions (Schr\u00f6dinger for\nnon-relativistic, Dirac for relativistic effects), but they all attempt to\nreckon some order from a continuous phenomenon. Despite beginning with a\ncontinuous picture, discrete quanta are a direct consequence of studying these\nequations.\n\nHydrogen wave function solutions (source).\n\nSince discretization seems to emerge from solving wave equations, one may seek\nother fundamental sources of quanta. It may make sense to examine the degrees\nof freedom of a system to see if they yield canonically distinct entities.\nMost commonly, this can be interpreted as the independent axes of freedom in a\nmodel\u2019s representation space. Still, this is not as canonical as one might\nhope as many potential models such as the AdS/CFT Correspondence where our\nmodels of quantum mechanics are dual to models that exist in higher\ndimensional ones. The holographic principle takes this in the other direction\nwhere entanglement on the two-dimensional boundary of a black hole may\nrepresent higher-dimensional information with different effective radii\nexpressed at different scales of measuring information on the surface. Once\nagain, we do find quantization everywhere we look, but not in a canonical way.\n\n## Emergence of Quanta\n\nWhen solving wave equations, we make use of apparently magical techniques like\nPerturbation to pull analytic results out of what should have no solution. I\nremember using these Perturbation techniques in my applied mathematics course\nand feeling as though we were doing something forbidden when we could enact a\nbound on error at two scales of a system in such a way that, at the limit, the\nerror could disappear (or at least become arbitrarily small). Regardless,\nthese models have proven extremely fruitful in finding mathematical models of\nreality. When solved, we do in fact find discrete quanta emerging from our\nmodels of the continuum. This is how we developed a theory of discrete units\nin Quantum Mechanics. These discretizations emerge from our solutions to wave\nequations is similar to how musical instruments have harmonic modes. The\ntimbre and harmony of intervals relies on the emergent discrete resonances,\nyet a continuous phenomenon underlies the mechanism. This emergence of quanta\nfrom continuous models is mesmerizing to me, and lately I have been wondering\nif a deeper understanding of their genesis lies in the study of computability.\n\n# On Mathematics\n\nThe Riemann Zeta Function, graphed (source).\n\nIn a similar vein, I have always been awed and confused by the apparent divide\nbetween number theory and the other algebraic fields of mathematics. Look\nclosely between any two regions of mathematical study and you will find\nnumerous dualities weaving a dense web of interconnection. Yet, number theory\nseems to exhibit a repelling force to the rest of math. Mathematical objects\nsuch as the Riemann Hypothesis build a bridge to number theory by exploiting\nthe periodicity of continuous functions. While I only have a cursory\nunderstanding of it, the Langlands Problem is a massive effort to construct\nformidable and durable machinery for answering number theoretic questions\nusing algebraic reasoning, but it remains one of the largest pieces of active\nwork in Mathematics today and we don\u2019t have good answers yet.\n\nA small sample of connected concepts in algebraic regions of mathematics.\n\nWhat I mean by \u201calgebraic\u201d is that, for much of mathematics, a little goes a\nlong way. By defining very simple constructs such as sets and binary\noperations with an amount of properties you could count on one hand, we can\nreconcile models so powerful that they predicted the existence of Black Holes\nbefore we ever directly imaged one. These are powerful ideas, and yet, they\nare also elegant and convenient. Simple concepts such as Eigenvalues combined\nwith infinite linear operators like differentials allow us to build bridges,\npredict quantum systems\u2019 behavior, and even probe the dynamics of biological\npopulations.\n\nAn eigen-operator Q acting on an object Psi yields Psi again, but scaled by a\nfactor of q.\n\nYet, in number theory, simple questions such as \u201cis every even integer greater\nthan 22 the sum of two prime numbers?\u201d have been unsolved for hundreds (and in\nsome cases, thousands) of years. We can make clever use of Modular Arithmetic\nalong with inductive techniques to prove results in many cases, but often it\nis not intuitive when a given question in number theory will be easy to solve\nor impossible.\n\n## Peano Arithmetic\n\nDominoes (source).\n\nWhat are these integers that so adeptly evade any attempt at constructing\nuseful tools of reasoning? The most commonly used formalism to construct the\nintegers is Peano Arithmetic. Like in the case of algebraic mathematics, we\nbegin with some clever axioms: there exists a number 00, and a function SS\nthat, when fed a number, it yields the successor to that number. As SS is\ndefined from a number to a number, it may be recursed. 11 is representable as\nS(0)S(0), 22 as S(S(0))S(S(0)) (and so on). These axioms also introduce a\nnotion of equality which is reflexive (that is to say that x=xx=x), symmetric\n(x=y\u27fay=xx=y\u27fay=x), transitive x=y,y=z\u27f9x=zx=y,y=z\u27f9x=z , and closed (meaning that\nif aa is a number and a=ba=b then bb is also a number).\n\nThis is sufficient to construct all of the integers (denoted as ZZ), but it is\nalso sufficient to limit the capabilities of mathematics. Kurt G\u00f6del and Alan\nTuring independently realized that any formal system complex enough to encode\nthe integers (called \u201cRecursively Enumerable\u201d) is incapable of proving its own\nconsistency. Such systems are also incomplete, meaning that there are\nstatements representable within the language of the system that cannot be\nproven or disproven using just the system\u2019s rules of deduction.\n\n## Church Numerals\n\n\u03bb-2D: An artistic Lambda Calculus visual language (from Lingdong Huang).\n\nAround the same time, Alonzo Church had formulated Lambda Calculus, an\nabstract model for computation that was far more elegant and easy to reason\nabout than that of a Turing Machine. Whereas a Turing machine expressed\ncomputation as operations over stored state with a set of instructions, Lambda\nCalculus took an axiomatic approach similar in spirt to Peano arithmetic.\n\nLambda Calculus\n\n  1. There exist variables, denoted by characters or strings representing a parameter or input. For example, xx.\n  2. There exists abstractions, denoted as \u03bbx.M\u03bbx.M which take a value as input and return some expression MM which may or may not use xx.\n  3. There exists application, denoted with a space MNMN or \u201cMM applied to NN\u201d where both left and right-hand sides are lambda terms.\n\nWhile difficult (if not impossible) to construct physically without already\nhaving some other universal model of computation like a Turing Machine, Lambda\nCalculus expresses the same set of algorithms that can be run on a Turing\nMachine (or any other universal model). It was not intuitive to me, at first,\nhow one would use such a simple system to replicate all types of computation.\nAfter all, it was far easier as a human to reason about things like numbers,\nlists, trees, boolean algebra, and other useful concepts in computer science\non a Turing Machine which was much closer to pen and paper than this new\nabstract world.\n\nThe easiest constructs to express in Lambda Calculus are, in fact, the\nintegers. The same recursive construction used in Peano Arithmetic can be\nemployed here with careful substitution to make the concept compatible with\nour new axioms. First, there exists a number 00 read as \u201cff applied no times\u201d.\nAs you might expect, the integer gg is read as \u201cff applied gg times\u201d:\n\n0=\u03bbf.\u03bbx.x0=\u03bbf.\u03bbx.x 1=\u03bbf.\u03bbx.fx1=\u03bbf.\u03bbx.fx 2=\u03bbf.\u03bbx.f(fx)2=\u03bbf.\u03bbx.f(fx)\n3=\u03bbf.\u03bbx.f(f(fx))3=\u03bbf.\u03bbx.f(f(fx))\n\nThen, a successor function SS can be represented as \u201cthe machinery that takes\na number gg and yields a new number g\u2032g\u2032 that applies ff one more time than\ngg\u201d.\n\nS=\u03bbg.\u03bbf.\u03bbx.f(gfx)S=\u03bbg.\u03bbf.\u03bbx.f(gfx)\n\nI\u2019ve used gg here to denote the number instead of nn because, when thinking\nabout Lambda Calculus, it is easy to forget that everything is a function\n(including these numbers we are defining). gg is indeed a \u201cnumber\u201d, but in\nthis universe numbers apply operations that many times. This explanation is\nlikely sufficient for this post, but you can take this as far as you would\nlike and define the normal operations over integers such as addition\n(m+n=\u03bbm.\u03bbn.\u03bbf.\u03bbx.mf(nfx))m+n=\u03bbm.\u03bbn.\u03bbf.\u03bbx.mf(nfx))), subtraction, and\nmultiplication.\n\nChurch Numerals alone are a powerful construction, but repeated application is\nnot sufficient if we wish to create a universal system equivalent to a Turing\nMachine. For that, we need to shim a concept of iteration called General\nRecursion. Ordinary recursion is fairly simple in Lambda Calculus, allowing\nfor infinite regress as easily as M=\u03bbf.ffM=\u03bbf.ff (also known as the MM\ncombinator). When fed itself, it becomes itself.\n\n(\u03bbf.ff)(\u03bbf.ff)=(\u03bbf.ff)(\u03bbf.ff)(\u03bbf.ff)(\u03bbf.ff)=(\u03bbf.ff)(\u03bbf.ff)\n\nAs you might guess, while a neat party trick, this does not allow us to create\nanything useful computationally. We need a piece of machinery that can take a\nfunction, and pass it to itself somehow. After all, if a function has access\nto itself then it may call itself which is our current goal. The MM combinator\ngets us so close, we only need:\n\n  1. A way of passing in a function ff that (somehow) takes itself as a parameter\n  2. Some way of terminating the infinite regress\n\nIn other words, we need a function YY that has the unique property\nYf=f(Yf)Yf=f(Yf). This would imply that YY passes ff to itself somehow, and\nsince ff is passed this value it can choose whether or not to call it (giving\nthe option for termination). This is the famous Y Combinator:\n\nY=\u03bbf.(\u03bbx.f(xx))(\u03bbx.f(xx))Y=\u03bbf.(\u03bbx.f(xx))(\u03bbx.f(xx))\n\nNotice how the body of YY contains machinery that looks a lot like MM, except\nwith an additional call to ff along the way. A good exercise is to try and\nreduce YfYf and to verify that it does become f(Yf)f(Yf). In a way, the YY\ncombinator is the child of Church Numerals (applying a function gg times) and\nthe MM combinator (self-application). The YY combinator only supports one\nargument, but can easily be generalized to support an arbitrary amount of\narguments.\n\nThe Y Combinator expressed in John Tromp\u2019s Lambda Diagrams.\n\n## Type Theory\n\nAs it was the case with Peano Arithmetic and recursively enumerable formal\nsystems leading to paradox via G\u00f6del\u2019s Incompleteness Theorems, the YY\ncombinator also encodes a paradox. That is to say, the YY combinator can be\nused to construct absurd self-referential statements. Even before Lambda\nCalculus was studies, individuals like Bertrand Russell attempted to remedy\nthese kinds of paradoxes with a new field of mathematics called Type Theory.\nOriginally created to solve Russel\u2019s Paradox (a similar inconsistency in set\ntheory), type theory aligns well with Lambda Calculus allowing us to endow\nfunctions with a notion of parameter and return types, along with a type for\nthe function itself. In its most basic form, typed lambda calculus operates\nover the type \u2217\u2217 which reads as \u201cthe set of all types\u201d with an additional \u2192\u2192\noperator that allows you to construct functions over the types. For instance,\n\u2217\u2192\u2217\u2217\u2192\u2217 is the type of \u201ca function from a type to a type\u201d.\n\nThe Lambda Cube, where \u2192 indicates adding dependent types, \u2191 indicates adding\npolymorphism, and \u2197 indicates allowing type operators.) (source).\n\nIn typed Lambda Calculus, it is impossible to create the YY combinator. The\nsame self-reference that gives it its utility results in an Achilles\u2019 heel\nthat results in the type signature never terminating. Still, the typed lambda\ncalculus is incredibly useful in its own right and supports many rich\noperations, just not general recursion. Many extensions can be added to the\ntypes, but until you allow for something like the YY combinator these systems\nare all strongly normalizing (which means operations are guaranteed to\nterminate and not infinitely regress).\n\nHaskell\u2019s logo combines the lambda with a symbol \u291c representing monadic\nbinding.\n\nSecond-order typed Lambda Calculus (also romantically called \u03bb2\u03bb2), which\nextends the simply typed Lambda Calculus with polymorphism, is what modern\nlanguages like Haskell are built on top of. But, if \u03bb2\u03bb2 is only strongly\nnormalizing and cannot express general recursion, how is it a useful\nprogramming language? We throw our hands up into the air and introduce a\nfamiliar function which is the seed that sets Haskell into motion:\n\n    \n    \n    fix f = f (fix f)\n\nThis is the YY combinator expressed in Haskell, where instead of relying on\nlambda terms we use the language\u2019s ability to allow functions to reference\nthemselves in their definitions. This is not as elegant as the YY combinator,\nbut just as powerful and it means that many properties about languages like\nHaskell are actually Undecidable (behaving just like the systems discussed in\nG\u00f6del\u2019s proofs).\n\n## Curry-Howard Isomorphism\n\nIn studying Lambda Calculus, Church and others recognized a surprising and\nprofound correspondence between computation and mathematics. They found that\nthe abstraction, application, and reduction of terms in Lambda Calculus were\nnot only capable of representing mathematical proofs, they were functionally\nequivalent. This remarkable duality comes from thinking about the type of a\nlambda term as the formula it proves and the proof as executing the program.\nThe formula is then true if the evaluation terminates.\n\nAs a caveat, this only works in general for provably finite algorithms (as is\nthe case in strongly normalizing languages), otherwise we run into Turing\u2019s\nHalting Problem. This subset of mathematics is called Intuitionist Logic and\nprohibits the use of The Law of Excluded Middle in evaluating proofs (which\nconsequently bars double-negation as well). The mathematics we commonly use\nallow for these concepts instead of forbidding them (like in ZFC).\n\nWhen proving the correspondence, it is far more convenient to use SKI Calculus\nrather than raw Lambda Calculus. As in the case with physical computational\nmodels of Turing Machines, there are many equivalent formulations that produce\nthe result we want. A computer may be constructed from NOR, NAND, or other\ncombinations of gates and still have the same emergent properties. SKI\ncalculus introduces three combinators that can be used to construct any Lambda\nexpression:\n\n  1. S=\u03bbx.\u03bby.\u03bbz.xz(yz)\u2192S=\u03bbx.\u03bby.\u03bbz.xz(yz)\u2192 substitution\n  2. K=\u03bbx.\u03bby.x\u2192K=\u03bbx.\u03bby.x\u2192 truth\n  3. I=\u03bbx.x\u2192I=\u03bbx.x\u2192 identity\n\nThe SS combinator in particular is difficult to understand at first, but it\nrepresents a concept known as Modus Ponens in propositional logic. This is the\nstep in theorem proving when you apply some piece of knowledge you have to an\nexpression you already have. A very simple example is that the identity\ncombinator II can be \u201cproven\u201d by applying the SS to KK twice (I=(SK)KI=(SK)K).\nAs usual, propositional logic proves difficult to follow but the key takeaway\nis that SS and KK represent the most fundamental operations in theorem\nproving, identifying that all proofs are actually programs.\n\nThis was a watershed moment in the intersection of mathematics and computer\nscience, allowing for mathematical theorem proving software. In particular, a\nspecific typed lambda calculus \u03bbC\u03bbC that allows for both dependent typing and\ntype operators in addition to the polymorphism of \u03bb2\u03bb2 is the basis of the Coq\ntheorem proving software. As you may have inferred, Coq is not a Turing\nComplete language but is still remarkably useful when we want to\ncomputationally verify mathematical proofs.\n\n# On The Canonical Existence of Integers\n\nRipples on an alpine lake.\n\nWhere does this leave us with our questions about the emergence of quanta in\nour models of physics? Lately I have been allowing myself to think more\nintuitively about these things, while attempting to remind myself that this is\na form of play. If you will indulge me in this exploration, I would love to\nshare the thoughts I have had so far (however incomplete they may be). My\nwriting up to this point has mostly covered a reflection of what we currently\nknow, so this marks a transition into my own reflection and opinions on where\nthings may be headed in our understanding of the world.\n\nI believe an equivalent and perhaps more formal rephrasing the question of the\nemergence of quantiztion would be \u201cDo discrete entities canonically exist, and\nif they don\u2019t, when, where, and by what means do they emerge?\u201d. While reading\nDavid Tong\u2019s essay, one sentence especially stood out to me:\n\n> The integers appear on the right-hand side only when we solve [the\n> Schr\u00f6dinger Equation].\n\nCould it really be the case that integers are an artifact of a computational\nunderstanding of reality? If we are to interpret the Church-Turing Thesis\nliterally, then all forms of computation are equivalent inasmuch as an\nalgorithm for one universal machine may run on any of them if written in the\nlanguage of the other machine. Turing Machines, Kolmogorov Machines, Lambda\nCalculus, Cellular Automata, Quantum Circuits, Adiabatic Quantum Computation,\nLarge Language Models, and even models inspired and modeled after the brain\nlike Neuromorphic Engineering are all universally equivalent. Quantum models\nof course offer additional efficiency in time complexity, allowing for\noperations like factoring integers asymptotically faster than a classical\ncomputer, but they still operate on the same space of algorithms. There is no\nalgorithm that is computable in a quantum computer that is not computable in a\nclassical one.\n\nIf computation is really something more fundamental; an operation on\ninformation itself (as is the case in Constructor Theory), and we are another\ncomplex form of computation, would a computational understanding of our world\nbe the only possible one we could understand? We may observe the continuum and\nall of its complex interactions, but we must measure it in order to have any\ninformation to draw conclusions from. What if the process of measurement is a\nform of computation on correllated entangled particles, akin to the emerging\nhypothesis of Quantum Darwinism?\n\nAnd what about the mathematics of the continuum? One may argue that analysis\nmakes the notion of a continuum formal, but I wonder if we are simply shimming\nour computationally discrete scaffolding onto our observations of the world.\nWe often construct the continuum in a discrete way, beginning with a finite\ncase and using some concept of an infinite process to yield a limiting\nbehavior, Zeno-style. As is the case with our other systems, this is wildly\nsuccessful and has yielded extensions of our algebras over infinite objects,\nbut at its core is it really a reflection of the truth (if there is such a\nthing)? G\u00f6del, a platonist, believed that statements like the Continuum\nHypothesis could be false even though they are independent (or, undecidable)\nin our constructions of mathematics (ZFC or ZFC+, in this case).\n\nG\u00f6del\u2019s Incompleteness Theorems, Turing\u2019s Halting Problem, Cantor\u2019s Theorem on\nthe uncountability of the reals, Russel\u2019s Paradox in set theory, the Y\nCombinator of Lambda Calculus, and the incompatibility of Kolmogorov\nComplexity in computational information theory are all reflections of an\nabstract form of reasoning called a Diagonalization Argument. It seems that\neverywhere we find systems capable of self-reference, inconsistency follows as\na direct conclusion. Something akin to integers arises in all of these cases\n(Zermelo Ordinals, for instance), and in the case of strongly normalizing\nsystems like typed Lambda Calculi without general recursion you can still\nformalize the notion of a successor and express finite integers.\n\nCantor\u2019s Diagonal Argument from Max Cooper\u2019s music video for his track Aleph 2\n\nTo me, it seems natural to accept that our reality is fundamentally continuous\nin some way. Wave-like phenomenon exhibit periodicity, which is a kind of\ntemporal quantization, but not in any canonical way. In the same way that we\nhave stared in vain at the structure of the prime numbers for thousands of\nyears unable to explain their structure, yet freely admitting that they have\nit, I wonder if a search for a theory of everything in physics may prove\nfruitless. By all means, this does not mean that we should stop, but as in the\ncase of Principia Mathematica being motivated by trying to axiomatically\nderive all of mathematics only to be proven impossible to do by G\u00f6del, maybe\nwe need to re-think our approach and start thinking outside of our systems to\nsee what they are actually capable of.\n\nSomewhere amidst the swirl of equivalent systems masquerading as independent\nentities, we may find a unifying pattern that is representative of the space\nof understandings that humans (and conscious entities) can possibly have. At\nthe other side of that endeavor, we may stare into the mesmerizing patterns in\nan orchard that connect to so many things and find what we see to be an\nabstract reflection of ourselves, and us a reflection of it.\n\n# Afterward\n\nI\u2019m so interested to find an answer to the question: \u201cwhat is the canonical\nmodel for computation?\u201d. I hope that, in finding this answer, we might inch\ncloser to understanding the connection between all of these systems. Category\nTheory seems uniquely poised to approach this problem, and (maybe not so)\ncoincidentally has already fueled a theory of how to make Lambda Calculus\npractical. It is a system of mathematics adept at looking at numerous\ninstances of similar operations and finding the skeleton underlying them all.\nA popular example is the categorical product which (at first glance) seems\nmiraculous and impossible for anyone to be so clever as to come up with it in\na vacuum. That would be correct, as Category Theory is more of a meta-study of\nmathematics and structure itself. At times, it feels more empirical than\ndeductive, but it is no less effective as a mathematical vehicle for truth as\nany other field.\n\nA diagram conveying the Categorical Product.\n\nAt its heart, Category Theory seeks to find \u201cthe most general\u201d form for a\ngiven abstraction, which often takes the form of a Universal Property. It\nreminds me of Hamiltonian and Lagrangian mechanics where a system can be fully\ncharacterized by its desire to be in the minimal state of some measure\n(energy, in the case of the Hamiltonian). Something about the fundamental\nbehavior of our universe seeks to find the shortest path to the lowest point\nof any space. If information is truly physical, and it very well could be\n(remember that the Bekenstein Bound lies at the heart of the holographic\nprinciple), it might make sense how so many of our most powerful results in\nmath are the most elegant ones. In my last post, I talked about how\ninformation compression is analogous to artificial intelligence. Maybe the\nmost abstract form of computation comes as a dimensionality minimization\nattempting to find the latent manifold information truly lies on. This kind of\nmechanism would be biologically adventitious as it would yield compact and\nefficient representations of incoming information that would be highly\ncorrelated with the global information landscape an individual was embedded\nin. Will our search for a canonical model for computation merge with our\nattempt to understand intelligence?\n\nWhere Category Theory could potentially reconcile a concrete understanding\nfrom all of this hand waving by characterizing the ingredients of such a\nsystem. This would hopefully make it more obvious where to search for how such\nsystems physically manifest themselves in our universe.\n\n2\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial-\nShareAlike 4.0 International License.\n\n", "frontpage": false}
