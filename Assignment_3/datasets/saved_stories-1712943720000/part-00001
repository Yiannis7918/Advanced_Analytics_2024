{"aid": "40011427", "title": "Moreutils: The utilities package every Unix/Linux developer should know (2015)", "url": "https://rentes.github.io/unix/utilities/2015/07/27/moreutils-package/", "domain": "rentes.github.io", "votes": 1, "user": "Tomte", "posted_at": "2024-04-12 11:39:53", "comments": 0, "source_title": "moreutils: the utilities package every UNIX/Linux/Mac OS developer should know - Clean Coding", "source_text": "moreutils: the utilities package every UNIX/Linux/Mac OS developer should know\n- Clean Coding\n\n# moreutils: the utilities package every UNIX/Linux/Mac OS developer should\nknow\n\nPosted by Miguel Rentes on July 27, 2015\n\nRead more about UNIX, utilities\n\nMost UNIX professionals know about the GNU core utilities, from the \u201cused-\neveryday\u201d ls, cp, ln, rm, touch, tail, wc, etc., to the \u201cnot-so-used\u201d shell\ncommands such as tsort, tac, factor, or seq. Among the UNIX utilities\navailable, there is one package that includes some awesome utilities that\nmakes our life\u2019s a lot easier: the moreutils package.\n\n  * Installing\n  * The moreutils tools\n\n    * chronic: runs a command quietly unless it fails\n    * combine: combine the lines in two files using boolean operations\n    * errno: look up errno names and descriptions\n    * ifdata: get network interface info without parsing ifconfig output\n    * ifne: run a program if the standard input is not empty\n    * isutf8: check if a file or standard input is utf-8\n    * lckdo: execute a program with a lock held\n    * mispipe: pipe two commands, returning the exit status of the first\n    * parallel: run multiple jobs at once\n    * pee: tee standard input to pipes\n    * sponge: soak up standard input and write to a file\n    * ts: timestamp standard input\n    * vidir: edit a directory in your text editor\n    * vipe: insert a text editor into a pipe\n    * zrun: automatically uncompress arguments to command\n\n## Installing\n\nBefore describing each of the utilities included, let me tell you that this\npackage is not exclusive for Linux systems. You can install it also under Mac\nOS and different UNIX flavours.\n\nUnder Mac OS, just use the following command:\n\n    \n    \n    $ brew install moreutils\n\nNote: There is a conflict between the GNU parallel utility and the shipped\nparallel on the moreutils package. If you want to install GNU parallel instead\nof the moreutils\u2019 parallel, use the following commands:\n\n    \n    \n    $ brew install moreutils --without-parallel $ brew install parallel\n\nYou can read more about it here.\n\nUnder Linux, use your favourite package manager or the command line to\nretrieve this package. If you are using Arch Linux all you have to do is:\n\n    \n    \n    $ sudo pacman -S moreutils\n\nUnder Debian/Ubuntu/Mint a similar command is:\n\n    \n    \n    $ sudo apt-get install moreutils\n\nAnd on RHEL, Fedora, CentOS:\n\n    \n    \n    $ sudo yum install moreutils\n\nDon\u2019t forget to check your Linux distribution to know how to install this\npackage if the above commands are not for your particular Linux distribution.\n\n##The moreutils tools\n\n###chronic This tool runs a command , and arranges for its standard out and\nstandard error to only be displayed if the command fails (exits nonzero or\ncrashes). If the command succeeds, any extraneous output will be hidden.\n\nBefore discovering this tool I would do something like this to hide a command\noutput:\n\n    \n    \n    $ command >& /dev/null\n\nbut using chronic is so much simpler, and has the benefit that I know if the\ncommand succeeded or not, which I would not know from the line above (all\noutput is redirected to /dev/null).\n\nA common use for chronic is for running a cron job. Rather than trying to keep\nthe command quiet, and having to deal with mails containing accidental output\nwhen it succeeds, and not verbose enough output when it fails, you can just\nrun it verbosely always, and use chronic to hide the successful output.\n\n    \n    \n    0 1 * * * chronic backup # instead of backup >/dev/null 2>&1\n\n### combine\n\nThis tool combines the lines in two files using boolean operations.\n\n    \n    \n    $ combine file1 and file2 $ combine file1 not file2 $ combine file1 or file2 $ combine file1 xor file2\n\nDepending on the boolean operation specified, the contents will be combined in\ndifferent ways:\n\n  * and Outputs lines that are in file1 if they are also present in file2.\n\n  * not Outputs lines that are in file1 but not in file2.\n\n  * or Outputs lines that are in file1 or file2.\n\n  * xor Outputs lines that are in either file1 or file2, but not in both files.\n\nThe input files need not be sorted, and the lines are output in the order they\noccur in file1 (followed by the order they occur in file2 for the two \u201cor\u201d\noperations). This means that the operations are not commutative; \u201ca and b\u201d\nwill not necessarily be the same as \u201cb and a\u201d. To obtain commutative behavior,\nuse the sort and uniq commands to the result, like this:\n\n    \n    \n    $ cat a one ten two three $ cat b ten twelve one thirteen $ combine a and b one ten $ combine b and a ten one $ combine a and b | sort | uniq one ten $ combine b and a | sort | uniq one ten\n\n### errno\n\nThis tool looks up errno macro names, errno codes, and the corresponding\ndescriptions.\n\n    \n    \n    $ errno ENOENT ENOENT 2 No such file or directory $ errno 100 ENETDOWN 100 Network is down $ errno -l EPERM 1 Operation not permitted ENOENT 2 No such file or directory ESRCH 3 No such process EINTR 4 Interrupted system call EIO 5 Input/output error ENXIO 6 No such device or address E2BIG 7 Argument list too long ENOEXEC 8 Exec format error EBADF 9 Bad file descriptor ECHILD 10 No child processes EAGAIN 11 Resource temporarily unavailable ENOMEM 12 Cannot allocate memory EACCES 13 Permission denied EFAULT 14 Bad address ENOTBLK 15 Block device required EBUSY 16 Device or resource busy EEXIST 17 File exists EXDEV 18 Invalid cross-device link ENODEV 19 No such device ENOTDIR 20 Not a directory (...)\n\nThis is a most valuable tool and a lot better than reading the system header\nfiles to figure out the meaning of a particular errno code. If you do a lot\nUNIX programming you know what I am taking about.\n\n### ifdata\n\nThis tool can be used to check for the existence of a network interface, or to\nget information about the interface, such as its IP address, all statistics on\ninput and output, number of packets, bytes, errors, drops, incoming and\noutgoing bit rate, etc.. Unlike ifconfig or ip, ifdata has simple to parse\noutput that is designed to be easily used by a shell script.\n\n    \n    \n    $ ifdata -si eth0 1943188030 8648846 0 16803 0 0 0 0 $ ifdata -sip eth0 8649245 $ ifdata -so eth0 141940989 953001 0 0 0 0 0 0 $ ifdata -bips eth0 3012 $ ifdata -bops eth0 66\n\n### ifne\n\nThis tool runs a program if the standard input is not empty. The name stands\nfor \u201cif not empty\u201d and it simply runs the passed command to it, if it receives\nat least one byte in the stdin. You can also use the -n flag which causes ifne\nto reverse the operation, e.g., runs the command passed to it if the standard\ninput is empty. Note that if the standard input is not empty, it is passed\nthrough ifne in this case. The below command line checks for core files on the\ncurrent directory, and if found (standard inputs is not empty), sends a mail\nto user root alerting for this fact.\n\n    \n    \n    $ find . -name core | ifne mail -s \"Core files found\" root\n\n### isutf8\n\nThis tool checks if a file or standard input are syntactically valid UTF-8.\nInput is either files named on the command line, or the standard input.\nInformation about files with invalid UTF-8 are printed to standard output,\notherwise nothing is printed.\n\n### lckdo\n\nNote: Now that package util-linux contains a similar command named flock,\nlckdo is deprecated, and will be removed from some future version of\nmoreutils.\n\nThe flock utility runs a program with a lock held, in order to prevent\nmultiple processes from running in parallel. It locks from within shell\nscripts or from the command line. It locks a specified file or directory,\nwhich is created (assuming appropriate permissions) if it does not already\nexist. By default, if the lock cannot be immediately acquired, flock waits\nuntil the lock is available. It can also lock an open file by its file\ndescriptor number. Use it just like nice or nohup.\n\n    \n    \n    (shell1) $ flock /tmp -c cat (shell2) $ flock -w .007 /tmp -c echo; /bin/echo $?\n\nThe first command sets an exclusive lock to directory /tmp and the second\ncommand will fail.\n\n    \n    \n    (shell1) $ flock -s /tmp -c cat (shell2) $ flock -s -w .007 /tmp -c echo; /bin/echo $?\n\nThe first command sets a shared lock to directory /tmp and the second command\nwill not fail. Notice that attempting to get exclusive lock with the second\ncommand would fail.\n\n    \n    \n    $ flock -x local-lock-file echo 'a b c'\n\nThis command grabs the exclusive lock local-lock-file before running echo with\n\u2018a b c\u2019.\n\n### mispipe\n\nThis command pipes two commands together like the shell does, but unlike\npiping in the shell, which returns the exit status of the last command; when\nusing mispipe, the exit status of the first command is returned.\n\nNote: Modern shells, like bash or zsh, offer a pipefail option, although that\noption does not behave the same like mispipe because it makes a failure of any\ncommand in the pipeline to be returned, not just the exit status of the first.\nThis can be a better alternative to mispipe which only returns the exit status\nof the first command passed to it.\n\n### parallel\n\nThis tool runs the specified command, passing it a single one of the specified\narguments. This is repeated for each argument. Jobs may be run in parallel.\nThe default is to run one job per CPU.\n\n    \n    \n    $ parallel sh -c \"echo hi; sleep 2; echo bye\" -- 1 2 3\n\nThe above command runs three subshells that each print a message, delay, and\nprint another message. If your system has multiple CPUs, parallel will run\nsome of the jobs in parallel, which should be clear from the order the\nmessages are output.\n\n    \n    \n    $ parallel -j 3 ufraw -o processed -- *.NEF\n\nThe above command runs three ufraw processes at the same time until all of the\nNEF files have been processed.\n\n    \n    \n    $ parallel -j 3 -- ls df \"echo hi\"\n\nThe above command runs three independent commands (ls, df and the echo) in\nparallel.\n\nNote: check the xargs command to also run multiple processes at a time,\nspecifically with the -n and -P flags.\n\n### pee\n\nThis command is similar to how tee uses the standard input but for pipes,\nhence the name. It allows redirecting output to multiple commands at once.\nEach command is run and fed a copy of the standard input. The output of all\ncommands is sent to stdout. While this is similar to tee, a copy of the input\nis not sent to stdout, like tee does. If that is desired, use pee cat ...\ninstead.\n\n    \n    \n    $ cat file 5 4 3 2 1 $ cat file | pee 'sort -u > sorted' 'sort -R > unsorted' $ cat sorted 1 2 3 4 5 $ cat unsorted 2 1 4 3 5\n\nIn this example, pee receives two commands: one for sorting the contents of\nthe file, and another for randomly sorting the same file contents, outputting\nto two different files named sorted and unsorted, respectively.\n\n### sponge\n\nThis tool reads standard input and writes it out to the specified file. Unlike\na shell redirect, sponge soaks up all its input before writing the output\nfile. This means that it only writes to the file once the input has been fully\nread. This allows constructing pipelines that read from and write to the same\nfile, without needing to redirect the output to temporary files.\n\nInstead of using these commands to sort a file contents:\n\n    \n    \n    $ sort filename | uniq > temp $ mv temp filename\n\nJust use:\n\n    \n    \n    $ sort filename | uniq | sponge filename\n\nNo need to redirecting anymore.\n\n### ts\n\nThis tool adds a timestamp to the beginning of each line of input. This is an\nawesome tool that I like to use specially on a chain of commands where I can\nmeasure how long a given command is taking to complete before passing the\ncontrol to the next command. It is also a great way of logging the time stamps\nof a programs\u2019 output.\n\n    \n    \n    $ cat script.sh echo \"The first line\" sleep 5s echo \"The last line\" $ chmod a+x script.sh $ ./script.sh The first line The last line $ ./script.sh | ts Jul 27 15:50:42 The first line Jul 27 15:50:47 The last line\n\nOne possible use of the ts command is to assert whenever a given machine is up\nand running. Restart a machine and then use ping with the ts to know exactly\nwhen that machine came up to life!\n\n    \n    \n    $ ping <IP address or hostname> | ts Jul 27 15:53:15 PING EE.FF.GG.HH (EE.FF.GG.HH) 56(84) bytes of data. Jul 27 15:53:15 From AA.BB.CC.DD icmp_seq=3 Destination Net Unreachable Jul 27 15:53:18 From AA.BB.CC.DD icmp_seq=7 Destination Net Unreachable (...) Jul 27 15:54:08 64 bytes from EE.FF.GG.HH: icmp_seq=57 ttl=127 time=0.673 ms\n\nThe optional format parameter controls how the timestamp is formatted, as used\nby the C function strftime. The default format is %b %d %H:%M:%S. In addition\nto the regular strftime conversion specifications, %.S and %.s are like %S and\n%s, but provide sub-second resolution (i.e., \u201c30.00001\u201d and\n\u201c1301682593.00001\u201d).\n\n### vidir\n\nThis tool allows editing of the contents of a directory in a text editor\n(check the $EDITOR environment variable, because it will be used for the text\neditor of your choice). If no directory is specified, the current directory is\nedited. When editing a directory, each item in the directory will appear on\nits own numbered line. These numbers are how vidir keeps track of what items\nare changed. Delete lines to remove files from the directory, or edit\nfilenames to rename files. You can also switch pairs of numbers to swap\nfilenames. Note that if \u201c-\u201c is specified as the directory to edit, it reads a\nlist of filenames from stdin and displays those for editing. Alternatively, a\nlist of files can be specified on the command line.\n\n### vipe\n\nThis tool allows you to run your editor in the middle of a unix pipeline and\nedit the data that is being piped between programs (once again, check the\n$EDITOR environment variable for your text editor of choice).\n\n    \n    \n    $ fortune | vipe | cowsay _________________________________________ / \"I am your density.\" \\ | | | -- George McFly in \"Back to the Future\" | | - This fortune cookie was just edited | \\ by Miguel Rentes (in the future!) / ----------------------------------------- \\ ^__^ \\ (oo)\\_______ (__)\\ )\\/\\ ||----w | || ||\n\nOn the above command I edited the fortune cookie before passing it to the\ncowsay command. This is a command that offers you great flexibility and power.\n\n### zrun\n\nThis tool automatically decompresses arguments to command. Prefixing a shell\ncommand with zrun causes any compressed files that are arguments of the\ncommand to be transparently uncompressed to temp files (not pipes) and the\nuncompressed files fed to the command. This is a quick way to run a command\nthat does not itself support compressed files, without manually uncompressing\nthe files. For example, if you want to diff the contents of two archives\nwithout having to uncompress them first, use the following command:\n\n    \n    \n    $ zrun diff archive1.gz archive2.gz\n\nThis command will uncompress automatically the two .gz files and pass the\ncontents to the diff command. Very cool.\n\nThe following compression types are supported: gz bz2 Z xz lzma lzo. If zrun\nis linked to some name beginning with z, like zprog, and the link is executed,\nthis is equivalent to executing zrun prog.\n\nThat\u2019s it! Please don\u2019t forget to read the manpages for greater detail on the\nabove commands. I hope you liked to learn about this fantastic tool package\nand that it motivated you to use it on your daily UNIX programming tasks!\nUntil next time, have an awesome coding fun!\n\n  * \u2190 Previous Post\n  * Next Post \u2192\n\nCopyright \u00a9 Miguel Rentes 2017\n\n", "frontpage": false}
