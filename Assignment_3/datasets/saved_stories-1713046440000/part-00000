{"aid": "40024091", "title": "Is the AI Stack the New 'Modern Data Stack'?", "url": "https://mattturck.com/mad2024/", "domain": "mattturck.com", "votes": 1, "user": "jdenquin", "posted_at": "2024-04-13 16:13:05", "comments": 0, "source_title": "Full Steam Ahead: The 2024 MAD (Machine Learning, AI & Data) Landscape", "source_text": "Full Steam Ahead: The 2024 MAD (Machine Learning, AI & Data) Landscape \u2013 Matt\nTurck\n\nSkip to content\n\nMatt Turck\n\nVC at FirstMark\n\n@mattturck\n\n# Full Steam Ahead: The 2024 MAD (Machine Learning, AI & Data) Landscape\n\nTwitterLinkedinFacebook\n\nThis is our tenth annual landscape and \u201cstate of the union\u201d of the data,\nanalytics, machine learning and AI ecosystem.\n\nIn 10+ years covering the space, things have never been as exciting and\npromising as they are today. All trends and subtrends we described over the\nyears are coalescing: data has been digitized, in massive amounts; it can be\nstored, processed and analyzed fast and cheaply with modern tools; and most\nimportantly, it can be fed to ever-more performing ML/AI models which can make\nsense of it, recognize patterns, make predictions based on it, and now\ngenerate text, code, images, sounds and videos.\n\nThe MAD (ML, AI & Data) ecosystem has gone from niche and technical, to\nmainstream. The paradigm shift seems to be accelerating with implications that\ngo far beyond technical or even business matters, and impact society,\ngeopolitics and perhaps the human condition.\n\nThere are still many chapters to write in the multi-decade megatrend, however.\nAs every year, this post is an attempt at making sense of where we are\ncurrently, across products, companies and industry trends.\n\nHere are the prior versions: 2012, 2014, 2016, 2017, 2018, 2019 (Part I and\nPart II), 2020, 2021 and 2023 (Part I, Part II, Part III, Part IV).\n\nOur team this year was Aman Kabeer and Katie Mills (FirstMark), Jonathan Grana\n(Go Fractional) and Paolo Campos, major thanks to all. And a big thank you as\nwell to CB Insights for providing the card data appearing in the interactive\nversion.\n\nThis annual state of the union post is organized in three parts:\n\n  * Part: I: The landscape (PDF, Interactive version)\n  * Part II: 24 themes we\u2019re thinking about in 2024\n  * Part III: Financings, M&A and IPOs\n\nPART I: THE LANDSCAPE\n\nLinks\n\nTo see a PDF of the 2024 MAD Landscape in full resolution (please zoom!),\nplease CLICK HERE\n\nTo access the interactive version of the 2024 MAD landscape, please CLICK HERE\n\nNumber of companies\n\nThe 2024 MAD landscape features 2,011 logos in total.\n\nThat number is up from 1,416 last year, with 578 new entrants to the map.\n\nFor reference, the very first version in 2012 had just 139 logos.\n\nThe intensely (insanely?) crowded nature of the landscape primarily results\nfrom two back-to-back massive waves of company creation and funding.\n\nThe first wave was the 10-ish year long data infrastructure cycle, which\nstarted with Big Data and ended with the Modern Data Stack. The long awaited\nconsolidation in that space has not quite happened yet, and the vast majority\nof the companies are still around.\n\nThe second wave is the ML/AI cycle, which started in earnest with Generative\nAI. As we are in the early innings of this cycle, and most companies are very\nyoung, we have been liberal in including young startups (a good number of\nwhich are seed stage still) in the landscape.\n\nNote: those two waves are intimately related. A core idea of the MAD Landscape\nevery year has been to show the symbiotic relationship between data\ninfrastructure (on the left side); analytics/BI and ML/AI (in the middle) and\napplications (on the right side).\n\nWhile it gets harder every year to fit the ever-increasing number of companies\non the landscape every year, but ultimately, the best way to think of the MAD\nspace is as an assembly line \u2013 a full lifecycle of data from collection to\nstorage to processing to delivering value through analytics or applications.\n\nTwo big waves + limited consolidation = lots of companies on the landscape.\n\nMain changes in \u201cInfrastructure\u201d and \u201cAnalytics\u201c\n\nWe\u2019ve made very few changes to the overall structure of the left side of the\nlandscape \u2013 as we\u2019ll see below (Is the Modern Data Stack dead?), this part of\nthe MAD landscape has seen a lot less heat lately.\n\nSome noteworthy changes: We renamed \u201cDatabase Abstraction\u201d to \u201cMulti-Model\nDatabases & Abstractions\u201d, to capture the rising wave around an all-in-one\n\u2018Multi-Model\u2019 database group (SurrealDB*, EdgeDB); killed the \u201cCrypto / Web 3\nAnalytics\u201d section we experimentally created last year, which felt out of\nplace in this landscape; and removed the \u201cQuery Engine\u201d section, which felt\nmore like a part of a section than a separate section (all the companies in\nthat section still appear on the landscape \u2013 Dremio, Starburst, PrestoDB etc).\n\nMain changes in \u201cMachine Learning & Artificial Intelligence\u201d\n\nWith the explosion of AI companies in 2023, this is where we found ourselves\nmaking by far the most structural changes.\n\n  * Given the tremendous activity in the \u2018AI enablement\u2019 layer in the last year, we added 3 new categories next to MLOps:\n\n    * \u201cAI Observability\u201d is a new category this year, with startups that help test, evaluate and monitor LLM applications\n    * \u201cAI Developer Platforms\u201d is close in concept to MLOps but we wanted to recognize the wave of platforms that are wholly focused on AI application development, in particular around LLM training, deployment and inference\n    * \u201cAI Safety & Security\u201d includes companies addressing concerns innate to LLMs, from hallucination to ethics, regulatory compliance, etc\n  * If the very public beef between Sam Altman and Elon Musk has told us anything, it\u2019s that the distinction between commercial and nonprofit is a critical one when it comes to foundational model developers. As such, we have split what was previously \u201cHorizontal AI/AGI\u201d into two categories: \u201cCommercial AI Research\u201d and \u201cNonprofit AI Research\u201d\n  * The final change we made was another nomenclature one, where we amended \u201cGPU Cloud\u201d to reflect the addition of core infrastructure feature sets made by many of the GPU Cloud providers: \u201cGPU Cloud / ML Infra\u201d\n\nMain changes in \u201cApplications\u201d\n\n  * The biggest update here is that...to absolutely no one\u2019s surprise...every application-layer company is now a self-proclaimed \u201cAI company\u201d \u2013 which, as much as we tried to filter, drove the explosion of new logos you see on the right side of the MAD landscape this year\n  * Some minor changes on the structure side:\n\n    * In \u201cHorizontal Applications\u201d, we added a \u201cPresentation & Design\u201d category\n    * We renamed \u201cSearch\u201d to \u201cSearch / Conversational AI\u201d to reflect the rise of LLM-powered chat-based interface such as Perplexity.\n    * In \u201cIndustry\u201d, we rebranded \u201cGov\u2019t & Intelligence\u201d to \u201cAerospace, Defense & Gov\u2019t\u201d\n\nMain changes in \u201cOpen Source Infrastructure\u201d\n\n  * We merged categories that have always been close, creating a single \u201cData Management\u201d category that spans both \u201cData Access\u201d and \u201cData Ops\u201d\n  * We added an important new category, \u201cLocal AI\u201d as builders sought to provide the infrastructure tooling to bring AI & LLMs to the local development age\n\nPART II: 24 THEMES WE\u2019RE THINKING ABOUT IN 2024\n\nThings in AI are both moving so fast, and getting so much coverage, that it is\nalmost impossible to provide a fully comprehensive \u201cstate of the union\u201d of the\nMAD space, as we did in prior years.\n\nSo here\u2019s for a different format: in no particular order, here are 24 themes\nthat are top of mind and/or come up frequently in conversations. Some are\nfairly fleshed out thoughts, some largely just questions or thought\nexperiments.\n\n  1. Structured vs unstructured data\n\nThis is partly a theme, partly something we find ourselves mentioning a lot in\nconversations to help explain the current trends.\n\nSo, perhaps as an introduction to this 2024 discussion, here\u2019s one important\nreminder upfront, which explains some of the key industry trends. Not all data\nis the same. At the risk of grossly over-simplifying, there are two main\nfamilies of data, and around each family, a set of tools and use cases has\nemerged.\n\n  * Structured data pipelines: that is data that can fit into rows and columns.\n\n    * For analytical purposes, data gets extracted from transactional databases and SaaS tools, stored in cloud data warehouses (like Snowflake), transformed, and analyzed and visualized using Business Intelligence (BI) tools, mostly for purposes of understanding the present and the past (what\u2019s known as \u201cdescriptive analytics\u201d). That assembly line is often enabled by the Modern Data Stack discussed below, with analytics as the core use case.\n    * In addition, structured data can also get fed in \u201ctraditional\u201d ML/AI models for purposes of predicting the future (predictive analytics) \u2013 for example, which customers are most likely to churn\n  * Unstructured data pipelines: that is the world of data that typically doesn\u2019t fit into rows and columns such as text, images, audio and video. Unstructured data is largely what gets fed in Generative AI models (LLMs, etc), both to train and use (inference) them.\n\nThose two families of data (and the related tools and companies) are\nexperiencing very different fortunes and levels of attention right now.\n\nUnstructured data (ML/AI) is hot; structured data (Modern Data Stack, etc) is\nnot.\n\n  2. Is the Modern Data Stack dead?\n\nNot that long ago (call it, 2019-2021), there wasn\u2019t anything sexier in the\nsoftware world than the Modern Data Stack (MDS). Alongside \u201cBig Data\u201d, it was\none of the rare infrastructure concepts to have crossed over from data\nengineers to a broader audience (execs, journalists, bankers).\n\nThe Modern Data Stack basically covered the kind of structured data pipeline\nmentioned above. It gravitated around the fast-growing cloud data warehouses,\nwith vendors positioned upstream from it (like Fivetran and Airbyte), on top\nof it (DBT) and downstream from it (Looker, Mode).\n\nAs Snowflake emerged as the biggest software IPO ever, interest in the MDS\nexploded, with rabid, ZIRP-fueled company creation and VC funding. Entire\ncategories became overcrowded within a year or two \u2013 data catalogs, data\nobservability, ETL, reverse ETL, to name a few.\n\nA real solution to a real problem, the Modern Data Stack was also a marketing\nconcept and a de-facto alliance amongst a number of startups across the value\nchain of data.\n\nFast forward to today, the situation is very different. In 2023, we had\npreviewed that the MDS was \u201cunder pressure\u201d, and that pressure will only\ncontinue to intensify in 2024.\n\nThe MDS is facing two key issues:\n\n  * Putting together a Modern Data Stack requires stitching together various best-of-breed solutions from multiple independent vendors. As a result, it\u2019s costly in terms of money, time and resources. This is not looked upon favorably by the CFO office in a post ZIRP budget cut era\n  * The MDS is no longer the cool kid on the block. Generative AI has stolen all the attention from execs, VCs and the press \u2013 and it requires the kind of unstructured data pipelines we mentioned above.\n\nWatch: MAD Podcast with Tristan Handy, CEO, dbt Labs (Apple, Spotify)\n\n  3. Consolidation in data infra, and the big getting bigger\n\nGiven the above, what happens next in data infra and analytics in 2024?\n\nIt may look something like this:\n\n  * Many startups in and around the Modern Data Stack will aggressively reposition as \u201cAI infra startups\u201d and try to find a spot in the Modern AI Stack (see below). This will work in some cases, but going from structured to unstructured data may require a fundamental product evolution in most cases.\n  * The data infra industry will finally see some consolidation. M&A has been fairly limited to date, but some acquisitions did happen in 2023, whether tuck-ins or medium-size acquisitions \u2013 including Stemma (acquired by Teradata), Manta (acquired by IBM), Mode (acquired by Thoughtspot), etc (see PART III below)\n  * There will be a lot more startup failure \u2013 as VC funding dried up, things have gotten tough. Many startups have cut costs dramatically, but at some point their cash runway will end. Don\u2019t expect to see flashy headlines, but this will (sadly) happen.\n  * The bigger companies in the space, whether scale-ups or public companies, will double down on their platform play and push hard to cover ever more functionality. Some of it will be through acquisitions (hence the consolidation) but a lot of it will also be through homegrown development.\n\n  4. Checking in on Databricks vs Snowflake\n\nSpeaking of big companies in the space, let\u2019s check in on the \u201ctitanic shock\u201d\n(see our MAD 2021 blog post) between the two key data infra players, Snowflake\nand Databricks.\n\nSnowflake (which historically comes from the structured data pipeline world)\nremains an incredible company, and one of the highest valued public tech\nstocks (14.8x EV/NTM revenue as of the time of writing). However, much like a\nlot of the software industry, its growth has dramatically slowed down \u2013 it\nfinished fiscal 2024 with a 38% year-over-year product revenue growth,\ntotaling $2.67 billion, projecting 22% NTM rev growth as of the time of\nwriting). Perhaps most importantly, Snowflake gives the impression of a\ncompany under pressure on the product front \u2013 it\u2019s been slower to embrace AI,\nand comparatively less acquisitive. The recent, and somewhat abrupt, CEO\ntransition is another interesting data point.\n\nDatabricks (which historically comes from the unstructured data pipeline and\nmachine learning world) is experiencing all-around strong momentum, reportedly\n(as it\u2019s still a private company) closing FY\u201924 with $1.6B in revenue with\n50%+ growth. Importantly, Databricks is emerging as a key Generative AI\nplayer, both through acquisitions (most notably, MosaicML for $1.3B) and\nhomegrown product development \u2013 first and foremost as a key repository for the\nkind of unstructured data that feeds LLMs, but also as creator of models, from\nDolly to DBRX, a new generative AI model the company just announced at the\ntime of writing.\n\nThe major new evolution in the Snowflake vs Databricks rivalry is the launch\nof Microsoft Fabric. Announced in May 2023, it\u2019s an end-to-end, cloud-based\nSaaS platform for data and analytics. It integrates a lot of Microsoft\nproducts, including OneLake (open lakehouse), PowerBI and Synapse Data\nScience, and covers basically all data and analytics workflows, from data\nintegration and engineering to data science. As always for large company\nproduct launches, there\u2019s a gap between the announcement and the reality of\nthe product, but combined with Microsoft\u2019s major push in Generative AI, this\ncould become a formidable threat (as an additional twist to the story,\nDatabricks largely sits on top of Azure).\n\n  5. BI in 2024, and Is Generative AI about to transform data analytics?\n\nOf all parts of the Modern Data Stack and structured data pipelines world, the\ncategory that has felt the most ripe for reinvention is Business Intelligence.\nWe highlighted in the 2019 MAD how the BI industry had almost entirely\nconsolidated, and talked about the emergence of metrics stores in the 2021\nMAD.\n\nThe transformation of BI/analytics has been slower than we\u2019d have expected.\nThe industry remains largely dominated by older products, Microsoft\u2019s PowerBI,\nSalesforce\u2019s Tableau and Google\u2019s Looker, which sometimes get bundled in for\nfree in broader sales contracts. Some more consolidation happened (Thoughtspot\nacquired Mode; Sisu was quietly acquired by Snowflake). Some young companies\nare taking innovative approaches, whether scale-ups (see dbt and their\nsemantic layer/MetricFlow) or startups (see Trace* and their metrics tree),\nbut they\u2019re generally early in the journey.\n\nIn addition to potentially playing a powerful role in data extraction and\ntransformation, Generative AI could have a profound impact in terms of\nsuperpowering and democratizing data analytics.\n\nThere\u2019s certainly been a lot of activity. OpenAI launched Code Interpreter,\nlater renamed to Advanced Data Analysis. Microsoft launched a Copilot AI\nchatbot for finance workers in Excel. Across cloud vendors, Databricks,\nSnowflake, open source and a substantial group of startups, a lot of people\nare working on or have released \u201ctext to SQL\u201d products, to help run queries\ninto databases using natural language.\n\nThe promise is both exciting and potentially disruptive. The holy grail of\ndata analytics has been its democratization. Natural language, if it were to\nbecome the interface to notebooks, databases and BI tools, would enable a much\nbroader group of people to do analysis.\n\nMany people in the BI industry are skeptical, however. The precision of SQL\nand the nuances of understanding the business context behind a query are\nconsidered big obstacles to automation.\n\n  6. The Rise of the Modern AI Stack\n\nA lot of what we\u2019ve discussed so far had to do with the world of structured\ndata pipelines.\n\nAs mentioned, the world of unstructured data infrastructure is experiencing a\nvery different moment. Unstructured data is what feeds LLMs, and there\u2019s rabid\ndemand for it. Every company that\u2019s experimenting or deploying Generative AI\nis rediscovering the old cliche: \u201cdata is the new oil\u201d. Everyone wants the\npower of LLMs, but trained on their (enterprise) data.\n\nCompanies big and small have been rushing into the opportunity to provide the\ninfrastructure of Generative AI.\n\nSeveral AI scale-ups have been aggressively evolving their offerings to\ncapitalize on market momentum \u2013 everyone from Databricks (see above) to Scale\nAI (which evolved their labeling infrastructure, originally developed for the\nself-driving car market, to partner as an enterprise data pipeline with OpenAI\nand others) to Dataiku* (which launched their LLM Mesh to enable Global 2000\ncompanies to seamlessly work across multiple LLM vendors and models).\n\nMeanwhile a new generation of AI infra startups is emerging, across a number\nof domains, including:\n\n  * Vector databases, which store data in a format (vector embeddings) that Generative AI models can consume. Specialized vendors (Pinecone, Weaviate, Chroma, Qudrant etc) have had a banner year, but some incumbent database players (MongoDB) were also quick to react and add vector search capabilities. There\u2019s also an ongoing debate about whether longer context windows will obviate the need for vector databases altogether, with strong opinions on both sides of the argument.\n  * Frameworks (LlamaIndex, Langchain etc), which connect and orchestrate all the moving pieces\n  * Guardrails, which sit between an LLM and users and make sure the model provides outputs that follow the organization\u2019s rules.\n  * Evaluators which help test, analyze and monitor Generative AI model performance, a hard problem as demonstrated by the general distrust in public benchmarks\n  * Routers, which help direct user queries across different models in real time, to optimize performance, cost and user experience\n  * Cost guards, which help monitor the costs of using LLMs\n  * Endpoints, effectively APIs that abstract away the complexities of underlying infrastructure (like models)\n\nWe\u2019ve been resisting using the term \u201cModern AI Stack\u201d, given the history of\nthe Modern Data Stack.\n\nBut the expression captures the many parallels: many of those startups are the\n\u201chot companies\u201d of the day, just like MDS companies before them, they tend to\ntravel in pack, forging marketing alliances and product partnerships.\n\nAnd this new generation of AI infra startups is going to face some of the same\nchallenges as MDS companies before them: are any of those categories big\nenough to build a multi-billion dollar company? Which part will big companies\n(mostly cloud providers, but also Databricks and Snowflake) end up building\nthemselves?\n\nWATCH \u2013 we have featured many emerging Modern AI Stack startups on the MAD\nPodcast:\n\n  * Vector databases:\n\n    * MAD Podcast with Edo Liberty, CEO, Pinecone (Apple, Spotify)\n    * MAD Podcast with Jeff Huber, CEO, Chroma (Apple, Spotify)\n    * MAD Podcast with Bob van Luijt, Weaviate (Apple, Spotify)\n  * MAD Podcast with Shreya Rajpal, CEO, Guardrails AI (Apple, Spotify)\n  * MAD Podcast with Jerry Liu, CEO, Llama Index (Apple, Spotify)\n  * MAD Podcast with Sharon Zhou, CEO, Lamini (Apple, Spotify)\n  * MAD Podcast with Dylan Fox, CEO, Assembly AI (Apple, Spotify)\n\n  7. Where are we in the AI hype cycle?\n\nAI has a multi decade-long history of AI summers and winters. Just in the last\n10-12 years, this is the third AI hype cycle we\u2019ve experienced: there was one\nin 2013-2015 after deep learning came to the limelight post ImageNet 2012;\nanother one sometime around 2017-2018 during the chatbot boom and the rise of\nTensorFlow; and now since November 2022 with Generative AI.\n\nThis hype cycle has been particularly intense, to the point of feeling like an\nAI bubble, for a number of reasons: the technology is incredibly impressive;\nit is very visceral and crossed over to a broad audience beyond tech circles;\nand for VCs sitting on a lot of dry powder, it\u2019s been the only game in town as\njust about everything else in technology has been depressed.\n\nHype has brought all the usual benefits (\u201cnothing great has ever been achieved\nwithout irrational exuberance\u201d, \u201clet a 1000 flowers bloom\u201d phase, with lots of\nmoney available for ambitious projects) and noise (everyone is an AI expert\novernight, every startup is an AI startup, too many AI\nconferences/podcasts/newsletters... and dare we say, too many AI market\nmaps???).\n\nThe main issue of any hype cycle is the inevitable blowback.\n\nThere\u2019s a fair amount of \u201cquirkiness\u201d and risk built into this market phase:\nthe poster-child company for the space has a very unusual legal and governance\nstructure; there are a lot of \u201ccompute for equity\u201d deals happening (with\npotential round-tripping) that are not fully understood or disclosed; a lot of\ntop startups are run by teams of AI researchers; and a lot of VC dealmaking is\nreminiscent of the ZIRP times: \u201cland grabs\u201d, big rounds and eye-watering\nvaluations for very young companies.\n\nThere certainly have been cracks in AI hype (see below), but we\u2019re still in a\nphase where every week a new thing blows everyone\u2019s minds. And news like the\nreported $40B Saudi Arabia AI fund seem to indicate that money flows into the\nspace are not going to stop anytime soon.\n\n  8. Experiments vs reality: was 2023 a headfake?\n\nRelated to the above \u2013 given the hype, how much has been real so far, vs\nmerely experimental?\n\n2023 was an action packed year: a) every tech vendor rushed to include\nGenerative AI in their product offering, b) every Global 2000 board mandated\ntheir teams to \u201cdo AI\u201d, and some enterprise deployments happened a record\nspeed, including at companies in regulated industries like Morgan Stanley and\nCitibank and c) of course, consumers showed rabid interest for Generative AI\napps.\n\nAs a result, 2023 was a year of big wins: OpenAI reached $2B in annual run\nrate; Anthropic grew at a pace that allowed it to forecast $850M in revenues\nfor 2024; Midjourney grew to $200M in revenue with no investment and a team of\n40; Perplexity AI went from 0 to 10 million monthly active users, etc.\n\nShould we be cynical? Some concerns:\n\n  * In the enterprise, a lot of the spend was on proof of concepts, or easy wins, often coming out of innovation budgets.\n  * How much was driven by executives wanting to not appear flat-footed, vs solving actual business problems?\n  * In consumer, AI apps show high churn. How much was it mere curiosity?\n  * Both in their personal and professional lives, many report not being entirely sure what to do with Generative AI apps and products\n  * Not all Generative AI products, even those built by the best AI minds, are going to be magical: should we view Inflection AI\u2019s decision to fold quickly, after raising $1.3B, as an admission that the world doesn\u2019t need yet another AI chatbot, or even LLM provider?\n\n  9. LLM companies: maybe not so commoditized after all?\n\nBillions of venture capital and corporate money are being invested in\nfoundational model companies.\n\nHence everyone\u2019s favorite question in the last 18 months: are we witnessing a\nphenomenal incineration of capital into ultimately commoditized products? Or\nare those LLM providers the new AWS, Azure and GCP?\n\nA troubling fact (for the companies involved) is that no LLM seems to be\nbuilding a durable performance advantage. At the time of writing, Claude 3\nSonnet and Gemini Pro 1.5 perform better than GPT-4 which performs better than\nGemini 1.0 Ultra, and so on and so forth \u2013 but this seems to change every few\nweeks. Performance also can fluctuate \u2013 ChatGPT at some point \u201clost its mind\u201d\nand \u201cgot lazy\u201d, temporarily.\n\nIn addition, open source models (Llama 3, Mistral and others like DBRX) are\nquickly catching up in terms of performance.\n\nSeparately \u2013 there are a lot more LLM providers on the market than could have\nappeared at first. A couple of years ago, the prevailing narrative was that\nthere could be only one or two LLM companies, with a winner-take-all dynamic \u2013\nin part because there was a tiny number of people around the world with the\nnecessary expertise to scale Transformers.\n\nIt turns out there are more capable teams than first anticipated. Beyond\nOpenAI and Anthropic, there are a number of startups doing foundational AI\nwork \u2013 Mistral, Cohere, Adept, AI21, Imbue, 01.AI to name a few \u2013 and then of\ncourse the teams at Google, Meta, etc.\n\nHaving said that \u2013 so far the LLM providers seem to be doing just fine. OpenAI\nand Anthropic revenues are growing at extraordinary rates, thank you very\nmuch. Maybe the LLM models do get commoditized, the LLM companies still have\nan immense business opportunity in front of them. They\u2019ve already become \u201cfull\nstack\u201d companies, offering applications and tooling to multiple audiences\n(consumer, enterprise, developers), on top of the underlying models.\n\nPerhaps the analogy with cloud vendors is indeed pretty apt. AWS, Azure and\nGCP attract and retain customers through an application/tooling layer and\nmonetize through a compute/storage layer that is largely undifferentiated.\n\n> Breaking: Anthropic working on its most powerful model yet, Jean-Claude\n> pic.twitter.com/geJFls6yHs\n>\n> \u2014 Matt Turck (@mattturck) March 4, 2024\n\nWATCH:\n\n  * MAD Podcast with Ori Goshen, co-founder, AI21 Labs\n  * MAD Podcast with Kanjun Qiu, CEO, Imbue\n\n  10. LLMs, SLMs and a hybrid future\n\nFor all the excitement about Large Language Models, one clear trend of the\nlast few months has been the acceleration of small language models (SLMs),\nsuch as Llama-2-13b from Meta, Mistral-7b and Mixtral 8x7b from Mistral and\nPhi-2 and Orca-2 from Microsoft.\n\nWhile the LLMs are getting ever bigger (GPT-3 reportedly having 175 billion\nparameters, GPT-4 reportedly having 1.7 trillion, and the world waiting for an\neven more massive GPT-5), SLMs are becoming a strong alternative for many use\ncases are they are cheaper to operate, easier to finetune, and often offer\nstrong performance.\n\nAnother trend accelerating is the rise of specialized models, focused on\nspecific tasks like coding (Code-Llama, Poolside AI) or industries (e.g.\nBloomberg\u2019s finance model, or startups Orbital Materials building models for\nmaterial sciences, etc).\n\nAs we are already seeing across a number of enterprise deployments, the world\nis quickly evolving towards hybrid architectures, combining multiple models.\n\nAlthough prices have been going down (see below), big proprietary LLMs are\nstill very expensive, experience latency problems, and so users/customers will\nincreasingly be deploying combinations of models, big and small, commercial\nand open source, general and specialized, to meet their specific needs and\ncost constraints.\n\nWatch: MAD Podcast with Eiso Kant, CTO, Poolside AI (Apple, Spotify)\n\n  11. Is traditional AI dead?\n\nA funny thing happened with the launch of ChatGPT: much of the AI that had\nbeen deployed up until then got labeled overnight as \u201cTraditional AI\u201d, in\ncontrast to \u201cGenerative AI\u201d.\n\nThis was a little bit of a shock to many AI practitioners and companies that\nup until then were considered to be doing leading-edge work, as the term\n\u201ctraditional\u201d clearly suggests an impending wholesale replacement of all forms\nof AI by the new thing.\n\nThe reality is a lot more nuanced. Traditional AI and Generative AI are\nultimately very complementary as they tackle different types of data and use\ncases.\n\nWhat is now labeled as \u201ctraditional AI\u201d, or occasionally as \u201cpredictive AI\u201d or\n\u201ctabular AI\u201d, is also very much part of modern AI (deep learning based).\nHowever, it generally focuses on structured data (see above), and problems\nsuch as recommendations, churn prediction, pricing optimization, inventory\nmanagement. \u201cTraditional AI\u201d has experienced tremendous adoption in the last\ndecade, and it\u2019s already deployed at scale in production in thousands of\ncompanies around the world.\n\nIn contrast, Generative AI largely operates on unstructured data (text, image,\nvideos, etc.). Is exceptionally good at a different class of problems (code\ngeneration, image generation, search, etc).\n\nHere as well, the future is hybrid: companies will use LLMs for certain tasks,\npredictive models for other tasks. Most importantly, they will often combine\nthem \u2013 LLMs may not be great at providing a precise prediction, like a churn\nforecast, but you could use an LLM that calls on the output of another model\nwhich is focused on providing that prediction, and vice versa.\n\n  12. Thin wrappers, thick wrappers and the race to be full stack\n\n\u201cThin wrappers\u201d was the dismissive term everyone loved to use in 2023. It\u2019s\nhard to build long lasting value and differentiation if your core capabilities\nare provided by someone else\u2019s technology (like OpenAI), the argument goes.\nAnd reports a few months ago that startups like Jasper were running into\ndifficulties, after experiencing a meteoric revenue rise, seem to corroborate\nthat line of thinking.\n\nThe interesting question is what happens over time, as young startups build\nmore functionality. Do thin wrappers become thick wrappers?\n\nIn 2024, it feels like thick wrappers have a path towards differentiation by:\n\n  * Focusing on a specific problem, often vertical \u2013 as anything too horizontal runs the risk of being in the \u201ckill zone\u201d of Big Tech\n  * Building workflow, collaboration and deep integrations, that are specific to that problem\n  * Doing a lot of work at the AI model level \u2013 whether finetuning models with specific datasets or creating hybrid systems (LLMs, SLMs, etc) tailored for their specific business\n\nIn other words, they will need to be both narrow and \u201cfull stack\u201d (both\napplications and infra).\n\n  13. Interesting areas to watch in 2024: AI agents, Edge AI\n\nThere\u2019s been plenty of excitement over the last year around the concept of AI\nagents \u2013 basically the last mile of an intelligent system that can execute\ntasks, often in a collaborative manner. This could be anything from helping to\nbook a trip (consumer use case) to automatically running full SDR campaigns\n(productivity use case) to RPA-style automation (enterprise use case).\n\nAI agents are the holy grail of automation \u2013 a \u201ctext to action\u201d paradigm where\nAI just gets stuff done for us.\n\nEvery few months, the AI world goes crazy for an agent-like product, from\nBabyAGI last year to Devin AI (an \u201cAI software engineer\u201d) just recently.\nHowever, in general, much of this excitement has proven premature to date.\nThere\u2019s a lot of work to be done first to make Generative less brittle and\nmore predictable, before complex systems involving several models can work\ntogether and take actual actions on our behalf. There are also missing\ncomponents \u2013 such as the need to build more memory into AI systems. However,\nexpect AI agents to be a particularly exciting area in the next year or two.\n\nAnother interesting area is Edge AI. As much as there is a huge market for\nLLMs that run at massive scale and delivered as end points, a holy grail in AI\nhas been models that can run locally on a device, without GPUs, in particular\nphones, but also intelligent, IoT-type devices. The space is very vibrant:\nMixtral, Ollama, Llama.cpp, Llamafile, GPT4ALL (Nomic). Google and Apple are\nalso likely to be increasingly active.\n\n  14. Is Generative AI heading towards AGI, or towards a plateau?\n\nIt\u2019s almost a sacrilegious question to ask given all the breathless takes on\nAI, and the incredible new products that seem to come out every week \u2013 but is\nthere a world where progress in Generative AI slows down rather than\naccelerates all the way to AGI? And what would that mean?\n\nThe argument is twofold: a) foundational models are a brute force exercise,\nand we\u2019re going to run out of resources (compute, data) to feed them, and b)\neven if we don\u2019t run out, ultimately the path to AGI is reasoning, which LLMs\nare not capable of doing.\n\nInterestingly, this is more or less the same discussion as the industry was\nhaving 6 years ago, as we described in a 2018 blog post. Indeed what seems to\nhave changed mostly since 2018 is the sheer amount of data and compute we\u2019ve\nthrown at (increasingly capable) models.\n\nHow much progress we\u2019ve made in AI reasoning is less clear, overall \u2013 although\nDeepMind\u2019s program AlphaGeometry seems to be an important milestone, as it\ncombines a language model with a symbolic engine, which logical rules to make\ndeductions.\n\nHow close we are from any kind of \u201crunning out\u201d of compute or data is very\nhard to assess.\n\nThe frontier for \u201crunning out of compute\u201d seems to be pushed back further\nevery day. NVIDIA\u2019s recently announced Blackwell GPU system, and the company\nsays it can deploy a 27 trillion parameter model (vs 1.7 trillion for GPT-4).\n\nThe data part is complex \u2013 there\u2019s a more tactical question around running out\nof legally licensed data (see all the OpenAI licensing deals), and a broader\nquestion around running out of textual data, in general. There is certainly a\nlot of work happening around synthetic data. Yann LeCun discussed how taking\nmodels to the next level would probably require them to be able to ingest much\nricher video input, which is not yet possible.\n\nThere\u2019s a tremendous amount of expectations on GPT-5. How much better it will\nbe than GPT-4 will be widely viewed as a bellwether of the overall pace of\nprogress in AI.\n\nFrom the narrow perspective of participants in the startup ecosystem\n(founders, investors), perhaps the question matters less, in the medium term \u2013\nif progress in Generative AI reached an asymptote tomorrow, we\u2019d still have\nyears of business opportunity ahead deploying what we currently have across\nverticals and use cases.\n\n  15. The GPU wars (is NVIDIA overvalued?)\n\nAre we in the early innings of a massive cycle where compute becomes the most\nprecious commodity in the world, or dramatically over-building GPU production\nin a way that\u2019s sure to lead to a big crash?\n\nAs pretty much the only game in town when it comes to Generative AI-ready\nGPUs, NVIDIA certainly has been having quite the moment, with a share price up\nfive-fold to a $2.2 trillion valuation, and total sales three-fold since late\n2022, massive excitement around its earnings and Jensen Huang at GTC rivaling\nTaylor Swift for the biggest event of 2024.\n\n> Love this shot of Jensen Huang from the NVIDIA Q4 results announcement\n> pic.twitter.com/9BrJgv88Yq\n>\n> \u2014 Matt Turck (@mattturck) February 22, 2024\n\nPerhaps this was also in part because it was the ultimate beneficiary of all\nthe billions invested by VCs in AI?\n\n> Generative AI investing: a process by which venture capital firms transfer\n> large amounts of money to NVIDIA via intermediaries known as \u201cstartups\u201d\n>\n> \u2014 Matt Turck (@mattturck) June 14, 2023\n\nRegardless, for all its undeniable prowess as a company, NVIDIA\u2019s fortunes\nwill be tied to how sustainable the current gold rush will turn out to be.\nHardware is hard, and predicting with accuracy how many GPUs need to be\nmanufactured by TSMC in Taiwan is a difficult art.\n\nIn addition, competition is trying its best to react, from AMD to Intel to\nSamsung; startups (like Groq or Cerebras) are accelerating, and new ones may\nbe formed, like Sam Altman\u2019s rumored $7 trillion chip company. A new coalition\nof tech companies including Google, Intel and Qualcomm is trying to go after\nNVIDIA\u2019s secret weapon: its CUDA software that keeps developers tied to Nvidia\nchips.\n\nOur take: As the GPU shortage subsides, there may be short-to medium term\ndownward pressure on NVIDIA, but the long term for AI chips manufacturers\nremains incredibly bright.\n\n  16. Open source AI: too much of a good thing?\n\nThis one is just to stir a pot a little bit. We\u2019re huge fans of open source\nAI, and clearly this has been a big trend of the last year or so. Meta made a\nmajor push with its Llama models, France\u2019s Mistral went from controversy\nfodder to new shining star of Generative AI, Google released Gemma, and\nHuggingFace continued its ascension as the ever so vibrant home of open source\nAI, hosting a plethora of models. Some of the most innovative work in\nGenerative AI has been done in the open source community.\n\nHowever, there\u2019s also a general feeling of inflation permeating the open\nsource community. Hundreds of thousands of open source AI models are now\navailable. Many are toys or weekend projects. Models go up and down the\nrankings, some of them experiencing meteoric rises by Github star standards (a\nflawed metric, but still) in just a few days, only to never transform into\nanything particularly usable.\n\nThe market will be self-correcting, with a power law of successful open-source\nprojects that will get disproportionate support from cloud providers and other\nbig tech companies. But in the meantime, the current explosion has been\ndizzying to many.\n\n  17. How much does AI actually cost?\n\nThe economics of Generative AI is a fast-evolving topic. And not surprisingly,\na lot of the future of the space revolves around it \u2013 for example, can one\nseriously challenge Google in search, if the cost of providing AI-driven\nanswers is significantly higher than the cost of providing ten blue links? And\ncan software companies truly be AI-powered if the inference costs eat up\nchunks of their gross margin?\n\nThe good news, if you\u2019re a customer/user of AI models: we seem to be in the\nearly phase of a race to the bottom on the price side, which is happening\nfaster than one may have predicted. One key driver has been the parallel rise\nof open source AI (Mistral etc) and commercial inference vendors (Together AI,\nAnyscale, Replit) taking those open models and serving them as end points.\nThere are very little switching costs for customers (other than the complexity\nof working with different models producing different results), and this is\nputting pressure on OpenAI and Anthropic. An example of this has been the\nsignificant cost drops for embedding models where multiple vendors (OpenAI,\nTogether AI etc) dropped prices at the same time.\n\nFrom a vendor perspective, the costs of building and serving AI remain very\nhigh. It was reported in the press that Anthropic spent more than half of the\nrevenue it generated paying cloud providers like AWS and GCP to run its LLMs.\nThere\u2019s the cost of licensing deals with publishers as well\n\nOn the plus side, maybe all of us as users of Generative technologies should\njust enjoy the explosion of VC-subsidized free services:\n\n> VCs brought you cheap Ubers\n>\n> VCs brought you cheap Airbnbs\n>\n> VCs are bringing you cheap AI inference\n>\n> YOU'RE WELCOME\n>\n> \u2014 Matt Turck (@mattturck) January 26, 2024\n\nWatch: MAD Podcast with Brandon Duderstadt and Zach Nussbaum, Nomic\n\n  18. Big companies and the shifting political economy of AI: Has Microsoft won?\n\nThis was one of the first questions everyone asked in late 2022, and it\u2019s even\nmore top of mind in 2024: will Big Tech capture most of the value in\nGenerative AI?\n\nAI rewards size \u2013 more data, more compute, more AI researchers tends to yield\nmore power. Big Tech has been keenly aware of this. Unlike incumbents in prior\nplatform shifts, it has also been intensely reactive to the potential\ndisruption ahead.\n\nAmong Big Tech companies, it certainly feels like Microsoft has been playing\n4-D chess. There\u2019s obviously the relationship with OpenAI, in which Microsoft\nfirst invested in 2019, and has now backed to the tune of $13B. But Microsoft\nalso partnered with open source rival Mistral. It invested in ChatGPT rival\nInflection AI (Pi), only to acqui-hire it in spectacular fashion recently.\n\nAnd ultimately, all those partnerships seem to only create more need for\nMicrosoft\u2019s cloud compute \u2013 Azure revenue grew 24% year-over-year to reach $33\nbillion in Q2 2024, with 6 points of Azure cloud growth attributed to AI\nservices.\n\n> In case you\u2019re confused:\n>\n> Microsoft is the biggest investor in OpenAI but also a competitor to OpenAI\n> and an investor in competitor chatbot Inflection AI \u2013 meanwhile Microsoft is\n> also a key partner, but also a competitor, to Databricks with Azure AI\n>\n> Hope this clarifies\n>\n> \u2014 Matt Turck (@mattturck) November 7, 2023\n\nMeanwhile, Google and Amazon have partnered with and invested in OpenAI rival\nAnthropic (at the time of writing, Amazon just committed another $2.75B to the\ncompany, in the 2nd tranche of its planned $4B investment). Amazon also\npartnered with open source platform Hugging Face. Google and Apple are\nreportedly discussing an integration of Gemini AI in Apple products. Meta is\npossibly under-cutting everyone by going full hog on open source AI. Then\nthere is everything happening in China.\n\nThe obvious question is how much room there is for startups to grow and\nsucceed. A first tier of startups (OpenAI and Anthropic, mainly, with perhaps\nMistral joining them soon) seem to have struck the right partnerships, and\nreached escape velocity. For a lot of other startups, including very well\nfunded ones, the jury is still very much out.\n\nShould we read in Inflection AI\u2019s decision to let itself get acquired, and\nStability AI\u2019s CEO troubles, an admission that commercial traction has been\nharder to achieve for a group of \u201csecond tier\u201d Generative AI startups?\n\n  19. Fanboying OpenAI \u2013 or not?\n\nOpenAI continues to fascinate \u2013 the $86B valuation, the revenue growth, the\npalace intrigue, and Sam Altman being the Steve Jobs of this generation:\n\n> Sam Altman returning to OpenAI after a day is like Steve Jobs returning to\n> Apple after 12 years, but for the TikTok generation https://t.co/AHqH7WmVfF\n>\n> \u2014 Matt Turck (@mattturck) November 18, 2023\n\nA couple of interesting questions:\n\nIs OpenAI trying to do too much? Before all the November drama, there was the\nOpenAI Dev Day, during which OpenAI made it clear that it was going to do\n*everything* in AI, both vertically (full stack) and horizontally (across use\ncases): models + infrastructure + consumer search + enterprise + analytics +\ndev tools + marketplace, etc. It\u2019s not an unprecedented strategy when a\nstartup is an early leader in a big paradigm shift with de facto unlimited\naccess to capital (Coinbase sort of did it in crypto). But it will be\ninteresting to watch: while it would certainly simplify the MAD Landscape,\nit\u2019s going to be a formidable execution challenge, particularly in a context\nwhere competition has intensified. From ChatGPT laziness issues to the\nunderwhelming performance of its marketplace effort suggest that OpenAI is not\nimmune to the business law of gravity.\n\nWill OpenAI and Microsoft break up? The relationship with Microsoft has been\nfascinating \u2013 obviously Microsoft\u2019s support has been a huge boost for OpenAI\nin terms of resources (including compute) and distribution (Azure in the\nenterprise), and the move was widely viewed as a master move by Microsoft in\nthe early days of the Generative AI wave. At the same time, as just mentioned\nabove, Microsoft has made it clear that it\u2019s not dependent on OpenAI (has all\nthe code, weights, data), it has partnered with competitors (e.g. Mistral),\nand through the Inflection AI acqui-hire it now has considerably beefed up its\nAI research team.\n\nMeanwhile, will OpenAI want to continue being single threaded in a partnership\nwith Microsoft, vs being deployed on other clouds?\n\nGiven OpenAI\u2019s massive ambitions, and Microsoft aim at global domination, at\nwhat point do both companies conclude that they\u2019re more competitors than\npartners?\n\n  20. Will 2024 be the year of AI in the enterprise?\n\nAs mentioned above, 2023 in the enterprise (defined, directionally, as Global\n2000 companies) felt like one of those pivotal years where everyone scrambles\nto embrace a new trend, but nothing much actually happens.\n\nThere were some proof-of-concepts, and adoption of discreet AI products that\nprovide \u201cquick wins\u201d without requiring a company-wide effort (e.g., AI video\nfor training and enterprise knowledge, like Synthesia*).\n\nBeyond those, perhaps the biggest winners of Generative AI in the enterprise\nso far have been the Accentures of the world (Accenture reportedly generated\n$2B in fees for AI consulting last year).\n\n> Big winners of the AI craze so far: consultants.\n>\n> \u2014 Matt Turck (@mattturck) May 12, 2023\n\nRegardless, there\u2019s tremendous hope that 2024 is going to be a big year for AI\nin the enterprise \u2013 or at least for Generative AI, as traditional AI already\nhas a significant footprint there already (see above).\n\nBut we\u2019re early in answering some of the key questions Global 2000-type\ncompanies face:\n\nWhat are the use cases? The low hanging fruit use cases so far have been\nmostly a) code generation co-pilots for developer teams, b) enterprise\nknowledge management (search, text summarization, translation, etc), and c) AI\nchatbots for customer service (a use case that pre-dates Generative AI). There\nare certainly others (marketing, automated SDRs etc) but there\u2019s a lot to\nfigure out (co-pilot mode vs full automation etc).\n\nWhat tools should we pick? As per the above, it feels like the future is\nhybrid, a combination of commercial vendors and open source, big and small\nmodels, horizontal and vertical GenAI tools. But where does one start?\n\nWho will be deploying and maintaining the tools? There is a clear skill\nshortage in Global 2000 companies. If you thought recruiting software\ndevelopers was hard, just try to recruit machine learning engineers.\n\nHow do we make sure they don\u2019t hallucinate? Yes there\u2019s a tremendous amount of\nwork being done around RAG and guardrails and evaluations etc, but the\npossibility that a Generative AI tool may be plain wrong, and the broader\nquestion that we don\u2019t really know how Generative AI models work, are big\nproblems in the enterprise.\n\nWhat is the ROI? Large tech companies have been early in leveraging Generative\nAI for their own needs, and they\u2019re showing interesting early data. In their\nearnings call, Palo Alto Networks mentioned roughly halving the cost of their\nT&E servicing, and ServiceNow mentioned increasing our developer innovation\nspeed by 52%, but we\u2019re early in understanding the cost / return equation for\nGenerative AI in the enterprise.\n\nThe good news for Generative AI vendors is that there\u2019s plenty of interest\nfrom enterprise customers to allocate budget (importantly, no longer\n\u201cinnovation\u201d budgets but actual OpEx budget, possibly re-allocated from other\nplaces) and resources to figuring it out. But we\u2019re probably talking about a\n3-5 year deployment cycle, rather than one.\n\nWATCH:\n\n  * MAD Podcast with Florian Douetteau, CEO, Dataiku (Apple, Spotify)\n  * MAD Podcast with Victor Riparbelli, CEO, Synthesia (Apple, Spotify)\n  * MAD Podcast with Mike Murchison, CEO, Ada (Apple, Spotify)\n\n  21. Is AI going to kill SaaS?\n\nThis was one of the trendy ideas of the last 12 months.\n\nOne version of the question: AI makes it 10x to code, so with just a few\naverage developers, you\u2019ll be able to create a custom-made version of a SaaS\nproduct, tailored to your needs. Why pay a lot of money to a SaaS provider\nwhen you can build your own.\n\nAnother version of the question: the future is one AI intelligence (possibly\nmade of several models) that runs your whole company with a series of agents.\nYou no longer buy HR software, finance software or sales software because the\nAI intelligence does everything, in a fully automated and seamless way.\n\nWe seem to be somewhat far away from both of those trends actually happening\nin any kind of full-fledged manner, but as we all know, things change very\nfast in AI.\n\nIn the meantime, it feels like a likely version of the future is that SaaS\nproducts are going to become more powerful as AI gets built into every one of\nthem.\n\n  22. Is AI going to kill venture capital?\n\nLeaving aside the (ever-amusing) topic of whether AI could automate venture\ncapital, both in terms of company selection, and post-investment value-add,\nthere\u2019s an interesting series of questions around whether the asset class is\ncorrectly-sized for the AI platform shift:\n\nIs Venture Capital too small? The OpenAIs of the world have needed to raise\nbillions of dollars, and may need to raise many more billions. A lot of those\nbillions have been provided by big corporations like Microsoft \u2013 probably in\nlarge part in the form of compute-for-equity deals, but not only. Of course,\nmany VCs have also invested in big foundational model companies, but at a\nminimum, those investments in highly capital-intensive startups are a clear\ndeparture from the traditional VC software investing model. Perhaps AI\ninvesting, at least when it comes to LLM companies, is going to require mega-\nsized VC funds \u2013 at the time of writing, Saudi Arabia seems to be about to\nlaunch a $40B AI fund in collaboration with US VC firms.\n\nIs Venture Capital too big? If you believe that AI is going to 10x our\nproductivity, including super coders and automated SDR agents and automated\nmarketing creation, then we\u2019re about to witness the birth of a whole\ngeneration of fully-automated companies run by skeleton teams (or maybe just\none solo-preneur) that could theoretically reach hundreds of millions in\nrevenues (and go public)? Does a $100M ARR company run by a solopreneur need\nventure capital ?\n\nReality is always more nuanced, but if one believes real value creation will\nhappen either at the foundation model layer or at the application layer,\nthere\u2019s a world where the venture capital asset class, as it exists today,\ngets uncomfortably barbelled .\n\n  23. Will AI revive consumer?\n\nConsumer has been looking for its next wind since the social media and mobile\ndays. Generative AI may very well be it.\n\nAs a particularly exciting example, MidJourney emerged seemingly out of\nnowhere with somewhere between $200M and $300M, and it\u2019s presumably vastly\nprofitable given it has a small team (40-60 people depending on who you ask).\n\nSome interesting areas (among many others):\n\nSearch: for the first time in decades, Google\u2019s search monopoly has some\nearly, but credible competitors. A handful of startups like Perplexity AI and\nYou.com are leading the evolution from search engines to answer engines.\n\nAI companions: beyond the dystopian aspects, what if every human had an\ninfinitely patient and helpful companion attuned to one\u2019s specific needs,\nwhether for knowledge, entertainment or therapy\n\n> Surprisingly controversial take: hyper-personalized companion AI that can be\n> your best friend and/or an always-on therapist is not dystopian, and instead\n> a major net positive for humanity that will lead to less loneliness,\n> violence and perhaps wars.\n>\n> \u2014 Matt Turck (@mattturck) December 17, 2023\n\nAI hardware: Humane, Rabbit, VisionPro are exciting entries in consumer\nhardware\n\nHyper-personalized entertainment: what new forms of entertainment and art will\nwe invent as Generative AI powered tools keep getting better (and cheaper)?\n\n> Movie watching experience:\n>\n> 2005: go to a movie theater\n>\n> 2015: stream Netflix\n>\n> 2025: ask LLM + text-to-video to create a new season of Narcos to watch\n> tonight, but have it take place in Syria with Brad Pitt, Mr Beast and Travis\n> Kelce in the leading roles\n>\n> \u2014 Matt Turck (@mattturck) February 15, 2024\n\nWatch:\n\n  * MAD Podcast with Aravind Srinivas, CEO, Perplexity AI (Apple, Spotify)\n  * MAD Podcast with Richard Socher, CEO, You.com (Apple, Spotify)\n  * MAD Podcast with Cris Valenzuela, CEO, Runway (Apple, Spotify)\n\n  24. AI and blockchain: BS, or exciting?\n\nI know, I know. The intersection of AI and crypto feels like perfect fodder\nfor X/Twitter jokes.\n\nHowever, it is an undeniable concern that AI is getting centralized in a\nhandful of companies that have the most compute, data and AI talent \u2013 from Big\nTech to the famously-not-open OpenAI. Meanwhile, the very core of the\nblockchain proposition is to enable the creation of decentralized networks\nthat allow participants to share resources and assets. There is fertile ground\nfor exploration there, a topic we started exploring years ago (presentation).\n\nA number of AI-related crypto projects have experienced noticeable\nacceleration, including Bittensor* (decentralized machine intelligence\nplatform), Render (decentralized GPU rendering platform), Arweave\n(decentralized data platform).\n\nWhile we didn\u2019t include a crypto section in this year\u2019s MAD Landscape, this is\nan interesting area to watch.\n\nNow, as always, the question is whether the crypto industry will be able to\nhelp itself, and not devolve into hundreds of AI-related memecoins, pump-and-\ndump schemes and scams.\n\nBONUS: Other topics we did not discuss here:\n\n  * Will AI kill us all? AI doomers vs AI accelerationists\n  * Regulation, privacy, ethics, deep fakes\n  * Can AI only be \u201cmade\u201d in SF?\n\n> \"All AI is in San Francisco\", as demonstrated by the fact that everyone is\n> obsessed with a Paris startup\n>\n> \u2014 Matt Turck (@mattturck) February 27, 2024\n\nPART III: FINANCINGS, M&A AND IPOS\n\nFinancings\n\nThe current financing environment is one of the \u201ctale of two markets\u201d\nsituations, where there\u2019s AI, and everything else.\n\nThe overall funding continued to falter, declining 42% to $248.4B in 2023. The\nfirst few months of 2024 are showing some possible green shoots, but as of now\nthe trend has been more or less the same.\n\nData infrastructure, for all the reasons described above, saw very little\nfunding activity, with Sigma Computing and Databricks being some of the rare\nexceptions.\n\nObviously, AI was a whole different story.\n\nThe inescapable characteristics of the AI funding market have been:\n\n  * A large concentration of capital in a handful of startups, in particular OpenAI, Anthropic, Inflection AI, Mistral, etc.\n  * A disproportionate level of activity from corporate investors. The 3 most active AI investors in 2023 were Microsoft, Google and NVIDIA\n  * Some murkiness in the above corporate deals about what amount is actual cash, vs \u201ccompute for equity\u201d\n\nSome noteworthy deals since our 2023 MAD, in rough chronological order (not an\nexhaustive list!):\n\nOpenAI, a (or the?) foundational model developer, raised $10.3B across two\nrounds, now valued at $86B; Adept, another foundational model developer,\nraised $350M at a $1B valuation; AlphaSense, a market research platform for\nfinancial services, raised $475M across two rounds, now valued at $2.5B,\nAnthropic, yet another foundational model developer, raised $6.45B over three\nrounds, at a $18.4B valuation; Pinecone, a vector database platform, raised\n$100M at a $750M valuation; Celestial AI, an optical interconnect technology\nplatform for memory and compute, raised $275M across two rounds; CoreWeave, a\nGPU Cloud provider, raised $421M at a $2.5B valuation; Lightmatter, developer\nof a light-powered chip for computing, raised $308M across two rounds, now\nvalued at $1.2B; Sigma Computing, a cloud-hosted data analytics platform,\nraised $340M at a $1.1B valuation; Inflection, another foundational model\ndeveloper, raised $1.3B at a $4B valuation; Mistral, a foundational model\ndeveloper, raised $528M across two rounds, now valued at $2B; Cohere,\n(surprise) a foundational model developer, raised $270M at a $2B valuation;\nRunway, a generative video model developer, raised $191M at a $1.5B valuation;\nSynthesia*, a video generation platform for enterprise, raised $90M at a $1B\nvaluation; Hugging Face, a machine learning and data science platform for\nworking with open source models, raised $235M at a $4.5B valuation; Poolside,\na foundational model developer specifically for code generation and software\ndevelopment, raised $126M; Modular, an AI development platform, raised $100M\nat a $600M valuation; Imbue, an AI agent developer, raised $212M; Databricks,\nprovider of data, analytics and AI solutions, raised $684M at a $43.2B\nvaluation; Aleph Alpha, another foundational model developer, raised $486M;\nAI21 Labs, a foundational model developer, raised $208M at a $1.4B valuation;\nTogether, a cloud platform for generative AI development, raised $208.5M\nacross two rounds, now valued at $1.25B; VAST Data, a data platform for deep\nlearning, raised $118M at a $9.1B valuation; Shield AI, an AI pilot developer\nfor the aerospace and defense industry, raised $500M at a $2.8B valuation;\n01.ai, a foundational model developer, raised $200M at a $1B valuation;\nHadrian, a manufacturer of precision component factories for aerospace and\ndefense, raised $117M; Sierra AI, an AI chatbot developer for customer service\n/ experience, raised $110M across two rounds; Glean, an AI-powered enterprise\nsearch platform, raised $200M at a $2.2B valuation; Lambda Labs, a GPU Cloud\nprovider, raised $320M at a $1.5B valuation; Magic, a foundational model\ndeveloper for code generation and software development, raised $117M at a\n$500M valuation.\n\nM&A, Take Privates\n\nThe M&A market has been fairly quiet since the 2023 MAD.\n\nA lot of traditional software acquirers were focused on their own stock price\nand overall business, rather than actively looking for acquisition\nopportunities.\n\nAnd the particularly strict antitrust environment has made things trickier for\npotential acquirers.\n\n> Adobe blocked from buying Figma\n>\n> JetBlue blocked from acquiring Spirit Airlines\n>\n> Amazon abandons $1.4B deal to buy iRobot as it sees \"no path to regulatory\n> approval\"\n>\n> Something is very broken in antitrust enforcement\n>\n> \u2014 Matt Turck (@mattturck) January 29, 2024\n\nPrivate equity firms have been reasonably active, seeking lower price\nopportunities in the tougher market.\n\nSome noteworthy transactions involving companies that have appeared over the\nyears on the MAD landscape (in order of scale):\n\nBroadcom, a semiconductor manufacturer, acquired VMWare, a cloud computing\ncompany, for $69B; Cisco, a networking and security infrastructure company,\nacquired Splunk, a monitoring and observability platform, for $28B; Qualtrics,\na customer experience management company, was taken private by Silver Lake and\nCPP Investments for $12.5B; Coupa, a spend management platform, was taken\nprivate by Thoma Bravo for $8B; New Relic, a monitoring and observability\nplatform, was acquired by Francisco Partners and TPG for $6.5B; Alteryx, a\ndata analytics platform, was taken private by Clearlake Capital and Insight\nPartners for $4.4B; Salesloft, a revenue orchestration platform, was acquired\nby Vista Equity for $2.3B, which then also acquired Drift, an AI chatbot\ndeveloper for customer experience; Databricks, a provider of data lakehouses,\nacquired MosaicML, an AI development platform, for $1.3B (and several other\ncompanies, for lower amounts like Arcion and Okera); Thoughtspot, a data\nanalytics platform, acquired Mode Analytics, a business intelligence startup,\nfor $200M; Snowflake, a provider of data warehouses, acquired Neeva, a\nconsumer AI search engine, for $150M; DigitalOcean, a cloud hosting provider,\nacquired Paperspace, a cloud computing and AI development startup, for $111M;\nNVIDIA, a chip manufacturer for cloud computing, acquired OmniML, an AI/ML\noptimization platform for the edge.\n\nAnd of course, there was the \u201cnon-acquisition acquisition\u201d of Inflection AI by\nMicrosoft.\n\nIs 2024 going to be the year of AI M&A? A lot depends on continued market\nmomentum.\n\n  * At the lower end of the market, A lot of young AI startups with strong teams have been funded in the last 12-18 months. In the last couple of AI hype cycles of the last decade, a lot of acquihires happened after the initial funding cycle \u2013 often at prices that seemed disproportionate to the actual traction those companies had, but AI talent has always been rare and today is not very different.\n  * At the higher end of the market, there is strong business rationale for further convergence between leading data platforms and leading AI platforms. Those deals are likely to be much more expensive, however.\n\nIPOs?\n\nIn public markets, AI has been a hot trend. The \u201cMagnificent Seven\u201d stocks\n(Nvidia, Meta, Amazon, Microsoft, Alphabet, Apple and Tesla) gained at least\n49% in 2023 and powered the overall stock market higher.\n\nOverall, there is still a severe dearth of pure-play AI stocks in public\nmarkets. The few that are available are richly rewarded \u2013 Palantir stock\njumped 167% in 2023.\n\nThis should bode well for a whole group of AI-related pre-IPO startups. There\nare a lot of companies at significant amounts of scale in the MAD space \u2013\nfirst and foremost Databricks, but also a number of others including Celonis,\nScale AI, Dataiku* or Fivetran.\n\nThen there\u2019s the intriguing question of how OpenAI and Anthropic will think\nabout public markets.\n\nIn the meantime, 2023 was a very poor year in terms of IPOs. Only a handful of\nMAD-related companies went public: Klaviyo, a marketing automation platform,\nwent public at a $9.2B valuation in September 2023 (see our Klaviyo S-1\nteardown); Reddit, a forum-style social networking platform (which licenses\nits content to AI players) , went public at a $6.4B valuation in March 2024;\nAstera Labs, a semiconductor company providing intelligent connectivity for AI\nand cloud infrastructure, went public at a $5.5B valuation in March 2024.\n\nCONCLUSION\n\nWe live in very special times. We are early in a paradigm shift. Time to\nexperiment and try new things. We\u2019re just getting started.\n\n> Thinking you're late to AI today is like thinking you're late to the\n> Internet in 1996\n>\n> \u2014 Matt Turck (@mattturck) December 23, 2023\n\nTwitterLinkedinFacebook\n\nPosted on March 31, 2024April 7, 2024Categories AI, Big Data\n\n## 4 thoughts on \u201cFull Steam Ahead: The 2024 MAD (Machine Learning, AI & Data)\nLandscape\u201d\n\n  1. Jeff Evernham says:\n\nApril 1, 2024 at 9:35 am\n\nGreat post, excellent work on the landscape, and a comprehensive review of the\nchaos of AI in 2023. Well done!\n\nI felt that two thoughts were missing and I\u2019m curious if you can comment. One,\nthe question of what impacts AI regulation (or for that matter, rulings on\ncopyright lawsuits) might do to the field and the subsequent investment\nlandscape. Two, China. It was only mentioned as an aside...and while AI in\n2023 was US-centric, you could say that TikTok has mastered traditional AI\nwith their recommendation algorithm...and Baidu, Tencent, and Alibaba are\ncertainly moving fast, probably with a lot of government help.\n\nMaybe these were topics #25 and #26 and you had to make the cutoff\nsomewhere...\n\nReply\n\n  2. Ravi Panchumarthy says:\n\nApril 4, 2024 at 5:33 pm\n\nIntel OpenVINO can be added in \u201cAI Frameworks, Tools & Libraries\u201d.\n\nReply\n\n  3. Bo Moon says:\n\nApril 5, 2024 at 1:29 pm\n\nSuper comprehensive Matt; kudos to you and the team. The shifts in the overall\nbucketing and naming was really interesting, and makes for a compelling view\nyou uniquely have because you do this ever year. More in depth than anything\nI\u2019ve read on the entire landscape of MAD in a long time. Cheers! -Bo\n\nReply\n\n    1. mattturck says:\n\nApril 8, 2024 at 3:58 pm\n\nThanks Bo!\n\nReply\n\n### Leave a Reply Cancel reply\n\n## Subscribe to Blog via Email\n\n## Subscribe to Blog via Email\n\n## POPULAR POSTS\n\n  * Red Hot: The 2021 Machine Learning, AI and Data (MAD) Landscape\n  * Is Big Data Still a Thing? (The 2016 Big Data Landscape)\n  * Resilience and Vibrancy: The 2020 Data & AI Landscape\n  * A Turbulent Year: The 2019 Data & AI Landscape\n  * Firing on All Cylinders: The 2017 Big Data Landscape\n  * The 2023 MAD (Machine Learning, Artificial Intelligence & Data) Landscape\n  * Great Power, Great Responsibility: The 2018 Big Data & AI Landscape\n  * Internet of Things: Are We There Yet? (The 2016 IoT Landscape)\n  * The Great VC Pullback of 2022\n  * Growing Pains: The 2018 Internet of Things Landscape\n\n## Categories\n\n## Search the Archives\n\n## Social\n\n  * View @mattturck\u2019s profile on Twitter\n  * View https://www.linkedin.com/in/turck/\u2019s profile on LinkedIn\n  * View https://www.youtube.com/@DataDrivenNYC\u2019s profile on YouTube\n\nMatt Turck Proudly powered by WordPress\n\n", "frontpage": false}
