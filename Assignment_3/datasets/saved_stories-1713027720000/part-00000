{"aid": "40022152", "title": "Self-Hosted Is Awesome", "url": "https://pixeljets.com/blog/self-hosted-is-awesome/", "domain": "pixeljets.com", "votes": 14, "user": "thunderbong", "posted_at": "2024-04-13 11:00:09", "comments": 7, "source_title": "Self-hosted is awesome", "source_text": "Self-hosted is awesome\n\nSign in Subscribe\n\n# Self-hosted is awesome\n\n### Table of Contents\n\n  * The list of self-hosted products I use\n\n    * The Cons\n  * Docker skills are essential\n  * GPT and Claude to the rescue\n  * Funding self-hosted product development\n  * Open-core concerns\n  * My real approach to self-host a product\n\n    * Basic steps for a demo\n\nI'm a big fan of self-hosting. As an indie hacker who has launched several\nmicro-SaaS products and as a CTO of a small company, I now prefer self-hosting\nall the tools I might need. With the rise of high-quality self-hosted\nofferings from talented teams using open source as their primary marketing\nchannel while offering a cloud version of their product to generate revenue,\nwe can save tens and hundreds of thousands of dollars over the lifetime of our\nprojects, while maintaining full control over our data.\n\n## The list of self-hosted products I use\n\nThese products are awesome and have state-of-art UX, not just \"it gets the job\ndone so I can cope with its weird design\" kind of feeling \u2013 like it used to be\n10 years ago, when self-hosted products were often just a couple of scripts\ncobbled together by some software engineering student. Just a couple of\nwonderful examples of work-oriented self-hosted products I use:\n\n  * Metabase (online dashboard to build SQL reports, we use it at Qwintry);\n  * Mattermost (self-hosted Slack alternative);\n  * Directus (turns your SQL database into CMS)\n  * n8n (developer-friendly Zapier)\n  * LibreChat (ChatGPT interface for all popular LLMs)\n  * Mautic (Marketing newsletters)\n\nOh, and there are also Supabase... and ELK stack... and Zabbix... (read more\nabout our poor-mans SRE setup)\n\nThis is a great self-hosted subreddit I recommend. I should note, that a lot\nof products being discussed there on Reddit are mostly for personal use (like,\ntorrents, etc), but I am mostly seeking for solutions to do my work.\n\nI believe self-hosting has several advantages for indie hackers and developers\nlike myself. When you self-host, you have complete control over your\ninfrastructure and data. This level of control is crucial for me as a\ndeveloper because I need the flexibility to customize and integrate various\ntools seamlessly into my workflow.\n\n### The Cons\n\nThat being said, I think it's important to acknowledge that self-hosting comes\nwith its own set of challenges. Maintenance, security, and scalability become\nmy team responsibility. Ensuring regular updates, implemeting proper security\nmeasures, and managing infrastructure can be time-consuming tasks. However, if\nyou have the technical skills and are willing to put in the effort, I believe\nself-hosting provides a level of independence and control that can be highly\nbeneficial in the long run - it certainly is in our case.\n\nThe big question is: how technical do you need to be to embrace self-hosted\nproducts? There are no any silver bullets here, and you need to know a lot\nabout how computers work, but I don't think you need to have 5 years of web\ndevelopment or system administration background to self-host effectively and\nreliably anymore \u2013 life got easier!\n\n## Docker skills are essential\n\nLuckily, Docker and Docker Compose have greatly simplified the process of\nself-hosting. I have to admit, as a developer and CTO, in 2014-2018, I was\ninitially hesitant to use Docker for our own web projects (especially the ones\nin the active development phase). It significantly complicated our deployment\nworkflow and added a lot of overhead while providing marginal value. I didn't\nfully buy into the concept of 100% reproducible builds, especially considering\nthe increased DevOps complexity that came with it.\n\nBack then, I loved the ability to quickly hack and debug PHP scripts directly\non production. While it's definitely a bad practice, there were countless\ntimes when this approach proved invaluable while debugging hard-to-reproduce\nbugs in a live environment: crucial for a small, rapidly changing product with\njust 1-3 developers!\n\nMoreover, I struggled to wrap my head around Docker's concepts, such as\nvolumes and binds. The cryptic shorthand syntax made it even more challenging\nto understand how these components worked together. I found myself spending\nmore time trying to decipher Docker's intricacies than focusing on our\napplication's core functionality.\n\nAt the time, our team had a well-established workflow that allowed us to\ndevelop, test, and deploy our applications efficiently (AND FAST!).\nIntroducing Docker felt like an unnecessary layer of complexity that would\ndisrupt our processes without providing significant benefits in return.\n\nHowever, our perspective eventually changed and has shifted towards Docker\neverywhere (with the exception of some development machines): our projects\nmatured and required more predictability; we strived for better CI/CD,\ndedicated teams of testers, better DevOps practices, and improved horizontal\nscalability. What's equally important is that Docker matured as well and\nbecame a great, boring technology, and a de-facto standard to host everything,\nstarting from API services and ending with databases.\n\nAnd Docker is what makes running complex software, self-hosted, so enjoyable.\nThese applications, developed by external teams using varying technical\nstacks, now always come with well-conditioned Docker Compose files (official\nor community-supported) that make the setup process a breeze. Instead of\ndealing with the hassle of manual installation and configuration, I simply use\nDocker's containerization approach to spin up these applications quickly and\neasily.\n\nYou can still be a good web developer without knowing Docker \u2013 but it's hard\nto enjoy self-hosting nowadays without knowing it!\n\n## GPT and Claude to the rescue\n\nBesides Docker, to self-host effectively, you will also need good\nunderstanding of:\n\n  * how Nginx routing works (well, you can use another webserver as an ingress controller, I just prefer Nginx).\n  * how Linux and networking in general works (firewall, ufw)\n  * how DNS and/or Cloudflare DNS works\n\nGreat news: you don't need to spend months experimenting with these - there is\na great shortcut nowadays, with the raise of LLMs, it can be done in a matter\nof hours! (and it can help with docker errors, too)\n\nWith GPT, I don't need to remember nginx or docker compose config syntax\nanymore.\n\n## Funding self-hosted product development\n\nDeveloping high-quality, free, and open-source products requires funding. A\ncommon approach is to offer a cloud version of the product with some\nenterprise features to generate revenue. The Directus project had an\ninteresting discussion on GitHub\n(https://github.com/directus/directus/discussions/17977) where the founder\nshared ideas on sustaining their product. They eventually adopted a strategy\nallowing free use of the entire platform unless the legal entity exceeds\n$5,000,000 USD in annual \"total finances.\" - this is an interesting approach!\n\n## Open-core concerns\n\nNot all self-hosted products are created equal. Some cross the line, offering\na barely usable free version as a marketing gimmick instead of a genuinely\nuseful product. In my opinion, an acceptable practice is to restrict clearly\nenterprise features, such as SSO mechanisms (like in n8n), under paid\nlicenses. However, restricting the free product to the point of being nearly\nunusable is inadequate.\n\nOne example of a self-hosted product that faced community backlash is\nBudibase. They recently restricted their open-source version to a limited\nnumber of users, which led to criticism on Reddit\n(https://www.reddit.com/r/selfhosted/comments/17v48t8/budibase_will_soon_limit_users_on_oss_self_hosted/).\nSome users blamed this decision on the fact that Budibase is now VC-funded,\nsuggesting that the pursuit of profitability led to the limitation of their\nfree offering.\n\nThis incident highlights the balance that open-source projects must strike\nwhen seeking to generate revenue while maintaining the trust and support of\ntheir community. Restricting the free version too heavily can lead to a loss\nof goodwill and a perception that the project has abandoned its open-source\nroots in favor of commercial interests.\n\n## My real approach to self-host a product\n\nLet's say I want to host n8n. These are my steps:\n\n### Basic steps for a demo\n\n  1. Log in via SSH to my Ubuntu running on a remote Hetzner cloud server (I don't ever host anything in Docker on my Macbook, I do everything on Hetzner via plain SSH and/or awesome VS Code Remote extension, in case I need heavy config edits)\n  2. Verify docker is available and is running on the server: docker ps\n  3. Google n8n docker and open docs: https://docs.n8n.io/hosting/installation/docker/#prerequisites\n  4. Run these two commands highlighted in the manual to run the service\n  5. Verify docker containers of n8n is running. If not, explore container errors via docker logs xxx and check n8n github repository for similar issues: chances are someone already struggled with this!\n  6. Port forward the service to my localhost so I can open the service in my Chrome via http://localhost:3333\n\nThese steps generally take around 3-5 minutes max to get the service running.\nThen, I usually play with the service for an hour or two to realize if I want\nto use it on a longterm basis.\n\n  1. If I do, go to Cloudflare to my domain and create a subdomain on one of my domains, with an A record pointing to my Hetzner cloud server (e.g. n8n.scrapeninja.net. HTTPS certificates are handled by Cloudflare, has good DNS UI, and also protects my server ip addresses for occasional DDoS attacks (and it's free!)\n  2. I create a nginx host and point it to the docker container. Here is an example of such a config:\n\n    \n    \n    server { listen 80; server_name n8n.scrapeninja.net; return 301 https://$host$request_uri; } server { listen 443 ssl; server_name n8n1.scrapeninja.net; ssl_certificate /etc/ssl/certs/ssl-cert-snakeoil.pem; ssl_certificate_key /etc/ssl/private/ssl-cert-snakeoil.key; location / { proxy_pass http://localhost:5678; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; # websocket support proxy_set_header Connection \"Upgrade\"; # websocket support proxy_set_header Host $host; chunked_transfer_encoding off; proxy_buffering off; proxy_cache off; } }\n\nThis is a n8n reverse proxy config for nginx.\n\n#### Anthony Sidashin\n\nApr 11, 2024\n\nPixeljets \u00a9 2024. Powered by Ghost\n\n", "frontpage": true}
