{"aid": "40085703", "title": "Signal Relays", "url": "https://www.pzuraq.com/blog/on-signal-relays", "domain": "pzuraq.com", "votes": 1, "user": "todsacerdoti", "posted_at": "2024-04-19 11:59:47", "comments": 0, "source_title": "pzuraq | On Signal Relays", "source_text": "pzuraq | blog | On Signal Relays\n\nApril 18, 2024\n\n# On Signal Relays\n\nApril 18, 2024\n\nIf you haven\u2019t heard, Signals are a new proposal for the JavaScript language,\nand they\u2019ve just entered stage 1! As a co-champion for the proposal, I\u2019m\npersonally very excited about this feature and its potential. Reactivity has\nbecome one of the most important parts of writing modern JS, and a decent\namount of my time these days is spent running plumbing for reactive state -\nsetting up and managing subscriptions and state on render, updating them on\nchanges, and tearing them all down when the component is gone.\n\nFrameworks have filled this void for the most part over the years and made\nthis process much, much easier. I still remember the initial examples we saw\nof React Hooks, how they tied all of this management up into a neat package\nthat didn\u2019t require me to think of all of these things anymore:\n\n    \n    \n    useEffect(() => { const subscription = props.source.subscribe(); return () => { // Clean up the subscription subscription.unsubscribe(); }; });\n\nThis, to me, was the main reason hooks were so exciting. Yes, there was the\nfact that everything looked more functional, and functional languages were all\nthe rage back then. And yes, it was cool that you could compose these hooks to\ncreate your own, nested hooks, really creating the potential for a whole\necosystem.\n\nBut the valuable insight, the core thing that hooks really got right, was\nrealizing that the app\u2019s lifecycle does not end at the component.\n\nBefore hooks, if you wanted to add and remove a subscription like in the above\nexample, it was easy enough right in the component itself. But as your code\nstarted getting more complex, you would find yourself having to drill those\nlifecycle events down into every related function and class, and add\nboilerplate to every component to hook them up. It was just like prop-\ndrilling, except maybe a bit worse because you had coordinate multiple\nlifecycle events every time. With hooks, you could easily avoid all of this\nbecause the those events were co-located in one place.\n\nSince then, hooks-like reactivity patterns have proliferated and are now a\ncore part of many frameworks, including Solid, Vue, Svelte (especially Svelte\n5 with runes), and many more. These frameworks all approach things a bit\ndifferently, but at a high level each of them have the following:\n\n  1. Root state, the fundamental state of the app (e.g. useState in React, createSignal in Solid, $state in Svelte 5, etc)\n  2. Derived state, values derived from other state that are invalidated and rederived whenever their inputs an updated (e.g. useMemo in React, createMemo in Solid, $derived in Svelte 5, etc.)\n  3. Effects, lifecycle functions that take state and turn it into side-effects, like writing to the DOM or subbing/unsubbing from a data source (e.g. useEffect in React, createEffect in Solid, $effect in Svelte 5, etc.)\n\nThese core primitives are the basis of modern reactive JavaScript UI\nframeworks, and they\u2019re also the basis for the design of the Signals proposal.\n\n### Cool! So, where are Effects?\n\nYou may have noticed that effects in the Signals proposal seem a little\ndifferent. There\u2019s Signal.State which is root state, and Signal.Computed is\nderived state, and these work pretty similarly to the frameworks I mentioned\nabove. But the closest thing we have to an \u201ceffect\u201d is Signal.subtle.Watcher\nwhich, (1) why is it under this subtle namespace? And (2) why does it seem\nfairly hard to use?\n\nBack when hooks were first released, I was a member of the Ember.js core team\nand working on the next version of our own reactivity model which, eventually,\nbecame a sort of proto-signals like model. I\u2019ve since moved on and now spend\nmost of my time working on Svelte apps (with a couple of React projects in\ntow), but I learned a lot from my time on the Ember team and on that project,\nand I\u2019ve dug into the guts of many Signals-like implementations over the\nyears, so I\u2019m fairly familiar with how they work across frameworks, where they\nare similar, and how and why they are different.\n\nThe easier parts of the design were root state and derived state, and this\nmakes sense to me because these are very similar across most implementations.\nWithout effects, a system of signals is a functionally pure reactive graph.\nState is consumed by functions, the results are cached and then consumed by\nother functions, until you get your result at the \u201ctop\u201d, the original computed\nvalue that you were trying to get.\n\nEffects, however, are trickier. Every framework approaches effects a bit\ndifferently, because they start to bring in concerns like app lifecycle and\nrendering. And in addition, there was a general sense among the framework\nteams that effects were a very powerful tool, and that they were often times\nmisused in ways that caused a lot of developer frustration. In particular,\nthere is one antipattern that effects encourage that is very widespread.\n\nAnd that is managing state.\n\n### State is the enemy, state is always the enemy...\n\nConsider the following Solid.js component:\n\n    \n    \n    function Comp(props) { const [loading, setLoading] = createSignal(true); const [value, setValue] = createSignal(undefined); createEffect(() => { setLoading(true); fetch(props.url).then((value) => { setLoading(false); setValue(value); }); }); }\n\nSomething along these lines is a fairly common pattern in signals-based\nframeworks. What we have here is:\n\n  1. A loading state signal\n  2. A value state signal\n  3. An effect that manages both of them.\n\nThis seems pretty straightforward. The fetch here is the side-effect - we\u2019re\nsending a request for data out into the world, and when it returns we will\nwant to update our value state and rerender. In the meantime, we set the\nloading state to show a spinner or some other UI to the user so they know\nwhat\u2019s going on. We memoize the effect as well so that it doesn\u2019t rerun unless\nprops.url changes.\n\nSeems simple enough! And at first, this pattern works really well. Beginners\ncan pick up on it pretty quickly and it\u2019s all fairly intuitive. But, things\nthat start simple very rarely stay that way.\n\n## Disjointed Implicit Reactivity\n\nIn time, what you\u2019ll find with the above pattern is that there is drift. More\ncode gets added to the the effect (turns out we need to capture error states\nas well, oh and maybe we want to preserve the last value?) and it becomes more\nand more difficult to trace the line from effect to state. Multiple effects\nare added to the component, and sometimes the effects end up sharing state and\nmutating each other\u2019s state. Maybe you want to load from cache first, but also\ndo a background refresh. Maybe you have multiple fetchs that can all trigger\nthe loading UI.\n\n    \n    \n    function Comp(props) { const [loading, setLoading] = createSignal(true); const [value, setValue] = createSignal(undefined); const [error, setError] = createSignal(undefined); createEffect(() => { setLoading(true); fetch(props.url).then((value) => { setLoading(false); setValue(value); }); }); // if there was an error, load the backup data instead createEffect(() => { if (error && props.backupUrl) { setLoading(true); fetch(props.backupUrl).then((value) => { setLoading(false); setValue(value); }); } }); }\n\nWhat\u2019s happening here, effectively, is that we are creating implicit\ndependencies between imperative effect code and declarative state/computed\ncode. Or, maybe put another way, we are doing a bunch of imperative stuff in\nour otherwise functionally pure code, and bringing all of the problems of\nimperative programming with it. I call this disjointed implicit reactivity\n(credits to @benlesh for coming up with that), which is to say it is reactive\ncode that no longer has an obvious, intuitive, and declarative flow, where\neach dependency is easy to see and understand. Instead, you have to start\nhunting for these implicit dependencies all over your app, and they can happen\nanywhere.\n\nThis is why in many frameworks, effects can become so monstrously complicated\nand difficult to debug. It is a core cause of action-at-a-distance in many\napps, and it has caused many a developer pain and sorrow. So, what can we do?\n\n## Isolate the State\n\nWe can\u2019t get rid of imperative code altogether. I mean, we can if we want to\ninvent a new language, sure. But this is JavaScript, we don\u2019t really have an\nalternative yet (though WASM is getting better every year...) and regardless,\nthe shear amount of existing code out there is going to prevent most apps and\ndevs from just switching over any time soon.\n\nAnd in JS, you have to write imperative code sometimes. Our fetch example, for\ninstance, is probably the simplest way you could fetch data from a remote\nbackend without using external libraries, and it has a few imperative\nstatements in it. You might be thinking \u201cthat\u2019s not too bad though!\u201d, but as\nwe\u2019ve seen this complexity can grow significantly over time.\n\nSo, what\u2019s the alternative?\n\nLet\u2019s step back and look at a visualization of the problem. Here is a simple\nsignals graph:\n\nThis graph doesn\u2019t yet have any effects, it just has a few components and some\nstate, and in one of the components, that state can be updated by a UI event.\nThis is pretty straightforward to follow, we can see very easily where each\npiece of state enters the graph, what it\u2019s updated by, and what depends on it.\nIn general, most non-effect based updates will look like this - user events,\ninteractions, browser APIs, maybe some top level communication with a service\nworker or something like that. If we didn\u2019t ever need to load data, this would\nbe pretty straightforward!\n\nNow let\u2019s add an effect:\n\nOk, so the effect is the child of one of our components, and it updates the\ntwo pieces of state that are its siblings. We\u2019re already starting to get a bit\nmore complicated here, the interaction between the effect and its siblings is\none step of indirection and requires the user to actually read the code. At\nfirst that\u2019s easy, but what happens if we add 10 or 20 more states? Or, in the\nworst case, what about something like this?\n\nOk, now this looks like a strawman if I\u2019ve ever seen one. Like, who would even\nbuild an app like this? It would require you to go out of your way for this to\nhappen, to somehow get a hold of some piece of state in a completely separate\ncomponent and start updating it. This is, of course, an oversimplified\nexample.\n\nBut it\u2019s more possible than you might think. I have seen such accidents in\nmore complicated apps that have evolved slowly over time, where abstractions\nwere made to handle loading state, and then remade a few times over, and then\neventually you get something like this. Tech debt accrues, people leave and\npeople join, and you end up with some rather gnarly looking code.\n\nBut what if it weren\u2019t possible to do this? What if effects couldn\u2019t write to\njust about any piece of state at all, and instead could only write to a\nlimited scope, preventing these kinds of situations altogether?\n\nHere\u2019s the same graph using a Relay, an abstraction that would provide a\npotential alternative to effects which would do just that:\n\nThe idea with Relays is that they are meant to bridge the results of an effect\ninto the graph as state (thus the name relay, meaning \u201cthe act of passing\nalong by stages\u201d). Once the result is in the graph, it acts like any other\npiece of state, and every computed can treat it like a declarative dependency\nas-per-usual. And if you want to understand how that state is entering the\ngraph, you just need to look one place - the definition of the Relay.\n\nThis is actually a fairly common pattern in the JavaScript ecosystem. The\nfirst time I remember seeing it was with SWR, which effectively creates a\nRelay for managing fetch requests, @modderme123 from the Solid team has\nwritten a blog post about it, and there\u2019s even an issue opened by @dead-\nclaudia, who came to a similar design independently, on the Signals repository\nat the moment. All this to say, this is already a fairly well established\npattern, and it could even be considered a best practice at this point.\n\n## API????\n\nOk but what would it actually look like? Here\u2019s my current thoughts with the\nexisting Signals API:\n\n    \n    \n    declare class Relay<T> extends Signal<T> { constructor( initialValue: T, <T>(set: (value: T) => void, get: () => T) => undefined | { update?(): void; destroy?(): void; } ); }\n\nThis API is inspired by Svelte Actions, and splits out the lifecycle of side-\neffects into three parts:\n\n  1. Initialization\n  2. Update (optional)\n  3. Destruction (optional)\n\nIn the lifecycle of a Relay, the function passed to the constructor is called\nto initialize the effect, state dependencies are tracked during\ninitialization, and optionally users can return an object containing update\nand/or destroy. If the initial dependencies are invalidated, the update\nfunction is called to modify the effect that was created - the initialization\nfunction as a whole is NOT called again while the relay is still active.\nFinally, destroy is called when the relay is no longer in use in order to\nteardown the effect. If the relay is used again later, then initialization is\ncalled again and the whole lifecycle is restarted.\n\nThis API is a bit different than useEffect or createEffect style APIs which\nteardown the effect and recreate it on every change. The reasoning I have for\nthis is that while tearing down and recreating is often a simpler API for most\nusers, there are a decent amount of cases where you want to do something a bit\nmore optimal during updates (e.g. maybe you just want to update a subscription\nand not tear the whole thing down). In my own experience this ends up being\nsomething like 20-30% of relays, and given this API is meant to be a language\nprimitive to build upon, the thought is that we should support these cases by\ndefault and allow wrappers to be added that can simplify them at a higher\nlevel.\n\nHere\u2019s what it might look like in use as a fetch wrapper:\n\n    \n    \n    export const fetchJson = (url: Signal<string>) => { return new Signal.Relay( { isLoading: false, value: undefined, }, (set, get) => { // Note: set comes first in the API because every relay will // need to `set`, but not every relay will need to `get` // Setup some local state for managing the fetch request let controller: AbortController; // `loadData` is a local function to deduplicate the code // in init and update const loadData = async () => { controller?.abort(); // Update isLoading to true, but keep the rest of the state set({ ...get(), isLoading: true }); controller = new AbortController(); const response = await fetch(url.get(), { signal: controller.signal }); const value = await response.json(); set({ ...get(), value, isLoading: false }); } // Call `loadData`, make the initial fetch, and track dependencies loadData(); return { update() { // When dependencies update, call `loadData` again to // cancel the previous fetch and make a new one. // Dependencies are tracked again and fed into the next // update. loadData(); }, destroy() { // Cancel any existing fetch request on destruction controller?.abort(); } } } ); }\n\n> Note: This example uses just one externally exposed signal, but you could\n> return an object containing multiple signals, or with getters that are\n> backed by signals, enabling more fine-grained reactive control.\n\nThis neatly wraps up all of the details of fetching data in one spot so that\nyou don\u2019t need to manage those yourself every time. It maintains the lifecycle\nmanagement benefits of effects, without allowing effects to write to anything\nthey happen to have access to, thus preventing the issues that come with that.\n\nStepping back, the point here is actually about isolation of state. Relays let\nyou isolate state in a way such that adding a relay doesn\u2019t impact the\nbehaviour of other relays on the page, and similarly removing them doesn\u2019t\ncause unexpected changes. The business logic of a relay is a black box - you\ndon\u2019t need to know the details of it in order to use it, and it can\u2019t affect\nanything else that you\u2019re using around it.\n\n### Ok, Relays seem cool, but then why do we need Watchers?\n\nRelays on their own are a great abstraction for managing effects and state\ntogether. But the issue is that if you start a relay, you will likely need to\nstop it at some point in order to clean up its contents and release whatever\nresources it may be using. In the subscription example, for instance, you\nwould want to end the subscription when the relay is no longer being used (and\nalso resubscribe if the relay ever enters the graph again).\n\nThis is tricky with just our three main concepts because there\u2019s no simple way\nto tell when a relay is no longer in use. Let\u2019s look at some options:\n\n  1. A relay is no longer in use when it is no longer consumed by any other derived state: This definition works for a single layer - if a Computed reruns and no longer uses the relay (maybe it creates a new relay instead, for instance), then we can tear it down. The issue here though is that it doesn\u2019t work with nesting. What if we stop using the computed itself? We need to be able to disconnect the entire subgraph that the computed is watching, not just its immediate dependencies.\n\n  2. A relay is no longer in use when all of its consumers have been freed (popped off the stack or garbage collected): This definition relies on memory management and garbage collection, which means (A) the exact timing of teardown is no longer controlled by the user and (B) we can run into leaks very easily if we accidentally hold onto a computed/relay, or if we have a high continuous load and GC cannot occur. This would be a non-starter for any app of sufficient complexity.\n\n  3. A relay is no longer in use when all of its consumers have been explicitly destroyed: We could add a destroy() method to all signals that explicitly disconnects them and leaves lifecycle management up to the user. There are two major issues with this:\n\n    1. Signals don\u2019t necessarily get destroyed and never used again. It\u2019s more like they are no longer in use for now, and at some point in the future they may be used again. Consider for instance a data manager like Apollo Client which has watchQuery, an API that creates a persistent, live-updating query on the data in Apollo\u2019s cache. If the UI stops using that data, we don\u2019t want to evict it from the cache, because the user may navigate back to the page that requires it and then we would have to fetch the data again. We want to stop actively subscribing to it for the time being, but if we ever start again, we want to be able to pick up where we left off.\n\n    2. The exact timing of when we stop (and restart) a relay depends on when it is used by other derived state. For instance, let\u2019s say that you have the following:\n        \n                function Comp(props) { const data = new ApolloWatchQueryRelay(props.query); const showData = new Signal.State(true); const preprocessedData = new Signal.Computed(() => { return showData.get() ? preprocessData(data.get().value) : undefined; }); }\n\nIf showData transitions to false, the expectation would be that any\nsubscriptions setup by the data relay would be torn down. That seems simple\nenough, we could do that like so:\n\n        \n                function Comp(props) { const data = new ApolloWatchQueryRelay(props.query); const showData = new Signal.State(true); const preprocessedData = new Signal.Computed(() => { if (showData.get()) { preprocessData(data.get().value) : undefined; } else { data.unsubscribe(); } }); }\n\nBut what happens if the component itself is removed? Do we need to rerun all\nof its computeds in order to teardown all subscriptions? And what if multiple\ncomputeds are using the relay? We would need to add this management code to\neach of them. This would be a minefield of management for users and it defeats\nmuch of the purpose of signals by forcing users to constantly think about data\nconsumption again, and forcing them to manage all the minutiae of manually\nsubscribing, unsubscribing, etc.\n\nStepping back, the core idea of relays is that:\n\n  1. They are active when they are being used either directly or indirectly by the \u201ccore app\u201d (e.g. the UI in frontend apps, or a persistent process such as an actor or thread in backend apps).\n  2. They are inactive when they are no longer connected to the core app via the signal graph.\n\nIn this model, Watchers represent that \u201ccore app\u201d. A watcher essentially tells\na signal graph that a given node is in use by some external process, so it\nshould remain active. This pushes the complexity of lifecycle management up a\nlevel, to the framework that is handling the details of rendering, scheduling,\nand managing applications. Signal authors can create complex graphs of\nsignals, hand them off to the app, and it can decide when it is watching the\ngraph and when it wants to stop watching the graph. All the user has to do is\ndefine what happens when we start watching the graph, and what happens when we\nstop.\n\nThis is why the Watcher API feels like it isn\u2019t really great for Effects -\nit\u2019s not meant for them. It\u2019s about extracting data from the graph and pushing\nthat data elsewhere (or, in the case of graphs that use side-effects to write\nthe data out, managing the active state of those effects). This is also why it\nwas placed under the subtle namespace, the idea being that it would hint to\ndevelopers that they should probably avoid using Watchers unless they are\nmaking a framework or other persistent process that needs to watch a signal\ngraph.\n\n## Conclusion\n\nSo, to sum up this post:\n\n  * Signal graphs, in most implementations, consist of Root State, Derived State, and Effects\n  * Sometimes, Effects are used to update root state with the results of async processes\n  * A common anti-pattern is to manage multiple pieces of root state with a singfle effect, or to use multiple effects to manage a single shared piece of root state, creating difficult to debug ownership and timing issues. We can label this anti-pattern as \u201cdisjointed implicit reactivity\u201d.\n  * Relays isolate and co-locate these effects with the root state they manage, preventing these issues by ensuring that there is one (and only one) place that the state can be managed and updated from.\n\nMy current opinion is that if we can gain consensus on the value of the Relay\npattern, we can ship a version of Signals that provides better defaults for\nmost users and prevents a lot of painful and difficult to debug situations. If\nnothing else, I sincerely hope that Signals users end up implementing this\npattern more often rather than reaching for Effects directly. It has\ndefinitely improved my life in code, and I hope it can make yours easier as\nwell!\n\n## Addenda\n\n#### Are these really a full replacement for Effects?\n\nThere are really two categories of Effects that users end up writing often:\n\n  1. Effects that push out of the graph, e.g. they take some state within the graph, read it, and push it out into the DOM or into some other system.\n  2. Effects that push out of the graph, and then write the results back in to the graph, e.g. setting a State signal.\n\nRelays are explicitly meant to fully replace the second category, and in my\nopinion are a much better solution for them. For the first, we could continue\nto have Effects and make a strong distinction between the two, but my\npreference would be to just have a Relay that doesn\u2019t use its state value,\nlike a computed that side-effects and returns undefined. It\u2019s ultimately one\nless API to add, and if it really feels wrong to some, it\u2019s trivial to wrap a\nRelay with an API that looks more like a plain Effect. But that said, I don\u2019t\nhave a strong opinion here and would be happy if both were added to the\nproposal.\n\n#### Can\u2019t users just use a Watcher directly? Or side-effect in a computed? Or\ndo [insert-bad-thing-here] anyways?\n\nYes. Users will always be able to work around the bounds in JavaScript,\nespecially when it comes to async and reactivity (and especially the\ncombination of the two). This is not at all a silver-bullet, users could still\ncreate implicit dependencies all over the place with Relays (and Effects, if\nwe also add them).\n\nThe goal of Relays is not to prevent all possible anti-patterns all the time.\nIt\u2019s to spread a known good pattern as the default, so that when users end up\nreaching for a side-effect they start by reaching for a Relay and, hopefully,\nend up with a fairly self-contained piece of code.\n\nWhen I look at JS code in the wild, I\u2019d say it\u2019s split 60-40 or even more\ntoward using effects that manages state for any one-off side-effecting thing.\nMost of the time users are using SWR or TanStack Query or some other\nabstraction which is effectively the Relay pattern for basic things like\nfetch, but it\u2019s not the case much of the rest of the time. Ideally, Relays\nwould help to shift the balance the other direction, so that most of the time\nfor something basic that is just reading in state from a side-effect, users\nend up using a Relay.\n\n#### You\u2019ve talked a lot about fetch, what are some of the other things you\ncould use this for?\n\nLot\u2019s of things!\n\n  * Websockets could be managed with a Relay that manages the connection and exposes the messages as a queue that updates, or as the latest message to come through\n  * Connections to web workers or service workers could use Relays to facilitate passing messages to the worker (by autotracking dependencies, reading them, and sending them out) and then reading back results\n  * Web APIs like IndexedDB that are async storage mechanisms could be wrapped in Relays\n  * On backends, queries to databases could be wrapped in Relays\n  * Likewise, subscriptions to message buses or producer/consumer queues could be managed by relays\n\nBasically any time you have some async action that needs to read state into\nthe graph, you can use a Relay. It\u2019s a really powerful primitive!\n\n#### Why weren\u2019t these included in the proposal in the first place?\n\nAs I mentioned above, we couldn\u2019t really get consensus and wanted to get the\nfirst draft of the proposal out the door so we could start gathering community\nfeedback. We did, however, get consensus to add all of the APIs you would need\nto create a Relay abstraction.\n\nThat is the purpose of the Signal.subtle.watched and Signal.subtle.unwatched\nAPIs. Without them, you could do most of the things a Relay needs to do using\na combination of Computed and State signals that side-effect on initialization\nand during updates. But you couldn\u2019t cleanup a computed that was no longer in\nuse, or restart a computed that was just added back into the graph. So, those\ntwo events were added as a compromise to enable experimentation.\n\nread some more\n\n", "frontpage": false}
