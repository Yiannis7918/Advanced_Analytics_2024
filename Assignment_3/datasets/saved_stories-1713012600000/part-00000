{"aid": "40021092", "title": "A few tips for working on high-surface-area problems", "url": "https://www.answer.ai/posts/2024-04-12-tips.html", "domain": "answer.ai", "votes": 1, "user": "dsr12", "posted_at": "2024-04-13 06:48:46", "comments": 0, "source_title": "A few tips for working on high-surface-area problems", "source_text": "Answer.AI - A few tips for working on high-surface-area problems\n\n# A few tips for working on high-surface-area problems\n\nWhat do you do when there are too many pieces to fit in your head?\n\nA few tips for working on things that involve a lot of moving pieces, that\nhave a high \u201csurface area\u201d.\n\nAuthor\n\nJohno Whitaker\n\nPublished\n\nApril 12, 2024\n\nA note from Johno\n\nI\u2019ve been writing brief notes on my own blog for years. I\u2019ll be posting on the\nAnswer.AI blog too now that I work here \u2013 here\u2019s what is hopefully the first\nof many posts. This one is just a few thoughts inspired by some recent work,\nwhich I hope you\u2019ll find interesting. I\u2019d love to hear what you think; you can\nfind me here on Twitter/X.\n\nSome of the many questions/directions we faced when trying to get QLoRA\nworking with FSDP - an example of a high-surface-area problem!\n\nSome problems are fairly well-defined and narrow in scope: \u2018translate this\nmaths into code\u2019, or \u2018try a different embedding dimension on this task\u2019. But\nas AI researchers we often work on things that involve a lot of moving pieces,\nand when something doesn\u2019t work it can be hard to find out where the issue(s)\nmay be, let alone what we need to do to fix them. I think of these tasks as\nhaving a high \u201csurface area\u201d, and in this post I\u2019ll share a few tips for\ndealing with these inspired by a recent experience with one such problem.\n\n## Tip 1: Start with a minimal example and build up\n\nRather than beginning with the full, complicated task, see if there\u2019s a\nsmaller version you can create that still lets you meaningfully probe the\nproblem. For example, rather than using Llama-2-7B with LoRA adapters, I did\nsome early tests with a network made of blocks like this:\n\n    \n    \n    class Block(torch.nn.Module): def __init__(self, size=512): super().__init__() self.l1 = torch.nn.Linear(size, size) self.l2 = torch.nn.Linear(size, size) for param in self.l2.parameters(): param.requires_grad = False\n\nStarting small lets you add bits of complexity one at a time, gradually\nrevealing different aspects of the problem. With this small example I could\nexperiment with and isolate specific aspects of the larger challenge - for\nexample, swapping out one linear layer with a quantized version. The goal here\nis to reduce the surface area that is in focus at a given time, and\nincrementally add more as we figure things out.\n\n## Tip 2: Log/instrument everything\n\nDebugging something opaque is a pain, so anything that provides more\nvisibility into what is happening is useful. Printing out tensor shapes,\nlogging losses, gradients and resource usage, and generally instrumenting\neverything that you possibly can are gifts to your future self here. For\nexample, consider the following two memory profiles captured with this\nexcellent pytorch tool:\n\nSaving a snapshot of memory use over two successive batches of training data\nreveals an unexpected spike in memory (left) until a fix is put in place\n(right)\n\nIn this case, a somewhat sneaky bug had crept in, causing memory usage to\nspike in the second batch of training. Printing the memory use at different\nstages helped show that something funky was going on, but it was only through\na combination of memory profiling and a minimal example that I was able to\nspot the issue. I hadn\u2019t used this memory visualization tool before - it\u2019s\nonly a few months old, and I hadn\u2019t heard of it until a colleague suggested\nit. Imagine all of the pain that could be saved if more AI researchers used\ntools like this!\n\nWhether you\u2019re on team \u201cinspect it manually in a debugger\u201d, team \u201cprint all\nthe things\u201d or team \u201clog to W&B and call that good\u201d, make sure you have some\nway to see more of what is actually going on wherever possible :)\n\n## Tip 3: Teamwork FTW\n\nExplaining a problem is an excellent debugging tool, even if the explainee\ndoesn\u2019t actually contribute any new knowledge - hence the excellent \u201crubber\nduck debugging\u201d technique. However, team members with deep complimentary\nknowledge are even better than a mute duck, and talking through things rather\nthan suffering in silence almost always pays off and leads to a quick\nsolution. If you don\u2019t have formal work colleagues, sharing in public forums\nor pestering your technical friends is often just as good.\n\nA missed opportunity for some instructive pair programming with a friend.\n\nAnother benefit of working with a team is the ability to divide and conquer\nwhen one \u2018problem\u2019 turns out to be many sub-problems in a trench coat. This\none plays nicely with Tips 1 and 2 - if you\u2019ve got well-instrumented minimal\nexamples it\u2019s a lot easier to identify specific issues, and have others work\non them without needing to front-load the full complexity of the task.\n\n## Tip 4: Refactor repeatedly to surface + eliminate complexity where possible\n\nSoftware complexity tends to grow over time. Features get added, chunks of\ncode get split into different files and made more modular, options proliferate\nas more and more configurations are supported... All of this may be perfectly\nreasonable, but can make it difficult to understand a specific circumstance.\nFocusing on one task and bringing as much of the code as possible into a\nsingle notebook or python file can be a great tool for debugging, forcing you\nto read the important bits as they get refactored out of their silos and into\nyour new version.\n\nYou may worry that the state-of-the-art deep learning techniques are beyond\nyou. Worry not! Beneath all the layers there are almost always fairly simple\npieces. For example, consider the case of applying LoRA adapters to a model. I\nhad to do this for a video I was making on diffusion models. The diffusers\nlibrary implementation spans multiple layers of abstractions and is stuffed\nwith conditions to handle different formats and approaches. It was only when I\nextracted out and re-wrote the key step that I could properly understand it\nand begin to experiment.\n\nMerging in LoRA weights in a diffusion model pipeline: minimal implementation\ncompared to the >300LOC diffusers version. Theirs supports far more options,\nbut for experimenting + debugging a minimal re-implementation was far easier\nto work with and understand. Once things are working, we can always switch\nback to the more complicated \u2018official\u2019 version.\n\nIdeally, start from some minimal example and build up from there. Your final\nresult doesn\u2019t need to be a permanent artefact, but having everything in one\nplace when working on especially thorny problems is extremely useful. This is\na skill that is hard to learn from examining others\u2019 code, since we typically\nonly get a look at the final result. Notebooks can be a great way to share the\nprogression as you verify things a few lines at a time before combining them\ninto larger blocks, but even here we usually see just the final (working)\nversion rather than all the intermediate pieces.\n\n## Final Remarks\n\nThese high-surface-area problems are tough. It\u2019s hard to get into flow when\nthere are so many questions that need answers, and debugging them is often a\nslog rather than a flash of inspiration. The final results can sometimes feel\nunderwhelming compared to coming up with some flashy new algorithm. And yet by\npushing through and persevering you can have a big impact... Hopefully this\npost has inspired you to do so, and given you a few tips to keep in mind when\nyou do.\n\n", "frontpage": false}
