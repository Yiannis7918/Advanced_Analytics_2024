{"aid": "40028166", "title": "Why `Streaming` Is My Favourite Haskell Streaming Library", "url": "http://jackkelly.name/blog/archives/2024/04/13/why_streaming_is_my_favourite_haskell_streaming_library/", "domain": "jackkelly.name", "votes": 1, "user": "todsacerdoti", "posted_at": "2024-04-14 02:23:59", "comments": 0, "source_title": "Why `streaming` Is My Favourite Haskell Streaming Library | Blog | jackkelly.name", "source_text": "Why `streaming` Is My Favourite Haskell Streaming Library | Blog | jackkelly.name\n\n# Why `streaming` Is My Favourite Haskell Streaming Library\n\nPosted on April 13, 2024 by Jack Kelly\n\nTags: coding, haskell\n\nIt\u2019s really easy to misuse lazy I/O (e.g., hGetContents) in nontrivial Haskell\nprograms. You can accidentally close a Handle before the computation which\nreads from it has been forced, and it\u2019s hard to predict exactly when data will\nbe produced or consumed by IO actions. Streaming libraries in Haskell avoid\nthese problems by explicitly interleaving the yielding of data and execution\nof effects, as well as helping control the memory usage of a program by\nlimiting the amount of data \u201cin flight\u201d.\n\nA number of veteran Haskellers have built streaming libraries, and off the top\nof my head I\u2019m aware of conduit, io-streams, iteratee, machines, pipes,\nstreaming, and streamly. Of those, I think conduit, pipes, streaming, and\nstreamly are the most commonly used ones today. It can be hard to know which\nlibrary to choose when there\u2019s so many options, so here is my heuristic:\n\n  1. If you\u2019re doing simple streaming (e.g., from a network connection straight into a file), use whatever your library uses (usually conduit); or\n  2. If you\u2019re doing anything more complicated, or you\u2019re doing greenfield work, use streaming.\n\nI\u2019ll explain why after the jump.\n\n## The Shortlist\n\n### Pipes\n\nFrom what I can tell, pipes and conduit are the most common industrial\nstreaming libraries. pipes is beautiful and elegant, but despite its very\nextensive tutorial (complete with beautiful diagrams and composition laws), I\nhave never been able to successfully write a nontrivial program using it. I\nthink it is too complicated, and its author regrets the complexity of pipes\u2019s\ncore type:\n\n> I firmly subscribe to the principle of least power which says that you\n> should use the simplest type or abstraction available that gets the job done\n> instead of trying to shoehorn everything into the same \u201cgod type\u201d or \u201cgod\n> abstraction\u201d. I learned this the hard way when I tried to shoehorn\n> everything into my pipes package and realized that it was a huge mistake, so\n> it\u2019s not like I\u2019m innocent in this regard. Don\u2019t make the same mistake I\n> did.\n\nThere are many attractive tools in the pipes ecosystem, but they all seem to\nuse pretty high-powered type signatures that even now I struggle to follow.\nExample: to re-chunk a Producer using pipes-group, you use the chunksOf\nfunction, which has this type signature:\n\n    \n    \n    chunksOf :: Monad m => -- | Chunk size Int -> Lens (Producer a' m x) (Producer a m x) (FreeT (Producer a' m) m x) (FreeT (Producer a m) m x)\n\nI\u2019ve been doing Haskell professionally for several years, and I still find\nthat signature a little intimidating. I can see why it\u2019s a Lens (it bundles\nthe chunking/unchunking operations together), but if we\u2019re doing optics, why\nisn\u2019t it an Iso? I also get the vibe of why it\u2019s using FreeT, but have zero\nmuscle memory when it comes to working with that type.\n\n### Conduit\n\nconduit, on the other hand, feels much more rough-and-ready, with additional\nconcepts like \u201cleftovers\u201d adding incidental complexity to the design. Many\nlibraries for common tasks like HTTP request/response use conduit, so it has a\nstrong gravitational pull. For simple applications, it\u2019s often easier to stick\nwith conduit and not worry about converting to/from some \u201cbetter\u201d streaming\nlibrary.\n\nBut every time I try to do something non-trivial with conduit, I feel like the\nAPI can do everything except solve my problem. I think this is partially due\nto the design of its core type: the ConduitT monad transformer, which lets you\nbuild computations which are part of a streaming pipeline:\n\n    \n    \n    data ConduitT i o m r -- | | | | -- | | | `- Final result type -- | | `--- Monad in which it can perform actions -- | `----- Output type (yielded downstream) -- `------- Input type (awaited from upstream)\n\nThis design decision (which I think is inspired by a similar type in pipes)\nleads to (IMHO) an unfortunate splitting of the interface: I can never figure\nout whether a function should be implemented as its own conduit (and connected\nas a subsequent stage in the pipeline), or as a function which transforms\nstreams.\n\nA challenge for conduit wizards: write a function that can rechunk a ConduitT\ni ByteString m r into yielding fixed-length ByteString substreams, without\nbuffering. I want to stream the data as I receive it, and only split a\nByteString if it spans a chunk boundary. The amount of data streamed out for\neach chunk except the final one should be equal to a chunk size argument, but\nthe final chunk might necessarily be smaller. I imagine that the type I\u2019d want\nis a function to turn the conduit into a conduit-that-yields-conduits, which\ncan be consumed piecemeal:\n\n    \n    \n    -- Possible type signature? rechunk :: ConduitT i ByteString m r -> ConduitT i (ConduitT () ByteString m ()) m r\n\nBut I really have no idea how to do this with conduit or pipes, while\nstreaming-bytestring can easily do it by repeatedly applying splitAt.\n\n### Streamly\n\nstreamly is a relatively new library in this space, and a very ambitious\nproject. It makes really bold performance claims and uses aggressive under-\nthe-hood concurrency to try and achieve them. It also provides a broad,\nunified toolbox of data streaming/concurrency/folding abstractions. I haven\u2019t\nused it since a change in its file-watching functions broke a work program\nduring a minor version update, leading us to remove it. That makes me shy away\nfrom it, but that was also a few years ago. It\u2019s had a fresh release this year\nand is probably worth keeping an eye on.\n\n## Streaming\n\nThe streaming package has a radically simpler design than any of the others\nwe\u2019ve discussed so far. It uses two core types, Stream and Of:\n\n    \n    \n    -- f: The functor which contains the stream elements -- m: The monad in which actions occur -- r: The type of the final result data Stream f m r = Step !(f (Stream f m r)) | Effect (m (Stream f m r)) | Return r data Of a b = !a :> b deriving Functor\n\nThe most common instantiation you see for a Stream is f ~ Of a, giving Stream\n(Of a) m r. A simple example might be a stream that yields the integers 1, 2,\n3 in order:\n\n    \n    \n    -- This is spelled out for clarity. -- There are more concise ways to write this stream. oneTwoThree :: Stream (Of Int) m () oneTwoThree = Step (1 :> Step (2 :> Step (3 :> Return ())))\n\nThe strictness annotations on the Step constructor and the left side of the Of\nconstructor ensure that stream elements will be forced to WHNF as soon as\nthey\u2019re yielded. The payoff from making the f parameter to Stream an arbitrary\nFunctor is that you can use more complicated structures as \u201cstream elements\u201d\nto achieve things like chunking with perfect streaming. Compare streaming\u2019s\nchunksOf to the one from pipes-group above:\n\n    \n    \n    chunksOf :: (Monad m, Functor f) => Int -> Stream f m r -> Stream (Stream f m) m r\n\nSo if f ~ Of a, chunksOf 3 would turn a Stream (Of a) m r into a Stream\n(Stream (Of a) m) m r \u2014 a stream of streams, which is exactly the behaviour we\nwant.\n\nBecause streaming doesn\u2019t have the pipes/conduit concept of \u201chorizontal\ncomposition\u201d, it can unify \u201cconnecting a consumer\u201d with \u201ctransforming the\nstream\u201d \u2014 both are standard function application.\n\nstreaming has one major wart, and I think it\u2019s a forgivable one: It has a\nseparate type for streaming ByteStrings. The Streaming.ByteString.ByteStream\ntype from streaming-bytestring is morally Stream (Of ByteString) m r, but with\nthe ByteStrings {-# UNPACK #-}-ed directly into the data structure. This is\nsuch a common special case that I think it\u2019s worth the specialisation.\n\n### Other Tricks With The Functor Parameter\n\nI\u2019ve praised simplicity a lot in this post, so now it\u2019s time to really justify\nthat f parameter to Stream. It would be much easier to bake the item directly\ninto the Step constructor, but the additional f adds a lot of power. We\u2019ve\nseen it used in chunksOf already, but it\u2019s possible to do even more. I\u2019ve been\nworking on a decompressor for an old computer game, and streaming allowed me\nto say some pretty useful things:\n\n    \n    \n    -- | Attempt to parse the header records from the start of a byte -- stream. On success, return the remainder of the stream. decodeHeader :: Monad m => ByteStream m r -> m (Either String (Header, ByteStream m r)) -- | Break up and decompress the input stream by zipping it with the -- list of records from the header. You can process each byte stream -- by using @Streaming.'Streaming.mapsM_'@. decompressAll :: MonadIO m => Header -> ByteStream m r -> Stream (Compose (Of Record) (ByteStream m)) m r\n\nLet\u2019s look into that Stream (Compose (Of Record) (ByteStream m)) m r type, and\nconsider what we\u2019ll actually have in the Step constructor of the result\nStream:\n\n  * Step !(f (Stream f m r)) is how the constructor is declared. Let\u2019s call the argument to f RestOfStream to keep the noise down;\n\n  * f is (Compose (Of Record) (ByteStream m)), so we\u2019re holding a (Compose (Of Record) (ByteStream m)) RestOfStream;\n\n  * Compose is from Data.Functor.Compose:\n    \n        newtype Compose f g a = Compose { getCompose :: f (g a)}\n\nExpanding the newtype shows that we\u2019re holding something representationally\nequal to Of Record (ByteStream m RestOfStream);\n\n  * Of is the left-strict pair, so we get the Record from the archive (strictly) alongside a (lazy) ByteStream corresponding to its data. At the end of that ByteStream, we get the next record from the archive, and so on until we stream out the entire file.\n\nLet me repeat that last part: as the stream iterates through the records, it\nyields the Record it\u2019s decompressing, as well as the corresponding\nuncompressed ByteStream, and you must reach the end of the ByteStream before\nyou can start on the next Record. This makes it very hard to accidentally\nbuffer one record before starting on the next, and since I can\u2019t even figure\nout how to do something as simple as a perfect rechunking of a ConduitT, I\nhave no idea how you\u2019d do this in pipes or conduit. Maybe I\u2019m not just not\nsmart enough.\n\nstreaming seems to make the easy jobs easy and the hard jobs possible, which\nis why it\u2019s the one I reach for by default.\n\nPrevious Post\n\nAll Posts | RSS | Atom\n\nCopyright \u00a9 2024 Jack Kelly\n\nSite generated by Hakyll (source)\n\n", "frontpage": false}
