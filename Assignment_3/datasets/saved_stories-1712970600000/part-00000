{"aid": "40016535", "title": "How Comma AI's OpenPilot Works (2020)", "url": "https://desosa.nl/projects/openpilot/2020/03/11/from-vision-to-architecture", "domain": "desosa.nl", "votes": 2, "user": "lord_sudo", "posted_at": "2024-04-12 19:07:32", "comments": 0, "source_title": "From Vision To Architecture: How to use openpilot and live - DESOSA 2020", "source_text": "From Vision To Architecture: How to use openpilot and live - DESOSA 2020\n\nDESOSA 2020\n\n# From Vision To Architecture: How to use openpilot and live\n\nAutonomous driving is a very simple task in theory, but still remains unsolved\nat large. How does openpilot tackle the problems that arise on the road?\n\nBefore we explore openpilot\u2019s inner workings, let\u2019s do a little thought\nexperiment.\n\n## Our Very Own openpilot\n\nImagine we were designing very simple software for an autonomous vehicle. In\norder for it to react to the environment (other cars, a lane split), we need\nto be able to read sensor data, act on that data and update the actuators,\nsuch as the steering wheel or throttle.\n\nFrom this description, we can derive a very simple abstract implementation of\nthe core system functionality:\n\n    \n    \n    while (true) { read sensor data compute adjustments using machine-learning model apply adjustments to actuators }\n\nWhile this may seem overly simplified, in essence this is how openpilot works\ninternally. In reality, openpilot uses over 300 Python files divided into\nvarious submodules, dependencies and multiple hardware components to run this\nsystem.\n\nThis post aims to outline the main architectural components and processes\nalong the path from sensor input to actuator output, their responsibilities,\nthe design patterns applied within or between components and the trade-offs\nthat were encountered in this architecture.\n\n## The Architecture\n\nNow that we have a basic idea about how an autonomous system works, let\u2019s see\nhow openpilot actually does it.\n\nWe identified the main components of openpilot by analysing and running the\nsource code from the GitHub repository and created a neat and tidy diagram\nfrom that analysis. Don\u2019t worry if this diagram seems overwhelming, in the\nfollowing sections we will try our best to explain what each component means\nand does. You, the reader, are encouraged to go back and forth between the\ntext and this diagram to fully grasp openpilot\u2019s inner workings.\n\nThe architecture diagram is a combination of run-time and development view,\nsince they are related and best explained together in this system. The logical\nview is not discussed because the system performs mostly a single task\n(control your car) and there is not much end-user functionality. The\nprocess/deployment view is also not discussed. This is because some parts of\ncomma.ai\u2019s deployment procedures and cloud infrastructure are not open source\nresulting in an incomplete analysis.\n\nMultiple sensors observe the environment in and around the car. The stock\nsensors included by the manufacturer are a radar and an infrared sensor. The\nComma Two delivers a front-facing camera, GPS, and an infrared driver\ndistraction camera. These inputs are unified to deliver the desired\nfunctionality.\n\nThe diagram conveys another important architectural decision that the\nopenpilot developers made: openpilot is not a single monolithic process but\nrather a coordinated cluster of processes. Being able to prioritize some\nprocesses over others gives openpilot the ability to adhere to the strict\ntiming requirements necessary for autonomous driving.\n\nWe\u2019re now going to untangle said processes in the bottom part of the diagram\nby analysing two scenarios:\n\n  1. A car is braking in front of us\n  2. The road is curving\n\nIn the following text, we will investigate these scenarios step by step,\nexplaining what the software components are, their responsibilities, and how\nthey communicate.\n\n### Scenario 1: Lead car brakes/slows down\n\nNow consider a car in front of you that suddenly brakes. Your ACC-equipped car\nwill notice this and its radar will send a message to the CAN bus. The CAN bus\nis continuously read by a hardware device of comma.ai\u2019s making, called the\npanda.\n\nThe panda forwards this information to openpilot\u2019s comma two. This Android\ndevice runs several background processes (~20 in total), that all communicate\nwith each other and coordinate their actions.\n\nAll messages to and from the panda are managed by the boardd background\nprocess. boardd publishes these messages for other processes to use.\n\nradard is listening closely to the messages boardd publishes, and will notice\na message from the car\u2019s radar system. radard combines the radar CAN message\npublished by boardd with data published by modeld (see the next section) and\npublishes a radarState message, which contains information such as the lead\ncar distance.\n\nThis radarState message is then picked up by plannerd. plannerd\u2019s\nresponsibility includes, as the name already conveys, planning the path the\ncar needs to take. It publishes this path, which can then be consumed by other\nprocesses.\n\nThe final process involved in this scenario is controlsd. Remember our little\npseudo-code loop at the beginning of this post? That while loop is implemented\nalmost verbatim in controlsd. controlsd converts the path published by\nplannerd into actual CAN messages, and does so in a car model-agnostic way.\nThis is an important detail, because openpilot aims to support as many cars as\npossible, and having controlsd use interfaces instead of concrete\nimplementations facilitates this vision. Adding support for new car models\nmainly deals with implementing new concrete implementations of the interfaces\nthat controlsd uses.\n\nFinally, controlsd sends the CAN messages back to boardd, which then writes\nthem to the car\u2019s CAN bus via the panda.\n\n### Scenario 2: Direction changes/road curve\n\nEven highways have curves. How does openpilot sense line markers and act upon\ncurves? Let\u2019s investigate.\n\nThe starting point for our analysis this time is not boardd, but camerad.\ncamerad, on the surface, is a very simple process with the only responsibility\nof publishing video frames from the back- and front facing cameras. These\nframes can then be consumed by other processes.\n\nOne process that is particularly interested in these frames is modeld. modeld\ntransforms the camera frames using its machine learning model and publishes\nthe result.\n\nFrom this point on, the same processes are involved as in scenario 1. Namely,\nplannerd watches modeld\u2019s output and incorporates it into its path planning.\nplannerd emits a steering wheel torque change encoded as a CAN message, which\nis then picked up by boardd and sent to the car\u2019s CAN bus.\n\n### Infrastructure Components\n\nIn the above two scenarios we visited arguably openpilot\u2019s most important\nprocesses. They are, however, not the only components within openpilot\u2019s\necosystem.\n\nOther components not directly related to core functionality aren\u2019t that\ninteresting, so we won\u2019t spend many words on them:\n\n  * A collection of bash scripts is used to remotely pull and install new releases.\n  * Additional APK files to be installed by the user are located in the APK folder.\n  * Phonelibs contains libraries used on the Comma Two for communication with Android.\n  * Pyextra contains library-like functionality used by multiple components, including explicit exception messages.\n\n## Putting it together with code\n\nGiven the architectural outline above, we can look into the process of\nimplementing it. So, put yourself in the shoes of a software architect for an\nautonomous driving system and think about the requirements that the system\nmust adhere to:\n\n  * Atomic (Chapter 6.3) when it comes to signal handling. Because we deal with data that eventually physically moves the car, ambiguous instructions are intolerable.\n  * Compatible and extensible. Since the vision of comma.ai includes offering support for all popular cars, the code should also be designed for this.\n  * Universal. When your product is reliant on the open-source community, it helps when common ideas from software design are applied.\n  * Modular (Chapter 3.5). When changing or improving certain parts in your system, you do not want to touch the whole codebase. Additionally, modularity allows the separate modules to be tested independently and allows the use of multiple programming languages or protocols.\n\nOpenpilot possesses these requirements and provides us with nice examples of\nimplemented design patterns, the most noteworthy to shed additional light on\nis publish and subscribe. This pattern plays a fundamental role in the\nautonomous driving system and enforces all things listed in the bullet list\nabove. Briefly said, publish and subscribe is a system to orchestrate message\npassing between different software systems or components. The publishers only\nsend, while the subscriber solely receives messages from the publishers that\nit is subscribed to.\n\nPub-Sub is particularly useful when an application asynchronously communicates\nwith other applications that are not necessarily implemented in the same\nlanguage and executed on the same platform or system. Moreover, within each\ncomponent it allows for cherry-picking from the available publishers. This\nensures that critical information only resides in places where it is of vital\nimportance and introduces extensibility.\n\n## Extensibility in general\n\nNext to the publish and subscribe pattern, openpilot has embraced other best\npractices from software engineering to allow for compatibility and\nflexibility. Examples include the use of base classes and interfaces. We can\nrelate these phenomena to the product vision that aims to provide a\ndistributed decentralized self driving car platform that is built and\nmaintained by a community. Zooming out a bit and looking from a deployment\nperspective; cereal, opendbc and panda are becoming standalone projects in\n2020. Together with the newly proposed development flow this should make it\nvery interesting for people from the open-source community to contribute and\ncreate a system in which quality and community are keywords.\n\n## Trade-offs\n\nWe have seen some of the functional properties of the system, now we will take\na look at some non-functional properties and their trade-offs.\n\n### Performance vs Privacy\n\nGeorge Hotz mentioned in a talk he gave in June 2019 that he believes that\n\u201cThe definition of driving is what people do when they drive\u201d, implying that a\ndriving assistant should be based on data provided by drivers. As mentioned\nand seen in the architecture diagram, one of the key parts of the system is\nthe driving model, modeld. Because the driving model plays a vital part in the\nsystem it needs to be accurate and consistent, in order to prevent potential\naccidents from happening. The data needed for the model comes directly from\ndrivers that use the openpilot system in their car, which brings up the\nquestion of data privacy. Some people might not want their car data to go to\ncomma.ai. However at comma.ai they are very clear about data privacy, if you\nmake use of their system, you give them the consent to use all the data\ngenerated while driving, which was also said by George Hotz in the\naforementioned talk. Thus, they made a trade-off between model performance and\ndata privacy in which they value the performance and accuracy over the privacy\nof the drivers.\n\n### Compatibility vs Maintainability\n\nAs mentioned near the end of scenario 1, openpilot aims to support as many\ncars as possible. Therefore building the system in such a way that it will be\ncompatible with all these different cars and models is very important. As seen\nin the architecture diagram, and mentioned in scenario 1, openpilot deals with\nall these different cars and models by creating a new implementation of the\ninterface used by controlsd. However, by creating all these files it also\nmeans that they need to be maintained separately. With the ever-growing number\nof openpilot supported cars, this means that eventually they need to maintain\nhundreds if not thousands of these interface implementations. Thus meaning\nthat the company chooses to make a trade-off between compatibility and\nmaintainability, by creating a system that has high compatibility, but in\nreturn loses some maintainability.\n\n## Bringing it all together\n\nWhat started out as a simple while-loop ended up in a journey across\nprocesses, modules and design principles. We saw how pub-sub creates a\nmodular, extensible design. We visited the trade-offs that developers made\nover the years, and their implications.\n\nopenpilot is a uniquely complex project, that aims to tackle a uniquely\ncomplex problem.\n\nopenpilot\n\nMar 11, 2020\n\n\u00a9 2020, by the authors. Licensed under CC BY-SA 4.0.\n\n", "frontpage": false}
