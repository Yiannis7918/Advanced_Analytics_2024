{"aid": "40089590", "title": "Teaching Tech Together (2019)", "url": "https://teachtogether.tech/en/index.html", "domain": "teachtogether.tech", "votes": 2, "user": "divyaranjan1905", "posted_at": "2024-04-19 17:27:00", "comments": 0, "source_title": "Teaching Tech Together", "source_text": "Teaching Tech Together\n\n# Teaching Tech Together\n\nHow to create and deliver lessons that work and build a teaching community\naround them\n\nGreg Wilson\n\nTaylor & Francis, 2019, 978-0-367-35328-5\n\nPurchase online\n\nDedication\n\nFor my mother, Doris Wilson, who taught hundreds of children to read and to\nbelieve in themselves.\n\nAnd for my brother Jeff, who did not live to see it finished. \"Remember, you\nstill have a lot of good times in front of you.\"\n\nAll royalties from the sale of this book are being donated to the Carpentries,\na volunteer organization that teaches foundational coding and data science\nskills to researchers worldwide.\n\n# The Rules\n\n  1. Be kind: all else is details.\n\n  2. Remember that you are not your learners...\n\n  3. ...that most people would rather fail than change...\n\n  4. ...and that ninety percent of magic consists of knowing one extra thing.\n\n  5. Never teach alone.\n\n  6. Never hesitate to sacrifice truth for clarity.\n\n  7. Make every mistake a lesson.\n\n  8. Remember that no lesson survives first contact with learners...\n\n  9. ...that every lesson is too short for the teacher and too long for the learner...\n\n  10. ...and that nobody will be more excited about the lesson than you are.\n\n# Introduction\n\nGrassroots groups have sprung up around the world to teach programming, web\ndesign, robotics, and other skills to free-range learners. These groups exist\nso that people don\u2019t have to learn these things on their own, but ironically,\ntheir founders and teachers are often teaching themselves how to teach.\n\nThere\u2019s a better way. Just as knowing a few basic facts about germs and\nnutrition can help you stay healthy, knowing a few things about cognitive\npsychology, instructional design, inclusivity, and community organization can\nhelp you be a more effective teacher. This book presents key ideas you can use\nright now, explains why we believe they are true, and points you at other\nresources that will help you go further.\n\n> #### Re-Use\n>\n> Parts of this book were originally created for the Software Carpentry\n> instructor training program, and all of it can be freely distributed and re-\n> used under the Creative Commons Attribution-NonCommercial 4.0 license\n> (Appendix 16). You can use the online version at http://teachtogether.tech/\n> in any class (free or paid), and can quote short excerpts under fair use\n> provisions, but cannot republish large parts in commercial works without\n> prior permission.\n>\n> Contributions, corrections, and suggestions are all welcome, and all\n> contributors will be acknowledged each time a new version is published.\n> Please see Appendix 18 for details and Appendix 17 for our code of conduct.\n\n## Who You Are\n\nSection 6.1 explains how to figure out who your learners are. The four that\nthis book is for are all end-user teachers: teaching isn\u2019t their primary\noccupation, they have little or no background in pedagogy, and they may work\noutside institutional classrooms.\n\nEmily\n\n    \n\ntrained as a librarian and now works as a web designer and project manager in\na small consulting company. In her spare time she helps run web design classes\nfor women entering tech as a second career. She is now recruiting colleagues\nto run more classes in her area, and wants to know how to make lessons others\ncan use and grow a volunteer teaching organization.\n\nMoshe\n\n    \n\nis a professional programmer with two teenage children whose school doesn\u2019t\noffer programming classes. He has volunteered to run a monthly after-school\nprogramming club, and while he frequently gives presentations to colleagues,\nhe has no classroom experience. He wants to learn how to build effective\nlessons in reasonable time, and would like to know more about the pros and\ncons of self-paced online classes.\n\nSamira\n\n    \n\nis an undergraduate in robotics who is thinking about becoming a teacher after\nshe graduates. She wants to help at weekend robotics workshops for her peers,\nbut has never taught a class before and feels a lot of impostor syndrome. She\nwants to learn more about education in general in order to decide if it\u2019s for\nher, and is also looking for specific tips to help her deliver lessons more\neffectively.\n\nGene\n\n    \n\nis a professor of computer science. They have been teaching undergraduate\ncourses on operating systems for six years, and increasingly believe that\nthere has to be a better way. The only training available through their\nuniversity\u2019s teaching and learning center is about posting assignments and\nsubmitting grades in the online learning management system, so they want to\nfind out what else they should be asking for.\n\nThese people have a variety of technical backgrounds and some previous\nteaching experience, but no formal training in teaching, lesson design, or\ncommunity organization. Most work with free-range learners and are focused on\nteenagers and adults rather than children; all have limited time and\nresources. We expect our quartet to use this material as follows:\n\nEmily\n\n    \n\nwill take part in a weekly online reading group with her volunteers.\n\nMoshe\n\n    \n\nwill cover part of this book in a one-day weekend workshop and study the rest\non his own.\n\nSamira\n\n    \n\nwill use this book in a one-semester undergraduate course with assignments, a\nproject, and a final exam.\n\nGene\n\n    \n\nwill read the book on their own in their office or while commuting, wishing\nall the while that universities did more to support high-quality teaching.\n\n## What to Read Instead\n\nIf you are in a hurry or want a taste of what this book will cover, [Brow2018]\npresents ten evidence-based tips for teaching computing. You may also enjoy:\n\n  * The Carpentries instructor training, from which this book is derived.\n\n  * [Lang2016] and [Hust2012], which are short and approachable, and which connect things you can do right now to the research that backs them.\n\n  * [Berg2012,Lemo2014,Majo2015,Broo2016,Rice2018,Wein2018b] are all full of practical suggestions for things you can do in your classroom, but may make more sense once you have a framework for understanding why their ideas work.\n\n  * [DeBr2015], which explains what\u2019s true about education by explaining what isn\u2019t, and [Dida2016], which grounds learning theory in cognitive psychology.\n\n  * [Pape1993], which remains an inspiring vision of how computers could change education. Amy Ko\u2019s excellent description does a better job of summarizing Papert\u2019s ideas than I possibly could, and [Craw2010] is a thought-provoking companion to both.\n\n  * [Gree2014,McMi2017,Watt2014] explain why so many attempts at educational reform have failed over the past forty years, how for-profit colleges are exploiting and exacerbating the growing inequality in our society, and how technology has repeatedly failed to revolutionize education.\n\n  * [Brow2007] and [Mann2015], because you can\u2019t teach well without changing the system in which we teach, and you can\u2019t do that on your own.\n\nThose who want more academic material may also find\n[Guzd2015a,Hazz2014,Sent2018,Finc2019,Hpl2018] rewarding, while Mark Guzdial\u2019s\nblog has consistently been informative and thought-provoking.\n\n## Acknowledgments\n\nThis book would not exist without the contributions of Laura Acion, Jorge\nAranda, Mara Averick, Erin Becker, Yanina Bellini Saibene, Azalee Bostroem,\nHugo Bowne-Anderson, Neil Brown, Gerard Capes, Francis Castro, Daniel Chen,\nDav Clark, Warren Code, Ben Cotton, Richie Cotton, Karen Cranston, Katie\nCunningham, Natasha Danas, Matt Davis, Neal Davis, Mark Degani, Tim Dennis,\nPaul Denny, Michael Deutsch, Brian Dillingham, Grae Drake, Kathi Fisler, Denae\nFord, Auriel Fournier, Bob Freeman, Nathan Garrett, Mark Guzdial, Rayna\nHarris, Ahmed Hasan, Ian Hawke, Felienne Hermans, Kate Hertweck, Toby Hodges,\nRoel Hogervorst, Mike Hoye, Dan Katz, Christina Koch, Shriram Krishnamurthi,\nKatrin Leinweber, Colleen Lewis, Dave Loyall, Pawe\u0142 Marczewski, Lenny Markus,\nSue McClatchy, Jessica McKellar, Ian Milligan, Julie Moronuki, Lex Nederbragt,\nAleksandra Nenadic, Jeramia Ory, Joel Ostblom, Elizabeth Patitsas, Aleksandra\nPawlik, Sorawee Porncharoenwase, Emily Porta, Alex Pounds, Thomas Price,\nDanielle Quinn, Ian Ragsdale, Erin Robinson, Rosario Robinson, Ariel Rokem,\nPat Schloss, Malvika Sharan, Florian Shkurti, Dan Sholler, Juha Sorva, Igor\nSteinmacher, Tracy Teal, Tiffany Timbers, Richard Tomsett, Preston Tunnell\nWilson, Matt Turk, Fiona Tweedie, Martin Ukrop, Anelda van der Walt, St\u00e9fan\nvan der Walt, Allegra Via, Petr Viktorin, Belinda Weaver, Hadley Wickham,\nJason Williams, Simon Willison, Karen Word, John Wrenn, and Andromeda Yelton.\nI am also grateful to Lukas Blakk for the logo, to Shashi Kumar for LaTeX\nhelp, to Markku Rontu for making the diagrams look better, and to everyone who\nhas used this material over the years. Any mistakes that remain are mine.\n\n## Exercises\n\nEach chapter ends with a variety of exercises that include a suggested format\nand how long they usually take to do in person. Most can be used in other\nformats\u2014in particular, if you are going through this book on your own, you can\nstill do many of the exercises that are intended for groups\u2014and you can always\nspend more time on them than what\u2019s suggested.\n\nIf you are using this material in a teacher training workshop, you can give\nthe exercises below to participants a day or two in advance to get an idea of\nwho they are and how best you can help them. Please read the caveats in\nSection 9.4 before doing this.\n\n### Highs and Lows (whole class/5)\n\nWrite brief answers to the following questions and share with your peers. (If\nyou are taking notes together online as described in Section 9.7, put your\nanswers there.)\n\n  1. What is the best class or workshop you ever took? What made it so good?\n\n  2. What was the worst one? What made it so bad?\n\n### Know Thyself (whole class/10)\n\nShare brief answers to the following questions with your peers. Record your\nanswers so that you can refer back to them as you go through the rest of this\nbook.\n\n  1. What do you most want to teach?\n\n  2. Who do you most want to teach?\n\n  3. Why do you want to teach?\n\n  4. How will you know if you\u2019re teaching well?\n\n  5. What do you most want to learn about teaching and learning?\n\n  6. What is one specific thing you believe is true about teaching and learning?\n\n### Why Learn to Program? (individual/20)\n\nPoliticians, business leaders, and educators often say that people should\nlearn to program because the jobs of the future will require it. However, as\nBenjamin Doxtdator pointed out, many of those claims are built on shaky\nground. Even if they were true, education shouldn\u2019t prepare people for the\njobs of the future: it should give them the power to decide what kinds of jobs\nthere are and to ensure that those jobs are worth doing. And as Mark Guzdial\npoints out, there are actually many reasons to learn how to program:\n\n  1. To understand our world.\n\n  2. To study and understand processes.\n\n  3. To be able to ask questions about the influences on their lives.\n\n  4. To use an important new form of literacy.\n\n  5. To have a new way to learn art, music, science, and mathematics.\n\n  6. As a job skill.\n\n  7. To use computers better.\n\n  8. As a medium in which to learn problem-solving.\n\nDraw a 3 \u00d7 3 grid whose axes are labeled \u201clow,\u201d \u201cmedium,\u201d and \u201chigh\u201d and place\neach reason in one sector according to how important it is to you (the X axis)\nand to the people you plan to teach (the Y axis).\n\n  1. Which points are closely aligned in importance (i.e. on the diagonal in your grid)?\n\n  2. Which points are misaligned (i.e. in the off-diagonal corners)?\n\n  3. How should this affect what you teach?\n\n# Mental Models and Formative Assessment\n\nThe first task in teaching is to figure out who your learners are. Our\napproach is based on the work of researchers like Patricia Benner, who studied\nhow nurses progress from novice to expert [Benn2000]. Benner identified five\nstages of cognitive development that most people go through in a fairly\nconsistent way. For our purposes, we will simplify this progression to three\nstages:\n\nNovices\n\n    \n\ndon\u2019t know what they don\u2019t know, i.e. they don\u2019t yet have a usable mental\nmodel of the problem domain.\n\nCompetent practitioners\n\n    \n\nhave a mental model that\u2019s adequate for everyday purposes. They can do normal\ntasks with normal effort under normal circumstances, and have some\nunderstanding of the limits to their knowledge (i.e. they know what they don\u2019t\nknow).\n\nExperts\n\n    \n\nhave mental models that include exceptions and special cases, which allows\nthem to handle situations that are out of the ordinary. We will discuss\nexpertise in more detail in Chapter 3.\n\nSo what is a mental model? As the name suggests, it is a simplified\nrepresentation of the most important parts of some problem domain that is good\nenough to enable problem solving. One example is the ball-and-spring models of\nmolecules used in high school chemistry. Atoms aren\u2019t actually balls, and\ntheir bonds aren\u2019t actually springs, but the model enables people to reason\nabout chemical compounds and their reactions. A more sophisticated model of an\natom has a small central ball (the nucleus) surrounded by orbiting electrons.\nIt\u2019s also wrong, but the extra complexity enables people to explain more and\nto solve more problems. (Like software, mental models are never finished:\nthey\u2019re just used.)\n\nPresenting a novice with a pile of facts is counter-productive because they\ndon\u2019t yet have a model to fit those facts into. In fact, presenting too many\nfacts too soon can actually reinforce the incorrect mental model they\u2019ve\ncobbled together. As [Mull2007a] observed in a study of video instruction for\nscience students:\n\n> Students have existing ideas about...phenomena before viewing a video. If\n> the video presents...concepts in a clear, well illustrated way, students\n> believe they are learning but they do not engage with the media on a deep\n> enough level to realize that what is presented differs from their prior\n> knowledge... There is hope, however. Presenting students\u2019 common\n> misconceptions in a video alongside the...concepts has been shown to\n> increase learning by increasing the amount of mental effort students expend\n> while watching it.\n\nYour goal when teaching novices should therefore be to help them construct a\nmental model so that they have somewhere to put facts. For example, Software\nCarpentry\u2019s lesson on the Unix shell introduces fifteen commands in three\nhours. That\u2019s one command every twelve minutes, which seems glacially slow\nuntil you realize that the lesson\u2019s real purpose isn\u2019t to teach those fifteen\ncommands: it\u2019s to teach paths, history, tab completion, wildcards, pipes,\ncommand-line arguments, and redirection. Specific commands don\u2019t make sense\nuntil novices understand those concepts; once they do, they can start to read\nmanual pages, search for the right keywords on the web, and tell whether the\nresults of their searches are useful or not.\n\nThe cognitive differences between novices and competent practitioners underpin\nthe differences between two kinds of teaching materials. A tutorial helps\nnewcomers to a field build a mental model; a manual, on the other hand, helps\ncompetent practitioners fill in the gaps in their knowledge. Tutorials\nfrustrate competent practitioners because they move too slowly and say things\nthat are obvious (though they are anything but obvious to novices). Equally,\nmanuals frustrate novices because they use jargon and don\u2019t explain things.\nThis phenomenon is called the expertise reversal effect [Kaly2003], and is one\nof the reasons you have to decide early on who your lessons are for.\n\n> #### A Handful of Exceptions\n>\n> One of the reasons Unix and C became popular is that\n> [Kern1978,Kern1983,Kern1988] somehow managed to be good tutorials and good\n> manuals at the same time. [Fehi2008] and [Ray2014] are among the very few\n> other books in computing that achieve this; even after re-reading them\n> several times, I don\u2019t know how they pull it off.\n\n## Are People Learning?\n\nMark Twain once wrote, \u201cIt ain\u2019t what you don\u2019t know that gets you into\ntrouble. It\u2019s what you know for sure that just ain\u2019t so.\u201d One of the exercises\nin building a mental model is therefore to clear away things that don\u2019t\nbelong. Broadly speaking, novices\u2019 misconceptions fall into three categories:\n\nFactual errors\n\n    \n\nlike believing that Vancouver is the capital of British Columbia (it\u2019s\nVictoria). These are usually simple to correct.\n\nBroken models\n\n    \n\nlike believing that motion and acceleration must be in the same direction. We\ncan address these by having novices reason through examples where their models\ngive the wrong answer.\n\nFundamental beliefs\n\n    \n\nsuch as \u201cthe world is only a few thousand years old\u201d or \u201csome kinds of people\nare just naturally better at programming than others\u201d [Guzd2015b,Pati2016].\nThese errors are often deeply connected to the learner\u2019s social identity, so\nthey resist evidence and rationalize contradictions.\n\nPeople learn fastest when teachers identify and clear up learners\u2019\nmisconceptions as the lesson is being delivered. This is called formative\nassessment because it forms (or shapes) the teaching while it is taking place.\nLearners don\u2019t pass or fail formative assessment; instead, it gives both the\nteacher and the learner feedback on how well they are doing and what they\nshould focus on next. For example, a music teacher might ask a learner to play\na scale very slowly to check their breathing. The learner finds out if they\nare breathing correctly, while the teacher gets feedback on whether the\nexplanation they just gave made sense.\n\n> #### Summing Up\n>\n> The counterpoint to formative assessment is summative assessment, which\n> takes place at the end of the lesson. Summative assessment is like a\n> driver\u2019s test: it tells the learner whether they have mastered the topic and\n> the teacher whether their lesson was successful. One way of thinking about\n> the difference is that a chef tasting food as she cooks it is formative\n> assessments, but the guests tasting it once it\u2019s served is summative.\n>\n> Unfortunately, school has trained most people to believe that all assessment\n> is summative, i.e. that if something feels like a test, doing poorly will\n> count against you. Making formative assessments feel informal helps reduce\n> this anxiety; in my experience, using online quizzes, clickers, or anything\n> else seems to increase it, since most people today believe that anything\n> they do on the web is being watched and recorded.\n\nIn order to be useful during teaching, a formative assessment has to be quick\nto administer (so that it doesn\u2019t break the flow of the lesson) and have an\nunambiguous correct answer (so that it can be used with groups). The most\nwidely used kind of formative assessment is probably the multiple choice\nquestion (MCQ). A lot of teachers have a low opinion of them, but when they\nare designed well, they can reveal much more than just whether someone knows\nspecific facts. For example, suppose you are teaching children how to do\nmulti-digit addition [Ojos2015] and you give them this MCQ:\n\n> What is 37 + 15? a) 52 b) 42 c) 412 d) 43\n\nThe correct answer is 52, but the other answers provide valuable insights:\n\n  * If the child chooses 42, she has no understanding of what \u201ccarrying\u201d means. (She might well write 12 as the answers to 7+5, then overwrite the 1 with the 4 she gets from 3+1.)\n\n  * If she chooses 412, she is treating each column of numbers as a separate problem. This is still wrong, but it\u2019s wrong for a different reason.\n\n  * If she chooses 43 then she knows she has to carry the 1 but is carrying it back into the column it came from. Again, this is a different mistake, and requires a different clarifying explanation from the teacher.\n\nEach of these incorrect answers is a plausible distractor with diagnostic\npower. A distractor is a wrong or less-than-best answer; \u201cplausible\u201d means\nthat it looks like it could be right, while \u201cdiagnostic power\u201d means that each\nof the distractors helps the teacher figure out what to explain next to that\nparticular learner.\n\nThe spread of responses to a formative assessment guides what you do next. If\nenough of the class has the right answer, you move on. If the majority of the\nclass chooses the same wrong answer, you should go back and work on correcting\nthe misconception that distractor points to. If their answers are evenly split\nbetween several options they are probably just guessing, so you should back up\nand re-explain the idea in a different way. (Repeating exactly the same\nexplanation will probably not be useful, which is one of things that makes so\nmany video courses pedagogically ineffective.)\n\nWhat if most of the class votes for the right answer but a few vote for wrong\nones? In that case, you have to decide whether you should spend time getting\nthe minority caught up or whether it\u2019s more important to keep the majority\nengaged. No matter how hard you work or what teaching practices you use, you\nwon\u2019t always be able to give everyone what they need; it\u2019s your responsibility\nas a teacher to make the call.\n\n> #### Where Do Wrong Answers Come From?\n>\n> In order to come up with plausible distractors, think about the questions\n> your learners asked or problems they had the last time you taught this\n> subject. If you haven\u2019t taught it before, think about your own\n> misconceptions, ask colleagues about their experiences, or look at the\n> history of your field: if everyone misunderstood your subject in some way\n> fifty years ago, the odds are that a lot of your learners will still\n> misunderstand it that way today. You can also ask open-ended questions in\n> class to collect misconceptions about material to be covered in a later\n> class, or check question and answer sites like Quora or Stack Overflow to\n> see what people learning the subject elsewhere are confused by.\n\nDeveloping formative assessments makes your lessons better because it forces\nyou to think about your learners\u2019 mental models. In my experience, once I do\nthis I automatically write the lesson to cover the most likely gaps and\nerrors. Formative assessments therefore pay off even if they aren\u2019t used\n(though teaching is more effective if they are).\n\nMCQs aren\u2019t the only kind of formative assessment: Chapter 12 describes other\nkinds of exercises that are quick and unambiguous. Whatever you pick, you\nshould do something that takes a minute or two every 10\u201315 minutes to make\nsure that your learners are actually learning. This rhythm isn\u2019t based on an\nintrinsic attentional limit: [Wils2007] found little support for the often-\nrepeated claim that learners can only pay attention for 10\u201315 minutes.\nInstead, the guideline ensures that if a significant number of people have\nfallen behind, you only have to repeat a short portion of the lesson. Frequent\nformative assessments also keep learners engaged, particularly if they\ninvolved small-group discussion (Section 9.2).\n\nFormative assessments can also be used before lessons. If you start a class\nwith an MCQ and everyone answers it correctly, you can avoid explaining\nsomething that your learners already know. This kind of active teaching gives\nyou more time to focus on things they don\u2019t know. It also shows learners that\nyou respect their time enough not to waste it, which helps with motivation\n(Chapter 10).\n\n> #### Concept Inventories\n>\n> Given enough data, MCQs can be made surprisingly precise. The best-known\n> example is the Force Concept Inventory [Hest1992], which assesses\n> understanding of basic Newtonian mechanics. By interviewing a large number\n> of respondents, correlating their misconceptions with patterns of right and\n> wrong answers, and then improving the questions, its creators constructed a\n> diagnostic tool that can pinpoint specific misconceptions. Researchers can\n> then use that tool to measure the effect of changes in teaching methods\n> [Hake1998].\n>\n> Tew and others developed and validated a language-independent assessment for\n> introductory programming [Tew2011]; [Park2016] replicated it, and [Hamo2017]\n> is developing a concept inventory for recursion. However, it\u2019s very costly\n> to build tools like this, and learners\u2019 ability to search for answers online\n> is an ever-increasing threat to their validity.\n\nWorking formative assessments into class only requires a little bit of\npreparation and practice. Giving learners colored or numbered cards so that\nthey can all answer an MCQ at once (rather than holding up their hands in\nturn), having one of the options be, \u201cI have no idea,\u201d and encouraging them to\ntalk to their neighbors for a few seconds before answering will all help\nensure that your teaching flow isn\u2019t disrupted. Section 9.2 describes a\npowerful, evidence-based teaching method that builds on these simple ideas.\n\n> #### Humor\n>\n> Teachers sometimes put supposedly-silly answers like \u201cmy nose!\u201d on MCQs,\n> particularly ones intended for younger learners. However, these don\u2019t\n> provide any insight into learners\u2019 misconceptions, and most people don\u2019t\n> actually find them funny. As a rule, you should only include a joke in a\n> lesson if you find it funny the third time you re-read it.\n\nA lesson\u2019s formative assessments should prepare learners for its summative\nassessment: no one should ever encounter a question on an exam that the\nteaching did not prepare them for. This doesn\u2019t mean you should never put new\nkinds of problems on an exam, but if you do, you should have given learners\npractice tackling novel problems beforehand. Chapter 6 explores this in depth.\n\n## Notional Machines\n\nThe term computational thinking is bandied about a lot, in part because people\ncan agree it\u2019s important while meaning very different things by it. Rather\nthan arguing over what it does and doesn\u2019t include, it\u2019s more useful to think\nabout the notional machine that you want learners to understand [DuBo1986].\nAccording to [Sorv2013], a notional machine:\n\n  * is an idealized abstraction of computer hardware and other aspects of programs\u2019 runtime environments;\n\n  * enables the semantics of programs to be described; and\n\n  * correctly reflects what programs do when executed.\n\nFor example, my notional machine for Python is:\n\n  1. Running programs live in memory, which is divided between a call stack and a heap.\n\n  2. Memory for data is always allocated from the heap.\n\n  3. Every piece of data is stored in a two-part structure. The first part says what type the data is, and the second part is the actual value.\n\n  4. Booleans, numbers, and character strings are never modified after they are created.\n\n  5. Lists, sets, and other collections store references to other data rather than storing those values directly. They can be modified after they are created, i.e. a list can be extended or new values can be added to a set.\n\n  6. When code is loaded into memory, Python converts it to a sequence of instructions that are stored like any other data. This is why it\u2019s possible to assign functions to variables and pass them as parameters.\n\n  7. When code is executed, Python steps through the instructions, doing what each one tells it to in turn.\n\n  8. Some instructions make Python read data, do calculations, and create new data. Other instructions control what instructions Python executes, which is how loops and conditionals work. Yet another instruction tells Python to call a function.\n\n  9. When a function is called, Python pushes a new stack frame onto the call stack.\n\n  10. Each stack frame stores variables\u2019 names and references to data. Function parameters are just another kind of variable.\n\n  11. When a variable is used, Python looks for it in the top stack frame. If it isn\u2019t there, it looks in the bottom (global) frame.\n\n  12. When the function finishes, Python erases its stack frame and jumps backs to the instructions it was executing before the function call. If there isn\u2019t a \u201cbefore,\u201d the program has finished.\n\nI use this cartoon version of reality whenever I teach Python. After about 25\nhours of instruction and 100 hours of work on their own time, I expect most\nlearners to have a mental model that includes most or all of these features.\n\n## Exercises\n\n### Your Mental Models (think-pair-share/15)\n\nWhat is one mental model you use to understand your work? Write a few\nsentences describing it and give feedback on a partner\u2019s. Once you have done\nthat, have a few people share their models with the whole group. Does everyone\nagree on what a mental model is? Is it possible to give a precise definition,\nor is the concept useful precisely because it is fuzzy?\n\n### Symptoms of Being a Novice (whole class/5)\n\nSaying that novices don\u2019t have a mental model of a particular domain is not\nthe same as saying that they don\u2019t have a mental model at all. Novices tend to\nreason by analogy and guesswork, borrowing bits and pieces of mental models\nfrom other domains that seem superficially similar.\n\nPeople who are doing this often say things that are not even wrong. As a\nclass, discuss what some other symptoms of being a novice are. What does\nsomeone do or say that leads you to classify them as a novice in some domain?\n\n### Modelling Novice Mental Models (pairs/20)\n\nCreate a multiple choice question related to a topic you have taught or intend\nto teach and explain the diagnostic power of each its distractors (i.e. what\nmisconception each distractor is meant to identify).\n\nWhen you are done, trade MCQs with a partner. Is their question ambiguous? Are\nthe misconceptions plausible? Do the distractors actually test for them? Are\nany likely misconceptions not tested for?\n\n### Thinking Things Through (whole class/15)\n\nA good formative assessment requires people to think through a problem. For\nexample, imagine that you have placed a block of ice in a bathtub and then\nfilled the tub to the rim with water. When the ice melts, does the water level\ngo up (so that the tub overflows), go down, or stay the same (Figure 2.1)?\n\nIce in a bathtub\n\nThe correct answer is that the level stays the same: the ice displaces its own\nweight in water, so it exactly fills the \u201chole\u201d it has made when it melts.\nFiguring out why helps people build a model of the relationship between\nweight, volume, and density [Epst2002].\n\nDescribe another formative assessment you have seen or used that required\npeople to think something through and thereby identify flaws in their\nreasoning. When you are done, explain your example to a partner and give them\nfeedback on theirs.\n\n### A Different Progression (individual/15)\n\nThe novice-competent-expert model of skill development is sometimes called the\nDreyfus model. Another commonly-used progression is the four stages of\ncompetence:\n\nUnconscious incompetence:\n\n    \n\nthe person doesn\u2019t know what they don\u2019t know.\n\nConscious incompetence:\n\n    \n\nthe person realizes that they don\u2019t know something.\n\nConscious competence:\n\n    \n\nthe person has learned how to do something, but can only do it while\nconcentrating and may still need to break things down into steps.\n\nUnconscious competence:\n\n    \n\nthe skill has become second nature and the person can do it reflexively.\n\nIdentify one subject where you are at each level. What level are most of your\nlearners at in the subject you teach most often? What level are you trying to\nget them to? How do these four stages relate to the novice-competent-expert\nclassification?\n\n### What Kind of Computing? (individual/10)\n\n[Tedr2008] summarizes three traditions in computing:\n\nMathematical:\n\n    \n\nPrograms are the embodiment of algorithms. They are either correct or\nincorrect, as well as more or less efficient.\n\nScientific:\n\n    \n\nPrograms are more or less accurate models of information processes that can be\nstudied using the scientific method.\n\nEngineering:\n\n    \n\nPrograms are built objects like dams and airplanes, and are more or less\neffective and reliable.\n\nWhich of these best matches your mental model of computing? If none of them\ndo, what model do you have?\n\n### Explaining Why Not (pairs/5)\n\nOne of your learners thinks that there is some kind of difference between text\nthat they type in character by character and identical text that they copy and\npaste. Think of a reason they might believe this or something that might have\nhappened to give them this impression, then pretend to be that learner while\nyour partner explains why this isn\u2019t the case. Trade roles and try again.\n\n### Your Model Now (whole class/5)\n\nAs a class, create a list of the key elements of your mental model of\nlearning. What are the half-dozen most important concepts and how do they\nrelate?\n\n### Your Notional Machines (small groups/20)\n\nWorking in small groups, write up a description of the notional machine you\nwant learners to use to understand how their programs run. How does a notional\nmachine for a blocks-based language like Scratch differ from that for Python?\nWhat about a notional machine for spreadsheets or for a browser that is\ninterpreting HTML and CSS when rendering a web page?\n\n### Enjoying Without Learning (individual/5)\n\nMultiple studies have shown that teaching evaluations don\u2019t correlate with\nlearning outcomes [Star2014,Uttl2017], i.e. that how highly learners rate a\ncourse doesn\u2019t predict how much they remember. Have you ever enjoyed a class\nthat you didn\u2019t actually learn anything from? If so, what made it enjoyable?\n\n## Review\n\nConcepts: Mental modelsConcepts: Assessment\n\n# Expertise and Memory\n\n> Memory is the residue of thought. \u2014 Daniel Willingham, Why Students Don\u2019t\n> Like School\n\nThe previous chapter explained the differences between novices and competent\npractitioners. This one looks at expertise: what it is, how people acquire it,\nand how it can be harmful as well as helpful. We then introduce one of the\nmost important limits on learning and look at how drawing pictures of mental\nmodels can help us turn knowledge into lessons.\n\nTo start, what do we mean when we say someone is an expert? The usual answer\nis that they can solve problems much faster than people who are \u201cmerely\ncompetent\u201d, or that they can recognize and deal with cases where the normal\nrules don\u2019t apply. They also somehow make this look effortless: in many cases,\nthey seem to know the right answer at a glance [Parn2017].\n\nExpertise is more than just knowing more facts: competent practitioners can\nmemorize a lot of trivia without noticeably improving their performance.\nInstead, imagine for a moment that we store knowledge as a network or graph in\nwhich facts are nodes and relationships are arcs^1. The key difference between\nexperts and competent practitioners is that experts\u2019 mental models are much\nmore densely connected, i.e. they are more likely to know a connection between\nany two facts.\n\nThe graph metaphor explains why helping learners make connections is as\nimportant as introducing them to facts: without those connections, people\ncan\u2019t recall and use what they know. It also explains many observed aspects of\nexpert behavior:\n\n  * Experts can often jump directly from a problem to a solution because there actually is a direct link between the two in their mind. Where a competent practitioner would have to reason A \u2192 B \u2192 C \u2192 D \u2192 E, an expert can go from A to E in a single step. We call this intuition: instead of reasoning their way to a solution, the expert recognizes a solution in the same way that they would recognize a familiar face.\n\n  * Densely-connected graphs are also the basis for experts\u2019 fluid representations, i.e. their ability to switch back and forth between different views of a problem [Petr2016]. For example, when trying to solve a problem in mathematics, an expert might switch between tackling it geometrically and representing it as a set of equations.\n\n  * This metaphor also explains why experts are better at diagnosis than competent practitioners: more linkages between facts makes it easier to reason backward from symptoms to causes. (This in turn is why asking programmers to debug during job interviews gives a more accurate impression of their ability than asking them to program.)\n\n  * Finally, experts are often so familiar with their subject that they can no longer imagine what it\u2019s like to not see the world that way. This means they are often less able to teach the subject than people with less expertise who still remember learning it themselves.\n\nThe last of these points is called expert blind spot. As originally defined in\n[Nath2003], it is the tendency of experts to organize explanation according to\nthe subject\u2019s deep principles rather than being guided by what their learners\nalready know. It can be overcome with training, but it is part of reason there\nis no correlation between how good someone is at doing research in an area and\nhow good they are at teaching it [Mars2002].\n\n> #### The J Word\n>\n> Experts often betray their blind spot by using the word \u201cjust,\u201d as in, \u201cOh,\n> it\u2019s easy, you just fire up a new virtual machine and then you just install\n> these four patches to Ubuntu and then you just re-write your entire program\n> in a pure functional language.\u201d As we discuss in Chapter 10, doing this\n> signals that the speaker thinks the problem is trivial and that the person\n> struggling with it must therefore be stupid, so don\u2019t do this.\n\n## Concept Maps\n\nOur tool of choice for representing someone\u2019s mental model is a concept map,\nin which facts are bubbles and connections are labeled connections. As\nexamples, Figure 3.1 shows why the Earth has seasons (from IHMC), and Appendix\n22 presents concept maps for libraries from three points of view.\n\nConcept map for seasons\n\nTo show how concept maps can be using in teaching programming, consider this\nfor loop in Python:\n\n    \n    \n    for letter in \"abc\": print(letter)\n\nwhose output is:\n\n    \n    \n    a b c\n\nThe three key \u201cthings\u201d in this loop are shown in the top of Figure 3.2, but\nthey are only half the story. The expanded version in the bottom shows the\nrelationships between those things, which are as important for understanding\nas the concepts themselves.\n\nConcept map for a for loop\n\nConcept maps can be used in many ways:\n\nHelping teachers figure out what they\u2019re trying to teach.\n\n    \n\nA concept map separates content from order: in our experience, people rarely\nwind up teaching things in the order in which they first drew them.\n\nAiding communication between lesson designers.\n\n    \n\nTeachers with very different ideas of what they\u2019re trying to teach are likely\nto pull their learners in different directions. Drawing and sharing concept\nmaps can help prevent this. And yes, different people may have different\nconcept maps for the same topic, but concept mapping makes those differences\nexplicit.\n\nAiding communication with learners.\n\n    \n\nWhile it\u2019s possible to give learners a pre-drawn map at the start of a lesson\nfor them to annotate, it\u2019s better to draw it piece by piece while teaching to\nreinforce the ties between what\u2019s in the map and what the teacher said. We\nwill return to this idea in Section 4.1.\n\nFor assessment.\n\n    \n\nHaving learners draw pictures of what they think they just learned shows the\nteacher what they missed and what was miscommunicated. Reviewing learners\u2019\nconcept maps is too time-consuming to do as a formative assessment during\nclass, but very useful in weekly lectures once learners are familiar with the\ntechnique. The qualification is necessary because any new way of doing things\ninitially slows people down\u2014if a learner is trying to make sense of basic\nprogramming, asking them to figure out how to draw their thoughts at the same\ntime is an unfair load.\n\nSome teachers are also skeptical of whether novices can effectively map their\nunderstanding, since introspection and explanation of understanding are\ngenerally more advanced skills than understanding itself. For example,\n[Kepp2008] looked at the use of concept mapping in computing education. One of\ntheir findings was that, \u201c...concept mapping is troublesome for many students\nbecause it tests personal understanding rather than knowledge that was merely\nlearned by rote.\u201d As someone who values understanding over rote knowledge, I\nconsider that a benefit.\n\n> #### Start Anywhere\n>\n> When first asked to draw a concept map, many people will not know where to\n> start. When this happens, write down two words associated with the topic\n> you\u2019re trying to map, then draw a line between them and add a label\n> explaining how those two ideas are related. You can then ask what other\n> things are related in the same way, what parts those things have, or what\n> happens before or after the concepts already on the page in order to\n> discover more nodes and arcs. After that, the hard part is often stopping.\n\nConcept maps are just one way to represent our understanding of a subject\n[Eppl2006]; others include Venn diagrams, flowcharts, and decision trees\n[Abel2009]. All of these externalize cognition, i.e. make mental models\nvisible so that they can be compared and combined^2.\n\n> #### Rough Work and Honesty\n>\n> Many user interface designers believe that it\u2019s better to show people rough\n> sketches of their ideas rather than polished mock-ups because people are\n> more likely to give honest feedback on something that they think only took a\n> few minutes to create: if it looks as though what they\u2019re critiquing took\n> hours to create, most will pull their punches. When drawing concept maps to\n> motivate discussion, you should therefore use pencils and scrap paper (or\n> pens and a whiteboard) rather than fancy computer drawing tools.\n\n## Seven Plus or Minus Two\n\nWhile the graph model of knowledge is wrong but useful, another simple model\nhas a sounder physiological basis. As a rough approximation, human memory can\nbe divided into two distinct layers. The first, called long-term or persistent\nmemory, is where we store things like our friends\u2019 names, our home address,\nand what the clown did at our eighth birthday party that scared us so much.\nIts capacity is essentially unlimited, but it is slow to access\u2014too slow to\nhelp us cope with hungry lions and disgruntled family members.\n\nEvolution has therefore given us a second system called short-term or working\nmemory. It is much faster, but also much smaller: [Mill1956] estimated that\nthe average adult\u2019s working memory could only hold 7\u00b12 items at a time. This\nis why phone numbers are 7 or 8 digits long: back when phones had dials\ninstead of keypads, that was the longest string of numbers most adults could\nremember accurately for as long as it took the dial to go around several\ntimes.\n\n> #### Participation\n>\n> The size of working memory is sometimes used to explain why sports teams\n> tend to have about half a dozen members or are broken into sub-groups like\n> the forwards and backs in rugby. It is also used to explain why meetings are\n> only productive up to a certain number of participants: if twenty people try\n> to discuss something, either three meetings are going on at once or half a\n> dozen people are talking while everyone else listens. The argument is that\n> people\u2019s ability to keep track of their peers is constrained by the size of\n> working memory, but so far as I know, the link has never been proven.\n\n7\u00b12 is the single most important number in teaching. A teacher cannot place\ninformation directly in a learner\u2019s long-term memory. Instead, whatever they\npresent is first stored in the learner\u2019s short-term memory, and is only\ntransferred to long-term memory after it has been held there and rehearsed\n(Section 5.1). If the teacher presents too much information too quickly, the\nnew information displaces the old before the latter is transferred.\n\nThis is one of the ways to use a concept map when designing a lesson: it helps\nmake sure learners\u2019 short-term memories won\u2019t be overloaded. Once the map is\ndrawn, the teacher chooses a subsection that will fit in short-term memory and\nlead to a formative assessment (Figure 3.3), then adds another subsection for\nthe next lesson episode and so on.\n\nUsing concept maps in lesson design\n\n> #### Building Concept Maps Together\n>\n> The next time you have a team meeting, give everyone a sheet of paper and\n> have them spend a few minutes drawing their own concept map of the project\n> you\u2019re all working on. On the count of three, have everyone reveal their\n> concept maps to their group. The discussion that follows may help people\n> understand why they\u2019ve been tripping over each other.\n\nNote that the simple model of memory presented here has largely been replaced\nby a more sophisticated one in which short-term memory is broken down into\nseveral modal stores (e.g. for visual vs. linguistic memory), each of which\ndoes some involuntary preprocessing [Mill2016a]. Our presentation is therefore\nan example of a mental model that aids learning and everyday work.\n\n### Pattern Recognition\n\nRecent research suggests that the actual size of short-term memory might be as\nlow as 4\u00b11 items [Dida2016]. In order to handle larger sets of information,\nour minds create chunks. For example, most of us remember words as single\nitems rather than as sequences of letters. Similarly, the pattern made by five\nspots on cards or dice is remembered as a whole rather than as five separate\npieces of information.\n\nExperts have more and larger chunks than non-experts, i.e. experts \u201csee\u201d\nlarger patterns and have more patterns to match things against. This allows\nthem to reason at a higher level and to search for information more quickly\nand more accurately. However, chunking can also mislead us if we mis-identify\nthings: newcomers really can sometimes see things that experts have looked at\nand missed.\n\nGiven how important chunking is to thinking, it is tempting to identify design\npatterns and teach them directly. These patterns help competent practitioners\nthink and talk to each other in many domains (including teaching [Berg2012]),\nbut pattern catalogs are too dry and too abstract for novices to make sense of\non their own. That said, giving names to a small number of patterns does seem\nto help with teaching, primarily by giving the learners a richer vocabulary to\nthink and communicate with [Kuit2004,Byck2005,Saja2006]. We will return to\nthis in Section 7.5.\n\n## Becoming an Expert\n\nSo how does someone become an expert? The idea that ten thousand hours of\npractice will do it is widely quoted but probably not true: doing the same\nthing over and over again is much more likely to solidify bad habits than\nimprove performance. What actually works is doing similar but subtly different\nthings, paying attention to what works and what doesn\u2019t, and then changing\nbehavior in response to that feedback to get cumulatively better. This is\ncalled deliberate or reflective practice, and a common progression is for\npeople to go through three stages:\n\nAct on feedback from others.\n\n    \n\nA learner might write an essay about what they did on their summer holiday and\nget feedback from a teacher telling them how to improve it.\n\nGive feedback on others\u2019 work.\n\n    \n\nThe learner might critique character development in a Harry Potter novel and\nget feedback from the teacher on their critique.\n\nGive feedback to themselves.\n\n    \n\nAt some point, the learner starts critiquing their own work as they do it\nusing the skills they have now built up. Doing this is so much faster than\nwaiting for feedback from others that proficiency suddenly starts to take off.\n\n> #### What Counts as Deliberate Practice?\n>\n> [Macn2014] found that, \u201c...deliberate practice explained 26% of the variance\n> in performance for games, 21% for music, 18% for sports, 4% for education,\n> and less than 1% for professions.\u201d However, [Eric2016] critiqued this\n> finding by saying, \u201cSumming up every hour of any type of practice during an\n> individual\u2019s career implies that the impact of all types of practice\n> activity on performance is equal\u2014an assumption that...is inconsistent with\n> the evidence.\u201d To be effective, deliberate practice requires both a clear\n> performance goal and immediate informative feedback, both of which are\n> things teachers should strive for anyway.\n\n## Exercises\n\n### Concept Mapping (pairs/30)\n\nDraw a concept map for something you would teach in five minutes. Trade with a\npartner and critique each other\u2019s maps. Do they present concepts or surface\ndetail? Which of the relationships in your partner\u2019s map do you consider\nconcepts and vice versa?\n\n### Concept Mapping (Again) (small groups/20)\n\nWorking in groups of 3\u20134, have each person independently draw a concept map\nshowing their mental model of what goes on in a classroom. When everyone is\ndone, compare the concept maps. Where do your mental models agree and\ndisagree?\n\n### Enhancing Short-Term Memory (individual/5 minutes)\n\n[Cher2007] suggests that the main reason people draw diagrams when they are\ndiscussing things is to enlarge their short-term memory: pointing at a wiggly\nbubble drawn a few minutes ago triggers recall of several minutes of debate.\nWhen you exchanged concept maps in the previous exercise, how easy was it for\nother people to understand what your map meant? How easy would it be for you\nif you set it aside for a day or two and then looked at it again?\n\n### That\u2019s a Bit Self-Referential, Isn\u2019t It? (whole class/30)\n\nWorking independently, draw a concept map for concept maps. Compare your\nconcept map with those drawn by other people. What did most people include?\nWhat were the significant differences?\n\n### Noticing Your Blind Spot (small groups/10)\n\nElizabeth Wickes listed all the things you need to understand in order to read\nthis one line of Python:\n\n    \n    \n    answers = ['tuatara', 'tuataras', 'bus', \"lick\"]\n\n  * The square brackets surrounding the content mean we\u2019re working with a list (as opposed to square brackets immediately to the right of something, which is a data extraction notation).\n\n  * The elements are separated by commas outside and between the quotes (rather than inside, as they would be for quoted speech).\n\n  * Each element is a character string, and we know that because of the quotes. We could have number or other data types in here if we wanted; we need quotes because we\u2019re working with strings.\n\n  * We\u2019re mixing our use of single and double quotes; Python doesn\u2019t care so long as they balance around the individual strings.\n\n  * Each comma is followed by a space, which is not required by Python, but which we prefer for readability.\n\nEach of these details might be overlooked by an expert. Working in groups of\n3\u20134, select something equally short from a lesson you have recently taught or\nlearned and break it down to this level of detail.\n\n### What to Teach Next (individual/5)\n\nRefer back to the concept map for photosynthesis in Figure 3.3. How many\nconcepts and links are in the selected chunks? What would you include in the\nnext chunk of the lesson and why?\n\n### The Power of Chunking (individual/5)\n\nLook at Figure 3.4 for 10 seconds, then look away and try to write out your\nphone number with these symbols^3. (Use a space for \u20190\u2019.) When you are\nfinished, look at the alternative representation in Appendix 23. How much\neasier are the symbols to remember when the pattern is made explicit?\n\nUnchunked representation\n\n# Cognitive Architecture\n\nWe have been talking about mental models as if they were real things, but what\nactually goes on in a learner\u2019s brain when they\u2019re learning? The short answer\nis that we don\u2019t know; the longer answer is that we know a lot more than we\nused to. This chapter will dig a little deeper into what brains do while\nthey\u2019re learning and how we can leverage that to design and deliver lessons\nmore effectively.\n\n## What\u2019s Going On In There?\n\nCognitive architecture\n\nFigure 4.1 is a simplified model of human cognitive architecture. The core of\nthis model is the separation between short-term and long-term memory discussed\nin Section 3.2. Long-term memory is like your basement: it stores things more\nor less permanently, but you can\u2019t access its contents directly. Instead, you\nrely on your short-term memory, which is the cluttered kitchen table of your\nmind.\n\nWhen you need something, your brain retrieves it from long-term memory and\nputs it in short-term memory. Conversely, new information that arrives in\nshort-term memory has to be encoded to be stored in long-term memory. If that\ninformation isn\u2019t encoded and stored, it\u2019s not remembered and learning hasn\u2019t\ntaken place.\n\nInformation gets into short-term memory primarily through your verbal channel\n(for speech) and visual channel (for images)^4. Most people rely primarily on\ntheir visual channel, but when images and words complement each other, the\nbrain does a better job of remembering them both: they are encoded together,\nso recall of one later on helps trigger recall of the other.\n\nLinguistic and visual input are processed by different parts of the human\nbrain, and linguistic and visual memories are stored separately as well. This\nmeans that correlating linguistic and visual streams of information takes\ncognitive effort: when someone reads something while hearing it spoken aloud,\ntheir brain can\u2019t help but check that it\u2019s getting the same information on\nboth channels.\n\nLearning is therefore increased when information is presented simultaneously\nin two different channels, but is reduced when that information is redundant\nrather than complementary, a phenomenon called the split-attention effect\n[Maye2003]. For example, people generally find it harder to learn from a video\nthat has both narration and on-screen captions than from one that has either\nthe narration or the captions but not both, because some of their attention\nhas to be devoted to checking that the narration and the captions agree with\neach other. Two notable exceptions to this are people who do not yet speak the\nlanguage well and people with hearing impairments or other special needs, both\nof whom may find that the value of the redundant information outweighs the\nextra processing effort.\n\n> #### Piece by Piece\n>\n> The split attention effect explains why it\u2019s more effective to draw a\n> diagram piece by piece while teaching than to present the whole thing at\n> once. If parts of the diagram appear at the same time as things are being\n> said, the two will be correlated in the learner\u2019s memory. Pointing at part\n> of the diagram later is then more likely to trigger recall of what was being\n> said when that part was being drawn.\n\nThe split-attention effect does not mean that learners shouldn\u2019t try to\nreconcile multiple incoming streams of information\u2014after all, this is what\nthey have to do in the real world [Atki2000]. Instead, it means that\ninstruction shouldn\u2019t require people to do it while they are first mastering\nunit skills; instead, using multiple sources of information simultaneously\nshould be treated as a separate learning task.\n\n> #### Not All Graphics are Created Equal\n>\n> [Sung2012] presents an elegant study that distinguishes seductive graphics\n> (which are highly interesting but not directly relevant to the instructional\n> goal), decorative graphics (which are neutral but not directly relevant to\n> the instructional goal), and instructive graphics (which are directly\n> relevant to the instructional goal). Learners who received any kind of\n> graphic gave material higher satisfaction ratings than those who didn\u2019t get\n> graphics, but only learners who got instructive graphics actually performed\n> better.\n>\n> Similarly, [Stam2013,Stam2014] found that having more information can\n> actually lower performance. They showed children pictures, pictures and\n> numbers, or just numbers for two tasks. For some, having pictures or\n> pictures and numbers outperformed having numbers only, but for others,\n> having pictures outperformed pictures and numbers, which outperformed just\n> having numbers.\n\n## Cognitive Load\n\nIn [Kirs2006], Kirschner, Sweller and Clark wrote:\n\n> Although unguided or minimally guided instructional approaches are very\n> popular and intuitively appealing...these approaches ignore both the\n> structures that constitute human cognitive architecture and evidence from\n> empirical studies over the past half-century that consistently indicate that\n> minimally guided instruction is less effective and less efficient than\n> instructional approaches that place a strong emphasis on guidance of the\n> student learning process. The advantage of guidance begins to recede only\n> when learners have sufficiently high prior knowledge to provide \u201cinternal\u201d\n> guidance.\n\nBeneath the jargon, the authors were claiming that having learners ask their\nown questions, set their own goals, and find their own path through a subject\nis less effective than showing them how to do things step by step. The \u201cchoose\nyour own adventure\u201d approach is known as inquiry-based learning, and is\nintuitively appealing: after all, who would argue against having learners use\ntheir own initiative to solve real-world problems in realistic ways? However,\nasking learners to do this in a new domain overloads them by requiring them to\nmaster a domain\u2019s factual content and its problem-solving strategies at the\nsame time.\n\nMore specifically, cognitive load theory proposed that people have to deal\nwith three things when they\u2019re learning:\n\nIntrinsic load\n\n    \n\nis what people have to keep in mind in order to absorb new material.\n\nGermane Load\n\n    \n\nis the (desirable) mental effort required to link new information to old,\nwhich is one of the things that distinguishes learning from memorization.\n\nExtraneous Load\n\n    \n\nis anything that distracts from learning.\n\nCognitive load theory holds that people have to divide a fixed amount of\nworking memory between these three things. Our goal as teachers is to maximize\nthe memory available to handle intrinsic load, which means reducing the\ngermane load at each step and eliminating the extraneous load.\n\n### Parsons Problems\n\nOne kind of exercise that can be explained in terms of cognitive load is often\nused when teaching languages. Suppose you ask someone to translate the\nsentence, \u201cHow is her knee today?\u201d into Frisian. To solve the problem, they\nneed to recall both vocabulary and grammar, which is a double cognitive load.\nIf you ask them to put \u201choe,\u201d \u201char,\u201d \u201cis,\u201d \u201chjoed,\u201d and \u201cknie\u201d in the right\norder, on the other hand, you are allowing them to focus solely on learning\ngrammar. If you write these words in five different fonts or colors, though,\nyou have increased the extraneous cognitive load, because they will\ninvoluntarily (and possibly unconsciously) expend some effort trying to figure\nout if the differences are meaningful (Figure 4.2).\n\nConstructing a sentence\n\nThe coding equivalent of this is called a Parsons Problem^5 [Pars2006]. When\nteaching people to program, you can give them the lines of code they need to\nsolve a problem and ask them to put them in the right order. This allows them\nto concentrate on control flow and data dependencies without being distracted\nby variable naming or trying to remember what functions to call. Multiple\nstudies have shown that Parsons Problems take less time for learners to do but\nproduce equivalent educational outcomes [Eric2017].\n\n### Faded Examples\n\nAnother type of exercise that can be explained in terms of cognitive load is\nto give learners a series of faded examples. The first example in a series\npresents a complete use of a particular problem-solving strategy. The next\nproblem is of the same type, but has some gaps for the learner to fill in.\nEach successive problem gives the learner less scaffolding, until they are\nasked to solve a complete problem from scratch. When teaching high school\nalgebra, for example, we might start with this:\n\n(4x + 8)/2| =| 5  \n---|---|---  \n4x + 8| =| 2 * 5  \n4x + 8| =| 10  \n4x| =| 10 - 8  \n4x| =| 2  \nx| =| 2 / 4  \nx| =| 1 / 2  \n  \nand then ask learners to solve this:\n\n(3x - 1)*3| =| 12  \n---|---|---  \n3x - 1| =| _ / _  \n3x - 1| =| 4  \n3x| =| _  \nx| =| _ / 3  \nx| =| _  \n  \nand this:\n\n(5x + 1)*3| =| 4  \n---|---|---  \n5x + 1| =| _  \n5x| =| _  \nx| =| _  \n  \nand finally this:\n\n(2x + 8)/4| =| 1  \n---|---|---  \nx| =| _  \n  \nA similar exercise for teaching Python might start by showing learners how to\nfind the total length of a list of words:\n\n    \n    \n    # total_length([\"red\", \"green\", \"blue\"]) => 12 define total_length(list_of_words): total = 0 for word in list_of_words: total = total + length(word) return total\n\nand then ask them to fill in the blanks in this (which focuses their attention\non control structures):\n\n    \n    \n    # word_lengths([\"red\", \"green\", \"blue\"]) => [3, 5, 4] define word_lengths(list_of_words): list_of_lengths = [] for ____ in ____: append(list_of_lengths, ____) return list_of_lengths\n\nThe next problem might be this (which focuses their attention on updating the\nfinal result):\n\n    \n    \n    # join_all([\"red\", \"green\", \"blue\"]) => \"redgreenblue\" define join_all(list_of_words): joined_words = ____ for ____ in ____: ____ return joined_words\n\nLearners would finally be asked to write an entire function on their own:\n\n    \n    \n    # make_acronym([\"red\", \"green\", \"blue\"]) => \"RGB\" define make_acronym(list_of_words): ____\n\nFaded examples work because they introduce the problem-solving strategy piece\nby piece: at each step, learners have one new problem to tackle, which is less\nintimidating than a blank screen or a blank sheet of paper (Section 9.11). It\nalso encourages learners to think about the similarities and differences\nbetween various approaches, which helps create the linkages in their mental\nmodels that help retrieval.\n\nThe key to constructing a good faded example is to think about the problem-\nsolving strategy it is meant to teach. For example, the programming problems\nabove all use the accumulator design pattern, in which the results of\nprocessing items from a collection are repeatedly added to a single variable\nin some way to create the final result.\n\n> #### Cognitive Apprenticeship\n>\n> An alternative model of learning and instruction that also uses scaffolding\n> and fading is cognitive apprenticeship, which emphasizes the way in which a\n> master passes on skills and insights to an apprentice. The master provides\n> models of performance and outcomes, then coaches novices by explaining what\n> they are doing and why [Coll1991,Casp2007]. The apprentice reflects on their\n> own problem solving, e.g. by thinking aloud or critiquing their own work,\n> and eventually explores problems of their own choosing.\n>\n> This model tells us that teachers should present several examples when\n> presenting a new idea so that learners can see what to generalize, and that\n> we should vary the form of the problem to make it clear what are and aren\u2019t\n> superficial features^6. Problems should be presented in real-world contexts,\n> and we should encourage self-explanation to help learners organize and make\n> sense of what they have just been taught (Section 5.1).\n\n### Labeled Subgoals\n\nLabeling subgoals means giving names to the steps in a step-by-step\ndescription of a problem-solving process. [Marg2016,Morr2016] found that\nlearners with labeled subgoals solved Parsons Problems better than learners\nwithout, and the same benefit is seen in other domains [Marg2012]. Returning\nto the Python example used earlier, the subgoals in finding the total length\nof a list of words or constructing an acronym are:\n\n  1. Create an empty value of the type to be returned.\n\n  2. Get the value to be added to the result from the loop variable.\n\n  3. Update the result with that value.\n\nLabeling subgoals works because grouping related steps into named chunks\n(Section 3.2) helps learners distinguish what\u2019s generic from what is specific\nto the problem at hand. It also helps them build a mental model of that kind\nof problem so that they can solve other problems of that kind, and gives them\na natural opportunity for self-explanation (Section 5.1).\n\n### Minimal Manuals\n\nThe purest application of cognitive load theory may be John Carroll\u2019s minimal\nmanual [Carr1987,Carr2014]. Its starting point is a quote from a user: \u201cI want\nto do something, not learn how to do everything.\u201d Carroll and colleagues\nredesigned training to present every idea as a single-page self-contained\ntask: a title describing what the page was about, step-by-step instructions of\nhow to do just one thing (e.g. how to delete a blank line in a text editor),\nand then several notes on how to recognize and debug common problems. They\nfound that rewriting training materials this way made them shorter overall,\nand that people using them learned faster. Later studies confirmed that this\napproach outperformed the traditional approach regardless of prior experience\nwith computers [Lazo1993]. [Carr2014] summarized this work by saying:\n\n> Our \u201cminimalist\u201d designs sought to leverage user initiative and prior\n> knowledge, instead of controlling it through warnings and ordered steps. It\n> emphasized that users typically bring much expertise and insight to this\n> learning, for example, knowledge about the task domain, and that such\n> knowledge could be a resource to instructional designers. Minimalism\n> leveraged episodes of error recognition, diagnosis, and recovery, instead of\n> attempting to merely forestall error. It framed troubleshooting and recovery\n> as learning opportunities instead of as aberrations.\n\n## Other Models of Learning\n\nCritics of cognitive load theory have sometimes argued that any result can be\njustified after the fact by labeling things that hurt performance as\nextraneous load and things that don\u2019t as intrinsic or germane. However,\ninstruction based on cognitive load theory is undeniably effective. For\nexample, [Maso2016] redesigned a database course to remove split attention and\nredundancy effects and to provide worked examples and sub-goals. The new\ncourse reduced the exam failure rate by 34% and increased learner\nsatisfaction.\n\nA decade after the publication of [Kirs2006], a growing number of people\nbelieve that cognitive load theory and inquiry-based approaches are compatible\nif viewed in the right way. [Kaly2015] argues that cognitive load theory is\nbasically micro-management of learning within a broader context that considers\nthings like motivation, while [Kirs2018] extends cognitive load theory to\ninclude collaborative aspects of learning. As with [Mark2018] (discussed in\nSection 5.1), researchers\u2019 perspectives may differ, but the practical\nimplementation of their theories often wind up being the same.\n\nOne of the challenges in educational research is that what we mean by\n\u201clearning\u201d turns out to be complicated once you look beyond the standardized\nWestern classroom. Two specific perspectives from educational psychology have\ninfluenced this book. The one we have used so far is cognitivism, which\nfocuses on things like pattern recognition, memory formation, and recall. It\nis good at answering low-level questions, but generally ignores larger issues\nlike, \u201cWhat do we mean by \u2018learning\u2019?\u201d and, \u201cWho gets to decide?\u201d The other is\nsituated learning, which focuses on bringing people into a community and\nrecognizes that teaching and learning are always rooted in who we are and who\nwe aspire to be. We will discuss it in more detail in Chapter 13.\n\nThe Learning Theories website and [Wibu2016] have good summaries of these and\nother perspectives. Besides cognitivism, those encountered most frequently\ninclude behaviorism (which treats education as stimulus/response\nconditioning), constructivism (which considers learning an active process\nduring which learners construct knowledge for themselves), and connectivism\n(which holds that knowledge is distributed, that learning is the process of\nnavigating, growing, and pruning connections, and which emphasizes the social\naspects of learning made possible by the internet). These perspectives can\nhelp us organize our thoughts, but in practice, we always have to try new\nmethods in the class, with actual learners, in order to find out how well they\nbalance the many forces in play.\n\n## Exercises\n\n### Create a Faded Example (pairs/30)\n\nIt\u2019s very common for programs to count how many things fall into different\ncategories: for example, how many times different colors appear in an image,\nor how many times different words appear in a paragraph of text.\n\n  1. Create a short example (no more than 10 lines of code) that shows people how to do this, and then create a second example that solves a similar problem in a similar way but has a couple of blanks for learners to fill in. How did you decide what to fade out? What would the next example in the series be?\n\n  2. Define the audience for your examples. For example, are these beginners who only know some basics programming concepts? Or are these learners with some experience in programming?\n\n  3. Show your example to a partner, but do not tell them what level you think it is for. Once they have filled in the blanks, ask them to guess the intended level.\n\nIf there are people among the trainees who don\u2019t program at all, try to place\nthem in different groups and have them play the part of learners for those\ngroups. Alternatively, choose a different problem domain and develop a faded\nexample for it.\n\n### Classifying Load (small groups/15)\n\n  1. Choose a short lesson that a member of your group has taught or taken recently.\n\n  2. Make a point-form list of the ideas, instructions, and explanations it contains.\n\n  3. Classify each as intrinsic, germane, or extraneous. What did you all agree on? Where did you disagree and why?\n\n(The exercise \u201cNoticing Your Blind Spot\u201d in Section 3.4 will give you an idea\nof how detailed your point-form list should be.)\n\n### Create a Parsons Problem (pairs/20)\n\nWrite five or six lines of code that does something useful, jumble them, and\nask your partner to put them in order. If you are using an indentation-based\nlanguage like Python, do not indent any of the lines; if you are using a\ncurly-brace language like Java, do not include any of the curly braces. (If\nyour group includes people who aren\u2019t programmers, use a different problem\ndomain, such as making banana bread.)\n\n### Minimal Manuals (individual/20)\n\nWrite a one-page guide to doing something that your learners might encounter\nin one of your classes, such as centering text horizontally or printing a\nnumber with a certain number of digits after the decimal point. Try to list at\nleast three or four incorrect behaviors or outcomes the learner might see and\ninclude a one- or two-line explanation of why each happens and how to correct\nit.\n\n### Cognitive Apprenticeship (pairs/15)\n\nPick a coding problem that you can do in two or three minutes and think aloud\nas you work through it while your partner asks questions about what you\u2019re\ndoing and why. Do not just explain what you\u2019re doing, but also why you\u2019re\ndoing it, how you know it\u2019s the right thing to do, and what alternatives\nyou\u2019ve considered but discarded. When you are done, swap roles with your\npartner and repeat the exercise.\n\n### Worked Examples (pairs/15)\n\nSeeing worked examples helps people learn to program faster than just writing\nlots of code [Skud2014], and deconstructing code by tracing it or debugging it\nalso increases learning [Grif2016]. Working in pairs, go through a 10\u201315 line\npiece of code and explain what every statement does and why it is necessary.\nHow long does it take? How many things do you feel you need to explain per\nline of code?\n\n### Critiquing Graphics (individual/30)\n\n[Maye2009,Mill2016a] presents six principles for good teaching graphics:\n\nSignalling:\n\n    \n\nvisually highlight the most important points so that they stand out from less-\ncritical material.\n\nSpatial contiguity:\n\n    \n\nplace captions as close to the graphics as practical to offset the cost of\nshifting between the two.\n\nTemporal contiguity:\n\n    \n\npresent spoken narration and graphics as close in time as practical.\n(Presenting both at once is better than presenting them one after another.)\n\nSegmenting:\n\n    \n\nwhen presenting a long sequence of material or when learners are inexperienced\nwith the subject, break the presentation into short segments and let learners\ncontrol how quickly they advance from to the next.\n\nPre-training:\n\n    \n\nif learners don\u2019t know the major concepts and terminology used in your\npresentation, teach just those concepts and terms beforehand.\n\nModality:\n\n    \n\npeople learn better from pictures plus narration than from pictures plus text,\nunless they are non-native speakers or there are technical words or symbols.\n\nChoose a video of a lesson or talk online that uses slides or other static\npresentations and rate its graphics as \u201cpoor,\u201d \u201caverage,\u201d or \u201cgood\u201d according\nto these six criteria.\n\n## Review\n\nConcepts: Cognitive load\n\n# Individual Learning\n\nPrevious chapters have explored what teachers can do to help learners. This\nchapter looks at what learners can do for themselves by changing their study\nstrategies and getting enough rest.\n\nThe most effective strategy is to switch from passive learning to active\nlearning [Hpl2018], which significantly improves performance and reduces\nfailure rates [Free2014]:\n\nPassive| Active  \n---|---  \nRead about something| Do exercises  \nWatch a video| Discuss a topic  \nAttend a lecture| Try to explain it  \n  \nReferring back to our simplified model of cognitive architecture (Figure 4.1),\nactive learning is more effective because it keeps new information in short-\nterm memory longer, which increases the odds that it will be encoded\nsuccessfully and stored in long-term memory. And by using new information as\nit arrives, learners build or strengthen ties between that information and\nwhat they already know, which in turn increases the chances that they will be\nable to retrieve it later.\n\nThe other key to getting more out of learning is metacognition, or thinking\nabout one\u2019s own thinking. Just as good musicians listen to their own playing\nand good teachers reflect on their teaching (Chapter 8), learners will learn\nbetter and faster if they make plans, set goals, and monitor their progress.\nIt\u2019s difficult for learners to master these skills in the abstract\u2014just\ntelling them to make plans doesn\u2019t have any effect\u2014but lessons can be designed\nto encourage good study practices, and drawing attention to these practices in\nclass helps learners realize that learning is a skill they can improve like\nany other [McGu2015,Miya2018].\n\nThe big prize is transfer of learning, which occurs when one thing we have\nlearned helps us learn other things more quickly. Researchers distinguish\nbetween near transfer, which occurs between similar or related areas like\nfractions and decimals in mathematics, and far transfer, which occurs between\ndissimilar domains\u2014for example, the idea that learning to play chess will help\nmathematical reasoning or vice versa.\n\nNear transfer undoubtedly occurs\u2014no kind of learning beyond simple\nmemorization could occur if it didn\u2019t\u2014and teachers leverage it all the time by\ngiving learners exercises that are similar to material that has just been\npresented in a lesson. However, [Sala2017] analyzed many studies of far\ntransfer and concluded that:\n\n> ...the results show small to moderate effects. However, the effect sizes are\n> inversely related to the quality of the experimental design... We conclude\n> that far transfer of learning rarely occurs.\n\nWhen far transfer does occur, it seems to happen only once a subject has been\nmastered [Gick1987]. In practice, this means that learning to program won\u2019t\nhelp you play chess and vice versa.\n\n## Six Strategies\n\nPsychologists study learning in a wide variety of ways, but have reached\nsimilar conclusions about what actually works [Mark2018]. The Learning\nScientists have catalogued six of these strategies and summarized them in a\nset of downloadable posters. Teaching these strategies to learners, and\nmentioning them by name when you use them in class, can help them learn how to\nlearn faster and better [Wein2018a,Wein2018b].\n\n### Spaced Practice\n\nTen hours of study spread out over five days is more effective than two five-\nhour days, and far better than one ten-hour day. You should therefore create a\nstudy schedule that spreads study activities over time: block off at least\nhalf an hour to study each topic each day rather than trying to cram\neverything in the night before an exam [Kang2016].\n\nYou should also review material after each class, but not immediately\nafter\u2014take at least a half-hour break. When reviewing, be sure to include at\nleast a little bit of older material: for example, spend twenty minutes\nlooking over notes from that day\u2019s class and then five minutes each looking\nover material from the previous day and from a week before. Doing this also\nhelps you catch any gaps or mistakes in previous sets of notes while there\u2019s\nstill time to correct them or ask questions: it\u2019s painful to realize the night\nbefore the exam that you have no idea why you underlined \u201cDemodulate!!\u201d three\ntimes.\n\nWhen reviewing, make notes about things that you had forgotten: for example,\nmake a flash card for each fact that you couldn\u2019t remember or that you\nremembered incorrectly [Matt2019]. This will help you focus the next round of\nstudy on things that most need attention.\n\n> #### The Value of Lectures\n>\n> According to [Mill2016a], \u201cThe lectures that predominate in face-to-face\n> courses are relatively ineffective ways to teach, but they probably\n> contribute to spacing material over time, because they unfold in a set\n> schedule over time. In contrast, depending on how the courses are set up,\n> online students can sometimes avoid exposure to material altogether until an\n> assignment is nigh.\u201d\n\n### Retrieval Practice\n\nThe limiting factor for long-term memory is not retention (what is stored) but\nrecall (what can be accessed). Recall of specific information improves with\npractice, so outcomes in real situations can be improved by taking practice\ntests or summarizing the details of a topic from memory and then checking what\nwas and wasn\u2019t remembered. For example, [Karp2008] found that repeated testing\nimproved recall of word lists from 35% to 80%.\n\nRecall is better when practice uses activities similar to those used in\ntesting. For example, writing personal journal entries helps with multiple-\nchoice quizzes, but less than doing practice quizzes [Mill2016a]. This\nphenomenon is called transfer-appropriate processing.\n\nOne way to exercise retrieval skills is to solve problems twice. The first\ntime, do it entirely from memory without notes or discussion with peers. After\ngrading your own work against a rubric supplied by the teacher, solve the\nproblem again using whatever resources you want. The difference between the\ntwo shows you how well you were able to retrieve and apply knowledge.\n\nAnother method (mentioned above) is to create flash cards. Physical cards have\na question or other prompt on one side and the answer on the other, and many\nflash card apps are available for phones. If you are studying as part of a\ngroup, swapping flash cards with a partner helps you discover important ideas\nthat you may have missed or misunderstood.\n\nRead-cover-retrieve is a quick alternative to flash cards. As you read\nsomething, cover up key terms or sections with small sticky notes. When you\nare done, go through it a second time and see how well you can guess what\u2019s\nunder each of those stickies. Whatever method you use, don\u2019t just practice\nrecalling facts and definitions: make sure you also check your understanding\nof big ideas and the connections between them. Sketching a concept map and\nthen comparing it to your notes or to a previously-drawn concept map is a\nquick way to do this.\n\n> #### Hypercorrection\n>\n> One powerful finding in learning research is the hypercorrection effect\n> [Metc2016]. Most people don\u2019t like to be told they\u2019re wrong, so it would be\n> reasonable to assume that the more confident someone is in the answer\n> they\u2019ve given on a test, the harder it is to change their mind if they were\n> actually wrong. It turns out that the opposite is true: the more confident\n> someone is that they were right, the more likely they are not to repeat the\n> error if they are corrected.\n\n### Interleaving\n\nOne way you can space your practice is to interleave study of different\ntopics: instead of mastering one subject, then a second and third, shuffle\nstudy sessions. Even better, switch up the order: A-B-C-B-A-C is better than\nA-B-C-A-B-C, which in turn is better than A-A-B-B-C-C [Rohr2015]. This works\nbecause interleaving fosters creation of more links between different topics,\nwhich in turn improves recall.\n\nHow long you should spend on each item depends on the subject and how well you\nknow it. Somewhere between 10 and 30 minutes is long enough for you to get\ninto a state of flow (Section 5.2) but not for your mind to wander.\nInterleaving study will initially feel harder than focusing on one topic at a\ntime, but that\u2019s a sign that it\u2019s working. If you are using flash cards or\npractice tests to gauge your progress, you should see improvement after only a\ncouple of days.\n\n### Elaboration\n\nExplaining things to yourself as you go through them helps you understand and\nremember them. One way to do this is to follow up each answer on a practice\nquiz with an explanation of why that answer is correct, or conversely with an\nexplanation of why some other plausible answer isn\u2019t. Another is to tell\nyourself how a new idea is similar to or different from one you have seen\npreviously.\n\nTalking to yourself may seem like an odd way to study, but [Biel1995] found\nthat people trained in self-explanation outperformed those who hadn\u2019t been\ntrained. Similarly, [Chi1989] found that some learners simply halt when they\nhit a step they don\u2019t understand when trying to solve problems. Others pause\nand generate an explanation of what\u2019s going on, and the latter group learns\nfaster. An exercise to build this skill is to go through an example program\nline by line with a class, having a different person explain each line in turn\nand say why it is there and what it accomplishes.\n\n### Concrete Examples\n\nOne particularly useful form of elaboration is the use of concrete examples.\nWhenever you have a statement of a general principle, try to provide one or\nmore examples of its use, or conversely take each particular problem and list\nthe general principles it embodies. [Raws2014] found that interleaving\nexamples and definitions like this made it more likely that learners would\nremember the latter correctly.\n\nOne structured way to do this is the ADEPT method: give an Analogy, draw a\nDiagram, present an Example, describe the idea in Plain language, and then\ngive the Technical details. Again, if you are studying with a partner or in a\ngroup, you can swap and check work: see if you agree that other people\u2019s\nexamples actually embody the principle being discussed or which principles are\nused in an example that they haven\u2019t listed.\n\nAnother useful technique is to teach by contrast, i.e. to show learners what a\nsolution is not or what kind of problem a technique won\u2019t solve. For example,\nwhen showing children how to simplify fractions, it\u2019s important to give them a\nfew like 5/7 that can\u2019t be simplified so that they don\u2019t become frustrated\nlooking for answers that don\u2019t exist.\n\n### Dual Coding\n\nThe last of the six core strategies that the Learning Scientists describe is\nto present words and images together. As discussed in Section 4.1, different\nsubsystems in our brains handle and store linguistic and visual information,\nso if complementary information is presented through both channels, they can\nreinforce one another. However, learning is less effective when the same\ninformation is presented simultaneously in two different channels, because\nthen the brain has to expend effort to check the channels against each other\n[Maye2003].\n\nOne way to take advantage of dual coding is to draw or label timelines, maps,\nfamily trees, or whatever else seems appropriate to the material. (I am\npersonally fond of pictures showing which functions call which others in a\nprogram.) Drawing a diagram without labels, then coming back later to label\nit, is excellent retrieval practice.\n\n## Time Management\n\nI used to brag about the hours I was working. Not in so many words, of\ncourse\u2014I had some social skills\u2014but I would show up for class around noon,\nunshaven and yawning, and casually mention to whoever would listen that I\u2019d\nbeen up working until 6:00 a.m.\n\nLooking back, I can\u2019t remember who I was trying to impress. What I remember\ninstead is how much of the work I did in those all-nighters I threw away once\nI\u2019d had some sleep, and how much damage the stuff I didn\u2019t throw away did to\nmy grades.\n\nMy mistake was to confuse \u201cworking\u201d with \u201cbeing productive.\u201d You can\u2019t produce\nsoftware (or anything else) without doing some work, but you can easily do\nlots of work without producing anything of value. Convincing people of this\ncan be hard, especially when they\u2019re in their teens or twenties, but it pays\ntremendous dividends.\n\nScientific study of overwork and sleep deprivation goes back to at least the\n1890s\u2014see [Robi2005] for a short, readable summary. The most important results\nfor learners are:\n\n  1. Working more than 8 hours a day for an extended period of time lowers your total productivity, not just your hourly productivity\u2014i.e. you get less done in total (not just per hour) when you\u2019re in crunch mode.\n\n  2. Working over 21 hours in a stretch increases the odds of you making a catastrophic error just as much as being legally drunk.\n\n  3. Productivity varies over the course of the workday, with the greatest productivity occurring in the first 4 to 6 hours. After enough hours, productivity approaches zero; eventually it becomes negative.\n\nThese facts have been reproduced and verified for over a century, and the data\nbehind them is as solid as the data linking smoking to lung cancer. The\nproblem is that people usually don\u2019t notice their abilities declining. Like\ndrunks who think they are still able to drive, people who are deprived of\nsleep don\u2019t realize that they are not finishing their sentences (or thoughts).\nFive 8-hour days per week has been proven to maximize long-term total output\nin every industry that has ever been studied; studying or programming are no\ndifferent.\n\nBut what about short bursts now and then, like pulling an all-nighter to meet\na deadline? That has been studied too, and the results aren\u2019t pleasant. Your\nability to think drops by 25% for each 24 hours you\u2019re awake. Put it another\nway, the average person\u2019s IQ is only 75 after one all-nighter, which puts them\nin the bottom 5% of the population. If you do two all-nighters in a row your\neffective IQ is 50, which is the level at which people are usually judged\nincapable of independent living.\n\n\u201cBut\u2014but\u2014I have so many assignments to do!\u201d you say. \u201cAnd they\u2019re all due at\nonce! I have to work extra hours to get them all done!\u201d No: people have to\nprioritize and focus in order to be productive, and in order to do that, they\nhave to be taught how. One widely-used technique is to make a list of things\nthat need to be done, sort them by priority, and then switch off email and\nother interruptions for 30\u201360 minutes and complete one of those tasks. If any\ntask on a to-do list is more than an hour long, break it down into smaller\npieces and prioritize those separately.\n\nThe most important part of this is switching off interruptions. Despite what\nmany people want to believe, human beings are not good at multi-tasking. What\nwe can become good at is automaticity, which is the ability to do something\nroutine in the background while doing something else [Mill2016a]. Most of us\ncan talk while chopping onions, or drink coffee while reading; with practice,\nwe can also take notes while listening, but we can\u2019t study effectively,\nprogram, or do other mentally challenging tasks while paying attention to\nsomething else\u2014we only think we can.\n\nThe point of organizing and preparing is to get into the most productive\nmental state possible. Psychologists call it flow [Csik2008]; athletes call it\n\u201cbeing in the zone,\u201d and musicians talk about losing themselves in what\nthey\u2019re playing. Whatever name you use, people produce much more per unit of\ntime in this state than normal. The bad news is that it takes roughly 10\nminutes to get back into a state of flow after an interruption, no matter how\nshort the interruption was. This means that if you are interrupted half a\ndozen times per hour, you are never at your productive peak.\n\n> #### How Did He Know?\n>\n> In his 1961 short story \u201cHarrison Bergeron,\u201d Kurt Vonnegut described a\n> future in which everyone is forced to be equal. Good-looking people have to\n> wear masks, athletic people have to wear weights\u2014and intelligent people are\n> forced to carry around radios that interrupt their thoughts at random\n> intervals. I sometimes wonder if\u2014oh, hang on, my phone just\u2014sorry, what were\n> we talking about?\n\n## Peer Assessment\n\nAsking people on a team to rate their peers is a common practice in industry.\n[Sond2012] surveyed the literature on peer assessment, distinguishing between\ngrading and reviewing. They found that peer assessment increased the amount,\ndiversity, and timeliness of feedback, helped learners exercise higher-level\nthinking, encouraged reflective practice, and supported development of social\nskills. The concerns were predictable: validity and reliability, motivation\nand procrastination, trolls, collusion, and plagiarism.\n\nHowever, the evidence shows that these concerns aren\u2019t significant in most\nclasses. For example, [Kauf2000] compared confidential peer ratings and grades\non several axes for two undergraduate engineering courses and found that self-\nrating and peer ratings statistically agreed, that collusion wasn\u2019t\nsignificant (i.e. people didn\u2019t just give all their peers high grades), that\nlearners didn\u2019t inflate their self-ratings, and crucially, that ratings were\nnot biased by gender or race.\n\nOne way to implement peer assessment is contributing student pedagogy, in\nwhich learners produce artifacts to contribute to others\u2019 learning. This can\nbe developing a short lesson and sharing it with the class, adding to a\nquestion bank, or writing up notes from a particular lecture for in-class\npublication. For example, [Fran2018] found that learners who made short videos\nto teach concepts to their peers had a significant increase in their own\nlearning compared to those who only studied the material or viewed the videos.\nI have found that asking learners to share one bug and its fix with the class\nevery day helps their analytic abilities and reduces impostor syndrome.\n\nAnother approach is calibrated peer review, in which a learner reviews one or\nmore examples using a rubric and compares their evaluation against the\nteacher\u2019s review of the same work [Kulk2013]. Once learners\u2019 evaluations are\nclose enough to the teacher\u2019s, they start evaluating their peers\u2019 actual work.\nIf several peers\u2019 assessments are combined, this can be as accurate as\nassessment by teachers [Pare2008].\n\nLike everything else, assessment is aided by rubrics. The evaluation form in\nSection 21.2 shows a sample to get you started. To use it, rank yourself and\neach of your teammates, then calculate and compare scores. Large disparities\nusually indicate a need for a longer conversation.\n\n## Exercises\n\n### Learning Strategies (individual/20)\n\n  1. Which of the six learning strategies do you regularly use? Which ones do you not?\n\n  2. Write down three general concepts that you want your learners to master and give two specific examples of each (concrete examples practice). For each of those concepts, work backward from one of your examples to explain how the concept explains it (elaboration).\n\n### Connecting Ideas (pairs/5)\n\nThis exercise is an example of using elaboration to improve retention. Pick a\npartner have each person independently choose an idea, then announce your\nideas and try to find a four-link chain that leads from one to the other. For\nexample, if the two ideas are \u201cSaskatchewan\u201d and \u201cstatistics,\u201d the links might\nbe:\n\n  * Saskatchewan is a province of Canada;\n\n  * Canada is a country;\n\n  * countries have governments;\n\n  * governments use statistics to analyze public opinion.\n\n### Convergent Evolution (pairs/15)\n\nOne practice that wasn\u2019t covered above is guided notes, which are notes\nprepared by the teacher that cue learners to respond to key information in a\nlecture or discussion. The cues can be blank spaces where learners add\ninformation, asterisks next to terms learners should define, and so on.\n\nCreate two to four guided note cards for a lesson you have recently taught or\nare going to teach. Swap cards with your partner: how easy is it to understand\nwhat is being asked for? How long would it take to fill in the prompts? How\nwell does this work for programming examples?\n\n### Changing Minds (pairs/10)\n\n[Kirs2013] argues that myths about digital natives, learning styles, and self-\neducators are all reflections of the mistaken belief that learners know what\nis best for them, and cautions that we may be in a downward spiral in which\nevery attempt by education researchers to rebut these myths confirms their\nopponents\u2019 belief that learning science is pseudo-science. Pick one thing you\nhave learned about learning so far in this book that surprised you or\ncontradicted something you previously believed and practice explaining it to a\npartner in 1\u20132 minutes. How convincing are you?\n\n### Flash Cards (individual/15)\n\nUse sticky notes or anything else you have at hand to make up half a dozen\nflash cards for a topic you have recently taught or learned. Trade with a\npartner and see how long it takes each of you to achieve 100% perfect recall.\nSet the cards aside when you are done, then come back after half an hour and\nsee what your recall rate is.\n\n### Using ADEPT (whole class/15)\n\nPick something you have recently taught or been taught and outline a short\nlesson that uses the five-step ADEPT method to introduce it.\n\n### The Cost of Multi-Tasking (pairs/10)\n\nThe Learning Scientists blog describes a simple experiment you can do with\nonly a stopwatch to demonstrate the mental cost of multi-tasking. Working in\npairs, measure how long it takes each person to do each of these three tasks:\n\n  * Count from 1 to 26 twice.\n\n  * Recite the alphabet from A to Z twice.\n\n  * Interleave the numbers and letters, i.e. say, \u201c1, A, 2, B, ...\u201d and so on.\n\nHave each pair report their numbers. Without specific practice, the third task\nalways takes significantly longer than either of the component tasks.\n\n### Myths in Computing Education (whole class/20)\n\n[Guzd2015b] presents a list of the top ten mistaken beliefs about computing\neducation, which includes:\n\n  1. The lack of women in Computer Science is just like all the other STEM fields.\n\n  2. To get more women in CS, we need more female CS faculty.\n\n  3. Student evaluations are the best way to evaluate teaching.\n\n  4. Good teachers personalize education for students\u2019 learning styles.\n\n  5. A good CS teacher should model good software development practice because their job is to produce excellent software engineers.\n\n  6. Some people are just naturally better programmers than others.\n\nHave everyone vote +1 (agree), -1 (disagree), or 0 (not sure) for each point,\nthen read the full explanations in the original article and vote again. Which\nones did people change their minds on? Which ones do they still believe are\ntrue, and why?\n\n### Calibrated Peer Review (pairs/20)\n\n  1. Create a 5\u201310 point rubric with entries like \u201cgood variable names,\u201d \u201cno redundant code,\u201d and \u201cproperly-nested control flow\u201d for grading the kind of programs you would like your learners to write.\n\n  2. Choose or create a small program that contains 3\u20134 violations of these entries.\n\n  3. Grade the program according to your rubric.\n\n  4. Have a partner grade the same program with the same rubric. What do they accept that you did not? What do they critique that you did not?\n\n## Review\n\nConcepts: Active learning\n\n# A Lesson Design Process\n\nMost people design lessons like this:\n\n  1. Someone asks you to teach something you barely know or haven\u2019t thought about in years.\n\n  2. You start writing slides to explain what you know about the subject.\n\n  3. After 2 or 3 weeks, you make up an assignment based on what you\u2019ve taught so far.\n\n  4. You repeat step 3 several times.\n\n  5. You stay awake into the wee hours of the morning to create a final exam and promise yourself that you\u2019ll be more organized next time.\n\nA more effective method is similar in spirit to a programming practice called\ntest-driven development (TDD). Programmers who use TDD don\u2019t write software\nand then test that it is working correctly. Instead, they write the tests\nfirst, then write just enough new software to make those tests pass.\n\nTDD works because writing tests forces programmers to be precise about what\nthey\u2019re trying to accomplish and what \u201cdone\u201d looks like. TDD also prevents\nendless polishing: when the tests pass, you stop coding. Finally, it reduces\nthe risk of confirmation bias: someone who hasn\u2019t yet written a piece of\nsoftware will be more objective than someone who has just put in several hours\nof hard work and really, really wants to be done.\n\nA similar method called backward design works very well for lesson design.\nThis method was developed independently in [Wigg2005,Bigg2011,Fink2013] and is\nsummarized in [McTi2013]. In simplified form, its steps are:\n\n  1. Create or recycle learner personas (discussed in the next section) to figure out who you are trying to help and what will appeal to them.\n\n  2. Brainstorm to get a rough idea of what you want to cover, how you\u2019re going to do it, what problems or misconceptions you expect to encounter, what\u2019s not going to be included, and so on. Drawing concept maps can help a lot at this stage (Section 3.1).\n\n  3. Create a summative assessment (Section 2.1) to define your overall goal. This can be the final exam for a course or the capstone project for a one-day workshop; regardless of its form or size, it shows how far you hope to get more clearly than a point-form list of objectives.\n\n  4. Create formative assessments that will give people a chance to practice the things they\u2019re learning. These will also tell you (and them) whether they\u2019re making progress and where they need to focus their attention. The best way to do this is to itemize the knowledge and skills used in the summative assessment you developed in the previous step and then create at least one formative assessment for each.\n\n  5. Order the formative assessments to create a course outline based on their complexity, their dependencies, and how well topics will motivate your learners (Section 10.1).\n\n  6. Write material to get learners from one formative assessment to the next. Each hour of instruction should consist of three to five such episodes.\n\n  7. Write a summary description of the course to help its intended audience find it and figure out whether it\u2019s right for them.\n\nThis method helps keep teaching focused on its objectives. It also ensures\nthat learners don\u2019t face anything at the end of the course that they are not\nprepared for.\n\n> #### Perverse Incentives\n>\n> Backward design is not the same thing as teaching to the test. When using\n> backward design, teachers set goals to aid in lesson design; they may never\n> actually give the final exam that they wrote. In many school systems, on the\n> other hand, an external authority defines assessment criteria for all\n> learners, regardless of their individual situations. The outcomes of those\n> summative assessments directly affect the teachers\u2019 pay and promotion, which\n> means teachers have an incentive to focus on having learners pass tests\n> rather than on helping them learn.\n>\n> [Gree2014] argues that focusing on testing and measurement appeals to those\n> with the power to set the tests, but is unlikely to improve outcomes unless\n> it is coupled with support for teachers to make improvements based on test\n> outcomes. The latter is often missing because large organizations usually\n> value uniformity over productivity [Scot1998].\n\nReverse design is described as a sequence, but it\u2019s almost never done that\nway. We may, for example, change our mind about what we want to teach based on\nsomething that occurs to us while we\u2019re writing an MCQ, or re-assess who we\u2019re\ntrying to help once we have a lesson outline. However, the notes we leave\nbehind should present things in the order described above so that whoever has\nto use or maintain the lesson after us can retrace our thinking [Parn1986].\n\n## Learner Personas\n\nThe first step in the reverse design process is figuring out who your audience\nis. One way to do this is to write two or three learner personas like those in\nSection 1.1. This technique is borrowed from user experience designers, who\ncreate short profiles of typical users to help them think about their\naudience.\n\nA learner persona consists of:\n\n  1. the person\u2019s general background;\n\n  2. what they already know;\n\n  3. what they want to do; and\n\n  4. any special needs they have.\n\nThe personas in Section 1.1 have the four points listed above, along with a\nshort summary of how this book will help them. A learner persona for a\nvolunteer group that runs weekend Python workshops might be:\n\n  1. Jorge just moved from Costa Rica to Canada to study agricultural engineering. He has joined the college soccer team and is looking forward to learning how to play ice hockey.\n\n  2. Other than using Excel, Word, and the internet, Jorge\u2019s most significant previous experience with computers is helping his sister build a WordPress site for the family business back home.\n\n  3. Jorge wants to measure properties of soil from nearby farms using a handheld device that sends data to his computer. Right now he has to open each data file in Excel, delete the first and last column, and calculate some statistics on what\u2019s left. He has to collect at least 600 measurements in the next few months, and really doesn\u2019t want to have to do these steps by hand for each one.\n\n  4. Jorge can read English well, but sometimes struggles to keep up with spoken conversation that involves a lot of jargon.\n\nRather than writing new personas for every lesson or course, teachers usually\ncreate and share half a dozen that cover everyone they are likely to teach,\nthen pick a few from that set to describe the audience for particular\nmaterial. Personas that are used this way become a convenient shorthand for\ndesign issues: when speaking with each other, teachers can say, \u201cWould Jorge\nunderstand why we\u2019re doing this?\u201d or, \u201cWhat installation problems would Jorge\nface?\u201d\n\n> #### Their Goals, Not Yours\n>\n> Personas should always describe what the learner wants to do rather than\n> what you think they actually need. Ask yourself what they are searching for\n> online; it probably won\u2019t include jargon that they don\u2019t yet know, so part\n> of what you have to do as an instructional designer is figure out how to\n> make your lesson findable.\n\n## Learning Objectives\n\nFormative and summative assessments help teachers figure out what they\u2019re\ngoing to teach, but in order to communicate that to learners and other\nteachers, a course description should also have learning objectives. These\nhelp ensure that everyone has the same understanding of what a lesson is\nsupposed to accomplish. For example, a statement like \u201cunderstand Git\u201d could\nmean any of the following:\n\n  * Learners can describe three ways in which version control systems like Git are better than file-sharing tools like Dropbox and two ways in which they are worse.\n\n  * Learners can commit a changed file to a Git repository using a desktop GUI tool.\n\n  * Learners can explain what a detached HEAD is and recover from it using command-line operations.\n\n> #### Objectives vs. Outcomes\n>\n> A learning objective is what a lesson strives to achieve. A learning outcome\n> is what it actually achieves, i.e. what learners actually take away. The\n> role of summative assessment is therefore to compare learning outcomes with\n> learning objectives.\n\nA learning objective describes how the learner will demonstrate what they have\nlearned once they have successfully completed a lesson. More specifically, it\nhas a measurable or verifiable verb that states what the learner will do and\nspecifies the criteria for acceptable performance. Writing these may initially\nseem restrictive, but they will make you, your fellow teachers, and your\nlearners happier in the long run: you will end up with clear guidelines for\nboth your teaching and assessment, and your learners will appreciate having\nclear expectations.\n\nOne way to understand what makes for a good learning objective is to see how a\npoor one can be improved:\n\n  * The learner will be given opportunities to learn good programming practices. This describes the lesson\u2019s content, not the attributes of successful learners.\n\n  * The learner will have a better appreciation for good programming practices. This doesn\u2019t start with an active verb or define the level of learning, and the subject of learning has no context and is not specific.\n\n  * The learner will understand how to program in R. While this starts with an active verb, it doesn\u2019t define the level of learning and the subject of learning is still too vague for assessment.\n\n  * The learner will write one-page data analysis scripts to read, filter, and summarize tabular data using R. This starts with an active verb, defines the level of learning, and provides context to ensure that outcomes can be assessed.\n\nWhen it comes to choosing verbs, many teachers use Bloom\u2019s Taxonomy. First\npublished in 1956 and updated at the turn of the century [Ande2001], it is a\nwidely used framework for discussing levels of understanding. Its most recent\nform has six categories; the list below gives a few of the verbs typically\nused in learning objectives written for each:\n\nRemembering:\n\n    \n\nExhibit memory of previously learned material by recalling facts, terms, basic\nconcepts, and answers. (recognize, list, describe, name, find)\n\nUnderstanding:\n\n    \n\nDemonstrate understanding of facts and ideas by organizing, comparing,\ntranslating, interpreting, giving descriptions, and stating main ideas.\n(interpret, summarize, paraphrase, classify, explain)\n\nApplying:\n\n    \n\nSolve new problems by applying acquired knowledge, facts, techniques and rules\nin a different way. (build, identify, use, plan, select)\n\nAnalyzing:\n\n    \n\nExamine and break information into parts by identifying motives or causes;\nmake inferences and find evidence to support generalizations. (compare,\ncontrast, simplify)\n\nEvaluating:\n\n    \n\nPresent and defend opinions by making judgments about information, validity of\nideas, or quality of work based on a set of criteria. (check, choose,\ncritique, prove, rate)\n\nCreating:\n\n    \n\nCompile information together in a different way by combining elements in a new\npattern or proposing alternative solutions. (design, construct, improve,\nadapt, maximize, solve)\n\nBloom\u2019s Taxonomy appears in almost every textbook on education, but [Masa2018]\nfound that even experienced educators have trouble agreeing on how to classify\nspecific things. The verbs are still useful, though, as is the notion of\nbuilding understanding in steps: as Daniel Willingham has said, people can\u2019t\nthink without something to think about [Will2010], and this taxonomy can help\nteachers ensure that learners have those somethings when they need them.\n\nAnother way to think about learning objectives comes from [Fink2013], which\ndefines learning in terms of the change it is meant to produce in the learner.\nFink\u2019s Taxonomy also has six categories, but unlike Bloom\u2019s they are\ncomplementary rather than hierarchical:\n\nFoundational Knowledge:\n\n    \n\nunderstanding and remembering information and ideas. (remember, understand,\nidentify)\n\nApplication:\n\n    \n\nskills, critical thinking, managing projects. (use, solve, calculate, create)\n\nIntegration:\n\n    \n\nconnecting ideas, learning experiences, and real life. (connect, relate,\ncompare)\n\nHuman Dimension:\n\n    \n\nlearning about oneself and others. (come to see themselves as, understand\nothers in terms of, decide to become)\n\nCaring:\n\n    \n\ndeveloping new feelings, interests, and values. (get excited about, be ready\nto, value)\n\nLearning How to Learn:\n\n    \n\nbecoming a better learner. (identify source of information for, frame useful\nquestions about)\n\nA set of learning objectives based on this taxonomy for an introductory course\non HTML and CSS might be:\n\n  * Explain what CSS properties are and how CSS selectors work.\n\n  * Style a web page using common tags and CSS properties.\n\n  * Compare and contrast writing HTML and CSS to writing with desktop publishing tools.\n\n  * Identify and correct issues in sample web pages that would make them difficult for the visually impaired to interact with.\n\n  * Describe features of favorite web sites whose design particularly appeals to you and explain why.\n\n  * Describe your two favorite online sources of information about CSS and explain what you like about them.\n\n## Maintainability\n\nOnce a lesson has been created someone needs to maintain it, and doing that is\na lot easier if it has been built in a maintainable way. But what exactly does\n\u201cmaintainable\u201d mean? The short answer is that a lesson is maintainable if it\u2019s\ncheaper to update it than to replace it. This equation depends on four\nfactors:\n\nHow well documented the course\u2019s design is.\n\n    \n\nIf the person doing maintenance doesn\u2019t know (or doesn\u2019t remember) what the\nlesson is supposed to accomplish or why topics are introduced in a particular\norder, it will take them more time to update it. One reason to use reverse\ndesign is to capture decisions about why each course is the way it is.\n\nHow easy it is for collaborators to collaborate technically.\n\n    \n\nTeachers usually share material by mailing PowerPoint files to each other or\nby putting them in a shared drive. Collaborative writing tools like Google\nDocs and wikis are a big improvement, as they allow many people to update the\nsame document and comment on other people\u2019s updates. The version control\nsystems used by programmers, such as GitHub, are another approach. They let\nany number of people work independently and then merge their changes in a\ncontrolled, reviewable way. Unfortunately, version control systems have a\nsteep learning curve and don\u2019t handle common office document formats.\n\nHow willing people are to collaborate.\n\n    \n\nThe tools needed to build a Wikipedia for lessons have been around for twenty\nyears, but most teachers still don\u2019t write and share lessons the way that they\nwrite and share encyclopedia entries.\n\nHow useful sharing actually is.\n\n    \n\nThe Reusability Paradox states that the more reusable a learning object is,\nthe less pedagogically effective it is [Wile2002]. The reason is that a good\nlesson resembles a novel more than it does a program: its parts are tightly\ncoupled rather than independent black boxes. Direct re-use may therefore be\nthe wrong goal for lessons; we might get further by trying to make them easier\nto remix.\n\nIf the Reusability Paradox is true, collaboration will be more likely if the\nthings being collaborated on are small. This fits well with Mike Caulfield\u2019s\ntheory of choral explanations, which argues that sites like Stack Overflow\nsucceed because they provide a chorus of answers for every question, each of\nwhich is most suitable for a slightly different questioner. If this is right,\nthe lessons of tomorrow may be guided tours of community-curated Q&A\nrepositories designed for learners at widely different levels.\n\n## Exercises\n\n### Create Learner Personas (small groups/30)\n\nWorking in small groups, create a 4-point persona that describes one of your\ntypical learners.\n\n### Classify Learning Objectives (pairs/10)\n\nLook at the example learning objectives for an introductory course on HTML and\nCSS in Section 6.2 and classify each according to Bloom\u2019s Taxonomy. Compare\nyour answers with those of your partner. Where did you agree and disagree?\n\n### Write Learning Objectives (pairs/20)\n\nWrite one or more learning objectives for something you currently teach or\nplan to teach using Bloom\u2019s Taxonomy. Working with a partner, critique and\nimprove the objectives. Does each one have a verifiable verb and clearly state\ncriteria for acceptable performance?\n\n### Write More Learning Objectives (pairs/20)\n\nWrite one or more learning objectives for something you currently teach or\nplan to teach using Fink\u2019s Taxonomy. Working with a partner, critique and\nimprove the objectives.\n\n### Help Me Do It By Myself (small groups/15)\n\nThe educational theorist Lev Vygotsky introduced the notion of a Zone of\nProximal Development (ZPD), which includes the problems that people cannot yet\nsolve on their own but are able to solve with help from a mentor. These are\nthe problems that are most fruitful to tackle next, as they are out of reach\nbut attainable.\n\nWorking in small groups, choose one learner persona you have developed and\ndescribe two or three problems that are in that learner\u2019s ZPD.\n\n### Building Lessons by Subtracting Complexity (individual/20)\n\nOne way to build a programming lesson is to write the program you want\nlearners to finish with, then remove the most complex part that you want them\nto write and make it the last exercise. You can then remove the next most\ncomplex part you want them to write and make it the penultimate exercise, and\nso on. Anything that\u2019s left after you have pulled out the exercises, such as\nloading libraries or reading data, becomes the starter code that you give\nthem.\n\nTake a program or web page that you want your learners to be able to create\nand work backward to break it into digestible parts. How many are there? What\nkey idea is introduced by each one?\n\n### Inessential Weirdness (individual/15)\n\nBetsy Leondar-Wright coined the phrase \u201cinessential weirdness\u201d to describe\nthings groups do that aren\u2019t really necessary, but which alienate people who\naren\u2019t yet members of that group. Sumana Harihareswara later used this notion\nas the basis for a talk on inessential weirdnesses in open source software,\nwhich includes things like using command-line tools with cryptic names. Take a\nfew minutes to read these articles, then make a list of inessential\nweirdnesses you think your learners might encounter when you first teach them.\nHow many of these can you avoid?\n\n### PETE (individual/15)\n\nOne pattern that works well for programming lessons is PETE: introduce the\nProblem, work through an Example, explain the Theory, and then Elaborate on a\nsecond example so that learners can see what is specific to each case and what\napplies to all cases. Pick something you have recently taught or been taught\nand outline a short lesson for it that follows these four steps.\n\n### PRIMM (individual/15)\n\nAnother lesson pattern is PRIMM [Sent2019]: Predict a program\u2019s behavior or\noutput, Run it to see what it actually does, Investigate why it does that by\nstepping through it in a debugger or drawing the flow of control, Modify it\n(or its inputs), and then Make something similar from scratch. Pick something\nyou have recently taught or been taught and outline a short lesson for it that\nfollows these five steps.\n\n### Concrete-Representational-Abstract (pairs/15)\n\nConcrete-Representational-Abstract (CRA) is an approach to introducing new\nideas that is used primarily with younger learners: physically manipulate a\nConcrete object, Represent the object with an image, then perform the same\noperations using numbers, symbols, or some other Abstraction.\n\n  1. Write each of the numbers 2, 7, 5, 10, 6 on a sticky note.\n\n  2. Simulate a loop that finds the largest value by looking at each in turn (concrete).\n\n  3. Sketch a diagram of the process you used, labeling each step (representational).\n\n  4. Write instructions that someone else could follow to go through the same steps (abstract).\n\nCompare your representational and abstract materials with your partner\u2019s.\n\n### Evaluating a Lesson Repository (small groups/10)\n\n[Leak2017] explores why computer science teachers don\u2019t use lesson sharing\nsites and recommends ways to make them more appealing:\n\n  1. The landing page should allow site visitors to identify their background and their interests in visiting the site. Sites should ask two questions: \u201cWhat is your current role?\u201d and \u201cWhat course and grade level are you interested in?\u201d\n\n  2. Sites should display all learning resources in the context of the full course so that potential users can understand their intended context of use.\n\n  3. Many teachers have concerns about having their (lack of) knowledge judged by their peers if they post to sites\u2019 discussion forums. These forums should therefore allow anonymous posting.\n\nIn small groups, discuss whether these three features would be enough to\nconvince you to use a lesson sharing site, and if not, what would.\n\n## Review\n\nConcepts: Learner personas\n\n# Pedagogical Content Knowledge\n\nEvery teacher needs three things:\n\ncontent knowledge\n\n    \n\nsuch as how to program;\n\ngeneral pedagogical knowledge\n\n    \n\nsuch as an understanding of the psychology of learning; and\n\npedagogical content knowledge\n\n    \n\n(PCK), which is the domain-specific knowledge of how to teach a particular\nconcept to a particular audience. In computing, PCK includes things like what\nexamples to use when teaching how parameters are passed to a function or what\nmisconceptions about nesting HTML tags are most common.\n\nWe can add technical knowledge to this mix [Koeh2013], but that doesn\u2019t change\nthe key point: it isn\u2019t enough to know the subject and how to teach\u2014you have\nto know how to teach that particular subject [Maye2004]. This chapter\ntherefore summarizes some results from computing education research that will\nadd to your store of PCK.\n\nAs with all research, some caution is required when interpreting results:\n\nTheories change as more data becomes available.\n\n    \n\nComputing education research (CER) is a young discipline: the American Society\nfor Engineering Education was founded in 1893 and the National Council of\nTeachers of Mathematics in 1920, but the Computer Science Teachers Association\ndidn\u2019t exist until 2005. While a steady stream of new insights are reported at\nconferences like SIGCSE, ITiCSE, and ICER, we simply don\u2019t know as much about\nlearning to program as we do about learning to read, play a sport, or do basic\narithmetic.\n\nMost of these studies\u2019 subjects are WEIRD:\n\n    \n\nthey are from Western, Education, Industrialized, Rich, and Democratic\nsocieties [Henr2010]. What\u2019s more, they are also mostly young and in\ninstitutional classrooms, since that\u2019s the population most researchers have\neasiest access to. We know much less about adults, members of marginalized\ngroups, learners in free-range settings, or end-user programmers, even though\nthere are far more of them.\n\nIf this was an academic treatise, I would therefore preface most claims with\nqualifiers like, \u201cSome research may seem to indicate that...\u201d But since actual\nteachers in actual classrooms have to make decisions regardless of whether\nresearch has clear answers yet or not, this chapter presents actionable best\nguesses rather than nuanced perhapses.\n\n> #### Jargon\n>\n> Like any specialty, CER has jargon. CS1 refers to an introductory semester-\n> long course in which learners meet variables, loops, and functions for the\n> first time, while CS2 refers to a second course that covers basic data\n> structures like stacks and queues, and CS0 refers to an introductory course\n> for people without any prior experience who aren\u2019t intending to continue\n> with computing right away. Full definitions for these terms can be found in\n> the ACM Curriculum Guidelines.\n\n## What Are We Teaching Them Now?\n\nVery little is known about what coding bootcamps and other free-range\ninitiatives teach, in part because many are reluctant to share their\ncurriculum. We know more about what is taught by institutions [Luxt2017]:\n\nTopic| %| Topic| %  \n---|---|---|---  \nProgramming Process| 87%| Data Types| 23%  \nAbstract Programming Thinking| 63%| Input/Output| 17%  \nData Structures| 40%| Libraries| 15%  \nObject-Oriented Concepts| 36%| Variables & Assignment| 14%  \nControl Structures| 33%| Recursion| 10%  \nOperations & Functions| 26%| Pointers & Memory Management| 5%  \n  \nHigh-level topic labels like these can hide a multitude of sins. A more\ntangible result comes from [Rich2017], which reviewed a hundred articles to\nfind learning trajectories for computing classes in elementary and middle\nschools. Their results for sequencing, repetition, and conditionals are\nessentially collective concept maps that combine and rationalize the implicit\nand explicit thinking of many different educators (Figure 7.1).\n\nLearning trajectory for conditions (from [Rich2017])\n\n## How Much Are They Learning?\n\nThere can be a world of difference between what teachers teach and how much\nlearners learn. To explore the latter, we must use other measures or do direct\nstudies. Taking the former approach, roughly two-thirds of post-secondary\nstudents pass their first computing course, with some variations depending on\nclass size and so on, but with no significant differences over time or based\non language [Benn2007a,Wats2014].\n\nHow does prior experience affect these results? To find out, [Wilc2018]\ncompared the performance and confidence of novices with and without prior\nprogramming experience in CS1 and CS2 (see below). They found that novices\nwith prior experience outscored novices without by 10% in CS1, but those\ndifferences disappeared by the end of CS2. They also found that women with\nprior exposure outperformed their male peers in all areas, but were\nconsistently less confident in their abilities (Section 10.4).\n\nAs for direct studies of how much novices learn, [McCr2001] presented a multi-\nsite international study that was later replicated by [Utti2013]. According to\nthe first study, \u201c...the disappointing results suggest that many students do\nnot know how to program at the conclusion of their introductory courses.\u201d More\nspecifically, \u201cFor a combined sample of 216 students from four universities,\nthe average score was 22.89 out of 110 points on the general evaluation\ncriteria developed for this study.\u201d This result may say as much about\nteachers\u2019 expectations as it does about student ability, but either way, our\nfirst recommendation is to measure and track results in ways that can be\ncompared over time so that you can tell if your lessons are becoming more or\nless effective.\n\n## What Misconceptions Do Novices Have?\n\nChapter 2 explained why clearing up novices\u2019 misconceptions is just as\nimportant as teaching them strategies for solving problems. The biggest\nmisconception novices have\u2014sometimes called the \u201csuperbug\u201d in coding\u2014is the\nbelief that computers understand what people mean in the way that another\nhuman being would [Pea1986]. Our second recommendation is therefore to teach\nnovices that computers don\u2019t understand programs, i.e. that calling a variable\n\u201ccost\u201d doesn\u2019t guarantee that its value is actually a cost.\n\n[Sorv2018] presents over forty other misconceptions that teachers can also try\nto clear up, many of which are also discussed in [Qian2017]\u2019s survey. One is\nthe belief that variables in programs work the same way they do in\nspreadsheets, i.e. that after executing:\n\n    \n    \n    grade = 65 total = grade + 10 grade = 80 print(total)\n\nthe value of total will be 90 rather than 75 [Kohn2017]. This is an example of\nthe way in which novices construct a plausible-but-wrong mental model by\nmaking analogies; other misconceptions include:\n\n  * A variable holds the history of the values it has been assigned, i.e. it remembers what its value used to be.\n\n  * Two objects with the same value for a name or id attribute are guaranteed to be the same object.\n\n  * Functions are executed as they are defined, or are executed in the order in which they are defined.\n\n  * A while loop\u2019s condition is constantly evaluated, and the loop stops as soon as it becomes false. Conversely, the conditions in if statements are also constantly evaluated, and their statements are executed as soon as the condition becomes true regardless of where the flow of control is at the time.\n\n  * Assignment moves values, i.e. after a = b, the variable b is empty.\n\n## What Mistakes Do Novices Make?\n\nThe mistakes novices make can tell us what to prioritize in our teaching, but\nit turns out that most teachers don\u2019t know how common different kinds of\nmistakes actually are. The largest study of this is [Brow2017], which found\nthat mismatched quotes and parentheses are the most common type of errors in\nnovice Java programs, but also the easiest to fix, while some mistakes (like\nputting the condition of an if in {} instead of ()) are most often made only\nonce. Unsurprisingly, mistakes that produce compiler errors are fixed much\nfaster than ones that don\u2019t. Some mistakes, however, are made many times, like\ninvoking methods with the wrong arguments (e.g. passing a string instead of an\ninteger).\n\n> #### Not Right vs. Not Done\n>\n> One difficulty in research like this is distinguishing mistakes from work in\n> progress. For example, an empty if statement or a method that is defined but\n> not yet used may be a sign of incomplete code rather than an error.\n\n[Brow2017] also compared the mistakes novices actually make with what their\nteachers thought they made. They found that, \u201c...educators formed only a weak\nconsensus about which mistakes are most frequent, that their rankings bore\nonly a moderate correspondence to the students in the...data, and that\neducators\u2019 experience had no effect on this level of agreement.\u201d For example,\nmistaking = (assignment) and == (equality) wasn\u2019t nearly as common as most\nteachers believed.\n\n> #### Not Just for Code\n>\n> [Park2015] collected data from an online HTML editor during an introductory\n> web development course and found that nearly all learners made syntax errors\n> that remained unresolved weeks into the course. 20% of these errors related\n> to the relatively complex rules that dictate when it is valid for HTML\n> elements to be nested in one another, but 35% related to the simpler tag\n> syntax determining how HTML elements are nested. The tendency of many\n> teachers to say, \u201cBut the rules are simple,\u201d is a good example of expert\n> blind spot discussed in Chapter 3...\n\n## How Do Novices Program?\n\n[Solo1984,Solo1986] pioneered the exploration of novice and expert programming\nstrategies. The key finding is that experts know both \u201cwhat\u201d and \u201chow,\u201d i.e.\nthey understand what to put into programs and they have a set of program\npatterns or plans to guide their construction. Novices lack both, but most\nteachers focus solely on the former, even though bugs are often caused by not\nhaving a strategy for solving the problem rather than to lack of knowledge\nabout the language. Recent work has shown the effectiveness of teaching four\ndistinct skills in a specific order [Xie2019]:\n\nsemantics of code| templates related to goals  \n---|---  \nreading| 1\\. read code and predict behavior| 3\\. recognize templates and their\nuses  \nwriting| 2\\. write correct syntax| 4\\. use templates to meet goals  \n  \nOur next recommendations are therefore to have learners read code, then modify\nit, then write it, and to introduce common patterns explicitly and have\nlearners practice using them. [Mull2007b] is just one of many studies proving\nthe benefits of teaching common patterns explicitly, and decomposing problems\ninto patterns creates natural opportunities for creating and labeling subgoals\n[Marg2012,Marg2016].\n\n## How Do Novices Debug?\n\nA decade ago, [McCa2008] wrote, \u201cIt is surprising how little page space is\ndevoted to bugs and debugging in most introductory programming textbooks.\u201d\nLittle has changed since: there are hundreds of books on compilers and\noperating systems, but only a handful about debugging, and I have never seen\nan undergraduate course devoted to the subject.\n\n[List2004,List2009] found that many novices struggled to predict the output of\nshort pieces of code and to select the correct completion of the code from a\nset of possibilities when told what it was supposed to do. More recently,\n[Harr2018] found that the gap between being able to trace code and being able\nto write it has largely closed by CS2, but that novices who still have a gap\n(in either direction) are likely to do poorly.\n\nOur fifth recommendation is therefore to explicitly teach novices how to\ndebug. [Fitz2008,Murp2008] found that good debuggers were good programmers,\nbut not all good programmers were good at debugging. Those who were used a\nsymbolic debugger to step through their programs, traced execution by hand,\nwrote tests, and re-read the spec frequently, which are all teachable habits.\nHowever, tracing execution step by step was sometimes used ineffectively: for\nexample, a novice might put the same print statement in both parts of an if-\nelse. Novices would also comment out lines that were actually correct as they\ntried to isolate a problem; teachers can make both of these mistakes\ndeliberately, point them out, and correct them to help novices get past them.\n\nTeaching novices how to debug can also help make classes easier to manage.\n[Alqa2017] found that learners with more experience solved debugging problems\nsignificantly faster, but times varied widely: 4\u201310 minutes was a typical\nrange for individual exercises, which means that some learners need 2\u20133 times\nlonger than others to get through the same exercises. Teaching the slower\nlearners what the faster ones are doing will help make the group\u2019s overall\nprogress more uniform.\n\nDebugging depends on being able to read code, which multiple studies have\nshown is the single most effective way to find bugs\n[Basi1987,Keme2009,Bacc2013]. The code quality rubric developed in\n[Steg2014,Steg2016a] is a good checklist of things to look for, though it is\nbest presented in chunks rather than all at once.\n\nHaving learners read code and summarize its behavior is a good exercise\n(Section 5.1), but often takes too long to be practical in class. Having them\npredict a program\u2019s output just before it is run, on the other hand, helps\nreinforce learning (Section 9.11) and also gives them a natural moment to ask\n\u201cwhat if\u201d questions. Teachers or learners can also trace changes to variables\nas they go along, which [Cunn2017] found was effective (Section 12.2).\n\n## What About Testing?\n\nNovice programmers seem just as reluctant to test software as professionals.\nThere\u2019s no doubt that doing it is valuable\u2014[Cart2017] found that high-\nperforming novices spent a lot of time testing, while low performers spent\nmuch more time working on code with errors\u2014and many teachers require learners\nto write tests for assignments. But how well do they do this? One answer comes\nfrom [Bria2015], which scored learners\u2019 programs by how many teacher-provided\ntest cases those programs passed, and conversely scores test cases written by\nlearners according to how many deliberately-seeded bugs they caught. They\nfound that novices\u2019 tests often have low coverage (i.e. they don\u2019t test most\nof the code) and that they often test many things at once, which makes it hard\nto pinpoint the causes of errors.\n\nAnother answer comes from [Edwa2014b], which looked at all of the bugs in all\nnovices\u2019 code submissions combined and identified those detected by the\nnovices\u2019 test suite. They found that novices\u2019 tests only detected an average\nof 13.6% of the faults present in the entire program population. What\u2019s more,\n90% of the novices\u2019 tests were very similar, which indicates that novices\nmostly write tests to confirm that code is doing what it\u2019s supposed to rather\nthan to find cases where it isn\u2019t.\n\nOne approach to teaching better testing practices is to define a programming\nproblem by providing a set of tests to be passed rather than through a written\ndescription (Section 12.1). Before doing this, though, take a moment to look\nat how many tests you\u2019ve written for your own code recently, and then decide\nwhether you\u2019re teaching what you believe people should do, or what they (and\nyou) actually do.\n\n## Do Languages Matter?\n\nThe short answer is \u201cyes\u201d: novices learn to program faster and learn more\nusing blocks-based tools like Scratch (Figure 7.2) [Wein2017]. One reason is\nthat blocks-based systems reduce cognitive load by eliminating the possibility\nof syntax errors. Another is that block interfaces encourage exploration in a\nway that text does not: like all good tools, Scratch can be learned\naccidentally [Malo2010].\n\nBut what happens after blocks? [Chen2018] found that learners whose first\nprogramming language was graphical had higher grades in introductory\nprogramming courses than learners whose first language was textual when the\nlanguages were introduced in or before early adolescent years. Our sixth\nrecommendation is therefore to start children and teens with blocks-based\ninterfaces before moving to text-based systems. The age qualification is there\nbecause Scratch deliberately looks like it\u2019s meant for younger users, and it\ncan still be hard to convince adults to take it seriously.\n\nScratch\n\nScratch has probably been studied more than any other programming tool. One\nexample is [Aiva2016], which analyzed over 250,000 Scratch projects and found\n(among other things) that about 28% of projects have some blocks that are\nnever called or triggered. As in the earlier aside about incomplete versus\nincorrect Java programs, the authors hypothesize that users may be using these\nblocks as a scratchpad to keep track of bits of code they don\u2019t (yet) want to\nthrow away. Another example is [Grov2017,Mlad2017], which studied novices\nlearning about loops in Scratch, Logo, and Python. They found that\nmisconceptions about loops are minimized when using a block-based language\nrather than a text-based language. What\u2019s more, as tasks become more complex\n(such as using nested loops) the differences become larger.\n\n> #### Harder Than Necessary\n>\n> The creators of programming languages make those languages harder to learn\n> by not doing basic usability testing. For example, [Stef2013] found that,\n> \u201c...the three most common words for looping in computer science, for, while,\n> and foreach, were rated as the three most unintuitive choices by non-\n> programmers.\u201d Their work shows that C-style syntax (as used in Java and\n> Perl) is just as hard for novices to learn as a randomly designed syntax,\n> but that the syntax of languages such as Python and Ruby is significantly\n> easier to learn, and the syntax of a language whose features are tested\n> before being added to the language is easier still. [Stef2017] is a useful\n> brief summary of what we actually know about designing programming languages\n> and why we believe it\u2019s true, while [Guzd2016] lays out five principles that\n> programming languages for learners should follow.\n\n### Object-Oriented Programming\n\nObjects and classes are power tools for experienced programmers, and many\neducators advocate an objects first approach to teaching programming (though\nthey sometimes disagree on exactly what that means [Benn2007b]). [Sorv2014]\ndescribes and motivates this approach, and [Koll2015] describes three\ngenerations of tools designed to support novice programming in object-oriented\nenvironments.\n\nIntroducing objects early has a few challenges. [Mill2016b] found that most\nnovices using Python struggled to understand self (which refers to the current\nobject): they omitted it in method definitions, failed to use it when\nreferencing object attributes, or both. [Rago2017] found something similar in\nhigh school students, and also found that high school teachers often weren\u2019t\nclear on the concept either. On balance, we recommend that teachers start with\nfunctions rather than objects, i.e. that learners not be taught how to define\nclasses until they understand basic control structures and data types.\n\n### Type Declarations\n\nProgrammers have argued for decades about whether variables\u2019 data types should\nhave to be declared or not, usually based on their personal experience as\nprofessionals rather than on any kind of data. [Endr2014,Fisc2015] found that\nrequiring novices to declare variable types does add some complexity to\nprograms, but it pays off fairly quickly by acting as documentation for a\nmethod\u2019s use\u2014in particular, by forestalling questions about what\u2019s available\nand how to use it.\n\n### Variable Naming\n\n[Kern1999] wrote, \u201cProgrammers are often encouraged to use long variable names\nregardless of context. This is a mistake: clarity is often achieved through\nbrevity.\u201d Lots of programmers believe this, but [Hofm2017] found that using\nfull words in variable names led to an average of 19% faster comprehension\ncompared to letters and abbreviations. In contrast, [Beni2017] found that\nusing single-letter variable names didn\u2019t affect novices\u2019 ability to modify\ncode. This may be because their programs are shorter than professionals\u2019 or\nbecause some single-letter variable names have implicit types and meanings.\nFor example, most programmers assume that i, j, and n are integers and that s\nis a string, while x, y, and z are either floating-point numbers or integers\nmore or less equally.\n\nHow important is this? [Bink2012] reported that reading and understanding code\nis fundamentally different from reading prose: \u201c...the more formal structure\nand syntax of source code allows programmers to assimilate and comprehend\nparts of the code quite rapidly independent of style. In particular...beacons\nand program plans play a large role in comprehension.\u201d It also found that\nexperienced developers are relatively unaffected by identifier style, so our\nrecommendation is just to use consistent style in all examples. Since most\nlanguages have style guides (e.g. PEP 8 for Python) and tools to check that\ncode follows these guidelines, our full recommendation is to use tools to\nensure that all code examples adhere to a consistent style.\n\n## Do Better Error Messages Help?\n\nIncomprehensible error messages are a major source of frustration for novices\n(and for experienced programmers as well). Several researchers have therefore\nexplored whether better error messages would help alleviate this. For example,\n[Beck2016] rewrote some of the Java compiler\u2019s messages so that instead of:\n\n    \n    \n    C:\\stj\\Hello.java:2: error: cannot find symbol public static void main(string[ ] args) ^ 1 error Process terminated ... there were problems.\n\nlearners would see:\n\n    \n    \n    Looks like a problem on line number 2. If \"string\" refers to a datatype, capitalize the 's'!\n\nSure enough, novices given these messages made fewer repeated errors and fewer\nerrors overall.\n\n[Bari2017] went further and used eye tracking to show that despite the\ngrumblings of compiler writers, people really do read error messages\u2014in fact,\nthey spend 13\u201325% of their time doing this. However, reading error messages\nturns out to be as difficult as reading source code, and how difficult it is\nto read the error messages strongly predicts task performance. Teachers should\ntherefore show learners how to read and interpret error messages. [Marc2011]\nhas a rubric for responses to error messages that can be useful in grading\nsuch exercises.\n\n### Does Visualization Help?\n\nVisualizing program execution is a perennially popular idea, and tools like\nthe Online Python Tutor [Guo2013] and Loupe (which shows how JavaScript\u2019s\nevent loop works) are useful teaching aids. However, people learn more from\nconstructing visualizations than they do from viewing visualizations\nconstructed by others [Stas1998,Ceti2016], so does visualization actually help\nlearning?\n\nTo answer this, [Cunn2017] replicated an earlier study of the kinds of\nsketching learners do when tracing code execution. They found that not\nsketching at all correlates with lower success, while tracing changes to\nvariables\u2019 values by writing new values near their names as they change was\nthe most effective strategy.\n\nOne possible confounding effect they checked was time: since sketchers take\nsignificantly more time to solve problems, do they do better just because they\nthink for longer? The answer is no: there was no correlation between the time\ntaken and the score achieved. Our recommendation is therefore to teach\nlearners to trace variables\u2019 values when debugging.\n\n> #### Flowcharts\n>\n> One often-overlooked finding about visualization is that people understand\n> flowcharts better than pseudocode if both are equally well structured\n> [Scan1989]. Earlier work showing that pseudocode outperformed flowcharts\n> used structured pseudocode and tangled flowcharts; when the playing field\n> was leveled, novices did better with the graphical representation.\n\n## What Else Can We Do to Help?\n\n[Viha2014] examined the average improvement in pass rates of various kinds of\nintervention in programming classes. They point out that there are many\nreasons to take their findings with a grain of salt: the pre-change teaching\npractices are rarely stated clearly, the quality of change is not judged, and\nonly 8.3% of studies reported negative findings, so either there is positive\nreporting bias or the way we\u2019re teaching right now is the worst possible and\nanything would be an improvement. And like many other studies discussed in\nthis chapter, they were only looking at university classes, so their findings\nmay not generalize to other groups.\n\nWith those caveats in mind, they found ten things teachers can do to improve\noutcomes (Figure 7.3):\n\nCollaboration:\n\n    \n\nActivities that encourage learner collaboration either in classrooms or labs.\n\nContent Change:\n\n    \n\nParts of the teaching material were changed or updated.\n\nContextualization:\n\n    \n\nCourse content and activities were aligned towards a specific context such as\ngames or media.\n\nCS0:\n\n    \n\nCreation of a preliminary course to be taken before the introductory\nprogramming course; could be organized only for some (e.g. at-risk) learners.\n\nGame Theme:\n\n    \n\nA game-themed component was introduced to the course.\n\nGrading Scheme:\n\n    \n\nA change in the grading scheme, such as increasing the weight of programming\nactivities while reducing that of the exam.\n\nGroup Work:\n\n    \n\nActivities with increased group work commitment such as team-based learning\nand cooperative learning.\n\nMedia Computation:\n\n    \n\nActivities explicitly declaring the use of media computation (Chapter 10).\n\nPeer Support:\n\n    \n\nSupport by peers in form of pairs, groups, hired peer mentors or tutors.\n\nOther Support:\n\n    \n\nAn umbrella term for all support activities, e.g. increased teacher hours,\nadditional support channels, etc.\n\nEffectiveness of interventions\n\nThis list highlights the importance of cooperative learning. [Beck2013] looked\nat this specifically over three academic years in courses taught by two\ndifferent teachers and found significant benefits overall and for many\nsubgroups. The cooperators had higher grades and left fewer questions blank on\nthe final exam, which indicates greater self-efficacy and willingness to try\nto debug things.\n\n> #### Computing Without Coding\n>\n> Writing code isn\u2019t the only way to teach people how to program: having\n> novices work on computational creativity exercises improves grades at\n> several levels [Shel2017]. A typical exercise is to describe an everyday\n> object (such as a paper clip or toothbrush) in terms of its inputs, outputs,\n> and functions. This kind of teaching is sometimes called unplugged; the CS\n> Unplugged site has lessons and exercises for doing this.\n\n## Where Next?\n\nFor those who want to go deeper, [Finc2019] is a comprehensive summary of CER,\n[Ihan2016] summarizes the methods that studies use most often. I hope that\nsome day we will have catalogs like [Ojos2015] and more teacher training\nmaterials like [Hazz2014,Guzd2015a,Sent2018] to help us all do better.\n\nMost of the research reported in this chapter was publicly funded but is\nlocked away behind paywalls: at a guess, I broke the law 250 times to download\npapers from sites like Sci-Hub while writing this book. I hope the day is\ncoming when no one will need to do that; if you are a researcher, please\nhasten that day by publishing your work in open access venues.\n\n## Exercises\n\n### Your Learners\u2019 Misunderstandings (small groups/15)\n\nWorking in small groups, re-read Section 7.3 and make a list of misconceptions\nyou think your learners have. How specific are they? How would you check how\naccurate your list is?\n\n### Checking for Common Errors (individual/20)\n\nThese common errors are taken from a longer list in [Sirk2012]:\n\nInverted assignment:\n\n    \n\nThe learner assigns the value of the left-hand variable to the right-hand\nvariable rather than the other way around.\n\nWrong branch:\n\n    \n\nThe learner thinks the code in the body of an if is run even if the condition\nis false.\n\nExecuting function instead of defining it:\n\n    \n\nThe learner believes that a function is executed as it is defined.\n\nWrite one exercise for each to check that learners aren\u2019t making that mistake.\n\n### Mangled Code (pairs/15)\n\n[Chen2017] describes exercises in which learners reconstruct code that has\nbeen mangled by removing comments, deleting or replacing lines of code, moving\nlines, and so on. Performance on these correlates strongly with performance on\nassessments in which learners write code, but these questions require less\nwork to mark. Take the solution to a programming exercise you\u2019ve created in\nthe past, mangle it in two different ways, swap with a partner, and see how\nlong it takes each of you to answer the other\u2019s question correctly.\n\n### The Rainfall Problem (pairs/10)\n\n[Solo1986] introduced the Rainfall Problem, which has been used in many\nsubsequent studies of programming [Fisl2014,Simo2013,Sepp2015]. Write a\nprogram that repeatedly reads in positive integers until it reads the integer\n99999. After seeing 99999, the program prints the average of the numbers seen.\n\n  1. Solve the Rainfall Problem in the programming language of your choice.\n\n  2. Compare your solution with that of your partner. What does yours do that theirs doesn\u2019t and vice versa?\n\n### Roles of Variables (pairs/15)\n\n[Kuit2004,Byck2005,Saja2006] presented a set of single-variable patterns that\nI have found very useful in teaching beginners:\n\nFixed value:\n\n    \n\nA data item that does not get a new proper value after its initialization.\n\nStepper:\n\n    \n\nA data item stepping through a systematic, predictable succession of values.\n\nWalker:\n\n    \n\nA data item traversing in a data structure.\n\nMost-recent holder:\n\n    \n\nA data item holding the latest value encountered while going through a\nsuccession of values.\n\nMost-wanted holder:\n\n    \n\nA data item holding the best or most appropriate value encountered so far.\n\nGatherer:\n\n    \n\nA data item accumulating the effect of individual values.\n\nFollower:\n\n    \n\nA data item that always gets its new value from the old value of some other\ndata item.\n\nOne-way flag:\n\n    \n\nA two-valued data item that cannot get its initial value once the value has\nbeen changed.\n\nTemporary:\n\n    \n\nA data item holding some value for a very short time only.\n\nOrganizer:\n\n    \n\nA data structure storing elements that can be rearranged.\n\nContainer:\n\n    \n\nA data structure storing elements that can be added and removed.\n\nChoose a 5\u201315 line program and classify its variables using these categories.\nCompare your classifications with those of a partner. Where you disagreed, did\nyou understand each other\u2019s view?\n\n### What Are You Teaching? (individual/10)\n\nCompare the topics you teach to the list developed in [Luxt2017] (Section\n7.1). Which topics do you cover? Which don\u2019t you cover? What extra topics do\nyou cover that aren\u2019t in their list?\n\n### Beneficial Activities (individual/10)\n\nLook at the list of interventions developed by [Viha2014] (Section 7.10).\nWhich of these things do you already do in your classes? Which ones could you\neasily add? Which ones are irrelevant?\n\n### Misconceptions and Challenges (small groups/15)\n\nThe Professional Development for CS Principles Teaching site includes a\ndetailed list of learners\u2019 misconceptions and exercises. Working in small\ngroups, choose one section (such as data structures or functions) and go\nthrough their list. Which of these misconceptions do you remember having when\nyou were a learner? Which do you still have? Which have you seen in your\nlearners?\n\n### What Do You Care Most About? (whole class/15)\n\n[Denn2019] asked people to propose and rate various CER questions, and found\nthat there was no overlap between those that researchers cared most about and\nthose that non-researchers cared most about. The researchers\u2019 favorites were:\n\n  1. What fundamental programming concepts are the most challenging for students?\n\n  2. What teaching strategies are most effective when dealing with a wide range of prior experience in introductory programming classes?\n\n  3. What affects students\u2019 ability to generalize from simple programming examples?\n\n  4. What teaching practices are most effective for teaching computing to children?\n\n  5. What kinds of problems do students in programming classes find most engaging?\n\n  6. What are the most effective ways to teach programming to various groups?\n\n  7. What are the most effective ways to scale computing education to reach the general student population?\n\nwhile the most important questions for non-researchers were:\n\n  1. How and when is it best to give students feedback on their code to improve learning?\n\n  2. What kinds of programming exercises are most effective when teaching students Computer Science?\n\n  3. What are the relative merits of project-based learning, lecturing, and active learning for students learning computing?\n\n  4. What is the most effective way to provide feedback to students in programming classes?\n\n  5. What do people find most difficult when breaking problems down into smaller tasks while programming?\n\n  6. What are the key concepts that students need to understand in introductory computing classes?\n\n  7. What are the most effective ways to develop computing competency among students in non-computing disciplines?\n\n  8. What is the best order in which to teach basic computing concepts and skills?\n\nHave each person in the class independently give one point to each of the\neight questions from the combined lists that they care most about, then\ncalculate an average score for each question. Which ones are most popular in\nyour class? In which group are the most popular questions?\n\n# Teaching as a Performance Art\n\nIn Darwin Among the Machines, George Dyson wrote, \u201cIn the game of life and\nevolution there are three players at the table: human beings, nature, and\nmachines. I am firmly on the side of nature. But nature, I suspect, is on the\nside of the machines...\u201d There are similarly now three players in the game of\neducation: textbooks and other read-only materials, live lectures, and\nautomated online lessons. You may give your learners both written lessons and\nsome combination of recorded video and self-paced exercises, but if you are\ngoing to teach in person you must offer something different from (and\nhopefully better than) either of them. This chapter therefore focuses on how\nto teach programming by actually doing it.\n\n## Live Coding\n\n> Teaching is theater, not cinema. \u2014 Neal Davis\n\nThe most effective way to teach programming is live coding\n[Rubi2013,Haar2017,Raj2018]. Instead of presenting pre-written material, the\nteacher writes code in front of the class while the learners follow along,\ntyping it in and running it as they go. Live coding works better than slides\nfor several reasons:\n\n  * It enables active teaching by allowing teachers to follow their learners\u2019 interests and questions in the moment. A slide deck is like a railway track: it may be a smooth ride, but you have to decide in advance where you\u2019re going. Live coding is more like driving an off-road vehicle: it may be bumpier, but it\u2019s a lot easier to change direction and go where people want.\n\n  * Watching a program being written is more motivating than watching someone page through slides.\n\n  * It facilitates unintended knowledge transfer: people learn more than we are consciously teaching by watching how we do things.\n\n  * It slows the teacher down: if they have to type in the program as they go along then they can only go twice as fast as their learners rather than ten times faster as they could with slides.\n\n  * It helps reduce the load on short-term memory because it makes the teacher more aware of how much they are throwing at their learners.\n\n  * Learners get to see how to diagnose and correct mistakes. They are going to spend a lot of time doing this; unless you\u2019re a perfect typist, live coding ensures that they get to see how to.\n\n  * Watching teachers make mistakes shows learners that it\u2019s all right to make mistakes of their own. If the teacher isn\u2019t embarrassed about making and talking about mistakes, learners will be more comfortable doing so too.\n\nAnother benefit of live coding is that it demonstrates the order in which\nprograms should be written. When looking at how people solved Parsons\nProblems, [Ihan2011] found that experienced programmers often dragged the\nmethod signature to the beginning, then added the majority of the control flow\n(i.e. loops and conditionals), and only then added details like variable\ninitialization and handling of corner cases. This out-of-order authoring is\nforeign to novices, who read and write code in the order it\u2019s presented on the\npage; seeing it helps them learn to decompose problems into subgoals that can\nbe tackled one by one. Live coding also gives teachers a chance to emphasize\nthe importance of small steps with frequent feedback [Blik2014] and the\nimportance of picking a plan rather than making more-or-less random changes\nand hoping things will get better [Spoh1985].\n\nIt takes a bit of practice to get comfortable talking while you code in front\nof an audience, but most people report that it quickly becomes no more\ndifficult than talking around a deck of slides. The sections below offer tips\non how to make your live coding better.\n\n### Embrace Your Mistakes\n\n> The typos are the pedagogy. \u2014 Emily Jane McTavish\n\nThe most important rule of live coding is to embrace your mistakes. No matter\nhow well you prepare, you will make some; when you do, think through them with\nyour audience. While data is hard to come by, professional programmers spend\nanywhere from 25% to 60% of their time debugging; novices spend much more\n(Section 7.6), but most textbooks and tutorials spend little time diagnosing\nand correcting problems. If you talk aloud while you figure out what you\nmistyped or where you took the wrong path, and explain how you\u2019ve corrected\nyourself, you will give your learners a toolbox they can use when they make\ntheir own mistakes.\n\n> #### Deliberate Fumbles\n>\n> Once you have given a lesson several times, you\u2019re unlikely to make anything\n> other than basic typing mistakes (which can still be informative). You can\n> try to remember past mistakes and make them deliberately, but that often\n> feels forced. An alternative approach is twitch coding: ask learners one by\n> one to tell you what to type next. This is pretty much guaranteed to get you\n> into some kind of trouble.\n\n### Ask For Predictions\n\nOne way to keep learners engaged while you are live coding is to ask them to\nmake predictions about what the code on the screen is going to do. You can\nthen write down the first few suggestions they make, have the whole class vote\non which they think is most likely, and then run the code. This is a\nlightweight form of peer instruction, which we will discuss in Section 9.2; as\nwell as keeping their attention on task, it gives them practice at reasoning\nabout code\u2019s behavior.\n\n### Take It Slow\n\nEvery time you type a command, add a line of code to a program, or select an\nitem from a menu, say what you are doing out loud and then point to what you\nhave done and its output on the screen and go through it a second time. This\nallows learners to catch up and to check that what they have just done is\ncorrect. It is particularly important when some of your learners have seeing\nor hearing challenges or are not fluent in the language of instruction.\n\nWhatever you do, don\u2019t copy and paste code: doing this practically guarantees\nthat you\u2019ll race ahead of your learners. And if you use tab completion, say it\nout loud so that your learners understand what you\u2019re doing: \u201cLet\u2019s use turtle\ndot \u2018r\u2019 \u2018i\u2019 and tab to get \u2018right\u2019.\u201d\n\nIf the output of your command or code makes what you just typed disappear from\nview, scroll back up so learners can see it again. If that\u2019s not practical,\nexecute the same command a second time or copy and paste the last command(s)\ninto the workshop\u2019s shared notes.\n\n### Be Seen and Heard\n\nWhen you sit down, you are more likely to look at your screen rather than at\nyour audience and may be hidden from learners in the back rows of your\nclassroom. If you are physically able to stand up for a couple of hours, you\nshould therefore do so while teaching. Plan for this and make sure that you\nhave a raised table, standing desk, or lectern for your laptop so that you\ndon\u2019t have to bend over to type.\n\nRegardless of whether you are standing or sitting, make sure to move around as\nmuch as you can: go to the screen to point something out, draw something on\nthe whiteboard, or just step away from your computer for a few moments and\nspeak directly to your audience. Doing this draws your learners\u2019 attention\naway from their screens and provides a natural time for them to ask questions.\n\nIf you are going to be teaching for more than a couple of hours, it\u2019s worth\nusing a microphone even in a small room. Your throat gets tired just like\nevery other part of your body; using a mike is no different from wearing\ncomfortable shoes (which you also ought to do). It can also make a big\ndifference to people with hearing disabilities.\n\n### Mirror Your Learner\u2019s Environment\n\nYou may have customized your environment with a fancy Unix shell prompt, a\ncustom color scheme for your development environment, or a plethora of\nkeyboard shortcuts. Your learners won\u2019t have any of this, so try to create an\nenvironment that mirrors what they do have. Some teachers create a separate\nbare-bones account on their laptop or a separate teaching-only account if\nthey\u2019re using an online service like Scratch or GitHub. Doing this can also\nhelp prevent packages that you installed for work yesterday breaking the\nlesson you are supposed to teach this morning.\n\n### Use the Screen Wisely\n\nYou will usually need to enlarge your font considerably for people to read it\nfrom the back of the room, which means you can put much less on the screen\nthan you\u2019re used to. In many cases you will be reduced to 60\u201370 columns and\n20\u201330 rows, so that you\u2019re using a 21st century supercomputer as if it was a\ndumb terminal from the early 1980s.\n\nTo manage this, maximize the window you are using to teach and then ask\neveryone to give you a thumbs-up or thumbs-down on its readability. Use a\nblack font on a lightly-tinted background rather than a light font on a dark\nbackground\u2014the light tint will glare less than pure white.\n\nPay attention to the room lighting as well: it should not be fully dark, and\nthere should be no lights directly on or above your projection screen. Allow a\nfew minutes for learners to reposition their tables so that they can see\nclearly.\n\nWhen the bottom of the projection screen is at the same height as your\nlearners\u2019 heads, people in the back won\u2019t be able to see the lower parts. You\ncan raise the bottom of your window to compensate, but this will give you even\nless space for typing.\n\nIf you can get a second projector and screen, use it: the extra real estate\nwill allow you to display your code on one side and its output or behavior on\nthe other. If second screen requires its own computer, ask a helper to control\nit rather than hopping back and forth between two keyboards.\n\nFinally, if you are teaching something like the Unix shell in a console\nwindow, it\u2019s important to tell people when you run an in-console text editor\nand when you return to the console prompt. Most novices have never seen a\nwindow take on multiple personalities in this way, and can quickly become\nconfused by when you are interacting with the shell, when you are typing in\nthe editor, and when you are dealing with an interactive prompt for Python or\nsome other language. You can avoid this problem by using a separate window for\nediting; if you do this, always tell learners when you are switching focus\nfrom one to the other.\n\n> #### Accessibility Aids Help Everyone\n>\n> Tools like Mousepos\u00e9 (for Mac) and PointerFocus (for Windows) highlight the\n> position of your mouse cursor on the screen, and screen recording tools like\n> Camtasia and standalone applications like KeyCastr echo invisible keys like\n> tab and Control-J as you type them. These can be a bit annoying when you\n> first start to use them, but help your learners figure out what you\u2019re\n> doing.\n\n### Double Devices\n\nSome people now use two devices when teaching: a laptop plugged into the\nprojector for learners to see and a tablet so that they can view their own\nnotes and the notes that the learners are taking (Section 9.7). This is more\nreliable than flipping back and forth between virtual desktops, though a\nprintout of the lesson is still the most reliable backup technology.\n\n### Draw Early, Draw Often\n\nDiagrams are always a good idea. I sometimes have a slide deck full of ones\nthat I have prepared in advance, but building diagrams step by step helps with\nretention (Section 4.1) and allows you to improvise.\n\n### Avoid Distractions\n\nTurn off any notifications you may use on your laptop, especially those from\nsocial media. Seeing messages flash by on the screen distracts you as well as\nyour learners, and it can be awkward when a message pops up you\u2019d rather not\nhave others see. Again, you might want to create a second account on your\ncomputer that doesn\u2019t have email or other tools set up at all.\n\n### Improvise\u2014After You Know the Material\n\nStick fairly closely to the lesson plan you\u2019ve drawn up or borrowed the first\ntime you teach a lesson. It may be tempting to deviate from the material\nbecause you would like to show a neat trick or demonstrate another way to do\nsomething, but there is a fair chance you\u2019ll run into something unexpected\nthat will cost you more time than you have.\n\nOnce you are more familiar with the material, though, you can and should start\nimprovising based on the backgrounds of your learners, their questions in\nclass, and what you personally find most interesting. This is like playing a\nnew song: you stick to the sheet music the first few times, but after you\u2019re\ncomfortable with the melody and chord changes, you can start to put your own\nstamp on it.\n\nWhen you want to use something new, run through it beforehand using the same\ncomputer that you\u2019ll be teaching on: installing several hundred megabytes of\nsoftware over high school WiFi in front of bored 16-year-olds isn\u2019t something\nyou ever want to have to do.\n\n> #### Direct Instruction\n>\n> Direct Instruction (DI) is a teaching method centered around meticulous\n> curriculum design delivered through a prescribed script. It\u2019s more like an\n> actor reciting lines than it is like the improvisational approach we\n> recommend. [Stoc2018] found a statistically significant positive effect for\n> DI even though it sometimes gets knocked for being mechanical. I prefer\n> improvisation because DI requires more up-front preparation than most free-\n> range learning groups can afford.\n\n### Face the Screen\u2014Occasionally\n\nIt\u2019s OK to face the projection screen occasionally when you are walking\nthrough a section of code or drawing a diagram: not looking at a roomful of\npeople who are all looking at you can help lower your anxiety levels and give\nyou a moment to think about what to say next.\n\nYou shouldn\u2019t do this for more than a few seconds at a time, though. A good\nrule of thumb is to treat the projection screen as one of your learners: if it\nwould be uncomfortable to stare at someone for as long as you are spending\nlooking at the screen, it\u2019s time to turn around and face your class again.\n\n### Drawbacks\n\nLive coding does have some drawbacks, but they can all be avoided or worked\naround with a little bit of practice. If you find that you are making too many\ntrivial typing mistakes, set aside five minutes every day to practice typing:\nit will help your day-to-day work as well. If you think you are spending too\nmuch time referring to your lesson notes, break them into smaller pieces so\nthat you only ever have to think about one small step at a time.\n\nAnd if you feel that you\u2019re spending too much time typing in library import\nstatements, class headers, and other boilerplate code, give yourself and your\nlearners some skeleton code as a starting point (Section 9.9). Doing this will\nalso reduce their cognitive load, since it will focus their attention where\nyou want it.\n\n## Lesson Study\n\nFrom politicians to researchers and teachers themselves, educational reformers\nhave designed systems to find and promote people who can teach well and\neliminate those who cannot. But the assumption that some people are born\nteachers is wrong: instead, like any other performance art, the keys to better\nteaching are practice and collaboration. As [Gree2014] explains, the Japanese\napproach to this is called jugyokenkyu, which means \u201clesson study\u201d:\n\n> In order to graduate, [Japanese] education majors not only had to watch\n> their assigned master teacher work, they had to effectively replace him,\n> installing themselves in his classroom first as observers and then, by the\n> third week, as a wobbly...approximation of the teacher himself. It worked\n> like a kind of teaching relay. Each trainee took a subject, planning five\n> days\u2019 worth of lessons... [and then] each took a day. To pass the baton, you\n> had to teach a day\u2019s lesson in every single subject: the one you planned and\n> the four you did not... and you had to do it right under your master\n> teacher\u2019s nose. Afterward, everyone\u2014the teacher, the college students, and\n> sometimes even another outside observer\u2014would sit around a formal table to\n> talk about what they saw.\n\nPutting work under a microscope in order to improve it is commonplace in\nfields as diverse as manufacturing and music. A professional musician, for\nexample, will dissect half a dozen recordings of \u201cBody and Soul\u201d or \u201cSmells\nLike Teen Spirit\u201d before performing it. They would also expect to get feedback\nfrom fellow musicians during practice and after performances.\n\nBut continuous feedback isn\u2019t part of teaching culture in most English-\nspeaking countries. There, what happens in the classroom stays in the\nclassroom: teachers don\u2019t watch each other\u2019s lessons on a regular basis, so\nthey can\u2019t borrow each other\u2019s good ideas. Teachers may get lesson plans and\nassignments from colleagues, the school board or a textbook publisher, or go\nthrough a few MOOCs on the internet, but each one has to figure out how to\ndeliver specific lessons in specific classrooms for specific learners. This is\nparticularly true for volunteers and other free-range teachers involved in\nafter-school workshops and bootcamps.\n\nWriting up new techniques and giving demonstration lessons (in which one\nperson teaches actual learners while other teachers observe) are not\nsolutions. For example, [Finc2007,Finc2012] found that of the 99 change\nstories analyzed, teachers only searched actively for new practices or\nmaterials in three cases, and only consulted published material in eight. Most\nchanges occurred locally, without input from outside sources, or involved only\npersonal interaction with other educators. [Bark2015] found something similar:\n\n> Adoption is not a \u201crational action\u201d...but an iterative series of decisions\n> made in a social context, relying on normative traditions, social cueing,\n> and emotional or intuitive processes... Faculty are not likely to use\n> educational research findings as the basis for adoption decisions...\n> Positive student feedback is taken as strong evidence by faculty that they\n> should continue a practice.\n\nJugyokenkyu works because it maximizes the opportunity for unplanned knowledge\ntransfer between teachers: someone sets out to demonstrate X, but while\nwatching them, their audience actually learns Y as well (or instead). For\nexample, a teacher might intend to show learners how to search for email\naddresses in a text file, but what their audience might take away is some new\nkeyboard shortcuts.\n\n## Giving and Getting Feedback on Teaching\n\nObserving someone helps you, and giving them feedback helps them, but it can\nbe hard to receive feedback, especially when it\u2019s negative (Figure 8.1).\n\nFeedback feelings (copyright \u00a9 Deathbulge 2013)\n\nFeedback is easier to give and receive when both parties share expectations\nabout what is and isn\u2019t in scope and about how comments ought to be phrased.\nIf you are the person asking for feedback:\n\nInitiate feedback.\n\n    \n\nIt\u2019s better to ask for feedback than to receive it unwillingly.\n\nChoose your own questions,\n\n    \n\ni.e. ask for specific feedback. It\u2019s a lot harder for someone to answer, \u201cWhat\ndo you think?\u201d than to answer either, \u201cWas I speaking too quickly?\u201d or , \u201cWhat\nis one thing from this lesson I should keep doing?\u201d Directing feedback like\nthis is also more helpful to you. It\u2019s always better to try to fix one thing\nat once than to change everything and hope it\u2019s for the better. Directing\nfeedback at something you have chosen to work on helps you stay focused, which\nin turn increases the odds that you\u2019ll see progress.\n\nUse a feedback translator.\n\n    \n\nHave someone else read over all the feedback and give you a summary. It can be\neasier to hear, \u201cSeveral people think you could speed up a little,\u201d than to\nread several notes all saying, \u201cThis is too slow\u201d or, \u201cThis is boring.\u201d\n\nBe kind to yourself.\n\n    \n\nMany of us are very critical of ourselves, so it\u2019s always helpful to jot down\nwhat we thought of ourselves before getting feedback from others. That allows\nus to compare what we think of our performance with what others think, which\nin turn allows us to scale the former more accurately. For example, it\u2019s very\ncommon for people to think that they\u2019re saying \u201cum\u201d and \u201cerr\u201d too often when\ntheir audience doesn\u2019t notice it. Getting that feedback once allows teachers\nto adjust their assessment of themselves the next time they feel that way.\n\nYou can give feedback to others more effectively as well:\n\nInteract.\n\n    \n\nStaring at someone is a good way to make them feel uncomfortable, so if you\nwant to give feedback on how someone normally teaches, you need to set them at\nease. Interacting with them the way that a real learner would is a good way to\ndo this, so ask questions or (pretend to) type along with their example. If\nyou are part of a group, have one or two people play the role of learner while\nthe others take notes.\n\nBalance positive and negative feedback.\n\n    \n\nThe \u201ccompliment sandwich\u201d made up of one positive comment, one negative, and a\nsecond positive becomes tiresome pretty quickly, but it\u2019s important to tell\npeople what they should keep doing as well as what they should change^7.\n\nTake notes.\n\n    \n\nYou won\u2019t remember everything you noticed if the presentation lasts longer\nthan a few seconds, and you definitely won\u2019t recall how often you noticed\nthem. Make a note the first time something happens and then add a tick mark\nwhen it happens again so that you can sort your feedback by frequency.\n\nTaking notes is more efficient when you have some kind of rubric so that\nyou\u2019re not scrambling to write your observations while the person you\u2019re\nobserving is still talking. The simplest rubric for free-form comments from a\ngroup is a 2x2 grid whose vertical axis is labeled \u201cwhat went well\u201d and \u201cwhat\ncan be improved\u201d, and whose horizontal axis is labeled \u201ccontent\u201d (what was\nsaid) and \u201cpresentation\u201d (how it was said). Observers write their comments on\nsticky notes as they watch the demonstration, then post those in the quadrants\nof a grid drawn on a whiteboard (Figure 8.2).\n\nTeaching rubric\n\n> #### Rubrics and Question Budgets\n>\n> Section 21.1 contains a sample rubric for assessing 5\u201310 minutes of\n> programming instruction. It presents items in more or less the order that\n> they\u2019re likely to come up, e.g. questions about the introduction come before\n> questions about the conclusion.\n>\n> Rubrics like this one tend to grow over time as people think of things\n> they\u2019d like to add. A good way to keep them manageable is to insist that the\n> total length stays constant: if someone wants to add a question, they have\n> to identify one that\u2019s less important and can be removed.\n\nIf you are interested in giving and getting feedback, [Gorm2014] has good\nadvice that you can use to make peer-to-peer feedback a routine part of your\nteaching, while [Gawa2011] looks at the value of having a coach.\n\n> #### Studio Classes\n>\n> Architecture schools often include studio classes in which students solve\n> small design problems and get feedback from their peers right then and\n> there. These classes are most effective when the teacher critiques the peer\n> critiques so that participants learn not only how to make buildings but how\n> to give and get feedback [Scho1984]. Master classes in music serve a similar\n> purpose, and I have found that giving feedback on feedback helps people\n> improve their teaching as well.\n\n## How to Practice Performance\n\nThe best way to improve your in-person lesson delivery is to watch yourself do\nit:\n\n  * Work in groups of three.\n\n  * Each person rotates through the roles of teacher, audience, and videographer. The teacher has 2 minutes to explain something. The person pretending to be the audience is there to be attentive, while the videographer records the session using a cellphone or other handheld device.\n\n  * After everyone has finished teaching, the whole group watches the videos together. Everyone gives feedback on all three videos, i.e. people give feedback on themselves as well as on others.\n\n  * After the videos have been discussed, they are deleted. (Many people are justifiably uncomfortable about images of themselves appearing online.)\n\n  * Finally, the whole class reconvenes and adds all the feedback to a shared 2x2 grid of the kind described above without saying who each item of feedback is about.\n\nIn order for this exercise to work well:\n\n  * Record all three videos and then watch all three. If the cycle is teach-review-teach-review, the last person to teach invariably runs short of time (sometimes on purpose). Doing all the reviewing after all the teaching also helps put a bit of distance between the two, which makes the exercise slightly less excruciating.\n\n  * Let people know at the start of the class that they will be asked to teach something so that they have time to choose a topic. Telling them this too far in advance can be counter-productive, since some people will fret over how much they should prepare.\n\n  * Groups must be physically separated to reduce audio cross-talk between their recordings. In practice, this means 2\u20133 groups in a normal-sized classroom, with the rest using nearby breakout spaces, coffee lounges, offices, or (on one occasion) a janitor\u2019s storage closet.\n\n  * People must give feedback on themselves as well as on each other so that they can calibrate their impressions of their own teaching against those of other people. Most people are harder on themselves than they ought to be, and it\u2019s important for them to realize this.\n\nThe announcement of this exercise is often greeted with groans and\napprehension, since few people enjoy seeing or hearing themselves. However,\nthose same people consistently rate it as one of the most valuable parts of\nteaching workshops. It\u2019s also good preparation for co-teaching (Section 9.3):\nteachers find it a lot easier to give each other informal feedback if they\nhave had some practice doing so and have a shared rubric to set expectations.\n\nAnd speaking of rubrics: once the class has put all of their feedback on a\nshared grid, pick a handful of positive and negative comments, write them up\nas a checklist, and have them do the exercise again. Most people are more\ncomfortable the second time around, and being assessed on the things that they\nthemselves have decided are important increases their sense of self-\ndetermination (Chapter 10).\n\n> #### Tells\n>\n> We all have nervous habits: we talk more rapidly and in a higher-pitched\n> voice than usual when we\u2019re on stage, play with our hair, or crack our\n> knuckles. Gamblers call these \u201ctells,\u201d and people often don\u2019t realize that\n> they pace, look at their shoes, or rattle the change in their pocket when\n> they don\u2019t actually know the answer to a question.\n>\n> You can\u2019t get rid of tells completely, and trying to do so can make you\n> obsess about them. A better strategy is to try to displace them\u2014for example,\n> to train yourself to scrunch your toes inside your shoes when you\u2019re nervous\n> instead of cleaning your ear with your pinky finger.\n\n## Exercises\n\n### Give Feedback on Bad Teaching (whole class/20)\n\nAs a group, watch this video of bad teaching and give feedback on two axes:\npositive vs. negative and content vs. presentation. Have each person in the\nclass add one point to a 2x2 grid on a whiteboard or in the shared notes\nwithout duplicating any points. What did other people see that you missed?\nWhat did they think that you strongly agree or disagree with?\n\n### Practice Giving Feedback (small groups/45)\n\nUse the process described in Section 8.4 to practice teaching in groups of\nthree and pool feedback.\n\n### The Bad and the Good (whole class/20)\n\nWatch the videos of live coding done poorly and live coding done well and\nsummarize your feedback on the differences using the usual 2x2 grid. How is\nthe second round of teaching better than the first? Is there anything that was\nbetter in the first than in the second?\n\n### See, Then Do (pairs/30)\n\nTeach 3\u20134 minutes of a lesson using live coding to a classmate, then swap and\nwatch while that person live codes for you. Don\u2019t bother trying to record\nthese sessions\u2014it\u2019s difficult to capture both the person and the screen with a\nhandheld device\u2014but give feedback the same way you have previously. Explain in\nadvance to your fellow trainee what you will be teaching and what the learners\nyou teach it to are expected to be familiar with.\n\n  * What felt different about live coding compared to standing up and lecturing? What was easier or harder?\n\n  * Did you make any mistakes? If so, how did you handle them?\n\n  * Did you talk and type at the same time, or alternate?\n\n  * How often did you point at the screen? How often did you highlight with the mouse?\n\n  * What will you try to keep doing next time? What will you try to do differently?\n\n### Tells (small groups/15)\n\n  1. Make a note of what you think your tells are, but do not share them with other people.\n\n  2. Teach a short lesson (2\u20133 minutes long).\n\n  3. Ask your audience how they think you betray nervousness. Is their list the same as yours?\n\n### Teaching Tips (small groups/15)\n\nThe CS Teaching Tips site has a large number of practical tips on teaching\ncomputing, as well as a collection of downloadable tip sheets. Go through\ntheir tip sheets in small groups and classify each tip according to whether\nyou use it all the time, use it occasionally, or never use it. Where do your\npractice and your peers\u2019 practice differ? Are there any tips you strongly\ndisagree with or think would be ineffective?\n\n## Review\n\nConcepts: Feedback\n\n# In the Classroom\n\nThe previous chapter described how to practice lesson delivery and described\none method\u2014live coding\u2014that allows teachers to adapt to their learners\u2019 pace\nand interests. This chapter describes other practices that are also useful in\nprogramming classes.\n\nBefore describing them, it\u2019s worth pausing for a moment to set expectations.\nThe best teaching method we know is individual tutoring: [Bloo1984] found that\nstudents taught one-to-one did two standard deviations better than those who\nlearned through conventional lecture, i.e. that individually tutored students\noutperformed 98% of students who were lectured to. However, while mentoring\nand apprenticeship were the most common ways to pass on knowledge throughout\nmost of history, the industrialization of formal education has made it the\nexception today. Despite the hype around artificial intelligence, it isn\u2019t\ngoing to square this circle any time soon, so every method described below is\nessentially an attempt to approach the effectiveness of individual tutoring at\nscale.\n\n## Enforce the Code of Conduct\n\nThe most important thing I\u2019ve learned about teaching in the last 30 years is\nhow important it is for everyone to treat everyone else with respect, both in\nand out of class. If you use this material in any way, please adopt a Code of\nConduct like the one in Appendix 17 and require everyone who takes part in\nyour classes to abide by it. It can\u2019t stop people from being offensive, any\nmore than laws against theft stop people from stealing, but it can make\nexpectations and consequences clear, and signal that you are trying to make\nyour class welcoming to all.\n\nBut a Code of Conduct is only useful if it is enforced. If you believe that\nsomeone has violated yours, you may warn them, ask them to apologize, and/or\nexpel them, depending on the severity of the violation and whether or not you\nbelieve it was intentional. Whatever you do:\n\nDo it in front of witnesses.\n\n    \n\nMost people will tone down their language and hostility in front of an\naudience, and having someone else present ensures that later discussion\ndoesn\u2019t degenerate into conflicting claims about who said what.\n\nIf you expel someone, say so to the rest of the class and explain why.\n\n    \n\nThis helps prevent rumors from spreading and shows that your Code of Conduct\nactually means something.\n\nEmail the offender as soon as you can\n\n    \n\nto summarize what happened and the steps you took, and copy the message to\nyour workshop\u2019s hosts or one of your fellow teachers so that there\u2019s a\ncontemporaneous record of the conversation. If the offender replies, don\u2019t\nengage in a long debate: it\u2019s never productive.\n\nWhat happens outside of class matters at least as much as what happens within\nit [Part2011], so you need to provide a way for learners to report problems\nthat you aren\u2019t there to see yourself. One step is to ask someone who isn\u2019t\npart of your group to be the first point of contact; that way, if someone\nwants to make a complaint about you or one of your fellow teachers, they have\nsome assurance of confidentiality and independent action. [Auro2019] has lots\nof other advice and is both short and practical.\n\n## Peer Instruction\n\nNo matter how good a teacher is, they can only say one thing at a time. How\nthen can they clear up many different misconceptions in a reasonable time? The\nbest solution developed so far is a technique called peer instruction.\nOriginally created by Eric Mazur at Harvard [Mazu1996], it has been studied\nextensively in a wide variety of contexts, including programming\n[Crou2001,Port2013], and [Port2016] found that learners value peer instruction\neven at first contact.\n\nPeer instruction attempts to provide one-to-one instruction in a scalable way\nby interleaving formative assessment with learner discussion:\n\n  1. Give a brief introduction to the topic.\n\n  2. Give learners a multiple choice question that probes for their misconceptions (rather than testing simple factual knowledge).\n\n  3. Have all the learners vote on their answers to the MCQ.\n\n     * If the learners all have the right answer, move on.\n\n     * If they all have the same wrong answer, address that specific misconception.\n\n     * If they have a mix of right and wrong answers, give them several minutes to argue with each other in groups of 2\u20134, then vote again.\n\nAs this video shows, group discussion significantly improves learners\u2019\nunderstanding because it uncovers gaps in their reasoning and forces them to\nclarify their thinking. Re-polling the class then lets the teacher know if\nthey can move on or if further explanation is necessary. A final round of\nadditional explanation after the correct answer is presented gives learners\none more chance to solidify their understanding.\n\nBut could this be a false positive? Are results improving because of increased\nunderstanding during discussion or simply from a follow-the-leader effect\n(\u201cvote like Jane, she\u2019s always right\u201d)? [Smit2009] tested this by following\nthe first question with a second one that learners answered individually. They\nfound that peer discussion actually does enhance understanding, even when none\nof the learners in a discussion group originally knew the correct answer. As\nlong as there is a diversity of opinion within the group, their misconceptions\ncancel out.\n\n> #### Taking a Stand\n>\n> It is important to have learners vote publicly so that they can\u2019t change\n> their minds afterward and rationalize it by making excuses to themselves\n> like \u201cI just misread the question.\u201d Much of the value of peer instruction\n> comes from the hypercorrection of getting the wrong answer and having to\n> think through the reasons why (Section 5.1).\n\n## Teach Together\n\nCo-teaching describes any situation in which two teachers work together in the\nsame classroom. [Frie2016] describes several ways to do this:\n\nTeam teaching:\n\n    \n\nBoth teachers deliver a single stream of content in tandem, taking turns like\nmusicians taking solos.\n\nTeach and assist:\n\n    \n\nTeacher A teaches while Teacher B moves around the classroom to help\nstruggling learners.\n\nAlternative teaching:\n\n    \n\nTeacher A provides a small set of learners with more intensive or specialized\ninstruction while Teacher B delivers a general lesson to the main group.\n\nTeach and observe:\n\n    \n\nTeacher A teaches while Teacher B observes the learners, collecting data on\ntheir understanding to help plan future lessons.\n\nParallel teaching:\n\n    \n\nThe class is divided in two and the teachers present the same material\nsimultaneously to each.\n\nStation teaching:\n\n    \n\nThe learners are divided into small groups that rotate from one station or\nactivity to the next while teachers supervise where needed.\n\nAll of these models create more opportunities for unintended knowledge\ntransfer than teaching alone. Team teaching is particularly beneficial in day-\nlong workshops: it gives each teacher\u2019s voice a chance to rest and reduces the\nrisk that they will be so tired by the end of the day that they will start\nsnapping at their learners or fumbling at their keyboard.\n\n> #### Helping\n>\n> Many people who aren\u2019t comfortable teaching are willing and able to provide\n> in-class technical support. They can help learners with setup and\n> installation, answer technical questions during exercises, monitor the room\n> to spot people who may need help, or keep an eye on the shared notes\n> (Section 9.7), and either answer questions or remind the teacher to do so\n> during breaks.\n>\n> Helpers are sometimes people training to become teachers (i.e. they\u2019re\n> Teacher B in the teach and assist model), but they can also be members of\n> the host institution\u2019s technical support staff, alumni of the class, or\n> advanced learners who already know the material well. Using the latter as\n> helpers is doubly effective: not only are they more likely to understand the\n> problems their peers are having, it also stops them from getting bored. This\n> helps the whole class stay engaged because boredom is infectious: if a\n> handful of people start checking out, the people around them will follow\n> suit.\n\nIf you and a partner are co-teaching:\n\n  * Take 2\u20133 minutes before the start of each class to confirm who\u2019s teaching what. If you have time, try drawing or reviewing a concept map together.\n\n  * Use that time to work out a couple of hand signals as well. \u201cYou\u2019re going too fast,\u201d \u201cspeak up,\u201d \u201cthat learner needs help,\u201d and, \u201cIt\u2019s time for a bathroom break\u201d are all useful.\n\n  * Each person should teach for at least 10\u201315 minutes at a stretch, since learners will be distracted by more frequent switch-ups.\n\n  * The person who isn\u2019t teaching shouldn\u2019t interrupt, offer corrections or elaborations, or do anything else to distract from what the person teaching is doing or saying. The one exception is to ask leading questions if the learners seem lethargic or unsure of themselves.\n\n  * Each person should take a couple of minutes before they start teaching to see what their partner is going to teach after they\u2019re done, and then not present any of that material.\n\n  * The person who isn\u2019t teaching should stay engaged with the class, not catch up on their email. Monitoring the shared notes (Section 9.7), keeping an eye on the learners to see who\u2019s struggling, jotting down some feedback to give your teaching partner at the next break\u2014anything that contributes to the lesson is better than anything that doesn\u2019t.\n\nMost importantly, take a few minutes when the class is over to congratulate or\ncommiserate with each other: in teaching as in life, shared misery is lessened\nand shared joy increased.\n\n## Assess Prior Knowledge\n\nThe more you know about your learners before you start teaching, the more you\nwill be able to help them. Inside a formal school system, the prerequisites to\nyour course will tell you something about what they\u2019re likely to already know.\nIn a free-range setting, though, your learners may be much more diverse, so\nyou may want to give them a short survey or questionnaire in advance of your\nclass to find out what knowledge and skills they have.\n\nAsking people to rate themselves on a scale from 1 to 5 is pointless because\nthe less people know about a subject, the less accurately they can estimate\ntheir knowledge (Figure 9.1, from\nhttps://theness.com/neurologicablog/index.php/misunderstanding-dunning-\nkruger/), a phenomenon called the Dunning-Kruger effect [Krug1999].\nConversely, people who are members of underrepresented groups will often\nunderrate their skills.\n\nThe Dunning-Kruger Effect\n\nRather than asking people to self-assess, you can ask them how easily they\ncould complete some specific tasks. Doing this is risky, though, because\nschool trains people to treat anything that looks like an exam as something\nthey have to pass rather than as a chance to shape instruction. If someone\nanswers \u201cI don\u2019t know\u201d to even a couple of questions on your pre-assessment,\nthey might conclude that your class is too advanced for them. You could\ntherefore scare off many of the people you most want to help.\n\nSection 21.5 presents a short pre-assessment questionnaire that most potential\nlearners are unlikely to find intimidating. If you use it or anything like it,\ntry to follow up with people who don\u2019t respond to find out why not and compare\nyour evaluation of learners with their self-assessment to improve your\nquestions.\n\n## Plan for Mixed Abilities\n\nIf your learners have widely varying levels of prior knowledge, you can easily\nwind up in a situation where a third of your class is lost and a third is\nbored. That\u2019s unsatisfying for everyone, but there are some strategies you can\nuse to manage the situation:\n\n  * Before running a workshop, communicate its level clearly to everyone by showing a few examples of exercises that they will be asked to complete. This helps potential participants gauge the level of the class far more effectively than a point-form list of topics.\n\n  * Provide extra self-paced exercises so that more advanced learners don\u2019t finish early and get bored.\n\n  * Keep an eye out for learners who are falling behind and intervene early so that they don\u2019t become frustrated and give up.\n\n  * Ask more advanced learners to help people next to them (see Section 9.6 below).\n\nOne other way to accommodate mixed abilities is to have everyone work through\nmaterial on their own at their own pace as they would in an online course, but\nto do it simultaneously and side by side with helpers roaming the room to get\npeople unstuck. Some people will go three or four times further than others\nwhen workshops are run like this, but everyone will have had a rewarding and\nchallenging day.\n\n> #### False Beginners\n>\n> A false beginner is someone who has studied a language before but is\n> learning it again. They may be indistinguishable from absolute beginners on\n> pre-assessment tests, but they are able to move much more quickly once the\n> class starts because they are re-learning rather than learning for the first\n> time.\n>\n> Being a false beginner is often a sign of preparatory privilege [Marg2010],\n> and false beginners are common in free-range programming classes. For\n> example, a child whose family is affluent enough to have sent them to a\n> robotics summer camp may do poorly on a pre-test of programming knowledge\n> because the material isn\u2019t fresh in their mind, but still has an advantage\n> over a child from a less fortunate background. The strategies described\n> above can help level the playing field in cases like this, but again, the\n> real solution is to use your own privilege to address larger out-of-class\n> factors [Part2011].\n\nThe most important thing is to accept that you can\u2019t help everyone all of the\ntime. If you slow down to accommodate two people who are struggling, you are\nfailing the other eighteen. Equally, if you spend a few minutes talking about\nan advanced topic to a learner who is bored, the rest of the class will feel\nleft out.\n\n## Pair Programming\n\nPair programming is a software development practice in which two programmers\nwork together on one computer. One person (the driver) does the typing while\nthe other (the navigator) offers comments and suggestions, and the two switch\nroles several times per hour.\n\nPair programming is an effective practice in professional work [Hann2009] and\nis also a good way to teach: benefits include increased success rate in\nintroductory courses, better software, and higher learner confidence in their\nsolutions. There is also evidence that learners from underrepresented groups\nbenefit even more than others [McDo2006,Hank2011,Port2013,Cele2018]. Partners\ncan help each other out during practical exercises, clarify each other\u2019s\nmisconceptions when the solution is presented, and discuss common interests\nduring breaks. I have found it particularly helpful with mixed-ability\nclasses, since pairs are more homogeneous than individuals.\n\nWhen you use pairing, put everyone in pairs, not just learners who are\nstruggling, so that no one feels singled out. It\u2019s also useful to have people\nsit in new places (and hence pair with different partners) on a regular basis,\nand to have people switch roles within each pair three or four times per hour\nso that the stronger personality in each pair doesn\u2019t dominate the session.\n\nIf your learners are new to pair programming, take a few minutes to\ndemonstrate what it actually looks like so that they understand that the\nperson who doesn\u2019t have their hands on the keyboard isn\u2019t supposed to just sit\nand watch. Finally, tell them that people who focus on trying to complete the\ntask as quickly as possible are less fair in their sharing [Lewi2015].\n\n> #### Switching Partners\n>\n> Teachers have mixed opinions on whether people should be required to change\n> partners at regular intervals. On the one hand it gives everyone a chance to\n> gain new insights and make new friends. On the other, moving computers and\n> power adapters to new desks several times a day is disruptive, and pairing\n> can be uncomfortable for introverts. That said, [Hann2010] found weak\n> correlation between the \u201cBig Five\u201d personality traits and performance in\n> pair programming, although an earlier study [Wall2009] found that pairs\n> whose members had differing levels of personality traits communicated more\n> often.\n\n## Take Notes...Together?\n\nNote-taking is a form of real-time elaboration (Section 5.1): it forces you to\norganize and reflect on material as it\u2019s coming in, which in turn increases\nthe likelihood that you will transfer it to long-term memory. Many studies\nhave shown that taking notes while learning improves retention\n[Aike1975,Boha2011]. While it has not yet been widely studied\n[Ornd2015,Yang2015], I have found that having learners take notes together in\na shared online page is also effective:\n\n  * It allows people to compare what they think they\u2019re hearing with what other people are hearing, which helps them fill in gaps and correct misconceptions right away.\n\n  * It gives the more advanced learners in the class something useful to do. Rather than getting bored and checking Instagram during class, they can take the lead in recording what\u2019s being said, which keeps them engaged and allows less advanced learners to focus more of their attention on new material.\n\n  * The notes the learners take are usually more helpful to them than those the teacher would prepare in advance, since the learners are more likely to write down what they actually found new rather than what the teacher predicted would be new.\n\n  * Glancing at recent notes while learners are working on an exercise helps the teacher discover that the class missed or misunderstood something.\n\n> #### Is the Pen Mightier than the Keyboard?\n>\n> [Muel2014] reported that taking notes on a computer is generally less\n> effective than taking notes using pen and paper. While their result was\n> widely shared, [More2019] was unable to replicate it.\n\nIf learners are taking notes together, you can also have them paste in short\nsnippets of code and point-form or sentence-length answers to formative\nassessment questions. To prevent everyone from trying to edit the same couple\nof lines at the same time, make a list of everyone\u2019s name and paste it into\nthe document whenever you want each person to answer a question.\n\nLearners often find that taking notes together is distracting the first time\nthey try it because they have to split their attention between what the\nteacher is saying and what their peers are writing (Section 4.1). If you are\nonly working with a particular group once, you should therefore heed the\nadvice in Section 9.12 and have them take notes individually.\n\n> #### Points for Improvement\n>\n> One way to demonstrate to learners that they are learning with you, not just\n> from you, is to allow them to take notes by editing (a copy of) your lesson.\n> Instead of posting PDFs for them to download, create editable copies of your\n> slides, notes, and exercises in a wiki, a Google Doc, or anything else that\n> allows you to review and comment on changes. Giving people credit for fixing\n> mistakes, clarifying explanations, adding new examples, and writing new\n> exercises doesn\u2019t reduce your workload, but increases engagement and the\n> lesson\u2019s lifetime (Section 6.3).\n\n## Sticky Notes\n\nSticky notes are one of my favorite teaching tools, and I\u2019m not alone in\nloving their versatility, portability, stickability, foldability, and subtle\nyet alluring aroma [Ward2015].\n\n### As Status Flags\n\nGive each learner two sticky notes of different colors, such as orange and\ngreen. These can be held up for voting, but their real use is as status flags.\nIf someone has completed an exercise and wants it checked, they put the green\nsticky note on their laptop; if they run into a problem and need help, they\nput up the orange one. This works much better than having people raise their\nhands: it\u2019s more discreet (which means they\u2019re more likely to actually do it),\nthey can keep working while their flag is raised rather than trying to type\none-handed, and the teacher can quickly see from the front of the room what\nstate the class is in. Status flags are particularly helpful when people in\nmixed-ability classes are working through material at their own speed (Section\n9.5).\n\nOnce your learners are comfortable with two stickies, give them a third that\nthey can put up when their brains are full or they need a bathroom break^8.\nAgain, adults are more likely to post a sticky than to raise their hand, and\nonce one blue sticky note goes up, a flurry of others usually follows.\n\n### To Distribute Attention\n\nSticky notes can also be used to ensure the teacher\u2019s attention is fairly\ndistributed. Have each learner write their name on a sticky note and put it on\ntheir laptop. Each time the teacher calls on them or answers one of their\nquestions, they take their sticky note down. Once all the sticky notes are\ndown, everyone puts theirs up again.\n\nThis technique makes it easy for the teacher to see who they haven\u2019t spoken\nwith recently, which in turn helps them avoid unconscious bias and interacting\npreferentially with their most extroverted learners. Without a check like\nthis, it\u2019s all too easy to create a feedback loop in which extroverts get more\nattention, which leads to them doing better, which in turn leads to them\ngetting more attention, while quieter, less confident, or marginalized\nlearners are left behind [Alvi1999,Juss2005].\n\nIt also shows learners that attention is being distributed fairly so that when\nthey are called on, they won\u2019t feel like they\u2019re being picked on. When I am\nworking with a new group, I allow people to take down their own sticky notes\nduring the first hour or two of class if they would rather not be called on.\nIf they keep doing this as time goes on, I try to have a quiet conversation\nwith them to find out why and to see if there\u2019s anything I can do to make them\nmore comfortable.\n\n### As Minute Cards\n\nYou can also use sticky notes as minute cards. Before each break, learners\ntake a minute to write one thing on the green sticky note that they think will\nbe useful and one thing on the orange note that they found too fast, too slow,\nconfusing, or irrelevant. While they are enjoying their coffee or lunch,\nreview their notes and look for patterns. It takes less than five minutes to\nsee what learners in a 40-person class are enjoying, what they are confused\nby, what problems they\u2019re having, and what questions you have not yet\nanswered.\n\nLearners should not sign their minute cards: they are meant as anonymous\nfeedback. The one-up/one-down technique described in Section 9.11 is a chance\nfor collective, attributable feedback.\n\n## Never a Blank Page\n\nProgramming workshops and other kinds of classes can be built around a set of\nindependent exercises, develop a single extended example in stages, or use a\nmixed strategy. The two main advantages of independent exercises are that\npeople who fall behind can easily re-synchronize and that lesson developers\ncan add, remove, and rearrange material at will (Section 6.3). A single\nextended example, on the other hand, will show learners how the bits and\npieces they\u2019re learning fit together: in educational parlance, it provides\nmore opportunity for them to integrate their knowledge.\n\nWhichever approach you take, novices should never start doing exercises with a\nblank page or screen, since they often find this intimidating or bewildering.\nIf they have been following along as you do live coding, ask them to add a few\nmore lines or to modify the example you have built up. Alternatively, if they\nare taking notes together, paste a few lines of starter code into the document\nfor them to extend or modify.\n\nModifying existing code instead of writing new code from scratch doesn\u2019t just\ngive learners structure: it is also closer to what they will do in real life.\nKeep in mind, though, that learners may be distracted by trying to understand\nall of the starter code rather than doing their own work. Java\u2019s public static\nvoid main() or a handful of import statements at the top of a Python program\nmay make sense to you, but is extraneous load to them (Chapter 4).\n\n## Setting Up Your Learners\n\nFree-range learners often want bring their own computers and to leave the\nclass with those machines set up to do real work. Free-range teachers should\ntherefore prepare to teach on both Windows and MacOS^9, even though it would\nbe simpler to require learners to use just one.\n\n> #### Common Denominators\n>\n> If your participants are using different operating systems, try to avoid\n> using features which are specific to just one and point out any that you do\n> use. For example, the \u201cminimize window\u201d controls and behavior on Windows are\n> different from those on MacOS.\n\nNo matter how many platforms you have to deal with, put detailed setup\ninstructions on your course website and email learners a couple of days before\nthe workshop starts to remind them to do the setup. A few people will still\nshow up without the required software because they ran into problems, couldn\u2019t\nfind time to complete all the steps, or are simply the sort of person who\nnever follows instructions in advance. To detect this, have everyone run some\nsimple command as soon as they arrive and show the teachers the result, then\nget helpers and other learners to assist people who have run into trouble.\n\n> #### Virtual Machines\n>\n> Some people use tools like Docker to put virtual machines on learners\u2019\n> computers so that everyone is working with exactly the same tools, but this\n> introduces a new set of problems. Older or smaller machines simply aren\u2019t\n> fast enough to run them, learners struggle to switch back and forth between\n> two different sets of keyboard shortcuts for things like copying and\n> pasting, and even competent practitioners will become confused about what\n> exactly is happening where.\n\nSetting up is so complicated that many teachers prefer to have learners use\nbrowser-based tools instead. However, this makes the class dependent on\ninstitutional WiFi (which can be of highly variable quality) and doesn\u2019t\nsatisfy learners\u2019 desire to leave with their own machines ready for real-world\nuse. As cloud-based tools like Glitch and RStudio Cloud become more robust,\nthough, the latter consideration is becoming less important.\n\nOne last way to tackle setup issues is to split the class over several days,\nand to have people install what\u2019s required for each day before leaving class\non the day before. Dividing the work into chunks makes each one less\nintimidating, learners are more likely to actually do it, and it ensures that\nyou can start on time for every lesson except the first.\n\n## Other Teaching Practices\n\nNone of the smaller practices described below are essential, but all will\nimprove lesson delivery. As with chess and marriage, success in teaching is\noften a matter of slow, steady progress.\n\n### Start With Introductions\n\nBegin your class by introducing yourself. If you\u2019re an expert, tell them a bit\nabout how you got to where you are; if you\u2019re only two steps ahead of them,\nemphasize what you and they have in common. Whatever you say, your goals are\nto make yourself more approachable and to encourage their belief that they can\nsucceed.\n\nLearners should also introduce themselves to each other. In a class of a\ndozen, they can do this verbally; in a larger class or if they are strangers\nto one another, I find it\u2019s better to have them each write a line or two about\nthemselves in the shared notes (Section 9.7).\n\n### Set Up Your Own Environment\n\nSetting up your environment is just as important as setting up your learners\u2019,\nbut more involved. As well as having network access and all the software\nyou\u2019re going to use, you should also have a glass of water or a cup of tea or\ncoffee. This helps keep your throat lubricated, but its real purpose is to\ngive you an excuse to pause and think for a couple of seconds when someone\nasks a hard question or when you lose track of what you were going to say\nnext. You will probably also want some whiteboard pens and a few of the other\nthings described in Section 21.3.\n\nOne way to keep your day-to-day work from getting in the way of your teaching\nis to create a separate account on your computer for the latter. Use system\ndefaults for everything in this second account, along with a larger font and a\nblank screen background, and turn off notifications so that your teaching\nisn\u2019t interrupted by pop-ups.\n\n### Avoid Homework in All-Day Formats\n\nLearners who have spent an entire day programming will be tired. If you give\nthem homework to do after hours, they\u2019ll start the next day tired as well, so\ndon\u2019t.\n\n### Don\u2019t Touch the Learner\u2019s Keyboard\n\nIt\u2019s often tempting to fix things for learners, but even if you narrate every\nstep, it\u2019s likely to demotivate them by emphasizing the gap between their\nknowledge and yours. Instead, keep your hands off the keyboard and talk your\nlearners through whatever they need to do: it will take longer, but it\u2019s more\nlikely to stick.\n\n### Repeat the Question\n\nWhenever someone asks a question in class, repeat it back to them before\nanswering to check that you\u2019ve understood it and to give people who might not\nhave heard it a chance to do so. This is particularly important when\npresentations are being recorded or broadcast, since your microphone will\nusually not pick up what other people are saying. Repeating questions back\nalso gives you a chance to redirect the question to something you\u2019re more\ncomfortable answering...\n\n### One Up, One Down\n\nAn adjunct to minute cards is to ask for summary feedback at the end of each\nday. Learners alternately give either one positive or one negative point about\nthe day without repeating anything that has already been said. The ban on\nrepeats forces people to say things they otherwise might not: once all the\n\u201csafe\u201d feedback has been given, participants will start saying what they\nreally think.\n\n> #### Different Modes, Different Answers\n>\n> Minute cards (Section 9.8) are anonymous; the alternating up-and-down\n> feedback is not. You should use the two together because anonymity allows\n> both honesty and trolling.\n\n### Have Learners Make Predictions\n\nResearch has shown that people learn more from demonstrations if they are\nasked to predict what\u2019s going to happen [Mill2013]. Doing this fits naturally\ninto live coding: after adding or changing a few lines of a program, ask the\nclass what is going to happen when it runs. If the example is even moderately\ncomplex, prediction can serve as a motivating question for a round of peer\ninstruction.\n\n### Setting Up Tables\n\nYou may not have any control over the layout of the desks or tables in the\nroom in which you teach, but if you do, we find it\u2019s best to have flat\n(dinner-style) seating rather than banked (theater-style) seating so that you\ncan reach learners who need help more easily and so that it\u2019s easier for\nlearners to pair with one another (Section 9.5). In-floor power outlets so\nthat you don\u2019t have to run power cords across the floor make life easier as\nwell as safer, but are still uncommon.\n\nWhatever layout you have, try to make sure that every seat has an unobstructed\nview of the screen. Good back support is important too, since people are going\nto be in them for an extended period. Like in-floor power outlets, good\nclassroom seating is still unfortunately uncommon.\n\n### Cough Drops\n\nIf you talk all day to a room full of people, your throat gets raw because you\nare irritating the epithelial cells in your larynx and pharynx. This doesn\u2019t\njust make you hoarse\u2014it also makes you more vulnerable to infection (which is\npart of the reason people often come down with colds after teaching).\n\nThe best way to protect yourself against this is to keep your throat lined,\nand the best way to do that is to use cough drops early and often. Good ones\nwill also mask the onset of coffee breath, for which your learners will\nprobably be grateful.\n\n### Think-Pair-Share\n\nThink-pair-share is a lightweight technique that helps people improve ideas\nthrough discussion with their peers. Each person starts by thinking\nindividually about a question or problem and jotting down a few notes. They\nthen explain their ideas to each another in pairs, merging them or selecting\nthe most promising. Finally, a few pairs present their ideas to the whole\ngroup.\n\nThink-pair-share works because it forces people to externalize their cognition\n(Section 3.1). It also gives them a chance to spot and resolve gaps or\ncontradictions in their ideas before exposing them to a larger group, which\ncan make less extroverted learners a little less nervous about appearing\nfoolish.\n\n### Morning, Noon, and Night\n\n[Smar2018] found that learners do less well if their classes and other work\nare scheduled at times that don\u2019t line up with their natural body clocks, i.e.\nthat if a morning person takes night classes or vice versa, their grades\nsuffer. It\u2019s usually not possible to accommodate this in small groups, but\nlarger ones should try to stagger start times for parallel sessions. This can\nalso help people juggling childcare responsibilities and other constraints,\nand reduce the length of lineups at coffee breaks and for washrooms.\n\n### Humor\n\nHumor should be used sparingly when teaching: most jokes are less funny when\nwritten down and become even less funny with each re-reading. Being\nspontaneously funny while teaching usually works better but can easily go\nwrong: what\u2019s a joke to your circle of friends may turn out to be a serious\npolitical issue to your audience. If you do make jokes when teaching, don\u2019t\nmake them at the expense of any group, or of any individual except possibly\nyourself.\n\n## Limit Innovation\n\nEach of the techniques presented in this chapter will make your classes\nbetter, but you shouldn\u2019t try to adopt them all at once. The reason is that\nevery new practice increases your cognitive load as well as your learners\u2019,\nsince you are all now trying to learn a new way to learn as well as the\nlesson\u2019s subject matter. If you are working with a group repeatedly, you can\nintroduce one new technique every few lessons; if you only have them for a\none-day workshop, it\u2019s best to pick just one method they haven\u2019t seen before\nand get them comfortable with that.\n\n## Exercises\n\n### Create a Questionnaire (individual/20)\n\nUsing the questionnaire in Section 21.5 as a template, create a short\nquestionnaire you could give learners before teaching a class of your own.\nWhat do you most want to know about their background, and how can both parties\nbe sure they agree on what level of understanding you\u2019re asking about?\n\n### One of Your Own (whole class/15)\n\nThink of one teaching practice that hasn\u2019t been described so far. Present your\nidea to a partner, listen to theirs, and select one to present to the group as\na whole. (This exercise is an example of think-pair-share.)\n\n### May I Drive? (pairs/10)\n\nSwap computers with a partner (preferably one who uses a different operating\nsystem than you) and work through a simple programming exercise. How\nfrustrating is it? How much insight does it give you into what novices have to\ngo through all the time?\n\n### Pairing (pairs/15)\n\nWatch this video of pair programming and then practice doing it with a\npartner. Remember to switch roles between driver and navigator every few\nminutes. How long does it take you to fall into a working rhythm?\n\n### Compare Notes (small groups/15)\n\nForm groups of 3\u20134 people and compare the notes you have taken on this\nchapter. What did you think was noteworthy that your peers missed and vice\nversa? What did you understand differently?\n\n### Credibility (individual/15)\n\n[Fink2013] describes three things that make teachers credible in their\nlearners\u2019 eyes:\n\nCompetence:\n\n    \n\nknowledge of the subject as shown by the ability to explain complex ideas or\nreference the work of others.\n\nTrustworthiness:\n\n    \n\nhaving the learners\u2019 best interests in mind. This can be shown by giving\nindividualized feedback, offering a rational explanation for grading\ndecisions, and treating all learners the same.\n\nDynamism:\n\n    \n\nexcitement about the subject (Chapter 8).\n\nDescribe one thing you do when teaching that fits into each category, and then\ndescribe one thing you don\u2019t do but should.\n\n### Measuring Effectiveness (individual/15)\n\n[Kirk1994] defines four levels at which to evaluate training:\n\nReaction:\n\n    \n\nhow did the learners feel about the training?\n\nLearning:\n\n    \n\nhow much did they actually learn?\n\nBehavior:\n\n    \n\nhow much have they changed their behavior as a result?\n\nResults:\n\n    \n\nhow have those changes in behavior affected their output or the output of\ntheir group?\n\nWhat are you doing at each level to evaluate what and how you teach? What\ncould you do that you\u2019re not doing?\n\n### Objections and Counter-Objections (think-pair-share/15)\n\nYou have decided not to ask your learners if your class was useful because you\nknow there is no correlation between their answers and how much they actually\nlearn (Section 7.1). Instead, you have put forward four proposals, each of\nwhich your colleagues have shot down:\n\nSee if they recommend the class to friends.\n\n    \n\nWhy would this be any more meaningful than asking them how they feel about the\nclass?\n\nGive them an exam at the end.\n\n    \n\nBut how much learners know at the end of the day is a poor predictor of how\nmuch they will remember two or three months later, and any kind of final exam\nwill make the class a lot more stressful.\n\nGive them an exam two or three months later.\n\n    \n\nThat\u2019s practically impossible with free-range learners, and the people who\ndidn\u2019t get anything out of the workshop are probably less likely to take part\nin follow-up, so feedback gathered this way will be skewed.\n\nSee if they keep using what they learned.\n\n    \n\nInstalling spyware on learners\u2019 computers is frowned upon, so how will this be\nimplemented?\n\nWorking on your own, come up with answers to these objections, then share your\nresponses with a partner and discuss the approaches you have come up with.\nWhen you are done, share your favored approach with the class.\n\n# Motivation and Demotivation\n\nLearners need encouragement to step out into unfamiliar terrain, so this\nchapter discusses ways teachers can motivate them. More importantly, it talks\nabout how teachers can demotivate them and how to avoid doing that.\n\nOur starting point is the difference between extrinsic motivation, which we\nfeel when we do something to avoid punishment or earn a reward, and intrinsic\nmotivation, which is what we feel when we find something personally\nfulfilling. Both affect most situations\u2014for example, people teach because they\nenjoy it and because they get paid\u2014but we learn best when we are intrinsically\nmotivated [Wlod2017]. According to self-determination theory, the three\ndrivers of intrinsic motivation are:\n\nCompetence:\n\n    \n\nthe feeling that you know what you\u2019re doing.\n\nAutonomy:\n\n    \n\nthe feeling of being in control of your own destiny.\n\nRelatedness:\n\n    \n\nthe feeling of being connected to others.\n\nA well-designed lesson encourages all three. For example, a programming\nexercise can let learners practice the tools they need to use to solve a\nlarger problem (competence), let them tackle the parts of that problem in\nwhatever order they want (autonomy), and allow them to talk to their peers\n(relatedness).\n\n> #### The Problem of Grades\n>\n> I\u2019ve never had an audience in my life. My audience is a rubric. \u2013 quoted by\n> Matt Tierney\n>\n> Grades and the way they distort learning are often used as an example of\n> extrinsic motivation, but as [Mill2016a] observes, they aren\u2019t going to go\n> away any time soon, so it\u2019s pointless to try to build a system that ignores\n> them. Instead, [Lang2013] explores how courses that emphasize grades can\n> incentivize learners to cheat and offers some tips on how to diminish this\n> effect, while [Covi2017] looks at the larger problem of balancing intrinsic\n> and extrinsic motivation in institutional education, and the constructive\n> alignment approach advocated in [Bigg2011] seeks to bring learning\n> activities and learning outcomes into line with each other.\n\n[Ambr2010] contains a list of evidence-based methods to motivate learners.\nNone of them are surprising\u2014it\u2019s hard to imagine someone saying that we\nshouldn\u2019t identify and reward what we value\u2014but it\u2019s useful to check lessons\nto make sure they are doing at least a few of these things. One strategy I\nparticularly like is to have learners who struggled but succeeded come in and\ntell their stories to the rest of the class. Learners are far more likely to\nbelieve stories from people like themselves [Mill2016a], and people who have\nbeen through your course will always have advice you would never have thought\nof.\n\n> #### Not Just for Learners\n>\n> Discussions of motivation in education often overlook the need to motivate\n> the teacher. Learners respond to a teacher\u2019s enthusiasm, and teachers\n> (particularly volunteers) need to care about a topic in order to keep\n> teaching it. This is another powerful reason to co-teach (Section 9.3): just\n> as having a running partner makes it more likely that you\u2019ll keep running,\n> having a teaching partner helps get you up and going on those days when you\n> have a cold and the projector bulb has burned out and nobody knows where to\n> find a replacement and seriously, are they doing construction again?\n\nTeachers can do other positive things as well. [Bark2014] found three things\nthat drove retention for all learners: meaningful assignments, faculty\ninteraction with learners, and learner collaboration on assignments. Pace and\nworkload relative to expectations were also significant drivers, but primarily\nfor male learners. Things that didn\u2019t drive retention were interactions with\nteaching assistants and interactions with peers in extracurricular activities.\nThese results seem obvious, but the reverse would seem obvious too: if the\nstudy had found that extracurricular activities did drive retention, we would\nalso think that made sense. Noticeably, two of the four retention drivers\n(faculty interaction and learner collaboration) take extra effort to replicate\nonline (Chapter 11).\n\n## Authentic Tasks\n\nAs Dylan Wiliam points out in [Hend2017], motivation doesn\u2019t always lead to\nachievement, but achievement almost always leads to motivation: learners\u2019\nsuccess motivates them far more than being told how wonderful they are. We can\nuse this idea in teaching by creating a grid whose axes are \u201cmean time to\nmaster\u201d and \u201cusefulness once mastered\u201d (Figure 10.1).\n\nWhat to teach\n\nThings that are quick to master and immediately useful should be taught first,\neven if they aren\u2019t considered fundamental by people who are already competent\npractitioners, because a few early wins will build learners\u2019 confidence in\nthemselves and their teacher. Conversely, things that are hard to learn and\naren\u2019t useful to your learners at their current stage of development should be\nskipped entirely, while topics along the diagonal need to be weighed against\neach other.\n\n> #### Useful to Whom?\n>\n> If someone wants to build websites, foundational computer science concepts\n> like recursion and computability may inhabit the lower right corner of this\n> grid. That doesn\u2019t mean they aren\u2019t worth learning, but if our aim is to\n> motivate people, they can and should be deferred. Conversely, a senior who\n> is taking a programming class to stimulate their mind may prefer exploring\n> these big ideas to doing anything practical. When you are making up your\n> grid, you should do it with your learner personas in mind (Section 6.1). If\n> topics wind up in very different places for different personas, you should\n> think about creating different courses.\n\nA well-studied instance of prioritizing what\u2019s useful without sacrificing\nwhat\u2019s fundamental is the media computation approach developed at Georgia Tech\n[Guzd2013]. Instead of printing \u201chello world\u201d or summing the first ten\nintegers, a learner\u2019s first program might open an image, resize it to create a\nthumbnail, and save the result. This is an authentic task, i.e. something that\nlearners believe they would actually do in real life. It also has a tangible\nartifact: if the image comes out the wrong size, learners have something in\nhand that can guide their debugging. [Lee2013] describes an adaption of this\napproach from Python to MATLAB, while others are building similar courses\naround data science, image processing, and biology\n[Dahl2018,Meys2018,Ritz2018].\n\nThere will always be tension between giving learners authentic problems and\nexercising the individual skills they need to solve those problems: after all,\nprogrammers don\u2019t answer multiple choice questions on the job any more than\nmusicians play scales over and over in front of an audience. Finding the\nbalance is hard, but a first step is to take out anything arbitrary or\nmeaningless. For example, programming examples shouldn\u2019t use variables called\nfoo and bar, and if you\u2019re going to have learners sort a list, make it a list\nof songs rather than strings like \u201caaa\u201d and \u201cbbb\u201d.\n\n## Demotivation\n\n> Women aren\u2019t leaving computing because they don\u2019t know what it\u2019s like;\n> they\u2019re leaving because they do know. \u2014 variously attributed\n\nIf you are teaching in a free-range setting, your learners are probably\nvolunteers, and probably want to be in your classroom. Motivating them is\ntherefore less of a concern than not demotivating them. Unfortunately, you can\neasily demotivate people by accident. For example, [Cher2009] reported four\nstudies showing that subtle environmental clues have a measurable difference\non the interest that people of different genders have in computing: changing\nobjects in a Computer Science classroom from those considered stereotypical of\ncomputer science (e.g. Star Trek posters and video games) to objects not\nconsidered stereotypical (e.g. nature posters and phone books) boosted female\nundergraduates\u2019 interest to the level of their male peers. Similarly,\n[Gauc2011] reports a trio of studies showing that gendered wording commonly\nemployed in job recruitment materials can maintain gender inequality in\ntraditionally male-dominated occupations.\n\nThere are three main demotivators for adult learners:\n\nUnpredictability\n\n    \n\ndemotivates people because if there\u2019s no reliable connection between what they\ndo and what outcome they achieve, there\u2019s no reason for them to try to do\nanything.\n\nIndifference\n\n    \n\ndemotivates because learners who believe that the teacher or educational\nsystem doesn\u2019t care about them or the material won\u2019t care about it either.\n\nUnfairness\n\n    \n\ndemotivates people who are disadvantaged for obvious reasons. What\u2019s\nsurprising is that it also demotivates people who benefit from unfairness:\nconsciously or unconsciously, they worry that they will some day find\nthemselves in the disadvantaged group [Wilk2011].\n\nIn extreme situations, learners may develop learned helplessness: when\nrepeatedly subjected to negative feedback in a situation that they can\u2019t\nchange, they may learn not to even try to change the things they could.\n\nOne of the fastest and surest ways to demotivate learners is to use language\nthat suggests that some people are natural programmers and others aren\u2019t.\nGuzdial has called this the biggest myth about teaching computer science, and\n[Pati2016] backed this up by showing that people see evidence for a \u201cgeek\ngene\u201d where none exists. They analyzed grade distributions from 778 university\ncourses and found that only 5.8% showed signs of being multimodal, i.e. only\none class in twenty showed signs of having two distinct populations of\nlearners. They then showed 53 Computer Science professors histograms of\nambiguous grade distributions; those who believed that some people are\ninnately predisposed to be better at Computer Science were more likely to see\nthem as bimodal than those who didn\u2019t.\n\nThese beliefs matter because teachers act on them [Brop1983]. If a teacher\nbelieves that a learner is likely to do well they naturally (often\nunconsciously) focus on that learner, who then fulfills the teacher\u2019s\nexpectations because of the increased attention, which in turn appears to\nconfirm the teacher\u2019s belief. Sadly, there is little sign that mere evidence\nof the kind presented in [Pati2016] is enough to break this vicious cycle...\n\nHere are a few other specific things that will demotivate your learners:\n\nA holier-than-thou or contemptuous attitude\n\n    \n\nfrom a teacher or a fellow learner.\n\nTelling them that their existing skills are rubbish.\n\n    \n\nUnix users sneer at Windows, programmers of all kinds make jokes about Excel,\nand no matter what web application framework you already know, some programmer\nwill tell you that it\u2019s out of date. Learners have often invested a lot of\ntime and effort into acquiring the skills they have; disparaging them is a\ngood way to guarantee that they won\u2019t listen to anything else you have to say.\n\nDiving into complex or detailed technical discussion\n\n    \n\nwith the most advanced learners in the class.\n\nPretending that you know more than you do.\n\n    \n\nLearners will trust you more if you are frank about the limitations of your\nknowledge, and will be more likely to ask questions and seek help.\n\nUsing the J word (\u201cjust\u201d) or feigning surprise.\n\n    \n\nAs discussed in Chapter 3, saying things like \u201cI can\u2019t believe you don\u2019t know\nX\u201d or \u201cyou\u2019ve never heard of Y?\u201d signals to the learner that the teacher\nthinks their problem is trivial and that they must be stupid for not being\nable to figure it out.\n\nSoftware installation headaches.\n\n    \n\nPeople\u2019s first contact with programming or with new programming tools is often\ndemoralizing, and believing that something is hard to learn is a self-\nfulfilling prophecy. It isn\u2019t just the time it takes to get set up or the\nfeeling that it\u2019s unfair to have to debug something that depends on precisely\nthe knowledge they don\u2019t yet have. The real problem is that every such failure\nreinforces their belief that they would have a better chance of making next\nThursday\u2019s deadline if they kept doing things the way they always have.\n\nIt is even easier to demotivate people online than in person, but there are\nnow evidence-based strategies for dealing with this. [Ford2016] found that\nfive barriers to contribution on Stack Overflow are seen as significantly more\nproblematic by women than men: lack of awareness of site features, feeling\nunqualified to answer questions, intimidating community size, discomfort\ninteracting with or relying on strangers, and the feeling that searching for\nthings online wasn\u2019t \u201creal work.\u201d Fear of negative feedback didn\u2019t quite make\nthis list, but would have been the next one added if the authors weren\u2019t quite\nso strict about their statistical cutoffs. All of these factors can and should\nbe addressed in both in-person and online settings using methods like those in\nSection 10.4, and doing so improves outcomes for everyone [Sved2016].\n\n> #### Productive Failure and Privilege\n>\n> Some recent work has explored productive failure, where learners are\n> deliberately given problems that can\u2019t be solved with the knowledge they\n> have and have to go out and acquire new information in order to make\n> progress [Kapu2016]. Productive failure is superficially reminiscent of\n> tech\u2019s \u201cfail fast, fail often\u201d mantra, but the latter is more a sign of\n> privilege than of understanding. People can only afford to celebrate failure\n> if they\u2019re sure they\u2019ll get a chance to try again; many of your learners,\n> and many people from marginalized or underprivileged groups, can\u2019t be sure\n> of that, and assuming that failure is an option is a great way to demotivate\n> them.\n\n### Impostor Syndrome\n\nImpostor syndrome is the belief that your achievements are lucky flukes and an\naccompanying fear that someone will finally figure this out. It is common\namong high achievers who undertake publicly visible work, but\ndisproportionately affects members of underrepresented groups: as discussed in\nSection 7.1, [Wilc2018] found that female learners with prior exposure to\ncomputing outperformed their male peers in all areas in introductory\nprogramming courses but were consistently less confident in their abilities,\nin part because society keeps signaling in subtle and not-so-subtle ways that\nthey don\u2019t really belong.\n\nTraditional classrooms can fuel impostor syndrome. Schoolwork is frequently\nundertaken alone or in small groups, but the results are shared and criticized\npublicly. As a result, we rarely see how others struggle to finish their work,\nwhich can feed the belief that everyone else finds this easy. Members of\nunderrepresented groups who already feel additional pressure to prove\nthemselves may be particularly affected.\n\nThe Ada Initiative has created some guidelines for fighting your own impostor\nsyndrome, which include:\n\nTalk about the issue with people you trust.\n\n    \n\nWhen you hear from others that impostor syndrome is a common problem, it\nbecomes harder to believe your feelings of being a fraud are real.\n\nGo to an in-person impostor syndrome session.\n\n    \n\nThere\u2019s nothing like being in a room full of people you respect and\ndiscovering that 90% of them have impostor syndrome.\n\nWatch your words, because they influence how you think.\n\n    \n\nSaying things like, \u201cI\u2019m not an expert in this, but...\u201d detracts from the\nknowledge you actually possess.\n\nTeach others about your field.\n\n    \n\nYou will gain confidence in your own knowledge and skill and help others avoid\nsome impostor syndrome shoals.\n\nAsk questions.\n\n    \n\nAsking questions can be intimidating if you think you should know the answer,\nbut getting answers eliminates the extended agony of uncertainty and fear of\nfailure.\n\nBuild alliances.\n\n    \n\nReassure and build up your friends, who will reassure and build you up in\nreturn. (If they don\u2019t, you might want to think about finding new friends...)\n\nOwn your accomplishments.\n\n    \n\nKeep actively recording and reviewing what you have done, what you have built,\nand what successes you\u2019ve had.\n\nAs a teacher, you can help people with their impostor syndrome by sharing\nstories of mistakes that you have made or things you struggled to learn. This\nreassures the class that it\u2019s OK to find topics hard. Being open with the\ngroup also builds trust and gives them confidence to ask questions. (Live\ncoding is great for this: as noted in Section 8.1, your typos show your class\nthat you\u2019re human.) Frequent formative assessments help as well, particularly\nif learners see you adjusting what you teach or how quickly you go based on\ntheir outcomes.\n\n### Mindset and Stereotype Threat\n\nCarol Dweck and others have studied the differences of fixed mindset and\ngrowth mindset on learning outcomes. If people believe that competence in some\narea is intrinsic (i.e. that you either \u201chave the gene\u201d for it or you don\u2019t),\neveryone does worse, including the supposedly advantaged. The reason is that\nif someone doesn\u2019t do well at first, they assume that they lack that aptitude,\nwhich biases their future performance. On the other hand, if people believe\nthat a skill is learned and can be improved, they do better on average.\n\nThere are concerns that growth mindset has been oversold, or that it is much\nmore difficult to translate research about it into practice than its more\nenthusiastic advocates have implied [Sisk2018]. However, it does appear that\nlearners with low socioeconomic status or who are academically at risk might\nbenefit from mindset interventions.\n\nAnother widely discussed effect is stereotype threat [Stee2011]. Reminding\npeople of negative stereotypes, even in subtle ways, can make them anxious\nabout the risk of confirming those stereotypes, which in turn can reduce their\nperformance. Again, there are some concerns about the replicability of key\nstudies, and the issue is further clouded by the fact that the term has been\nused in many ways [Shap2007], but no one would argue that mentioning\nstereotypes in class will help learners.\n\n## Accessibility\n\nPutting lessons and exercises out of someone\u2019s reach is about as demotivating\nas it gets, and it\u2019s very easy to do this inadvertently. For example, the\nfirst online programming lessons I wrote had a transcript of the narration\nbeside the slides, but didn\u2019t include the actual source code: that was in\nscreenshots of PowerPoint slides. Someone using a screen reader could\ntherefore hear what was being said about the program, but wouldn\u2019t know what\nthe program actually was. It isn\u2019t always feasible to accommodate every\nlearner\u2019s needs, but adding description captions to images and making\nnavigation controls accessible to people who can\u2019t use a mouse can make a big\ndifference.\n\n> #### Curb Cuts\n>\n> Making material accessible helps everyone, not just people facing\n> challenges. Curb cuts\u2014the small sloped ramps joining a sidewalk to the\n> street\u2014were originally created to make it easier for the physically disabled\n> to move around, but proved to be equally helpful to people with strollers\n> and grocery carts. Similarly, captioning images doesn\u2019t just help the\n> visually impaired: it also makes images easier for search engines to find\n> and index.\n\nThe first and most important step in making lessons accessible is to involve\npeople with disabilities in decision making: the slogan nihil de nobis, sine\nnobis (literally, \u201cnothing for us without us\u201d) predates accessibility rights,\nbut is always the right place to start. A few specific recommendations are:\n\nFind out what you need to do.\n\n    \n\nEach of these posters offers do\u2019s and don\u2019ts for people on the autistic\nspectrum, users of screen readers, and people with low vision, physical or\nmotor disabilities, hearing exercises, and dyslexia.\n\nDon\u2019t do everything at once.\n\n    \n\nThe enhancements described in the previous point can seem pretty daunting, so\nmake one change at a time.\n\nDo the easy things first.\n\n    \n\nFont size, using a clip-on microphone so that people can hear you more easily,\nand checking your color choices are good places to start.\n\nKnow how well you\u2019re doing.\n\n    \n\nSites like WebAIM allow you to check how accessible your online materials are\nto visually impaired users.\n\n[Coom2012,Burg2015] are good guides to visual design for accessibility. Their\nrecommendations include:\n\nFormat documents with actual headings and other landmarks\n\n    \n\nrather than just changing font sizes and styles.\n\nAvoid using color alone to convey meaning in text or graphics.\n\n    \n\nInstead, use color plus different cross-hatching patterns (which also makes\nmaterial understandable when printed in black and white).\n\nRemove unnecessary elements\n\n    \n\nrather than just making them invisible, because screen readers will still\noften say them aloud.\n\nAllow self-pacing and repetition\n\n    \n\nfor people with reading or hearing issues.\n\nInclude narration of on-screen action in videos\n\n    \n\n(and talk while you type when live coding).\n\n### Spoons\n\nIn 2003, Christine Miserandino started using spoons as a way to explain what\nit\u2019s like to live with chronic illness. Healthy people start each day with an\nunlimited supply of spoons, but people with lupus or other debilitating\nconditions only have a few, and everything they do costs them one. Getting out\nof bed? That\u2019s a spoon. Making a meal? That\u2019s another spoon, and pretty soon,\nyou\u2019ve run out.\n\n> You cannot simply just throw clothes on when you are sick... If my hands\n> hurt that day buttons are out of the question. If I have bruises that day, I\n> need to wear long sleeves, and if I have a fever I need a sweater to stay\n> warm and so on. If my hair is falling out I need to spend more time to look\n> presentable, and then you need to factor in another 5 minutes for feeling\n> badly that it took you 2 hours to do all this.\n\nAs Elizabeth Patitsas has argued, people who have a lot of spoons can\naccumulate more, but people whose supply is limited may struggle to get ahead.\nWhen designing classes and exercises, remember that some of your learners may\nhave physical or mental obstacles that aren\u2019t obvious. When in doubt, ask:\nthey almost certainly have more experience with what works and what doesn\u2019t\nthan anyone else.\n\n## Inclusivity\n\nInclusivity is a policy of including people who might otherwise be excluded or\nmarginalized. In computing, it means making a positive effort to be more\nwelcoming to women, underrepresented racial or ethnic groups, people with\nvarious sexual orientations, the elderly, those facing physical challenges,\nthe formerly incarcerated, the economically disadvantaged, and everyone else\nwho doesn\u2019t fit Silicon Valley\u2019s affluent white/Asian male demographic. Figure\n10.2 (from NPR) graphically illustrates the effects of computing\u2019s\nexclusionary culture on women.\n\nFemale computer science majors in the US\n\n[Lee2017] is a brief, practical guide to doing that with references to the\nresearch literature. The practices it describes help learners who belong to\none or more marginalized or excluded groups, but help motivate everyone else\nas well. They are phrased in terms of term-long courses, but many can be\napplied in workshops and other free-range settings:\n\nAsk learners to email you before the workshop\n\n    \n\nto explain how they believe the training could help them achieve their goals.\n\nReview your notes\n\n    \n\nto make sure they are free from gendered pronouns, include culturally diverse\nnames, etc.\n\nEmphasize that what matters is the rate at which they are learning,\n\n    \n\nnot the advantages or disadvantages they had when they started.\n\nEncourage pair programming,\n\n    \n\nbut demonstrate it first so that learners understand the roles of driver and\nnavigator.\n\nActively mitigate behavior that some learners may find intimidating,\n\n    \n\ne.g. use of jargon or \u201cquestions\u201d that are actually asked to display\nknowledge.\n\nOne way to support learners from marginalized groups is to have people sign up\nfor workshops in groups rather than individually. That way, everyone in the\nroom knows in advance that they will be with people they trust, which\nincreases the chances of them actually coming. It also helps after the\nworkshop: if people come with their friends or colleagues, they can work\ntogether to use what they\u2019ve learned.\n\nMore fundamentally, lesson authors need to take everyone\u2019s entire situation\ninto account. For example, [DiSa2014a] found that 65% of male African-American\nparticipants in a game testing program went on to study computing, in part\nbecause the gaming aspect of the program was something their peers respected.\n[Lach2018] explored two general strategies for creating inclusive content and\nthe risks associated with them:\n\nCommunity representation\n\n    \n\nhighlights learners\u2019 social identities, histories, and community networks\nusing after-school mentors or role models from learners\u2019 neighborhoods, or\nactivities that use community narratives and histories as a foundation for a\ncomputing project. The major risk with this approach is shallowness, e.g.\nusing computers to build slideshows rather than do any real computing.\n\nComputational integration\n\n    \n\nincorporates ideas from the learner\u2019s community, such as reproducing\nindigenous graphic designs in a visual programming environment. The major risk\nhere is cultural appropriation, e.g. using practices without acknowledging\norigins.\n\nIf in doubt, ask your learners and members of the community what they think\nyou ought to do. We return to this in Chapter 13.\n\n> #### Conduct as Accessibility\n>\n> We said in Section 9.1 that classes should enforce a Code of Conduct like\n> the one in Appendix 17. This is a form of accessibility: while closed\n> captions make video accessible to people with hearing disabilities, a Code\n> of Conduct makes lessons accessible to people who would otherwise be\n> marginalized.\n\n### Moving Past the Deficit Model\n\nDepending on whose numbers you trust, only 12\u201318% of people getting computer\nscience degrees are women, which is less than half the percentage seen in the\nmid-1980s (Figure 10.3, from [Robe2017]). And western countries are the odd\nones for having such low percentage of women in computing: women are still\noften 30\u201340% of computer science students elsewhere [Galp2002,Varm2015].\n\nDegrees awarded and female enrollment\n\nSince it\u2019s unlikely that women have changed drastically in the last 30 years,\nwe have to look for structural causes to understand what\u2019s gone wrong and how\nto fix it. One explanation is the way that home computers were marketed as\n\u201cboys\u2019 toys\u201d starting in the 1980s [Marg2003]; another is the way that\ncomputer science departments responded to explosive growth in enrollment in\nthe 1980s and again in the 2000s by changing admission requirements\n[Robe2017]. None of these factors may seem dramatic to people who aren\u2019t\naffected by them, but they act like the steady drip of water on a stone: over\ntime, they erode motivation, and with it, participation.\n\nThe first and most important step toward fixing this is to stop thinking in\nterms of a \u201cleaky pipeline\u201d [Mill2015]. More generally, we need to move past a\ndeficit model, i.e. to stop thinking that the members of underrepresented\ngroups lack something and are therefore responsible for not getting ahead.\nBelieving that puts the burden on people who already have to do extra work to\novercome structural inequities and (not coincidentally) gives those who\nbenefit from the current arrangements an excuse not to look at themselves too\nclosely.\n\n> #### Rewriting History\n>\n> [Abba2012] describes the careers and accomplishments of the women who shaped\n> the early history of computing, but have all too often been written out of\n> it; [Ensm2003,Ensm2012] describes how programming was turned from a female\n> into a male profession in the 1960s, while [Hick2018] looks at how Britain\n> lost its early dominance in computing by systematically discriminating\n> against its most qualified workers: women. (See [Milt2018] for a review of\n> all three books.) Discussing this history makes some men in computing very\n> uncomfortable; in my opinion, that\u2019s a good reason to do it.\n\nMisogyny in video games, the use of \u201ccultural fit\u201d in hiring to excuse\nconscious or unconscious bias, a culture of silence around harassment, and the\ngrowing inequality in society that produces preparatory privilege (Section\n9.5) are not any one person\u2019s fault, but fixing them is everyone\u2019s\nresponsibility. As a teacher, you have more power than most; this workshop has\nexcellent practical advice on how to be a good ally, and its advice is\nprobably more important than anything this book teaches you about teaching.\n\n## Exercises\n\n### Authentic Tasks (pairs/15)\n\n  1. In pairs, list half a dozen things you did this week that use the skills you teach.\n\n  2. Place your items on a 2x2 grid of \u201ctime to master\u201d and \u201cusefulness\u201d. Where do you agree and disagree?\n\n### Core Needs (whole class/10)\n\nPaloma Medina identifies six core needs for people at work: belonging,\nimprovement (i.e. making progress), choice, equality, predictability, and\nsignificance. After reading her description of these, order them from most to\nleast significant for you personally, then compare rankings with your peers.\nHow do you think your rankings compare with those of your learners?\n\n### Implement One Strategy for Inclusivity (individual/5)\n\nPick one activity or change in practice from [Lee2017] that you would like to\nwork on. Put a reminder in your calendar three months in the future to ask\nyourself whether you have done something about it.\n\n### After the Fact (think-pair-share/20)\n\n  1. Think back to a course that you took in the past and identify one thing the teacher did that demotivated you. Make notes about what could have been done afterward to correct the situation.\n\n  2. Pair up with your neighbor and compare stories, then add your comments to a set of notes shared by the whole class.\n\n  3. Review the comments in the shared notes as a group. Highlight and discuss a few of the things that could have been done differently.\n\n  4. Do you think that doing this will help you handle situations like these in the future?\n\n### Walk the Route (whole class/15)\n\nFind the nearest public transportation drop-off point to your building and\nwalk from there to your office and then to the nearest washroom, making notes\nabout things you think would be difficult for someone with mobility issues.\nNow borrow a wheelchair and repeat the journey. How complete was your list of\nexercises? And did you notice that the first sentence in this exercise assumed\nyou could actually walk?\n\n### Who Decides? (whole class/15)\n\nIn [Litt2004], Kenneth Wesson wrote, \u201cIf poor inner-city children consistently\noutscored children from wealthy suburban homes on standardized tests, is\nanyone naive enough to believe that we would still insist on using these tests\nas indicators of success?\u201d Read this article by Cameron Cottrill, and then\ndescribe an example from your own experience of \u201cobjective\u201d assessments that\nreinforced the status quo.\n\n### Common Stereotypes (pairs/10)\n\nSome people still say, \u201cIt\u2019s so simple that even your grandmother could use\nit.\u201d In pairs, list two or three other phrases that reinforce stereotypes\nabout computing.\n\n### Not Being a Jerk (individual/15)\n\nThis short article by Gary Bernhardt rewrites an unnecessarily hostile message\nto be less rude. Using it as a model, find something unpleasant on Stack\nOverflow or some other public discussion forum and rewrite it to be more\ninclusive.\n\n### Saving Face (individual/10)\n\nWould any of your hoped-for learners be embarrassed to admit that they don\u2019t\nalready know some of the things you want to teach? If so, how can you help\nthem save face?\n\n### Childhood Toys (whole class/15)\n\n[Cutt2017] surveyed adult computer users about their childhood activities and\nfound that the strongest correlation between confidence and computer use were\nbased on reading on one\u2019s own and playing with construction toys like Lego\nthat do not having moving parts. Survey the class and see what other\nactivities people engaged in, then search for these activities online. How\nstrongly gendered are descriptions and advertising for them? What effect do\nyou think this has?\n\n### Lesson Accessibility (pairs/30)\n\nIn pairs, choose a lesson whose materials are available online and\nindependently rank it according to the do\u2019s and don\u2019ts in these posters. Where\ndid you and your partner agree? Where did you disagree? How well did the\nlesson do for each of the six categories of user?\n\n### Tracing the Cycle (small groups/15)\n\n[Coco2018] traces a depressingly common pattern in which good intentions are\nundermined by an organization\u2019s leadership being unwilling to actually change.\nWorking in groups of 4\u20136, write brief texts or emails that you imagine each of\nthe parties involved would send to the other at each stage in this cycle.\n\n### What\u2019s the Worst Thing That Could Happen? (small groups/5)\n\nOver the years, I have had a projector catch fire, a student go into labor,\nand a fight break out in class. I\u2019ve fallen off stage twice, fallen asleep in\none of my own lectures, and had many jokes fall flat. In small groups, make up\na list of the worst things that have happened to you while you were teaching,\nthen share with the class. Keep the list to remind yourself later that no\nmatter how bad class was, at least none of that happened.\n\n## Review\n\nConcepts: Motivation\n\n# Teaching Online\n\n> If you use robots to teach, you teach people to be robots. \u2014 variously\n> attributed\n\nTechnology has changed teaching and learning many times. Before blackboards\nwere introduced into schools in the early 1800s, there was no way for teachers\nto share an improvised example, diagram, or exercise with an entire class at\nonce. Cheap, reliable, easy to use, and flexible, blackboards enabled teachers\nto do things quickly and at a scale that they had only been able to do slowly\nand piecemeal before. Similarly, hand-held video cameras revolutionized\nathletics training, just as tape recorders revolutionized music instruction a\ndecade earlier.\n\nMany of the people pushing the internet into classrooms don\u2019t know this\nhistory, and don\u2019t realize that theirs is just the latest in a long series of\nattempts to use machines to teach [Watt2014]. From the printing press through\nradio and television to desktop computers and mobile devices, every new way to\nshare knowledge has produced a wave of aggressive optimists who believe that\neducation is broken and that technology can fix it. However, ed tech\u2019s loudest\nadvocates have often known less about \u201ced\u201d than \u201ctech,\u201d and behind their\nrhetoric, many have been driven more by the prospect of profit than by the\ndesire to empower learners.\n\nToday\u2019s debate is often muddied by confusing \u201conline\u201d with \u201cautomated.\u201d Run\nwell, a dozen people working through a problem in a video chat feels like any\nother small-group discussion. Conversely, a squad of teaching assistants\ngrading hundreds of papers against an inflexible rubric might as well be a\ncollection of Perl scripts. This chapter therefore starts by looking at fully\nautomated online instruction using recorded videos and automatically graded\nexercises, then explores some alternative hybrid models.\n\n## MOOCs\n\nThe highest-profile effort to reinvent education using the internet is the\nMassive Open Online Course, or MOOC. The term was invented by David Cormier in\n2008 to describe a course organized by George Siemens and Stephen Downes. That\ncourse was based on a connectivist view of learning, which holds that\nknowledge is distributed and that learning is the process of finding,\ncreating, and pruning connections.\n\nThe term \u201cMOOC\u201d was quickly co-opted by creators of courses more closely\nresembled the hub-and-spoke model of a traditional classroom, with the teacher\nat the center defining goals and the learners seen as recipients or\nreplicators of knowledge. Classes that use the original connectivist model are\nnow sometimes referred to as \u201ccMOOCs,\u201d while classes that centralize control\nare called \u201cxMOOCs.\u201d (The latter is also sometimes called a \u201cMESS,\u201d for\nMassively Enhanced Sage on the Stage.)\n\nFive years ago, you couldn\u2019t walk across a major university campus without\nhearing someone talking about how MOOCs would revolutionize education, destroy\nit, or possibly both. MOOCs would give learners access to a wider range of\ncourses and allow them to work when it was convenient for them rather than\nfitting their learning to someone else\u2019s schedule.\n\nBut MOOCs haven\u2019t been nearly as effective as their more enthusiastic\nproponents predicted [Ubel2017]. One reason is that recorded content is\nineffective for many novices because it cannot clear up their individual\nmisconceptions (Chapter 2): if they don\u2019t understand an explanation the first\ntime around, there usually isn\u2019t a different one on offer. Another is that the\nautomated assessment needed to put the \u201cmassive\u201d in MOOC only works well at\nthe lowest levels of Bloom\u2019s Taxonomy (Section 6.2). It\u2019s also now clear that\nlearners have to shoulder much more of the burden of staying focused in a\nMOOC, that the impersonality of working online can encourage uncivil behavior\nand demotivate people, and that \u201cavailable to everyone\u201d actually means\n\u201cavailable to everyone affluent enough to have high-speed internet and lots of\nfree time.\u201d\n\n[Marg2015] examined 76 MOOCs on various subjects and found that while the\norganization and presentation of material was good, the quality of lesson\ndesign was poor. Closer to home, [Kim2017] studied thirty popular online\ncoding tutorials, and found that they largely taught the same content the same\nway: bottom-up, starting with low-level programming concepts and building up\nto high-level goals. Most required learners to write programs and provided\nsome form of immediate feedback, but this feedback was typically very shallow.\nFew explained when and why concepts are useful (i.e. they didn\u2019t show how to\ntransfer knowledge) or provided guidance for common errors, and other than\nrudimentary age-based differentiation, none personalized lessons based on\nprior coding experience or learner goals.\n\n> #### Personalized Learning\n>\n> Few terms have been used and abused in as many ways as personalized\n> learning. To most ed tech proponents, it means dynamically adjusting the\n> pace of lessons based on learner performance, so that if someone answers\n> several questions in a row correctly, the computer will skip some of the\n> subsequent questions.\n>\n> Doing this can produce modest improvements, but better is possible. For\n> example, if many learners find a particular topic difficult, the teacher can\n> prepare multiple alternative explanations of that point rather than\n> accelerating a single path. That way, if one explanation doesn\u2019t resonate,\n> others are available. However, this requires a lot more design work on the\n> teacher\u2019s part, which may be why it hasn\u2019t proven popular. And even if it\n> does work, the effects are likely to be much less than some of its advocates\n> believe. A good teacher makes a difference of 0.1\u20130.15 standard deviations\n> in end-of-year performance in grade school [Chet2014] (see this article for\n> a brief summary). It\u2019s unrealistic to believe that any kind of automation\n> can outdo this any time soon.\n\nSo how should the internet be used in teaching and learning tech skills? Its\npros and cons are:\n\nLearners can access more lessons, more quickly, than ever before.\n\n    \n\nProvided, of course, that a search engine considers those lessons worth\nindexing, that their internet service provider and government don\u2019t block it,\nand that the truth isn\u2019t drowned in a sea of attention-sapping disinformation.\n\nLearners can access better lessons than ever before,\n\n    \n\nunless they are being steered toward second-rate material in order to\nredistribute wealth from the have-nots to the haves [McMi2017]. It\u2019s also\nworth remembering that scarcity increases perceived value, so as online\neducation becomes cheaper, it will increasingly become what everyone wants for\nsomeone else\u2019s children.\n\nLearners can access far more people than ever before as well.\n\n    \n\nBut only if those learners actually have access to the required technology,\ncan afford to use it, and aren\u2019t driven offline by harassment or marginalized\nbecause they don\u2019t conform to the social norms of whichever group is talking\nloudest. In practice, most MOOC users come from secure, affluent backgrounds\n[Hans2015].\n\nTeachers can get far more detailed insight into how learners work.\n\n    \n\nSo long as learners are doing things that are amenable to large-scale\nautomated analysis and either don\u2019t object to surveillance in the classroom or\naren\u2019t powerful enough for their objections to matter.\n\n[Marg2015,Mill2016a,Nils2017] describe ways to accentuate the positives in the\nlist above while avoiding the negatives:\n\nMake deadlines frequent and well-publicized,\n\n    \n\nand enforce them so that learners will get into a work rhythm.\n\nKeep synchronous all-class activities like live lectures to a minimum\n\n    \n\nso that people don\u2019t miss things because of scheduling conflicts.\n\nHave learners contribute to collective knowledge,\n\n    \n\ne.g. take notes together (Section 9.7), serve as classroom scribes, or\ncontribute problems to shared problem sets (Section 5.3).\n\nEncourage or require learners to do some of their work in small groups\n\n    \n\nthat do have synchronous online activities such as a weekly online discussion.\nThis helps learners stay engaged and motivated without creating too many\nscheduling headaches. (See Appendix 20 for some tips on how to make these\ndiscussions fair and productive.)\n\nCreate, publicize, and enforce a code of conduct\n\n    \n\nso that everyone can actually take part in online discussions (Section 9.1).\n\nUse lots of short lesson episodes rather than a handful of lecture-length\nchunks\n\n    \n\nin order to minimize cognitive load and provide lots of opportunities for\nformative assessment. This also helps with maintenance: if all of your videos\nare short, you can simply re-record any that need maintenance, which is often\ncheaper than trying to patch longer ones.\n\nUse video to engage rather than instruct.\n\n    \n\nDisabilities aside (Section 10.3), learners can read faster than you can talk.\nThe exception to this rule is that video is actually the best way to teach\npeople verbs (actions): short screencasts that show people how to use an\neditor, step through code in a debugger, and so on are more effective than\nscreenshots with text.\n\nIdentify and clear up misconceptions early.\n\n    \n\nIf data shows that learners are struggling with some parts of a lesson, create\nalternative explanations of those points and extra exercises for them to\npractice on.\n\nAll of this has to be implemented somehow, which means that you need some kind\nof teaching platform. You can either use an all-in-one learning management\nsystem like Moodle or Sakai, or assemble something yourself using Slack or\nZulip for chat, Google Hangouts or appear.in for video conversations, and\nWordPress, Google Docs, or any number of wiki systems for collaborative\nauthoring. If you are just starting out, pick whatever is easiest to set up\nand administer and is most familiar to your learners. If faced with a choice,\nthe second consideration is more important than the first: you\u2019re expecting\npeople to learn a lot in your class, so it\u2019s only fair for you to learn how to\ndrive the tools they\u2019re most comfortable with.\n\nAssembling a platform for learning is necessary but not sufficient: if you\nwant your learners to thrive, you need to create a community. Hundreds of\nbooks and presentations talk about how to do this, but most are based on their\nauthors\u2019 personal experiences. [Krau2016] is a welcome exception: while it\npredates the accelerating descent of Twitter and Facebook into weaponized\nabuse and misinformation, most of its findings are still relevant. [Foge2005]\nis also full of useful tips about the communities of practice that learners\nmay hope to join; we explore some of its ideas in Chapter 13.\n\n> #### Freedom To and Freedom From\n>\n> Isaiah Berlin\u2019s 1958 essay \u201cTwo Concepts of Liberty\u201d made a distinction\n> between positive liberty, which is the ability to actually do something, and\n> negative liberty, which is the absence of rules saying that you can\u2019t do it.\n> Online discussions usually offer negative liberty (nobody\u2019s stopping you\n> from saying what you think) but not positive liberty (many people can\u2019t\n> actually be heard). One way to address this is to introduce some kind of\n> throttling, such as only allowing each learner to contribute one message per\n> discussion thread per day. Doing this gives those with something to say a\n> chance to say it, while clearing space for others to say things as well.\n\nOne other concern people have about teaching online is cheating. Day-to-day\ndishonesty is no more common in online classes than in face-to-face settings\n[Beck2014], but the temptation to have someone else write the final exam, and\nthe difficulty of checking whether this happened, is one of the reasons\neducational institutions have been reluctant to offer credit for pure online\nclasses. Remote exam proctoring is possible, but before investing in this,\nread [Lang2013]: it explores why and how learners cheat, and how courses can\nbe structured to avoid giving them a reason to do so.\n\n## Video\n\nA prominent feature of most MOOCs is their use of recorded video lectures.\nThese can be effective: as mentioned in Chapter 8, a teaching technique called\nDirect Instruction based on precise delivery of a well-designed script has\nrepeatedly been shown to be effective [Stoc2018]. However, scripts for direct\ninstruction have to be designed, tested, and refined very carefully, which is\nan investment that many MOOCs have been unwilling or unable to make. Making a\nsmall change to a web page or a slide deck only takes a few minutes; making\neven a small change to a short video takes an hour or more, so the cost to the\nteacher of acting on feedback can be unsupportable. And even when they\u2019re well\nmade, videos have to be combined with activities to be beneficial: [Koed2015]\nestimated, \u201c...the learning benefit from extra doing...to be more than six\ntimes that of extra watching or reading.\u201d\n\nIf you are teaching programming, you may use screencasts instead of slides,\nsince they offer some of the same advantages as live coding (Section 8.1).\n[Chen2009] offers useful tips for creating and critiquing screencasts and\nother videos; Figure 11.1 (from [Chen2009]) reproduces the patterns that paper\npresents and the relationships between them. (It\u2019s also a good example of a\nconcept map (Section 3.1).)\n\nPatterns for screencasting\n\nSo what makes an instructional video effective? [Guo2014] measured engagement\nby looking at how long learners watched MOOC videos, and found that:\n\n  * Shorter videos are much more engaging\u2014videos should be no more than six minutes long.\n\n  * A talking head superimposed on slides is more engaging than voice over slides alone.\n\n  * Videos that felt personal could be more engaging than high-quality studio recordings, so filming in informal settings could work better than professional studio work for lower cost.\n\n  * Drawing on a tablet is more engaging than PowerPoint slides or code screencasts, though it\u2019s not clear whether this is because of the motion and informality or because it reduces the amount of text on the screen.\n\n  * It\u2019s OK for teachers to speak fairly fast as long as they are enthusiastic.\n\nOne thing [Guo2014] didn\u2019t address is the chicken-and-egg problem: do learners\nfind a certain kind of video engaging because they\u2019re used to it, so producing\nmore videos of that kind will increase engagement simply because of a feedback\nloop? Or do these recommendations reflect some deeper cognitive processes?\nAnother thing this paper didn\u2019t look at is learning outcomes: we know that\nlearner evaluations of courses don\u2019t correlate with learning\n[Star2014,Uttl2017], and while it\u2019s plausible that learners won\u2019t learn from\nthings they don\u2019t watch, it remains to be proven that they do learn from\nthings they do watch.\n\n> #### I\u2019m a Little Uncomfortable\n>\n> [Guo2014]\u2019s research was approved by a university research ethics board, the\n> learners whose viewing habits were monitored almost certainly clicked\n> \u201cagree\u201d on a terms of service agreement at some point, and I\u2019m glad to have\n> these insights. On the other hand, the word \u201cprivacy\u201d didn\u2019t appear in the\n> title or abstract of any of the dozens of papers or posters at the\n> conference where these results were presented. Given a choice, I\u2019d rather\n> not know how engaged learners are than foster ubiquitous surveillance in the\n> classroom.\n\nThere are many different ways to record video lessons; to find out which are\nmost effective, [Mull2007a] assigned 364 first-year physics learners to online\nmultimedia treatments of Newton\u2019s First and Second Laws in one of four styles:\n\nExposition:\n\n    \n\nconcise lecture-style presentation.\n\nExtended Exposition:\n\n    \n\nas above with additional interesting information.\n\nRefutation:\n\n    \n\nExposition with common misconceptions explicitly stated and refuted.\n\nDialog:\n\n    \n\nLearner-tutor discussion of the same material as in the Refutation.\n\nRefutation and Dialog produced the greatest learning gains compared to\nExposition; learners with low prior knowledge benefited most, and those with\nhigh prior knowledge were not disadvantaged. Again, this highlights the\nimportance of directly addressing learners\u2019 misconceptions. Don\u2019t just tell\npeople what is: tell them what isn\u2019t and why not.\n\n## Hybrid Models\n\nFully automated teaching is only one way to use the web in teaching. In\npractice, almost all learning in affluent societies has an online component\ntoday, either officially or through peer-to-peer back channels and\nsurreptitious searches for answers to homework questions. Combining live and\nautomated instruction allows teachers to use the strengths of both. In a\ntraditional classroom, the teacher can answer questions immediately, but it\ntakes days or weeks for learners to get feedback on their coding exercises.\nOnline, it can take longer for a learner to get an answer, but they can get\nimmediate feedback on their coding (at least for those kinds of exercises we\ncan auto-grade).\n\nAnother difference is that online exercises have to be more detailed because\nthey have to anticipate learners\u2019 questions. I find that in-person lessons\nstart with the intersection of what everyone needs to know and expands on\ndemand, while online lessons have to include the union of what everyone needs\nto know because the teacher isn\u2019t there to do the expanding.\n\nIn reality, the distinction between online and in-person is now less important\nfor most people than the distinction between synchronous and asynchronous: do\nteachers and learners interact in real time, or is their communication spread\nout and interleaved with other activities? In-person will almost always be\nsynchronous, but online is increasingly a mixture of both:\n\n> I think that our grandchildren will probably regard the distinction we make\n> between what we call the real world and what they think of as simply the\n> world as the quaintest and most incomprehensible thing about us. \u2014 William\n> Gibson\n\nThe most popular implementation of this blended future today is the flipped\nclassroom, in which learners watch recorded lessons on their own and class\ntime is used for discussion and working through problem sets. Originally\ndescribed in [King1993], the idea was popularized as part of peer instruction\n(Section 9.2) and has been studied intensively over the past decade. For\nexample, [Camp2016] compared learners who took an introductory computer\nscience class online with those who took it in a flipped classroom. Completion\nof (unmarked) practice exercises correlated with exam scores for both, but the\ncompletion rate of rehearsal exercises by online learners was significantly\nlower than lecture attendance rates for in-person learners.\n\nBut if recordings are available, will learners still show up to class to do\npractice exercises? [Nord2017] examined the impact of recordings on both\nlecture attendance and learners\u2019 performance at different levels. In most\ncases the study found no negative consequences of making recordings available;\nin particular, learners didn\u2019t skip lectures when recordings are available (at\nleast, not any more than they usually do). The benefits of providing\nrecordings were greatest for learners early in their careers, but diminished\nas learners become more mature.\n\nAnother hybrid model brings online life into the classroom. Taking notes\ntogether is a first step (Section 9.7); pooling answers to multiple choice\nquestions in real time using tools like Pear Deck and Socrative is another. If\nthe class is small\u2014say, a dozen to fifteen people\u2014you can also have all of the\nlearners join a video conference so that they can screenshare with the\nteacher. This allows them to show their work (or their problems) to the entire\nclass without having to connect their laptop to the projector. Learners can\nalso then use the chat in the video call to post questions for the teacher; in\nmy experience, most of them will be answered by their fellow learners, and the\nteacher can handle the rest when they reach a natural break. This model helps\nlevel the playing field for remote learners: if someone isn\u2019t able to attend\nclass for health reasons or because of family or work commitments, they can\nstill take part on a nearly-equal basis if everyone is used to collaborating\nonline in real time.\n\nI have also delivered classes using real-time remote instruction, in which\nlearners are co-located at 2\u20136 sites with helpers present while I taught via\nstreaming video (Section 18.1). This scales well, saves on travel costs, and\nallows the use of techniques like pair programming (Section 9.6). What doesn\u2019t\nwork is having one group in person and one or more groups remotely: with the\nbest will in the world, the local participants get far more attention.\n\n## Online Engagement\n\n[Nuth2007] found that there are three overlapping worlds in every classroom:\nthe public (what the teacher is saying and doing), the social (peer-to-peer\ninteractions between learners), and the private (inside each learner\u2019s head).\nOf these, the most important is usually the social: learners pick up as much\nvia cues from their peers as they do from formal instruction.\n\nThe key to making any form of online teaching effective is therefore to\nfacilitate peer-to-peer interactions. To aid this, courses almost always have\nsome kind of discussion forum. [Mill2016a] observed that learners use these in\nvery different ways:\n\n> ...procrastinators are particularly unlikely to participate in online\n> discussion forums, and this reduced participation, in turn, is correlated\n> with worse grades. A possible explanation for this correlation is that\n> procrastinators are especially hesitant to join in once the discussion is\n> under way, perhaps because they worry about being perceived as newcomers in\n> an established conversation. This aversion to jump in late causes them to\n> miss out on the important learning and motivation benefits of peer-to-peer\n> interaction.\n\n[Vell2017] analyzes discussion forum posts from 395 CS2 students at two\nuniversities by dividing them into four categories:\n\nActive:\n\n    \n\nrequest for help that does not display reasoning and doesn\u2019t display what the\nstudent has already tried or already knows.\n\nConstructive:\n\n    \n\nreflect students\u2019 reasoning or attempts to construct a solution to the\nproblem.\n\nLogistical:\n\n    \n\ncourse policies, schedules, assignment submission, etc.\n\nContent clarification:\n\n    \n\nrequest for additional information that doesn\u2019t reveal the student\u2019s own\nthinking.\n\nThey found that constructive and logistical questions dominated, and that\nconstructive questions correlated with grades. They also found that students\nrarely ask more than one active question in a course, and that these don\u2019t\ncorrelate with grades. While this is disappointing, knowing it helps set\nteachers\u2019 expectations: while we might all want our courses to have lively\nonline communities, we have to accept that most won\u2019t, or that most learner-\nto-learner discussion will take place through channels that they are already\nusing that we may not be part of.\n\n> #### Co-opetition\n>\n> [Gull2004] describes an online coding contest that combines collaboration\n> and competition. The contest starts when a problem description is posted\n> along with a correct but inefficient solution. When it ends, the winner is\n> the person who has made the greatest overall contribution to improving the\n> performance of the overall solution. All submissions are in the open, so\n> that participants can see one another\u2019s work and borrow ideas from each\n> other. As the paper shows, the final solution is almost always a hybrid\n> borrowing ideas from many people.\n>\n> [Batt2018] described a small-scale variation of this in an introductory\n> computing class. In stage one, each learner submitted a programming project\n> individually. In stage two, learners were paired to create an improved\n> solution to the same problem. The assessment indicates that two-stage\n> projects tend to improve learners\u2019 understanding and that they enjoyed the\n> process. Projects like these not only improve engagement, they also give\n> participants more experience building on someone else\u2019s code.\n\nDiscussion isn\u2019t the only way to get learners to work together online.\n[Pare2008] and [Kulk2013] report experiments in which learners grade each\nother\u2019s work, and the grades they assign are then compared with the grades\ngiven by graduate-level teaching assistants or other experts. Both found that\nlearner-assigned grades agreed with expert-assigned grades as often as the\nexperts\u2019 grades agreed with each other, and that a few simple steps (such as\nfiltering out obviously unconsidered responses or structuring rubrics)\ndecreased disagreement even further. And as discussed in Section 5.3,\ncollusion and bias are not significant factors in peer grading.\n\n> #### Trust, but Educate\n>\n> The most common way to measure the validity of feedback is to compare\n> learners\u2019 grades to experts\u2019 grades, but calibrated peer review (Section\n> 5.3) can be equally effective. Before asking learners to grade each others\u2019\n> work, they are asked to grade samples and compare their results with the\n> grades assigned by the teacher. Once the two align, the learner is allowed\n> to start giving grades to peers. Given that critical reading is an effective\n> way to learn, this result may point to a future in which learners use\n> technology to make judgments, rather than being judged by technology.\n\nOne technique we will definitely see more of in coming years is online\nstreaming of live coding sessions [Raj2018,Haar2017]. This has most of the\nbenefits discussed in Section 8.1, and when combined with collaborative note-\ntaking (Section 9.7) it can be a close approximation to an in-class\nexperience.\n\nLooking even further ahead, [Ijss2000] identified four levels of online\npresence, from realism (we can\u2019t tell the difference) through immersion (we\nforget the difference) and involvement (we\u2019re engaged but aware of the\ndifference) to suspension of disbelief (we are doing most of the work).\nCrucially, they distinguish physical presence, which is the sense of actually\nbeing somewhere, and social presence, which is the sense of being with others.\nThe latter is more important in most learning situations, and again, we can\nfoster it by using learners\u2019 everyday technology in the classroom. For\nexample, [Deb2018] found that real-time feedback on in-class exercises using\nlearners\u2019 own mobile devices improved concept retention and learner engagement\nwhile reducing failure rates.\n\nOnline and asynchronous teaching are both still in their infancy. Centralized\nMOOCs may prove to be an evolutionary dead end, but there are still many other\npromising models to explore. In particular, [Broo2016] describes fifty ways\nthat groups can discuss things productively, only a handful of which are\nwidely known or implemented online. If we go where our learners are\ntechnologically rather than requiring them to come to us, we may wind up\nlearning as much as they do.\n\n## Exercises\n\n### Two-Way Video (pairs/10)\n\nRecord a 2\u20133 minute video of yourself doing something, then swap machines with\na partner so that each of you can watch the other\u2019s video at 4x speed. How\neasy is it to follow what\u2019s going on? What if anything did you miss?\n\n### Viewpoints (individual/10)\n\nAccording to [Irib2009], different disciplines focus on different factors\naffecting the success or otherwise of online communities:\n\nBusiness:\n\n    \n\ncustomer loyalty, brand management, extrinsic motivation.\n\nPsychology:\n\n    \n\nsense of community, intrinsic motivation.\n\nSociology:\n\n    \n\ngroup identity, physical community, social capital, collective action.\n\nComputer Science:\n\n    \n\ntechnological implementation.\n\nWhich of these perspectives most closely corresponds to your own? Which are\nyou least aligned with?\n\n### Helping or Harming (small groups/30)\n\nSusan Dynarski\u2019s article in the New York Times explains how and why schools\nare putting students who fail in-person courses into online courses, and how\nthis sets them up for even further failure. Read the article and then:\n\n  1. In small groups, come up with 2\u20133 things that schools could do to compensate for these negative effects and create rough estimates of their per-learner costs.\n\n  2. Compare your suggestions and costs with those of other groups. How many full-time teaching positions do you think would have to be cut in order to free up resources to implement the most popular ideas for a hundred learners?\n\n  3. As a class, do you think that would be a net benefit for the learners or not?\n\nBudgeting exercises like this are a good way to tell who\u2019s serious about\neducational change. Everyone can think of things they\u2019d like to do; far fewer\nare willing to talk about the tradeoffs needed to make change happen.\n\n# Exercise Types\n\nEvery good carpenter has a set of screwdrivers, and every good teacher has\ndifferent kinds of exercises to check what learners are actually learning,\nhelp them practice their new skills, and keep them engaged. This chapter\nstarts by describing several kinds of exercises you can use to check if your\nteaching has been effective. It then looks at the state of the art in\nautomated grading, and closes by exploring discussion, projects, and other\nimportant kinds of work that require more human attention to assess. Our\ndiscussion draws in part on the Canterbury Question Bank [Sand2013], which has\nentries for various languages and topics in introductory computing.\n\n## The Classics\n\nAs Section 2.1 discussed, multiple choice questions (MCQs) are most effective\nwhen the wrong answers probe for specific misconceptions. They are usually\ndesigned to test the lower levels of Bloom\u2019s Taxonomy (Section 6.2), but can\nalso require learners to exercise judgment.\n\n> #### A Multiple Choice Question\n>\n> In what order do operations occur when the computer evaluates the expression\n> price = addTaxes(cost - discount)?\n>\n>   1. subtraction, function call, assignment\n>\n>   2. function call, subtraction, assignment\n>\n>   3. function call, then assignment and subtraction simultaneously\n>\n>   4. none of the above\n>\n>\n\nThe second classic type of programming exercise is code and run (C&R), in\nwhich the learner writes code that produces a specified output. C&R exercises\ncan be as simple or as complex as the teacher wants, but when used in class,\nthey should be brief and have only one or two plausible correct answers. It\u2019s\noften enough to ask novices to calculate and print a single value or call a\nspecific function: experienced teachers often forget how hard it can be to\nfigure out which parameters go where. For more advanced learners, figuring out\nwhich function to call is more engaging and a better gauge of their\nunderstanding.\n\n> #### Code & Run\n>\n> The variable picture contains a full-color image read from a file. Using one\n> function, create a black and white version of the image and assign it to a\n> new variable called monochrome.\n\nWrite and run exercises can be combined with MCQs. For example, this MCQ can\nonly be answered by running the Unix ls command:\n\n> #### Combining MCQ with Code & Run\n>\n> You are in the directory /home. Which of the following files is not in that\n> directory?\n>\n>   1. autumn.csv\n>\n>   2. fall.csv\n>\n>   3. spring.csv\n>\n>   4. winter.csv\n>\n>\n\nC&Rs help people practice the skills they most want to learn, but they can be\nhard to assess: there can be lots of unexpected ways to get the right answer,\nand people will be demoralized if an automatic grading system rejects their\ncode because it doesn\u2019t match the teacher\u2019s. One way to reduce how often this\noccurs is to assess only their output, but that doesn\u2019t give them feedback on\nhow they are programming. Another is to give them a small test suite they can\nrun their code against before they submit it (at which point it is run against\na more comprehensive set of tests). Doing this helps them figure out if they\nhave completely misunderstood the intent of the exercise before they do\nanything that they think might cost them grades.\n\nInstead of writing code that satisfies some specification, learners can be\nasked to write tests to determine whether a piece of code conforms to a spec.\nThis is a useful skill in its own right, and doing it may give learners a bit\nmore sympathy for how hard their teachers work.\n\n> #### Inverting Code & Run\n>\n> The function monotonic_sum calculates the sum of each section of a list of\n> numbers in which the values are strictly increasing. For example, given the\n> input [1, 3, 3, 4, 5, 1], the output is [4, 12, 1]. Write and run unit tests\n> to determine which of the following bugs the function contains:\n>\n>   * Considers every negative number the start of a new sub-sequence.\n>\n>   * Does not include the first value of each sub-sequence in the sub-sum.\n>\n>   * Does not include the last value of each sub-sequence in the sub-sum.\n>\n>   * Only re-starts the sum when values decrease rather than fail to\n> increase.\n>\n>\n\nFill in the blanks is a refinement of C&R in which the learner is given some\nstarter code and has to complete it. (In practice, most C&R exercises are\nactually fill in the blanks because the teacher provides comments to remind\nthe learners of the steps they should take.) Questions of this type are the\nbasis for faded examples; as discussed in Chapter 4, novices often find them\nless intimidating than writing all the code from scratch, and since the\nteacher has provided most of the answer\u2019s structure, submissions are much more\npredictable and therefore easier to check.\n\n> #### Fill in the Blanks\n>\n> Fill in the blanks so that the code below prints the string \u2019hat\u2019.\n>  \n>  \n>     text = 'all that it is' slice = text[____:____] print(slice)\n\nParsons Problems also avoid the \u201cblank screen of terror\u201d problem while\nallowing learners to concentrate on control flow separately from vocabulary\n[Pars2006,Eric2015,Morr2016,Eric2017]. Tools for building and doing Parsons\nProblems online exist [Ihan2011], but they can be emulated (albeit somewhat\nclumsily) by asking learners to rearrange lines of code in an editor.\n\n> #### Parsons Problem\n>\n> Rearrange and indent these lines to sum the positive values in a list. (You\n> will need to add colons in appropriate places as well.)\n>  \n>  \n>     total = 0 if v > 0 total += v for v in values\n\nNote that giving learners more lines than they need, or asking them to\nrearrange some lines and add a few more, makes Parsons Problems significantly\nharder [Harm2016].\n\n## Tracing\n\nTracing execution is the inverse of a Parsons Problem: given a few lines of\ncode, the learner has to trace the order in which those lines are executed.\nThis is an essential debugging skill and a good way to solidify learners\u2019\nunderstanding of loops, conditionals, and the evaluation order of function and\nmethod calls. The easiest way to implement it is to have learners write out a\nsequence of labeled steps. Having them choose the correct sequence from a set\n(i.e. presenting this as an MCQ) adds cognitive load without adding value,\nsince they have to do all the work of figuring out the correct sequence, then\nsearch for it in the list of options.\n\n> #### Tracing Execution Order\n>\n> In what order are the labeled lines in this block of code executed?\n>  \n>  \n>     A) vals = [-1, 0, 1] B) inverse_sum = 0 try: for v in vals: C)\n> inverse_sum += 1/v except: D) pass\n\nTracing values is similar to tracing execution, but instead of spelling out\nthe order in which code is executed, the learner lists the values that one or\nmore variables take on as the program runs. One way to implement this is to\ngive the learner a table whose columns are labeled with variable names and\nwhose rows are labeled with line numbers, and ask them to fill in the values\ntaken on by the variables on those lines.\n\n> #### Tracing Values\n>\n> What values do left and right take on as this program executes?\n>  \n>  \n>     A) left = 23 B) right = 6 C) while right: D) left, right = right, left %\n> right\n\nLine| left| right  \n---|---|---  \n  \nYou can also require learners to trace code backwards to figure out what the\ninput must have been for the code to produce a particular result [Armo2008].\nThese reverse execution problems require search and deductive reasoning, and\nwhen the output is an error message, they help learners develop valuable\ndebugging skills.\n\n> #### Reverse Execution\n>\n> Fill in the missing number in values that caused this function to crash.\n>  \n>  \n>     values = [ [1.0, -0.5], [3.0, 1.5], [2.5, ___] ] runningTotal = 0.0 for\n> (reading, scaling) in values: runningTotal += reading / scaling\n\nMinimal fix exercises also help learners develop debugging skills. Given a few\nlines of code that contain a bug, the learner must find it and make one small\nchange to fix it. Making the change can be done using C&R, while identifying\nit can be done as a multiple choice question.\n\n> #### Minimal Fix\n>\n> This function is supposed to test whether a number lies within a range. Make\n> one small change so that it actually does so.\n>  \n>  \n>     def inside(point, lower, higher): if (point <= lower): return false elif\n> (point <= higher): return false else: return true\n\nTheme and variation exercises are similar, but the learner is asked to make a\nsmall alteration that changes the output in some specific way instead of\nmaking a change to fix a bug. Allowed changes can include changing a\nvariable\u2019s initial value, replacing one function call with another, swapping\ninner and outer loops, or changing the order of tests in a complex\nconditional. Again, this kind of exercise gives learners a chance to practice\na useful real-world skill: the fastest way to produce the code they need is to\ntweak code that already does something close.\n\n> #### Theme and Variations\n>\n> Change the inner loop in the function below so that it fills the upper left\n> triangle of an image with a specified color.\n>  \n>  \n>     function fillTriangle(picture, color) is for x := 1 to picture.width do\n> for y := 1 to picture.height do picture[x, y] = color end end end\n\nRefactoring exercises are the complement of theme and variation exercises:\ngiven a working piece of code, the learner has to modify it in some way\nwithout changing its output. For example, the learner could replace loops with\nvectorized expressions or simplify the condition in a while loop. This is also\na useful real-world skill, but there are often so many ways to refactor code\nthat grading requires human inspection.\n\n> #### Refactoring\n>\n> Write a single list comprehension that has the same effect as this loop.\n>  \n>  \n>     result = [] for v in values: if len(v) > threshold: result.append(v)\n\n## Diagrams\n\nHaving learners draw concept maps and other diagrams gives insight into how\nthey\u2019re thinking (Section 3.1), but free-form diagrams take human time and\njudgment to assess. Labeling diagrams, on the other hand, is almost as\npowerful pedagogically but much easier to scale.\n\nRather than having learners create diagrams from scratch, provide them with a\ndiagram and a set of labels and have them put the latter in the right places\non the former. The diagram can be a data structure (\u201cafter this code is\nexecuted, which variables point to which parts of this structure?\u201d), a chart\n(\u201cmatch each of these pieces of code with the part of the chart it\ngenerated\u201d), or the code itself (\u201cmatch each term to an example of that\nprogram element\u201d).\n\n> #### Labeling a Diagram\n>\n> Figure 12.1 shows how a small fragment of HTML is represented in memory. Put\n> the labels 1\u20139 on the elements of the tree to show the order in which they\n> are reached in a depth-first traversal.\n\nLabeling a diagram\n\nAnother way to use diagrams is to give learners the pieces of the diagram and\nask them to arrange them correctly. This is a visual equivalent of a Parsons\nProblem, and you can provide as much or as little of a skeleton to help with\nplacement as you think they\u2019re ready for. I have fond memories of trying to\nplace resistors and capacitors in a circuit diagram in order to get the right\nvoltage at a certain point, and have seen teachers give learners a fixed set\nof Scratch blocks and ask them to create a particular drawing using only those\nblocks.\n\nMatching problems can be thought of as a special case of labeling in which the\n\u201cdiagram\u201d is a column of text and the labels are taken from the other column.\nOne-to-one matching gives the learner two lists of equal length and asks them\nto pair corresponding items, e.g. \u201cmatch each piece of code with the output it\nproduces.\u201d\n\n> #### Matching\n>\n> Match each regular expression operator in Figure 12.2 with what it does.\n\nMatching items\n\nWith many-to-many matching the lists aren\u2019t the same length, so some items may\nbe matched to several others and others may not be matched at all. Many-to-\nmany are more difficult because learners can\u2019t do easy matches first to reduce\ntheir search space. Matching problems can be implemented by having learners\nsubmit lists of matching pairs (such as \u201cA3, B1, C2\u201d), but that\u2019s clumsy and\nerror-prone. Having them recognize a set of correct pairs in an MCQ is even\nworse, as it\u2019s painfully easy to misread. Drawing or dragging works much\nbetter, but may require some work to implement.\n\nRanking is a special case of matching that is (slightly) more amenable to\nanswering via lists, since our minds are pretty good at detecting errors or\nanomalies in sequences. The ranking criteria determine the level of reasoning\nrequired. If you have learners order sorting algorithms from fastest to\nslowest you are probably exercising recall (i.e. asking them recognizing the\nalgorithms\u2019 names and know their properties), while asking them to rank\nsolutions from most robust to most brittle exercises reasoning and judgment.\n\nSummarization also requires learners to use higher-order thinking and gives\nthem a chance to practice a skill that is very useful when reporting bugs. For\nexample, you can ask learners, \u201cWhich sentence best describes how the output\nof f changes as x varies from 0 to 10?\u201d and then given several options as a\nmultiple choice question. You can also ask for very short free-form answers to\nquestions in constrained domains, such as, \u201cWhat is the key feature of a\nstable sorting algorithm?\u201d We can\u2019t fully automate checks for these without a\nfrustrating number of false positives (accepting wrong answers) and false\nnegatives (rejecting correct ones), but questions of this kind lend themselves\nwell to peer grading (Section 5.3).\n\n## Automatic Grading\n\nAutomatic program grading tools have been around longer than I have been\nalive: the earliest published mention dates from 1960 [Holl1960], and the\nsurveys published in [Douc2005,Ihan2010] mention many specific tools by name.\nBuilding such tools is a lot more complex than it might first seem. How are\nassignments represented? How are submissions tracked and reported? Can\nlearners co-operate? How can submissions be executed safely? [Edwa2014a] is an\nentire paper devoted to an adaptive scheme for detecting and managing infinite\nloops in code submissions, and that\u2019s just one of the many issues that comes\nup.\n\nWhen discussing auto-graders, it is important to distinguish learner\nsatisfaction from learning outcomes. For example, [Magu2018] switched informal\nprogramming labs for a second-year CS course to a weekly machine-evaluated\ntest using an auto-grader. Learners didn\u2019t like the automated system, but the\noverall failure rate for the course was halved and the number of learners\ngaining first class honors tripled. In contrast, [Rubi2014] also began to use\nan auto-grader designed for competitions, but saw no significant decrease in\ntheir learners\u2019 dropout rates; once again, learners made some negative\ncomments about the tool, which the authors attribute to the quality of its\nfeedback messages rather than to dislike of auto-grading.\n\n[Srid2016] took a different approach. They used fuzz testing (i.e. randomly\ngenerated test cases) to check whether learner code does the same thing as a\nreference implementation supplied by the teacher. In the first project of a\n1400-learner introductory course, fuzz testing caught errors that were missed\nby a suite of hand-written test cases for more than 48% of learners.\n\n[Basu2015] gave learners a suite of solution test cases, but learners had to\nunlock each one by answering questions about its expected behavior before they\nwere allowed to apply it to their proposed solution. For example, suppose\nlearners had to write a function to find the largest adjacent pair of numbers\nin a list. Before being allowed to use the question\u2019s tests, they had to\nchoose the right answer to, \u201cWhat does largestPair(4, 3, -1, 5, 3, 3)\nproduce?\u201d In a 1300-person university course, the vast majority of learners\nchose to validate their understanding of test cases this way before attempting\nto solve problems, and then asked fewer questions and expressed less confusion\nabout assignments.\n\n> #### Against Off-the-Shelf Tools\n>\n> It\u2019s tempting to use off-the-shelf style checking tools to grade learners\u2019\n> code. However, [Nutb2016] initially found no correlation between human-\n> provided marks and style-checker rule violations. Sometimes this was because\n> learners violated one rule many times (thereby losing more points than they\n> should have), but other times it was because they submitted the assignment\n> starter code with few alterations and got more points than they should have.\n>\n> Even tools built specifically for teaching can fall short of teachers\u2019\n> needs. [Keun2016a,Keun2016b] looked at the messages produced by 69 auto-\n> grading tools. They found that the tools often do not give feedback on how\n> to fix problems and take the next step. They also found that most teachers\n> cannot easily adapt most of the tools to their needs: like many workflow\n> tools, they tend to enforce their creators\u2019 unrecognized assumptions about\n> how institutions work. Their classification scheme is a useful shopping list\n> when looking at tools of this kind.\n\n[Buff2015] presents a well-informed reflection on the whole idea of providing\nautomated feedback. Their starting point is that, \u201cAutomated grading systems\nhelp learners identify bugs in their code, [but] may inadvertently discourage\nlearners from thinking critically and testing thoroughly and instead encourage\ndependence on the teacher\u2019s tests.\u201d One of the key issues they identified is\nthat a learner may thoroughly test their code, but the feature may still not\nbe implemented according to the teacher\u2019s specifications. In this case, the\n\u201cfailure\u201d is not caused by a lack of testing but by a misunderstanding of the\nrequirements, and it is unlikely that more testing will expose the problem. If\nthe auto-grading system doesn\u2019t provide insightful, actionable feedback, this\nexperience will only frustrate the learner.\n\nIn order to provide that feedback, [Buff2015]\u2019s system identifies which\nmethods in the learner\u2019s code are executed by failing tests so that the system\ncan associate failed tests with particular features within the learner\u2019s\nsubmission. The system decides whether specific hints have been \u201cearned\u201d by\nseeing whether the learner has tested the associated feature enough, so\nlearners cannot rely on hints instead of doing tests.\n\n[Srid2016] describes some other approaches for sharing feedback with learners\nwhen automatically testing their code. The first is to provide the expected\noutput for the tests\u2014but then learners hard-code output for those inputs\n(because anything that can be gamed will be). The second is to report the\npass/fail results for the learners\u2019 code, but only supply the actual inputs\nand outputs of the tests after the submission date. However, telling learners\nthat they are wrong but not telling them why is frustrating.\n\nA third option is to use a technique called hashing to generate a value that\ndepends on the output but doesn\u2019t reveal it. If the user produces exactly the\nright output then its hash will unlock the solution, but it is impossible to\nwork backward from the hash to figure out what the output is supposed to be.\nHashing requires more work and explanation to set up, but strikes a good\nbalance between revealing answers prematurely and not revealing them when it\nwould help.\n\n## Higher-Level Thinking\n\nMany other kinds of programming exercises are hard for teachers to assess in a\nclass with more than handful of learners and equally hard for automated\nplatforms to assess at all. Larger programming projects are (hopefully) what\nclasses are building toward, but the only way to give feedback is case by\ncase.\n\nCode review is also hard to grade automatically in general, but can be tackled\nif learners are given a list of faults to look for and asked to match\nparticular comments against particular lines of code. For example, the learner\ncan be told that there are two indentation errors and one bad variable name\nand asked to point them out. If they are more advanced, they could be given\nhalf a dozen kinds of remarks they could make about the code without being\ntold how many of each they should find.\n\n[Steg2016b] is a good starting point for a code style rubric, while [Luxt2009]\nlooks at peer review in programming classes more generally. If you are going\nto have learners do reviews, use calibrated peer review (Section 5.3) so that\nthey have models of what good feedback should look like.\n\n> #### Code Review\n>\n> Mark the problems in each line of code using the rubric provided.\n>  \n>  \n>     01) def addem(f): 02) x1 = open(f).readlines() 03) x2 = [x for x in x1\n> if x.strip()] 04) changes = 0 05) for v in x2: 06) print('total', total) 07)\n> tot = tot + int(v) 08) print('total')\n>\n> 1\\. poor variable name| 2\\. use of undefined variable  \n> ---|---  \n> 3\\. missing return value| 4\\. unused variable  \n  \n## Exercises\n\n### Code and Run (pairs/10)\n\nCreate a short C&R exercise, then trade with a partner and see how long it\ntakes each of you to understand and do the other\u2019s exercise. Were there any\nambiguities or misunderstandings in the exercise description?\n\n### Inverting Code and Run (small groups/15)\n\nForm groups of 4\u20136 people. Have each member of the group create an inverted\nC&R exercise that requires people to figure out what input produces a\nparticular output. Pick two at random and see how many different inputs the\ngroup can find that satisfy the requirements.\n\n### Tracing Values (pairs/10)\n\nWrite a short program (10\u201315 lines), trade with a partner, and trace how the\nvariables in the program change value over time. What differences are there in\nhow you and your partner wrote down your traces?\n\n### Refactoring (small groups/15)\n\nForm groups of 3\u20134 people. Have each person select a short piece of code\n(10\u201330 lines long) they have written that isn\u2019t as tidy as it could be, then\nchoose one at random and have everyone in the group tidy it up independently.\nHow do your cleaned-up versions differ? How well or how poorly would you be\nable to accommodate all of these variations if marking automatically or in a\nlarge class?\n\n### Labeling a Diagram (pairs/10)\n\nDraw a diagram showing something that you have explained recently: how\nbrowsers fetch data from servers, the relationship between objects and\nclasses, or how data frames are indexed in R. Put the labels on the side and\nask your partner to place them.\n\n### Pencil-and-Paper Puzzles (whole class/15)\n\n[Butl2017] describes a set of pencil-and-paper puzzles that can be turned into\nintroductory programming assignments and reports that these assignments are\nenjoyed by learners and encourage meta-cognition. Think of a simple pencil-\nand-paper puzzle or game you played as a child and describe how you would turn\nit into a programming exercise.\n\n### Counting Failures (pairs/15)\n\nAny useful estimate of how much time an exercise needs must take into account\nhow frequent failures are and how much time is lost to them. For example,\nediting text files seems like a simple task, but what about finding those\nfiles? Most GUI editors save things to the user\u2019s desktop or home directory;\nif the files used in a course are stored somewhere else, a substantial\nfraction won\u2019t be able to navigate to the right directory without help. (If\nthis seems like a small problem to you, please revisit the discussion of\nexpert blind spot in Chapter 3.)\n\nWorking with a partner, make a list of \u201csimple\u201d things you have seen go wrong\nin exercises you have used or taken. How often do they come up? How long do\nthey take learners to fix on their own or with help? How much time do you\ncurrently budget in class to deal with them?\n\n### Speaking of Timings (individual/10)\n\nHow accurate have the time estimates on the exercises in this book been so\nfar?\n\n# Building a Community of Practice\n\nYou don\u2019t have to fix all of society\u2019s ills in order to teach programming, but\nyou do have to be involved in what happens outside your class if you want\npeople to learn. This applies to teachers as well as learners: many free-range\nteachers start as volunteers or part-timers and have to juggle many other\ncommitments. What happens outside the classroom is as important to their\nsuccess as it is to their learners\u2019, so the best way to help both is to foster\na teaching community.\n\n> #### Finland and Why Not\n>\n> Finland\u2019s schools are among the most successful in the world, but as Anu\n> Partanen pointed out, they haven\u2019t succeeded in isolation. Other countries\u2019\n> attempts to adopt Finnish teaching methods are doomed to fail unless those\n> countries also ensure that children (and their parents) are safe, well\n> nourished, and treated fairly by the courts [Sahl2015,Wilk2011]. This isn\u2019t\n> surprising given what we know about the importance of motivation for\n> learning (Chapter 10): everyone does worse if they believe the system is\n> unpredictable, unfair, or indifferent.\n\nA framework for thinking about teaching communities is situated learning,\nwhich focuses on how legitimate peripheral participation leads to people\nbecoming members of a community of practice [Weng2015]. Unpacking those terms,\na community of practice is a group of people bound together by interest in\nsome activity, such as knitting or particle physics. Legitimate peripheral\nparticipation means doing simple, low-risk tasks that the community recognizes\nas valid contributions: making your first scarf, stuffing envelopes during an\nelection campaign, or proofreading documentation for open source software.\n\nSituated learning focuses on the transition from being a newcomer to being\naccepted as a peer by those who are already community members. This typically\nmeans starting with simple tasks and tools, then doing similar tasks with more\ncomplex tools, and finally tackling the same work as advanced practitioners.\nFor example, children learning music may start by playing nursery rhymes on a\nrecorder or ukulele, then play other simple songs on a trumpet or saxophone in\na band, and finally start exploring their own musical tastes. Common ways to\nsupport this progression include:\n\nProblem solving:\n\n    \n\n\u201cI\u2019m stuck\u2014can we work on designing this lesson together?\u201d\n\nRequests for information:\n\n    \n\n\u201cWhat\u2019s the password for the mailing list manager?\u201d\n\nSeeking experience:\n\n    \n\n\u201cHas anyone had a learner with a reading disability?\u201d\n\nSharing assets:\n\n    \n\n\u201cI put together a website for a class last year that you can use as a starting\npoint.\u201d\n\nCoordination:\n\n    \n\n\u201cCan we combine our t-shirt orders to get a discount?\u201d\n\nBuilding an argument:\n\n    \n\n\u201cIt will be easier to convince my boss to make changes if I know how other\nbootcamps do this.\u201d\n\nDocumenting projects:\n\n    \n\n\u201cWe\u2019ve had this problem five times now. Let us write it down once and for\nall.\u201d\n\nMapping knowledge:\n\n    \n\n\u201cWhat other groups are doing things like this in nearby neighborhoods or\ncities?\u201d\n\nVisits:\n\n    \n\n\u201cCan we come and see your after-school program? We need to establish one in\nour city.\u201d\n\nBroadly speaking, a community of practice can be a:\n\nCommunity of action:\n\n    \n\npeople focused on a shared goal, such as getting someone elected.\n\nCommunity of concern:\n\n    \n\nmembers are brought together by a shared issue, such as dealing with a long-\nterm illness.\n\nCommunity of interest:\n\n    \n\nfocused on a shared love of something like backgammon or knitting.\n\nCommunity of place:\n\n    \n\npeople who happen to live or work side by side.\n\nMost communities are mixes of these, such as people in Toronto who like\nteaching tech. A community\u2019s focus can also change over time: for example, a\nsupport group for people dealing with depression (community of concern) can\ndecide to raise funds to keep a help line going (community of action). Running\nthe help line can then become the group\u2019s focus (community of interest).\n\n> #### Soup, Then Hymns\n>\n> Manifestos are fun to write, but most people join a volunteer community to\n> help and be helped rather than to argue over the wording of a vision\n> statement^10. You should therefore focus on what people can create that will\n> be used by other community members right away. Once your organization shows\n> that it can achieve small things, people will be more confident that it\u2019s\n> worth helping you with bigger projects. That\u2019s the time to worry about\n> defining the values that will guide your members.\n\n## Learn, Then Do\n\nThe first step in building a community is to decide if you should, or whether\nyou would be more effective joining an existing organization. Thousands of\ngroups are already teaching people tech skills, from the 4-H Club and literacy\nprograms to get-into-coding nonprofits like Black Girls Code and Bridge.\nJoining an existing group will give you a head start on teaching, an immediate\nset of colleagues, and a chance to learn more about how to run things;\nhopefully, learning those skills while making an immediate contribution will\nbe more important than being able to say that you\u2019re the founder or leader of\nsomething new.\n\nWhether you join an existing group or set up one of your own, you will be more\neffective if you do a bit of background reading on community organizing.\n[Alin1989,Lake2018] is probably the best-known work on grassroots organizing,\nwhile [Brow2007,Midw2010,Lake2018] are practical manuals rooted in decades of\npractice. If you want to read more deeply, [Adam1975] is a history of the\nHighlander Folk School, whose approach has been emulated by many successful\ngroups, while [Spal2014] is a guide to teaching adults written by someone with\ndeep personal roots in organizing and NonprofitReady.org offers free\nprofessional development training.\n\n## Four Steps\n\nEveryone who gets involved with your organization (including you) goes through\nfour phases: recruitment, onboarding, retention, and retirement. You don\u2019t\nneed to worry about this cycle when you\u2019re getting started, but it is worth\nthinking about as soon as more than a handful of non-founders are involved.\n\nThe first step is recruiting volunteers. Your marketing should help you with\nthis by making your organization findable and by making its mission and value\nclear to people who might want to get involved (Chapter 14). Share stories\nthat exemplify the kind of help you want as well as stories about the people\nyou\u2019re helping, and make it clear that there are many ways to get involved.\n(We discuss this in more detail in the next section.)\n\nYour best source of new recruits is your own classes: \u201csee one, do one, teach\none\u201d has worked well for volunteer organizations for as long as there have\nbeen volunteer organizations. Make sure that every class or other encounter\nends by telling people how they could help and that their help would be\nwelcome. People who come to you this way will know what you do and have recent\nexperience of being on the receiving end of what you offer, which helps your\norganization avoid collective expert blind spot (Chapter 3).\n\n> #### Start Small\n>\n> Ben Franklin observed that a person who has performed a favor for someone is\n> more likely to do them another favor than someone who had received a favor\n> from that person. Asking people to do something small for you is therefore a\n> good step toward getting them to do something larger. One natural way to do\n> this when teaching is to ask people to submit fixes for your lesson\n> materials for typos or unclear wording, or to suggest new exercises or\n> examples. If your materials are written in a maintainable way (Section 6.3),\n> this gives them a chance to practice some useful skills and gives you an\n> opportunity to start a conversation that might lead to a new recruit.\n\nThe middle of the volunteer lifecycle is onboarding and retention, which we\nwill cover in Sections 13.3 and 13.4. The final step is retirement: everyone\nmoves on eventually, and healthy organizations plan for this. A few simple\nthings can make both the person leaving and everyone who is staying feel\npositive about the change:\n\nAsk people to be explicit about their departure\n\n    \n\nso that everyone knows they\u2019ve actually left.\n\nMake sure they don\u2019t feel embarrassed or ashamed about leaving\n\n    \n\nor about anything else.\n\nGive them an opportunity to pass on their knowledge.\n\n    \n\nFor example, you can ask them to mentor someone for a few weeks as their last\ncontribution, or to be interviewed by someone who is staying with the\norganization to collect any stories that are worth re-telling.\n\nMake sure they hand over the keys.\n\n    \n\nIt\u2019s awkward to discover six months after someone has left that they\u2019re the\nonly person who knows how to book a field for the annual picnic.\n\nFollow up 2\u20133 months after they leave\n\n    \n\nto see if they have any further thoughts about what worked and what didn\u2019t\nwhile they were with you, or any advice to offer that they either didn\u2019t think\nto give or were uncomfortable giving on their way out the door.\n\nThank them,\n\n    \n\nboth when they leave and the next time your group gets together.\n\n> #### A Missing Manual\n>\n> Thousands of books have been written on how to start a company. Only a\n> handful describe how to end one or leave one gracefully, even though there\n> is an ending for every beginning. If you ever write one, please let me know.\n\n## Onboarding\n\nAfter deciding to become part of a group, people need to get up to speed, and\n[Shol2019] summarizes what we know about doing this. The first rule is to have\nand enforce a Code of Conduct (Section 9.1), and to find an independent party\nwho is willing to receive and review reports of inappropriate behavior.\nSomeone outside the organization will have the objectivity that organization\nmembers may lack, and can protect reporters who might hesitate to raise issues\nconcerning project leaders out of fear of retribution or damage to their\nreputation. Project leaders should also publicize the enforcement decisions so\nthat the community recognizes that the code is meaningful.\n\nThe next most important thing is to be welcoming. As Fogel said [Foge2005],\n\u201cIf a project doesn\u2019t make a good first impression, newcomers may wait a long\ntime before giving it a second chance.\u201d Other authors have empirically\nconfirmed the importance of kind and polite social environments in open\nprojects [Sing2012,Stei2013,Stei2018]:\n\nPost a welcome message\n\n    \n\non the project\u2019s social media pages, Slack channels, forums, or email lists.\nProjects might consider maintaining a dedicated \u201cWelcome\u201d channel or list,\nwhere a project lead or community manager writes a short post asking newcomers\nto introduce themselves.\n\nHelp people find ways to make an initial contribution,\n\n    \n\nsuch as labeling particular lessons or workshops that need work as \u201csuitable\nfor newcomers\u201d and asking established members not to fix them in order to\nensure there are suitable places for new arrivals to start work.\n\nDirect the newcomer to project members like them\n\n    \n\nto demonstrate that they belong.\n\nPoint the newcomer to essential project resources\n\n    \n\nsuch as the contribution guidelines.\n\nDesignate one or two members to serve as a point of contact\n\n    \n\nfor each newcomer. Doing this can make the newcomer less reluctant to ask\nquestions.\n\nA third rule that helps everyone (not just newcomers) is to make knowledge\nfindable and keep it up to date. Newcomers are like explorers who must orient\nthemselves within an unfamiliar landscape [Dage2010]. Information that is\nspread out usually makes newcomers feel lost and disoriented. Given the\ndifferent possibilities of places to maintain information (e.g. wikis, files\nin version control, shared documents, old tweets or Slack messages, and email\narchives) it is important to keep information about a specific topic\nconsolidated in a single place so that newcomers do not need to navigate\nmultiple data sources to find what they need. Organizing the information makes\nnewcomers more confident and oriented [Stei2016].\n\nFinally, acknowledge newcomers\u2019 first contributions and figure out where and\nhow they might help in the longer term. Once they have carried their first\ncontribution over the line, you and they are likely to have a better sense of\nwhat they have to offer and how the project can help them. Help newcomers find\nthe next problem they might want to work on or point them at the next thing\nthey might enjoy reading. In particular, encouraging them to help the next\nwave of newcomers is both a good way to recognize what they have learned and\nan effective way to pass it on.\n\n## Retention\n\n> If your people aren\u2019t having a ball doing it, there is something very wrong.\n> \u2014 Saul Alinsky\n\nCommunity members shouldn\u2019t expect to enjoy every moment of their work with\nyour organization, but if they don\u2019t enjoy any of it, they won\u2019t stick around.\nEnjoyment doesn\u2019t necessarily mean having an annual party: people may enjoy\ncooking, coaching, or just working quietly beside others. There are several\nthings every organization should do to ensure that people are getting\nsomething they value out of their work:\n\nAsk people what they want rather than guessing.\n\n    \n\nJust as you are not your learners (Section 6.1), you are probably different\nfrom other members of your organization. Ask people what they want to do, what\nthey\u2019re comfortable doing (which may not be the same thing), and what\nconstraints there are on their time. They might say, \u201cAnything,\u201d but even a\nshort conversation will probably uncover the fact that they like interacting\nwith people but would rather not be managing the group\u2019s finances or vice\nversa.\n\nProvide many ways to contribute.\n\n    \n\nThe more ways there are for people to help, the more people will be able to.\nSomeone who doesn\u2019t like standing in front of an audience may be able to\nmaintain your organization\u2019s website, handle its accounts, or proofread\nlessons.\n\nRecognize contributions.\n\n    \n\nEveryone likes to be appreciated, so communities should acknowledge their\nmembers\u2019 contributions both publicly and privately by mentioning them in\npresentations, putting them on the website, and so on. Every hour that someone\nhas given your project may be an hour taken away from their personal life or\ntheir official employment; recognize that fact and make it clear that while\nmore hours would be welcome, you do not expect them to make unsustainable\nsacrifices.\n\nMake space.\n\n    \n\nYou think you\u2019re being helpful, but intervening in every decision robs people\nof their autonomy, which in return reduces their motivation (Section 10). In\nparticular, if you\u2019re always the first one to reply to email or chat messages,\npeople have less opportunity to grow as members and to create horizontal\ncollaborations. As a result, the community will continue to be centered around\none or two individuals rather than becoming a highly connected network in\nwhich others feel comfortable participating.\n\nAnother way to reward participation is to offer training. Organizations need\nbudgets, grant proposals, and dispute resolution. Most people are never taught\nhow to do this any more than they are taught how to teach, so the opportunity\nto gain transferable skills is a powerful reason for people to get and stay\ninvolved. If you are going to do this, don\u2019t try to provide the training\nyourself unless it\u2019s what you specialize in. Many civic and community groups\nhave programs of this kind, and you can probably make a deal with one of them.\n\nFinally, while volunteers can do a lot, tasks like system administration and\naccounting eventually need paid staff. When you reach this point, either pay\npeople nothing or pay them a proper wage. If you pay them nothing, their real\nreward is the satisfaction of doing good; if you pay them a token amount, on\nthe other hand, you take that away without giving them the satisfaction of\nearning a living.\n\n## Governance\n\nEvery organization has a power structure: the only question is whether it\u2019s\nformal and accountable or informal and therefore unaccountable [Free1972]. The\nlatter actually works pretty well for groups of up to half a dozen people in\nwhich everyone knows everyone else. Beyond that, you need rules to spell out\nwho has the authority to make which decisions and how to achieve consensus\n(Section 20.1).\n\nThe governance model I prefer is a commons, which is something managed jointly\nby a community according to rules they themselves have evolved and adopted\n[Ostr2015]. As [Boll2014] emphasizes, all three parts of that definition are\nessential: a commons isn\u2019t just a shared pasture or a set of software\nlibraries, but also includes the community that shares it and the rules they\nuse to do so.\n\nFor-profit corporations and incorporated nonprofits are more popular models;\nthe mechanics vary from jurisdiction to jurisdiction, so you should seek\nadvice before choosing^11. Both kinds of organization vest ultimate authority\nin their board. Broadly speaking, this is either a service board whose members\nalso take on other roles in the organization or a governance board whose\nprimary responsibility is to hire, monitor, and if need be fire the director.\nBoard members can be elected by the community or appointed; in either case,\nit\u2019s important to prioritize competence over passion (the latter being more\nimportant for the rank and file) and to try to recruit for particular skills\nsuch as accounting, marketing, and so on.\n\n> #### Choose Democracy\n>\n> When the time comes, make your organization a democracy: sooner or later\n> (usually sooner), every appointed board turns into a mutual agreement\n> society. Giving your members power is messy, but is the only way invented so\n> far to ensure that organizations continue to meet people\u2019s actual needs.\n\n## Look After Yourself\n\nBurnout is a chronic risk in any community activity [Pign2016], so learn to\nsay no more often than you say yes. If you don\u2019t take care of yourself, you\nwon\u2019t be able to take care of your community.\n\n> #### Running Out of \u201cNo\u201d\n>\n> Research in the 1990s seemed to show that our ability to exert willpower is\n> finite: if we have to resist eating the last donut in the box when we\u2019re\n> hungry, we are less likely to fold laundry and vice versa. This phenomenon\n> is called ego depletion, and while recent studies have failed to replicate\n> those early results [Hagg2016], saying \u201cyes\u201d when we\u2019re too tired to say\n> \u201cno\u201d is a trap many organizers fall into.\n\nOne way to make your \u201cno\u201d stick is to write a to-don\u2019t list of things that\nwould be worth doing but which you aren\u2019t going to do. At the time of writing,\nmine includes four books, two software projects, redesign of my personal\nwebsite, and learning to play the penny whistle.\n\nFinally, remind yourself every now and then that every organization eventually\nneeds fresh ideas and leadership. When that time comes, train your successors\nand move on as gracefully as you can. They will undoubtedly do things you\nwouldn\u2019t have, but few things in life are as satisfying as watching something\nyou helped build take on a life of its own. Celebrate that\u2014you won\u2019t have any\ntrouble finding something else to keep you busy.\n\n## Exercises\n\nSeveral of these exercises are taken from [Brow2007].\n\n### What Kind of Community? (individual/15)\n\nRe-read the description of the four types of communities and decide which\none(s) your group is or aspires to be.\n\n### People You May Meet (small groups/30)\n\nAs an organizer, part of your job is sometimes to help people find a way to\ncontribute despite themselves. In small groups, pick three of the people below\nand discuss how you would help them become a better contributor to your\norganization.\n\nAnna\n\n    \n\nknows more about every subject than everyone else put together\u2014at least, she\nthinks she does. No matter what you say, she\u2019ll correct you; no matter what\nyou know, she knows better.\n\nCatherine\n\n    \n\nhas so little confidence in her own ability that she won\u2019t make any decision,\nno matter how small, until she has checked with someone else.\n\nFrank\n\n    \n\nenjoys knowing things that other people don\u2019t. He can work miracles, but when\nasked how he did it, he\u2019ll grin and say, \u201cOh, I\u2019m sure you can figure it out.\u201d\n\nHediyeh\n\n    \n\nis quiet. She never speaks up in meetings, even when she knows other people\nare wrong. She might contribute to the mailing list, but she\u2019s very sensitive\nto criticism and always backs down instead of defending her point.\n\nKen\n\n    \n\ntakes advantage of the fact that most people would rather shoulder his share\nof the work than complain about him. The frustrating thing is that he\u2019s so\nplausible when someone finally does confront him. \u201cThere have been mistakes on\nall sides,\u201d he says, or, \u201cWell, I think you\u2019re nit-picking.\u201d\n\nMelissa\n\n    \n\nmeans well, but somehow something always comes up, and her tasks are never\nfinished until the last possible moment. Of course, that means that everyone\nwho is depending on her can\u2019t do their work until after the last possible\nmoment...\n\nRaj\n\n    \n\nis rude. \u201cIt\u2019s just the way I talk,\u201d he says. \u201cIf you can\u2019t hack it, go find\nanother team.\u201d His favorite phrase is, \u201cThat\u2019s stupid,\u201d and he uses an\nobscenity in every second sentence.\n\n### Values (small groups/45)\n\nAnswer these questions on your own, then compare your answers with others\u2019.\n\n  1. What are the values your organization expresses?\n\n  2. Are these the values you want the organization to express?\n\n  3. If not, what values would you like it to express?\n\n  4. What are specific behaviors that demonstrate those values?\n\n  5. What behaviors would demonstrate the opposite of those values?\n\n### Meeting Procedures (small groups/30)\n\nAnswer these questions on your own, then compare your answers with others\u2019.\n\n  1. How are your meetings run?\n\n  2. Is this how you want your meetings to be run?\n\n  3. Are the rules for running meetings explicit or just assumed?\n\n  4. Are these the rules you want?\n\n  5. Who is eligible to vote or make decisions?\n\n  6. Is this who you want to be vested with decision-making authority?\n\n  7. Do you use majority rule, make decisions by consensus, or something else?\n\n  8. Is this the way you want to make decisions?\n\n  9. How do people in a meeting know when a decision has been made?\n\n  10. How do people who weren\u2019t at a meeting know what decisions were made?\n\n  11. Is this working for your group?\n\n### Size (small groups/20)\n\nAnswer these questions on your own, then compare your answers with others\u2019.\n\n  1. How big is your group?\n\n  2. Is this the size you want for your organization?\n\n  3. If not, what size would you like it to be?\n\n  4. Do you have any limits on the size of membership?\n\n  5. Would you benefit from setting such a limit?\n\n### Becoming a Member (small groups/45)\n\nAnswer these questions on your own, then compare your answers with others\u2019.\n\n  1. How does someone join your group?\n\n  2. How well does this process work?\n\n  3. Are there membership dues?\n\n  4. Are people required to agree to any rules of behavior upon joining?\n\n  5. Are these the rules for behavior you want?\n\n  6. How does a newcomer find out what needs to be done?\n\n  7. How well does this process work?\n\n### Staffing (small groups/30)\n\nAnswer these questions on your own, then compare your answers with others\u2019.\n\n  1. Do you have paid staff in your organization or is everyone a volunteer?\n\n  2. Should you have paid staff?\n\n  3. Do you want/need more or less staff?\n\n  4. What do the staff members do?\n\n  5. Are these the primary roles and functions that you need staff to fill?\n\n  6. Who supervises your staff?\n\n  7. Is this the supervision process that you want for your group?\n\n  8. What is your staff paid?\n\n  9. Is this the right salary to get the needed work done?\n\n### Money (small groups/30)\n\nAnswer these questions on your own, then compare your answers with others\u2019.\n\n  1. Who pays for what?\n\n  2. Is this who you want to be paying?\n\n  3. Where do you get your money?\n\n  4. Is this how you want to get your money?\n\n  5. If not, do you have any plans to get it another way?\n\n  6. If so, what are they?\n\n  7. Who is following up to make sure that happens?\n\n  8. How much money do you have?\n\n  9. How much do you need?\n\n  10. What do you spend most of your money on?\n\n  11. Is this how you want to spend your money?\n\n### Borrowing Ideas (whole class/15)\n\nMany of my ideas about how to build a community have been shaped by my\nexperience in open source software development. [Foge2005] (which is available\nonline) is a good guide to what has and hasn\u2019t worked for those communities,\nand the Open Source Guides site has a wealth of useful information as well.\nChoose one section of the latter, such as \u201cFinding Users for Your Project\u201d or\n\u201cLeadership and Governance,\u201d and give a two-minute presentation to the group\nof one idea from it that you found useful or that you strongly disagreed with.\n\n### Who Are You? (small groups/20)\n\nThe National Oceanic and Atmospheric Administration (NOAA) has a short,\nuseful, and amusing guide to dealing with disruptive behaviors. It categorizes\nthose behaviors under labels like \u201ctalkative,\u201d \u201cindecisive,\u201d and \u201cshy,\u201d and\noutlines strategies for handling each. In groups of 3\u20136, read the guide and\ndecide which of these descriptions best fits you. Do you think the strategies\ndescribed for handling people like you are effective? Are other strategies\nequally or more effective?\n\n### Creating Lessons Together (small groups/30)\n\nOne of the keys to the success of the Carpentries is their emphasis on\nbuilding and maintaining lessons collaboratively [Wils2016,Deve2018]. Working\nin groups of 3\u20134:\n\n  1. Pick a short lesson you have all used.\n\n  2. Do a careful review to create a unified list of suggestions for improvements.\n\n  3. Offer those suggestions to the lesson\u2019s author.\n\n### Are You Crispy? (individual/10)\n\nJohnathan Nightingale wrote:\n\n> When I worked at Mozilla, we used the term \"crispy\" to refer to the state\n> right before burnout. People who are crispy aren\u2019t fun to be around. They\n> are curt. They are itching for a fight they can win. They cry without much\n> warning. ...we would recognize crispiness in our colleagues and take care of\n> each other [but] it is an ugly thing that we saw it so much that we had a\n> whole cultural process around it.\n\nAnswer \u201cyes\u201d or \u201cno\u201d to each of the following questions. How close are you to\nburning out?\n\n  * Have you become cynical or critical at work?\n\n  * Do you have to drag yourself to work or do you have trouble getting started?\n\n  * Have you become irritable or impatient with co-workers?\n\n  * Do you find it hard to concentrate?\n\n  * Do you fail to get satisfaction from your achievements?\n\n  * Are you using food, drugs or alcohol to feel better or to simply not feel?\n\n# Outreach\n\nIt\u2019s fashionable in tech circles to disparage universities and government\ninstitutions as slow-moving dinosaurs, but in my experience they are no worse\nthan companies of similar size. Your local school board, library, and your\ncity councilor\u2019s office may be able to offer space, funding, publicity,\nconnections with other groups that you may not have met yet, and a host of\nother useful things; getting to know them can help you solve or avoid problems\nin the short term and pay dividends down the road.\n\n## Marketing\n\nPeople with academic or technical backgrounds often think that marketing is\nabout spin and misdirection. In reality, it\u2019s about seeing things from other\npeople\u2019s perspective, understanding their wants and needs, and explaining how\nyou can help them\u2014in short, how to teach them. This chapter will look at how\nto use ideas from the previous chapters to get people to understand and\nsupport what you\u2019re doing.\n\nThe first step is to figure out what you are offering to whom, i.e. what\nactually brings in the volunteers, funding, and other support you need to keep\ngoing. The answer is often counter-intuitive. For example, most scientists\nthink their papers are their product, but it\u2019s actually their grant proposals,\nbecause those are what brings in grant money [Kuch2011]. Their papers are the\nadvertising that persuades people to fund those proposals, just as albums are\nnow what persuades people to buy musicians\u2019 concert tickets and t-shirts.\n\nSuppose that your group offers weekend programming workshops to people who are\nre-entering the workforce after being away for several years. If workshop\nparticipants can pay enough to cover your costs, then they are your customers\nand the workshops are the product. If, on the other hand, the workshops are\nfree or the learners are only paying a token amount to cut the no-show rate,\nthen your actual product may be some mix of:\n\n  * your grant proposals;\n\n  * the alumni of your workshops that the companies sponsoring you would like to hire;\n\n  * the half-page summary of your workshops in the mayor\u2019s annual report to city council that shows how she\u2019s supporting the local tech sector; or\n\n  * the personal satisfaction that volunteers get from teaching.\n\nAs with lesson design (Chapter 6), the first steps in marketing are to create\npersonas of people who might be interested in what you\u2019re doing and to figure\nout which of their needs you can meet. One way to summarize the latter is to\nwrite elevator pitches aimed at different personas. A widely used template for\nthese is:\n\nFor| target audience  \n---|---  \nwho| dissatisfaction with what\u2019s currently available  \nour| category  \nprovide| key benefit.  \nUnlike| alternatives  \nour program| key distinguishing feature.  \n  \nContinuing the weekend workshop example, we could use this pitch for\nparticipants:\n\n> For people re-entering the workforce after being away for several years who\n> still have family responsibilities, our introductory programming workshops\n> provide weekend classes with on-site childcare. Unlike online classes, our\n> program gives people a chance to meet others at the same stage of life.\n\nand this one for decision makers at companies that might sponsor the\nworkshops:\n\n> For companies that want to recruit entry-level software developers that\n> struggle to find mature candidates from diverse backgrounds our introductory\n> programming workshops provide potential recruits. Unlike college recruiting\n> fairs, our program connects companies with a wide variety of candidates.\n\nIf you don\u2019t know why different potential stakeholders might be interested in\nwhat you\u2019re doing, ask them. If you do know, ask them anyway: answers can\nchange over time, and you may discover things you previously overlooked.\n\nOnce you have these pitches, they should drive what you put on your website\nand in publicity material to help people figure out as quickly as possible if\nyou and they have something to talk about. (You probably shouldn\u2019t copy them\nverbatim, though: many people in tech have seen this template so often that\ntheir eyes will glaze over if they encounter it again.)\n\nAs you are writing these pitches, remember that there are many reasons to\nlearn how to program (Section 1.4). A sense of accomplishment, control over\ntheir own lives, and being part of a community may motivate people more than\nmoney (Chapter 10). They might volunteer to teach with you because their\nfriends are doing it; similarly, a company may say that they\u2019re sponsoring\nclasses for economically disadvantaged high school students because they want\na larger pool of potential employees further down the road, but the CEO might\nactually be doing it simply because it\u2019s the right thing to do.\n\n## Branding and Positioning\n\nA brand is someone\u2019s first reaction to a mention of a product; if the reaction\nis \u201cwhat\u2019s that?\u201d, you don\u2019t have a brand (yet). Branding is important because\npeople aren\u2019t going to help something they don\u2019t know about or don\u2019t care\nabout.\n\nMost discussion of branding today focuses on how to build awareness online.\nMailing lists, blogs, and Twitter all give you ways to reach people, but as\nthe volume of misinformation increases, people pay less attention to each\nindividual interruption. This makes positioning ever more important. Sometimes\ncalled \u201cdifferentiation,\u201d it is what sets your offering apart from others\u2014the\n\u201cunlike\u201d section of your elevator pitches. When you reach out to people who\nare already familiar with your field, you should emphasize your positioning,\nsince it\u2019s what will catch their attention.\n\nThere are other things you can do to help build your brand. One is to use\nprops like a robot that one of your learners made from scraps she found around\nthe house [Schw2013] or the website another learner made for his parents\u2019\nretirement home. Another is to make a short video\u2014no more than a few minutes\nlong\u2014that showcases the backgrounds and accomplishments of your learners. The\naim of both is to tell a story: while people always ask for data, they believe\nand remember stories.\n\n> #### Foundational Myths\n>\n> One of the most compelling stories a person or group can tell is why and how\n> they got started. Are you teaching what you wish someone had taught you but\n> didn\u2019t? Was there one particular person you wanted to help, and that opened\n> the floodgates? If there isn\u2019t a section on your website starting, \u201cOnce\n> upon a time,\u201d think about adding one.\n\nOne crucial step is to make your organization findable in online searches.\n[DiSa2014b] discovered that the search terms that parents used for out-of-\nschool computing classes didn\u2019t actually find those classes, and many other\ngroups face similar challenges. There\u2019s a lot of folklore about how to make\nthings findable (otherwise known as search engine optimization or SEO); given\nGoogle\u2019s near-monopoly powers and lack of transparency, most of it boils down\nto trying to stay one step ahead of algorithms designed to prevent people from\ngaming rankings.\n\nUnless you\u2019re very well funded, the best you can do is to search for yourself\nand your organization on a regular basis and see what comes up, then read\nthese guidelines and do what you can to improve your site. Keep this XKCD\ncartoon in mind: people don\u2019t want to know about your org chart or get a\nvirtual tour of your site\u2014they want your address, parking information, and\nsome idea of what you teach, when you teach it, and how it\u2019s going to change\ntheir lives.\n\n> #### Not Everyone Lives Online\n>\n> These examples assume people have access to the internet and that groups\n> have money, materials, free time, and/or technical skills. Many don\u2019t\u2014in\n> fact, those serving economically disadvantaged groups almost certainly\n> don\u2019t. (As Rosario Robinson says, \u201cFree works for those that can afford\n> free.\u201d) Stories are more important than course outlines in those situations\n> because they are easier to retell. Similarly, if the people you hope to\n> reach are not online as often as you, then notice boards in schools, local\n> libraries, drop-in centers, and grocery stores may be the most effective way\n> to reach them.\n\n## The Art of the Cold Call\n\nBuilding a website and hoping that people find it is easy; calling people up\nor knocking on their door without any sort of prior introduction is much\nharder. As with standing up and teaching, though, it\u2019s a craft that can be\nlearned. Here are ten simple rules for talking people into things:\n\n1: Don\u2019t.\n\n    \n\nIf you have to talk someone into something, odds are that they don\u2019t really\nwant to do it. Respect that: it\u2019s almost always better in the long run to\nleave some particular thing undone than to use guilt or any underhanded\npsychological tricks that will only engender resentment.\n\n2: Be kind.\n\n    \n\nI don\u2019t know if there actually is a book called Secret Tricks of the Ninja\nSales Masters, but if there is, it probably tells readers that doing something\nfor a potential customer creates a sense of obligation, which in turn\nincreases the odds of a sale. That may work, but it only works once and it\u2019s a\nskeezy thing to do. On the other hand, if you are genuinely kind and help\nother people because it\u2019s what good people do, you just might inspire them to\nbe good people too.\n\n3: Appeal to the greater good.\n\n    \n\nIf you open by talking about what\u2019s in it for them, you are signaling that\nthey should think of their interaction with you as a commercial exchange of\nvalue to be bargained over. Instead, start by explaining how whatever you want\nthem to help with is going to make the world a better place, and mean it. If\nwhat you\u2019re proposing isn\u2019t going to make the world a better place, propose\nsomething better.\n\n4: Start small.\n\n    \n\nMost people are understandably reluctant to dive into things head-first, so\ngive them a chance to test the waters and to get to know you and everyone else\ninvolved in whatever it is you want help with. Don\u2019t be surprised or\ndisappointed if that\u2019s where things end: everyone is busy or tired or has\nprojects of their own, or maybe just has a different mental model of how\ncollaboration is supposed to work. Remember the 90-9-1 rule\u201490% of people will\nwatch, 9% will speak up, and 1% will actually do things\u2014and set your\nexpectations accordingly.\n\n5: Don\u2019t build a project: build a community.\n\n    \n\nI used to belong to a baseball team that never actually played baseball: our\n\u201cgames\u201d were just an excuse for us to hang out and enjoy each other\u2019s company.\nYou probably don\u2019t want to go quite that far, but sharing a cup of tea with\nsomeone or celebrating the birth of their first grandchild can get you things\nthat no reasonable amount of money can.\n\n6: Establish a point of connection.\n\n    \n\n\u201cI was speaking to X\u201d or \u201cwe met at Y\u201d gives them context, which in turn makes\nthem more comfortable. This must be specific: spammers and cold-callers have\ntrained us all to ignore anything that starts, \u201cI recently came across your\nwebsite...\u201d\n\n7: Be specific about what you are asking for.\n\n    \n\nPeople need to know this so that they can figure out whether the time and\nskills they have are a match for what you need. Being realistic up front is\nalso a sign of respect: if you tell people you need a hand moving a few boxes\nwhen you\u2019re actually packing up an entire house, they\u2019re probably not going to\nhelp you a second time.\n\n8: Establish your credibility.\n\n    \n\nMention your backers, your size, how long your group has been around, or\nsomething that you\u2019ve accomplished in the past so that they\u2019ll believe you\u2019re\nworth taking seriously.\n\n9: Create a slight sense of urgency.\n\n    \n\n\u201cWe\u2019re hoping to launch this in the spring\u201d is more likely to get a positive\nresponse than \u201cWe\u2019d eventually like to launch this.\u201d However, the word\n\u201cslight\u201d is important: if your request is urgent, most people will assume\nyou\u2019re disorganized or that something has gone wrong and may then err on the\nside of prudence.\n\n10: Take a hint.\n\n    \n\nIf the first person you ask for help says no, ask someone else. If the fifth\nor the tenth person says no, ask yourself if what you\u2019re trying to do makes\nsense and is worth doing.\n\nThe email template below follows all of these rules. It has worked pretty\nwell: we found that about half of emails were answered, about half of those\nwanted to talk more, and about half of those led to workshops, which means\nthat 10\u201315% of targeted emails turned into workshops. That can still be pretty\ndemoralizing if you\u2019re not used to it, but is much better than the 2\u20133%\nresponse rate most organizations expect with cold calls.\n\n> Hi NAME,\n>\n> I hope you don\u2019t mind mail out of the blue, but I wanted to follow up on our\n> conversation at VENUE to see if you would be interested in having us run a\n> teacher training workshop\u2014we\u2019re scheduling the next batch over the next\n> couple of weeks.\n>\n> This one-day workshop will teach your volunteers a handful of practical,\n> evidence-based teaching practices. It has been run over a hundred times in\n> various forms on six continents for nonprofit organizations, libraries, and\n> companies, and all of the material is freely available online at\n> http://teachtogether.tech. Topics will include:\n>\n>   * learner personas\n>\n>   * differences between different kinds of learners\n>\n>   * using formative assessment to diagnose misunderstandings\n>\n>   * teaching as a performance art\n>\n>   * what motivates and demotivates adult learners\n>\n>   * the importance of inclusivity and how to be a good ally\n>\n>\n\n>\n> If this sounds interesting, please give me a shout\u2014I\u2019d welcome a chance to\n> talk ways and means.\n>\n> Thanks,\n>\n> NAME\n\n> #### Referrals\n>\n> Building alliances with other groups that are doing things related to your\n> work pays off in many ways. One of those is referrals: if someone who\n> approaches you for help would be better served by some other organization,\n> take a moment to make an introduction. If you\u2019ve done this several times,\n> add something to your website to help the next person find what they need.\n> The organizations you are helping will soon start to help you in return.\n\n## Academic Change\n\nEveryone is afraid of the unknown and of embarrassing themselves. As a result,\nmost people would rather fail than change. For example, Lauren Herckis looked\nat why university faculty don\u2019t adopt better teaching methods. She found that\nthe main reason is a fear of looking stupid in front of learners; secondary\nreasons were concern that the inevitable bumps in changing teaching methods\nwould affect course evaluations (which could in turn affect promotion and\ntenure) and people\u2019s desire to continue emulating the teachers who had\ninspired them. It\u2019s pointless to argue about whether these issues are \u201creal\u201d\nor not: faculty believe they are, so any plan to work with faculty needs to\naddress them^12.\n\n[Bark2015] did a two-part study of how computer science educators adopt new\nteaching practices as individuals, organizationally, and in society as a\nwhole. They asked and answered three key questions:\n\nHow do faculty hear about new teaching practices?\n\n    \n\nThey intentionally seek out new practices because they\u2019re motivated to solve a\nproblem (particularly student engagement), are made aware through deliberate\ninitiatives by their institutions, pick them up from colleagues, or get them\nfrom expected and unexpected interactions at conferences (teaching-related or\notherwise).\n\nWhy do they try them out?\n\n    \n\nSometimes because of institutional incentives (e.g. they innovate to improve\ntheir chances of promotion), but there is often tension at research\ninstitutions where rhetoric about the importance of teaching is largely\ndisbelieved. Another important reason is their own cost/benefit analysis: will\nthe innovation save them time? A third is that they are inspired by role\nmodels\u2014again, this largely affects innovations aimed to improve engagement and\nmotivation rather than learning outcomes\u2014and a fourth is trusted sources, e.g.\npeople they meet at conferences who are in the same situation they are and\nreported successful adoption.\n\nBut faculty had concerns that were often not addressed by people advocating\nchanges. The first was Glass\u2019s Law: any new tool or practice initially slows\nyou down, so while new practices might make teaching more effective in the\nlong run, they can\u2019t be afforded in the short run. Another is that the\nphysical layout of classrooms makes many new practices hard: for example,\ndiscussion groups don\u2019t work well in theater-style seating.\n\nBut the most telling result was this: \u201cDespite being researchers themselves,\nthe CS faculty we spoke to for the most part did not believe that results from\neducational studies were credible reasons to try out teaching practices.\u201d This\nis consistent with other findings: even people whose entire careers are\ndevoted to research often disregard educational research.\n\nWhy do they keep using them?\n\n    \n\nAs [Bark2015] says, \u201cStudent feedback is critical,\u201d and is often the strongest\nreason to continue using a practice, even though we know that learners\u2019 self-\nreports don\u2019t correlate strongly with learning outcomes [Star2014,Uttl2017]\n(though attendance in lectures is a good indicator of engagement). Another\nreason to retain a practice is institutional requirements, although if this is\nthe only motivation, people will often drop the practice when the explicit\nincentive or monitoring is removed.\n\nThe good news is that you can tackle these problems systematically. [Baue2015]\nlooked at adoption of new medical techniques within the US Veterans\nAdministration. They found that evidence-based practices in medicine take an\naverage of 17 years to be incorporated into routine general practice, and that\nonly about half of such practices are ever widely adopted. This depressing\nfinding and others like it spurred the growth of implementation science, which\nis the study of how to get people to adopt better practices.\n\nAs Chapter 13 said, the starting point is to find out what the people you\u2019re\ntrying to help believe they need. For example, [Yada2016] summarizes feedback\nfrom K-12 teachers on the preparation and support they want. While it may not\nall be applicable to all settings, having a cup of tea with a few people and\nlistening before you speak makes a world of difference to their willingness to\ntry something new.\n\nOnce you know what people need, the next step is to make changes\nincrementally, within institutions\u2019 own frameworks. [Nara2018] describes an\nintensive three-year bachelor\u2019s program based on tight-knit cohorts and\nadministrative support that tripled graduation rates, while [Hu2017] describes\nthe impact of introducing a six-month certification program for existing high\nschool teachers who want to teach computing. The number of computing teachers\nhad been stable from 2007 to 2013, but quadrupled after introduction of the\nnew certification program without diluting quality: new-to-computing teachers\nseemed to be as effective as teachers with more computing training at teaching\nthe introductory course.\n\nMore broadly, [Borr2014] categorizes ways to make change happen in higher\neducation. The categories are defined by whether the change is individual or\nsystemic and whether it is prescribed (top-down) or emergent (bottom-up). The\nperson trying to make the changes (and make them stick) has a different role\nin each situation, and should pursue different strategies accordingly. The\npaper goes on to explain each of the methods in detail, while\n[Hend2015a,Hend2015b] present the same ideas in more actionable form.\n\nComing from outside, you will probably fall into the Individual/Emergent\ncategory to start with, since you will be approaching teachers one by one and\ntrying to make change happen bottom-up. If this is the case, the strategies\nBorrego and Henderson recommend center around having teachers reflect on their\nteaching individually or in groups. Live coding to show them what you do or\nthe examples you use, then having them live code in turn to show how they\nwould use those ideas and techniques in their setting, gives everyone a chance\nto pick up things that will be useful to them in their context.\n\n## Free-Range Teaching\n\nSchools and universities aren\u2019t the only places people go to learn\nprogramming; over the past few years, a growing number have turned to free-\nrange workshops and intensive bootcamp programs. The latter are typically one\nto six months long, run by volunteer groups or by for-profit companies, and\ntarget people who are retraining to get into tech. Some are very high quality,\nbut others exist primarily to separate people from their money [McMi2017].\n\n[Thay2017] interviewed 26 alumni of such bootcamps that provide a second\nchance for those who missed computing education opportunities earlier (though\nphrasing it this way makes some pretty big assumptions when it comes to people\nfrom underrepresented groups). Bootcamp participants face great personal costs\nand risks: they must spend significant time, money, and effort before, during,\nand after bootcamps, and changing careers can take a year or more. Several\ninterviewees felt that their certificates were looked down on by employers; as\nsome said, getting a job means passing an interview, but since interviewers\noften won\u2019t share their reasons for rejection, it\u2019s hard to know what to fix\nor what else to learn. Many resorted to internships (paid or otherwise) and\nspent a lot of time building their portfolios and networking. The three\ninformal barriers they most clearly identified were jargon, impostor syndrome,\nand a sense of not fitting in.\n\n[Burk2018] dug into this a bit deeper by comparing the skills and credentials\nthat tech industry recruiters are looking for to those provided by four-year\ndegrees and bootcamps. Based on interviews with 15 hiring managers from firms\nof various sizes and some focus groups, they found that recruiters uniformly\nemphasized soft skills (especially teamwork, communication, and the ability to\ncontinue learning). Many companies required a four-year degree (though not\nnecessarily in computer science), but many also praised bootcamp graduates for\nbeing older or more mature and having more up-to-date knowledge.\n\nIf you are approaching an existing bootcamp, your best strategy could be to\nemphasize what you know about teaching rather than what you know about tech,\nsince many of their founders and staff have programming backgrounds but little\nor no training in education. The first few chapters of this book have played\nwell with this audience in the past, and [Lang2016] describes evidence-based\nteaching practices that can be put in place with minimal effort and at low\ncost. These may not have the most impact, but scoring a few early wins helps\nbuild support for larger efforts.\n\n## Final Thoughts\n\nIt is impossible to change large institutions on your own: you need allies,\nand to get allies, you need tactics. The most useful guide I have found is\n[Mann2015], which catalogs more than four dozen of these and organizes them\naccording to whether they\u2019re best deployed early, later, throughout the change\ncycle, or when you encounter resistance. A handful of their patterns include:\n\nIn Your Space:\n\n    \n\nKeep the new idea visible by placing reminders throughout the organization.\n\nToken:\n\n    \n\nTo keep a new idea alive in a person\u2019s memory, hand out tokens that can be\nidentified with the topic being introduced.\n\nChampion Skeptic:\n\n    \n\nAsk strong opinion leaders who are skeptical of your new idea to play the role\nof \u201cofficial skeptic.\u201d Use their comments to improve your effort, even if you\ndon\u2019t change their minds.\n\nFuture Commitment:\n\n    \n\nIf you are able to anticipate some of your needs, you can ask for a future\ncommitment from busy people. If given some lead time, they may be more willing\nto help.\n\nThe most important strategy is to be willing to change your goals based on\nwhat you learn from the people you are trying to help. Tutorials showing them\nhow to use a spreadsheet might help them more quickly and more reliably than\nan introduction to JavaScript. I have often made the mistake of confusing\nthings I was passionate about with things that other people ought to know; if\nyou truly want to be a partner, always remember that learning and change have\nto go both ways.\n\nThe hardest part about building relationships is getting started. Set aside an\nhour or two every month to find allies and maintain your relationships with\nthem. One way to do this is to ask them for advice: how do they think you\nought to raise awareness of what you\u2019re doing? Where have they found space to\nrun classes? What needs do they think aren\u2019t being met and would you be able\nto meet them? Any group that has been around for a few years will have useful\nadvice; they will also be flattered to be asked, and will know who you are the\nnext time you call.\n\nAnd as [Kuch2011] says, if you can\u2019t be first in a category, try to create a\nnew category that you can be first in. If you can\u2019t do that, join an existing\ngroup or think about doing something else entirely. This isn\u2019t defeatist: if\nsomeone else is already doing what you have in mind, you should either chip in\nor tackle one of the other equally useful things you could be doing instead.\n\n## Exercises\n\n### Pitching a City Councilor (individual/10)\n\nThis chapter described an organization that offers weekend programming\nworkshops for people re-entering the workforce. Write an elevator pitch for\nthat organization aimed at a city councilor whose support the organization\nneeds.\n\n### Pitching Your Organization (individual/30)\n\nIdentify two groups of people your organization needs support from and write\nan elevator pitch aimed at each one.\n\n### Email Subjects (pairs/10)\n\nWrite the subject lines (and only the subject lines) for three email messages:\none announcing a new course, one announcing a new sponsor, and one announcing\na change in project leadership. Compare your subject lines to a partner\u2019s and\nsee if you can merge the best features of each while also shortening them.\n\n### Handling Passive Resistance (small groups/30)\n\nPeople who don\u2019t want change will sometimes say so out loud, but may also\noften use various forms of passive resistance, such as just not getting around\nto it over and over again, or raising one possible problem after another to\nmake the change seem riskier and more expensive than it\u2019s actually likely to\nbe [Scot1987]. Working in small groups, list three or four reasons why people\nmight not want your teaching initiative to go ahead, and explain what you can\ndo with the time and resources you have to counteract each.\n\n### Why Learn to Program? (individual/15)\n\nRevisit the \u201cWhy Learn to Program?\u201d exercise in Section 1.4. Where do your\nreasons for teaching and your learners\u2019 reasons for learning align? Where do\nthey not? How does that affect your marketing?\n\n### Conversational Programmers (think-pair-share/15)\n\nA conversational programmer is someone who needs to know enough about\ncomputing to have a meaningful conversation with a programmer, but isn\u2019t going\nto program themselves. [Wang2018] found that most learning resources don\u2019t\naddress this group\u2019s needs. Working in pairs, write a pitch for a half-day\nworkshop intended to help people that fit this description and then share your\npair\u2019s pitch with the rest of the class.\n\n### Collaborations (small groups/30)\n\nAnswer the following questions on your own, then compare your answers to those\ngiven by other members of your group.\n\n  1. Do you have any agreements or relationships with other groups?\n\n  2. Do you want to have relationships with any other groups?\n\n  3. How would having (or not having) collaborations help you to achieve your goals?\n\n  4. What are your key collaborative relationships?\n\n  5. Are these the right collaborators for achieving your goals?\n\n  6. What groups or entities would you like your organization to have agreements or relationships with?\n\n### Educationalization (whole class/10)\n\n[Laba2008] explores why the United States and other countries keep pushing the\nsolution of social problems onto educational institutions and why that\ncontinues not to work. As he points out, \u201c[Education] has done very little to\npromote equality of race, class, and gender; to enhance public health,\neconomic productivity, and good citizenship; or to reduce teenage sex, traffic\ndeaths, obesity, and environmental destruction. In fact, in many ways it has\nhad a negative effect on these problems by draining money and energy away from\nsocial reforms that might have had a more substantial impact.\u201d He goes on to\nwrite:\n\n> So how are we to understand the success of this institution in light of its\n> failure to do what we asked of it? One way of thinking about this is that\n> education may not be doing what we ask, but it is doing what we want. We\n> want an institution that will pursue our social goals in a way that is in\n> line with the individualism at the heart of the liberal ideal, aiming to\n> solve social problems by seeking to change the hearts, minds, and capacities\n> of individual students. Another way of putting this is that we want an\n> institution through which we can express our social goals without violating\n> the principle of individual choice that lies at the center of the social\n> structure, even if this comes at the cost of failing to achieve these goals.\n> So education can serve as a point of civic pride, a showplace for our\n> ideals, and a medium for engaging in uplifting but ultimately\n> inconsequential disputes about alternative visions of the good life. At the\n> same time, it can also serve as a convenient whipping boy that we can blame\n> for its failure to achieve our highest aspirations for ourselves as a\n> society.\n\nHow do efforts to teach computational thinking and digital citizenship in\nschools fit into this framework? Do bootcamps avoid these traps or simply\ndeliver them in a new guise?\n\n### Institutional Adoption (whole class/15)\n\nRe-read the list of motivations to adopt new practices given in Section 14.4.\nWhich of these apply to you and your colleagues? Which are irrelevant to your\ncontext? Which do you emphasize if and when you interact with people working\nin formal educational institutions?\n\n### If At First You Don\u2019t Succeed (small groups/15)\n\nW.C. Fields probably never said, \u201cIf at first you don\u2019t succeed, try, try\nagain. Then quit\u2014there\u2019s no use being a damn fool about it.\u201d It\u2019s still good\nadvice: if the people you\u2019re trying to reach aren\u2019t responding, it could be\nthat you\u2019ll never convince them. In groups of 3\u20134, make a short list of signs\nthat you should stop trying to do something you believe in. How many of them\nare already true?\n\n### Making It Fail (individual/15)\n\n[Farm2006] presents some tongue-in-cheek rules for ensuring that new tools\naren\u2019t adopted, all of which apply to new teaching practices:\n\n  1. Make it optional.\n\n  2. Economize on training.\n\n  3. Don\u2019t use it in a real project.\n\n  4. Never integrate it.\n\n  5. Use it sporadically.\n\n  6. Make it part of a quality initiative.\n\n  7. Marginalize the champion.\n\n  8. Capitalize on early missteps.\n\n  9. Make a small investment.\n\n  10. Exploit fear, uncertainty, doubt, laziness, and inertia.\n\nWhich of these have you seen done recently? Which have you done yourself? What\nform did they take?\n\n### Mentoring (whole class/15)\n\nThe Institute for African-American Mentoring in Computer Science has published\nguidelines for mentoring doctoral students. Read them individually, then go\nthrough them as a class and rate your efforts for your own group as +1\n(definitely doing), 0 (not sure or not applicable), or -1 (definitely not\ndoing).\n\n# Why I Teach\n\nWhen I started volunteering at the University of Toronto, some of my students\nasked me why I would teach for free. This was my answer:\n\n> When I was your age, I thought universities existed to teach people how to\n> learn. Later, in grad school, I thought universities were about doing\n> research and creating new knowledge. Now that I\u2019m in my forties, though,\n> I\u2019ve realized that what we\u2019re really teaching you is how to take over the\n> world, because you\u2019re going to have to whether you want to or not.\n>\n> My parents are in their seventies. They don\u2019t run the world any more; it\u2019s\n> people my age who pass laws and make life-and-death decisions in hospitals.\n> As scary as it is, we are the grownups.\n>\n> Twenty years from now, we\u2019ll be heading for retirement and you will be in\n> charge. That may sound like a long time when you\u2019re nineteen, but take three\n> breaths and it\u2019s gone. That\u2019s why we give you problems whose answers can\u2019t\n> be cribbed from last year\u2019s notes. That\u2019s why we put you in situations where\n> you have to figure out what needs to be done right now, what can be left for\n> later, and what you can simply ignore. It\u2019s because if you don\u2019t learn how\n> to do these things now, you won\u2019t be ready to do them when you have to.\n\nIt was all true, but it wasn\u2019t the whole story. I don\u2019t want people to make\nthe world a better place so that I can retire in comfort. I want them to do it\nbecause it\u2019s the greatest adventure of our time. A hundred and fifty years\nago, most societies practiced slavery. A hundred years ago, my grandmother\nwasn\u2019t legally a person in Canada. In the year I was born, most of the world\u2019s\npeople suffered under totalitarian rule, and judges were still ordering\nelectroshock therapy to \u201ccure\u201d homosexuals. There\u2019s still a lot wrong with the\nworld, but look at how many more choices we have than our grandparents did.\nLook at how many more things we can know, and be, and enjoy because we\u2019re\nfinally taking the Golden Rule seriously.\n\nI am less optimistic today than I was then. Climate change, mass extinction,\nsurveillance capitalism, inequality on a scale we haven\u2019t seen in a century,\nthe re-emergence of racist nationalism: my generation has watched it all\nhappen and shrugged. The bill for our cowardice, lethargy, and greed won\u2019t\ncome due until my daughter is grown, but it will come, and by the time it does\nthere will be no easy solutions to these problems (and possibly no solutions\nat all).\n\nSo this is why I teach today: I\u2019m angry. I\u2019m angry because your sex and your\ncolor and your parents\u2019 wealth and connections shouldn\u2019t count for more than\nhow smart or honest or hard-working you are. I\u2019m angry because we turned the\ninternet into a cesspool. I\u2019m angry because Nazis are on the march once again\nand billionaires are playing with rocket ships while the planet is melting.\nI\u2019m angry, so I teach, because the world only gets better when we teach people\nhow to make it better.\n\nIn his 1947 essay \u201cWhy I Write\u201d, George Orwell wrote:\n\n> In a peaceful age I might have written ornate or merely descriptive books,\n> and might have remained almost unaware of my political loyalties. As it is I\n> have been forced into becoming a sort of pamphleteer... Every line of\n> serious work that I have written since 1936 has been written, directly or\n> indirectly, against totalitarianism... It seems to me nonsense, in a period\n> like our own, to think that one can avoid writing of such subjects. Everyone\n> writes of them in one guise or another. It is simply a question of which\n> side one takes.\n\nReplace \u201cwriting\u201d with \u201cteaching\u201d and you\u2019ll have the reason I do what I do.\n\nThank you for reading\u2014I hope we can teach together some day. Until then:\n\nStart where you are. Use what you have. Help who you can.\n\n# License\n\nThis is a human-readable summary of (and not a substitute for) the license.\nPlease see https://creativecommons.org/licenses/by-nc/4.0/legalcode for the\nfull legal text.\n\nThis work is licensed under the Creative Commons Attribution-NonCommercial 4.0\nlicense (CC-BY-NC-4.0). You are free to:\n\n  * Share\u2014copy and redistribute the material in any medium or format\n\n  * Adapt\u2014remix, transform, and build upon the material.\n\nThe licensor cannot revoke these freedoms as long as you follow the license\nterms.\n\nUnder the following terms:\n\n  * Attribution\u2014You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n\n  * NonCommercial\u2014You may not use the material for commercial purposes.\n\nNo additional restrictions\u2014You may not apply legal terms or technological\nmeasures that legally restrict others from doing anything the license permits.\n\nNotices:\n\n  * You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.\n\n  * No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.\n\n# Code of Conduct\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to making participation in our project and\nour community a harassment-free experience for everyone, regardless of age,\nbody size, disability, ethnicity, gender identity and expression, level of\nexperience, education, socioeconomic status, nationality, personal appearance,\nrace, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n  * using welcoming and inclusive language,\n\n  * being respectful of differing viewpoints and experiences,\n\n  * gracefully accepting constructive criticism,\n\n  * focusing on what is best for the community, and\n\n  * showing empathy towards other community members.\n\nExamples of unacceptable behavior by participants include:\n\n  * the use of sexualized language or imagery and unwelcome sexual attention or advances,\n\n  * trolling, insulting/derogatory comments, and personal or political attacks,\n\n  * public or private harassment,\n\n  * publishing others\u2019 private information, such as a physical or electronic address, without explicit permission, and\n\n  * other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces\nwhen an individual is representing the project or its community. Examples of\nrepresenting a project or community include using an official project e-mail\naddress, posting via an official social media account, or acting as an\nappointed representative at an online or offline event. Representation of a\nproject may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by emailing the project\u2019s maintainer at gvwilson@third-bit.com. All\ncomplaints will be reviewed and investigated and will result in a response\nthat is deemed necessary and appropriate to the circumstances. The project\nteam is obligated to maintain confidentiality with regard to the reporter of\nan incident. Further details of specific enforcement policies may be posted\nseparately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project\u2019s leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the Contributor Covenant version 1.4.\n\n# Joining Our Community\n\nWe hope you will choose to help us make this book better. If you are new to\nworking in this collaborative way, please see Appendix 17 for our code of\nconduct, and then:\n\nStart small.\n\n    \n\nFix a typo, clarify the wording of an exercise, correct or update a citation,\nor suggest a better example or analogy to illustrate some point.\n\nJoin the conversation.\n\n    \n\nHave a look at the issues and proposed changes that other people have already\nfiled and add your comments to them. It\u2019s often possible to improve\nimprovements, and it\u2019s a good way to introduce yourself to the community and\nmake new friends.\n\nDiscuss, then edit.\n\n    \n\nIf you want to propose a large change, such as reorganizing or splitting an\nentire chapter, please file an issue that outlines your proposal and your\nreasoning and tag it with \u201cProposal.\u201d We encourage everyone to add comments to\nthese issues so that the whole discussion of what and why is in the open and\ncan be archived. If the proposal is accepted, the actual work may then be\nbroken down into several smaller issues or changes that can be tackled\nindependently.\n\n## Using This Material\n\nAs Chapter 1 stated, all of this material can be freely distributed and re-\nused under the Creative Commons Attribution-NonCommercial 4.0 license\n(Appendix 16). You can use the online version at http://teachtogether.tech/ in\nany class (free or paid), and can quote short excerpts under fair use\nprovisions, but cannot republish large parts in commercial works without prior\npermission.\n\nThis material has been used in many ways, from a multi-week online class to an\nintensive in-person workshop. It\u2019s usually possible to cover large parts of\nChapter 2 to Chapter 6, Chapter 8, and Chapter 10 in two long days.\n\n### In Person\n\nThis is the most effective way to deliver this training, but also the most\ndemanding. Participants are physically together. When they need to practice\nteaching in small groups, some or all of them go to nearby breakout spaces.\nParticipants use their own tablets or laptops to view online material during\nthe class and for shared note-taking (Section 9.7), and use pen and paper or\nwhiteboards for other exercises. Questions and discussion are done aloud.\n\nIf you are teaching in this format, you should use sticky notes as status\nflags so that you can see who needs help, who has questions, and who\u2019s ready\nto move on (Section 9.8). You should also use them to distribute attention so\nthat everyone gets a fair share of the teacher\u2019s time, and as minute cards to\nencourage learners to reflect on what they\u2019ve just learned and to give you\nactionable feedback while you still have time to act on it.\n\n### Online in Groups\n\nIn this format, 10\u201340 learners are together in 2\u20136 groups of 4\u201312, but those\ngroups are geographically distributed. Each group uses one camera and\nmicrophone to connect to the video call, rather than each person being on the\ncall separately. Good audio matters more than good video in both directions: a\nvoice with no images (like radio) is much easier to understand than images\nwith no narrative, and instructors do not have to be able to see people to\nanswer questions so long as those questions can be heard clearly. That said,\nif a lesson isn\u2019t accessible then it\u2019s not useful (Section 10.3): providing\ndescriptive text helps everyone when audio quality is poor, and everyone with\nhearing challenges even when it\u2019s not.\n\nThe entire class does shared note-taking together, and also uses the shared\nnotes for asking and answering questions. Having several dozen people try to\ntalk on a call works poorly, so in most sessions, the teacher does the talking\nand learners respond through the note-taking tool\u2019s chat.\n\n### Online as Individuals\n\nThe natural extension of being online in groups is to be online as\nindividuals. As with online groups, the teacher will do most of the talking\nand learners will mostly participate via text chat. Good audio is once again\nmore important than good video, and participants should use text chat to\nsignal that they want to speak next (Appendix 20).\n\nHaving participants online individually makes it more difficult to draw and\nshare concept maps (Section 3.4) or give feedback on teaching (Section 8.5).\nTeachers should therefore rely more on exercises with written results that can\nbe put in the shared notes, such as giving feedback on stock videos of people\nteaching.\n\n### Multi-Week Online\n\nThe class meets every week for an hour via video conferencing. Each meeting\nmay be held twice to accommodate learners\u2019 time zones and schedules.\nParticipants use shared note-taking as described above for online group\nclasses, post homework online between classes, and comment on each other\u2019s\nwork. In practice, comments are relatively rare: people strongly prefer to\ndiscuss material in the weekly meetings.\n\nThis was the first format used, and I no longer recommend it: while spreading\nthe class out gives people time to reflect and tackle larger exercises, it\nalso greatly increases the odds that they\u2019ll have to drop out because of other\ndemands on their time.\n\n## Contributing and Maintaining\n\nContributions of all kinds are welcome, from suggestions for improvements to\nerrata and new material. All contributors must abide by our Code of Conduct\n(Appendix 17); by submitting your work, you are agreeing that it may\nincorporated in either original or edited form and released under the same\nlicense as the rest of this material (Appendix 16). If your material is\nincorporated, we will add you to the acknowledgments (Section 1.3) unless you\nrequest otherwise.\n\nThe source for this book is stored on GitHub at:\n\nhttps://github.com/gvwilson/teachtogether.tech/\n\nIf you know how to use Git and GitHub and would like to change, fix, or add\nsomething, please submit a pull request that modifies the LaTeX source. If you\nwould like to preview your changes, please run make pdf or make html on the\ncommand line.\n\nIf you want to report an error, ask a question, or make a suggestion, please\nfile an issue in the repository. You need to have a GitHub account in order to\ndo this, but do not need to know how to use Git.\n\nIf you do not wish to create a GitHub account, please email your contribution\nto gvwilson@third-bit.com with either \u201cT3\u201d or \u201cTeaching Tech Together\u201d\nsomewhere in the subject line. We will try to respond within a week.\n\nFinally, we always enjoy hearing how people have used this material, and are\nalways grateful for more diagrams.\n\n# Glossary\n\nAbsolute beginner\n\n    \n\nSomeone who has never encountered concepts or material before. The term is\nused in distinction to false beginner.\n\nActive learning\n\n    \n\nAn approach to instruction in which learners engage with material through\ndiscussion, problem solving, case studies, and other activities that require\nthem to reflect on and use new information in real time. See also passive\nlearning.\n\nActive teaching\n\n    \n\nAn approach to instruction in which the teacher acts on new information\nacquired from learners while teaching (e.g. by dynamically changing an example\nor rearranging the intended order of content). See also passive teaching.\n\nAuthentic task\n\n    \n\nA task which contains important elements of things that learners would do in\nreal (non-classroom situations). To be authentic, a task should require\nlearners to construct their own answers rather than choose between provided\nanswers, and to work with the same tools and data they would use in real life.\n\nAutomaticity\n\n    \n\nThe ability to do a task without concentrating on its low-level details.\n\nBackward design\n\n    \n\nAn instructional design method that works backwards from a summative\nassessment to formative assessments and thence to lesson content.\n\nBehaviorism\n\n    \n\nA theory of learning whose central principle is stimulus and response, and\nwhose goal is to explain behavior without recourse to internal mental states\nor other unobservables. See also cognitivism.\n\nBloom\u2019s Taxonomy\n\n    \n\nA six-part hierarchical classification of understanding whose levels are\nknowledge, comprehension, application, analysis, synthesis, and evaluation\nthat has been widely adopted. See also Fink\u2019s Taxonomy.\n\nBrand\n\n    \n\nThe associations people have with a product\u2019s name or identity.\n\nCalibrated peer review\n\n    \n\nHaving learners compare their reviews of sample work with a teacher\u2019s reviews\nbefore being allowed to review their peers\u2019 work.\n\nChunking\n\n    \n\nThe act of grouping related concepts together so that they can be stored and\nprocessed as a single unit.\n\nCo-teaching\n\n    \n\nTeaching with another teacher in the classroom.\n\nCognitive apprenticeship\n\n    \n\nA theory of learning that emphasizes the process of a master passing on skills\nand insights situationally to an apprentice.\n\nCognitive load\n\n    \n\nThe mental effort needed to solve a problem. Cognitive load theory divides\nthis into intrinsic, germane, and extraneous load, and holds that people learn\nfastest when germane and extraneous load are reduced.\n\nCognitivism\n\n    \n\nA theory of learning that holds that mental states and processes can and must\nbe included in models of learning. See also behaviorism.\n\nCommons\n\n    \n\nsomething managed jointly by a community according to rules they themselves\nhave evolved and adopted.\n\nCommunity of practice\n\n    \n\nA self-perpetuating group of people who share and develop a craft such as\nknitters, musicians, or programmers. See also legitimate peripheral\nparticipation.\n\nCommunity representation\n\n    \n\nUsing cultural capital to highlight learners\u2019 social identities, histories,\nand community networks in learning activities.\n\nComputational integration\n\n    \n\nUsing computing to re-implement pre-existing cultural artifacts, e.g. creating\nvariants of traditional designs using computer drawing tools.\n\nCompetent practitioner\n\n    \n\nSomeone who can do normal tasks with normal effort under normal circumstances.\nSee also novice and expert.\n\nComputational thinking\n\n    \n\nThinking about problem-solving in ways inspired by programming (though the\nterm is used in many other ways).\n\nConcept inventory\n\n    \n\nA test designed to determine how well a learner understands a domain. Unlike\nmost instructor-authored tests, concept inventories are based on extensive\nresearch and validation.\n\nConcept map\n\n    \n\nA picture of a mental model in which concepts are nodes in a graph and\nrelationships are (labeled) arcs.\n\nConnectivism\n\n    \n\nA theory of learning that holds that knowledge is distributed, that learning\nis the process of navigating, growing, and pruning connections, and which\nemphasizes the social aspects of learning made possible by the internet.\n\nConstructivism\n\n    \n\nA theory of learning that views learners as actively constructing knowledge.\n\nContent knowledge\n\n    \n\nA person\u2019s understanding of a subject. See also general pedagogical knowledge\nand pedagogical content knowledge.\n\nContributing student pedagogy\n\n    \n\nHaving learners produce artifacts to contribute to others\u2019 learning.\n\nConversational programmer\n\n    \n\nSomeone who needs to know enough about computing to have a meaningful\nconversation with a programmer, but isn\u2019t going to program themselves.\n\nCS Unplugged\n\n    \n\nA style of teaching that introduces computing concepts using non-programming\nexamples and artifacts.\n\nCS0\n\n    \n\nAn introductory college-level course on computing aimed at non-majors with\nlittle or no prior experience of programming.\n\nCS1\n\n    \n\nAn introductory college-level computer science course, typically one semester\nlong, that focuses on variables, loops, functions, and other basic mechanics.\n\nCS2\n\n    \n\nA second college-level computer science course that typically introduces basic\ndata structures such as stacks, queues, and dictionaries.\n\nDeficit model\n\n    \n\nThe idea that some groups are underrepresented in computing (or some other\nfield) because their members lack some attribute or quality.\n\nDeliberate practice\n\n    \n\nThe act of observing performance of a task while doing it in order to improve\nability.\n\nDemonstration lesson\n\n    \n\nA staged lesson in which one teacher presents to actual learners while other\nteachers observe in order to learn new teaching techniques.\n\nDiagnostic power\n\n    \n\nThe degree to which a wrong answer to a question or exercise tells the teacher\nwhat misconceptions a particular learner has.\n\nDirect instruction\n\n    \n\nA teaching method centered around meticulous curriculum design delivered\nthrough prescribed script.\n\nDunning-Kruger effect\n\n    \n\nThe tendency of people who only know a little about a subject to incorrectly\nestimate their understanding of it.\n\nEducational psychology\n\n    \n\nThe study of how people learn. See also instructional design.\n\nEgo depletion\n\n    \n\nThe impairment of self control resulting from prolonged or intensive use.\nRecent work has failed to substantiate its existence.\n\nElevator pitch\n\n    \n\nA short description of an idea, project, product, or person that can be\ndelivered and understood in just a few seconds.\n\nEnd-user programmer\n\n    \n\nSomeone who does not consider themselves a programmer, but who nevertheless\nwrites and debugs software, such as an artist creating complex macros for a\ndrawing tool.\n\nEnd-user teacher\n\n    \n\nBy analogy with end-user programmer, someone who is teaching frequently, but\nwhose primary occupation is not teaching, who has little or no background in\npedagogy, and who may work outside institutional classrooms.\n\nExpert\n\n    \n\nSomeone who can diagnose and handle unusual situations, knows when the usual\nrules do not apply, and tends to recognize solutions rather than reasoning to\nthem. See also competent practitioner and novice.\n\nExpert blind spot\n\n    \n\nThe inability of experts to empathize with novices who are encountering\nconcepts or practices for the first time.\n\nExpertise reversal effect\n\n    \n\nThe way in which instruction that is effective for novices becomes ineffective\nfor competent practitioners or experts.\n\nExternalized cognition\n\n    \n\nThe use of graphical, physical, or verbal aids to augment thinking.\n\nExtraneous load\n\n    \n\nAny cognitive load that distracts from learning.\n\nExtrinsic motivation\n\n    \n\nBeing driven by external rewards such as payment or fear of punishment. See\nalso intrinsic motivation.\n\nFaded example\n\n    \n\nA series of examples in which a steadily increasing number of key steps are\nblanked out. See also scaffolding.\n\nFalse beginner\n\n    \n\nSomeone who has studied a language before but is learning it again. False\nbeginners start at the same point as true beginners (i.e. a pre-test will show\nthe same proficiency) but can move much more quickly.\n\nFar transfer\n\n    \n\nThe transfer of learning between widely-separated domains, e.g. improvement in\nmath skills as a result of playing chess.\n\nFink\u2019s Taxonomy\n\n    \n\nA six-part non-hierarchical classification of understanding first proposed in\n[Fink2013] whose categories are foundational knowledge, application,\nintegration, human dimension, caring, and learning how to learn. See also\nBloom\u2019s Taxonomy.\n\nFixed mindset\n\n    \n\nThe belief that an ability is innate, and that failure is due to a lack of\nsome necessary attribute. See also growth mindset.\n\nFlipped classroom\n\n    \n\nOne in which learners watch recorded lessons on their own time, while class\ntime is used to work through problem sets and answer questions.\n\nFlow\n\n    \n\nThe feeling of being fully immersed in an activity; frequently associated with\nhigh productivity.\n\nFluid representation\n\n    \n\nThe ability to move quickly between different models of a problem.\n\nFormative assessment\n\n    \n\nAssessment that takes place during a lesson in order to give both the learner\nand the teacher feedback on actual understanding. See also summative\nassessment.\n\nFree-range learner\n\n    \n\nSomeone learning outside an institutional classroom with required homework and\nmandated curriculum. (Those who use the term occasionally refer to learners in\nclassrooms as \u201cbattery-farmed learners,\u201d but we don\u2019t because that would be\nrude.)\n\nFuzz testing\n\n    \n\nA software testing technique based on generating and submitting random data.\n\nGeneral pedagogical knowledge\n\n    \n\nA person\u2019s understanding of the general principles of teaching. See also\ncontent knowledge and pedagogical content knowledge.\n\nGermane load\n\n    \n\nThe cognitive load required to link new information to old.\n\nGovernance board\n\n    \n\nA board whose primary responsibility is to hire, monitor, and if need be, fire\nthe director.\n\nGrowth mindset\n\n    \n\nThe belief that ability comes with practice. See also fixed mindset.\n\nGuided notes\n\n    \n\nTeacher-prepared notes that cue learners to respond to key information in a\nlecture or discussion.\n\nHashing\n\n    \n\nGenerating a condensed pseudo-random digital key from data; any specific input\nproduces the same output, but different inputs are highly likely to produce\ndifferent outputs.\n\nHypercorrection effect\n\n    \n\nThe more strongly someone believed that their answer on a test was right, the\nmore likely they are not to repeat the error once they discover that in fact\nthey were wrong.\n\nImplementation science\n\n    \n\nThe study of how to translate research findings to everyday clinical practice.\n\nImpostor syndrome\n\n    \n\nA feeling of insecurity about one\u2019s accomplishments that manifests as a fear\nof being exposed as a fraud.\n\nInclusivity\n\n    \n\nWorking actively to include people with diverse backgrounds and needs.\n\nInquiry-based learning\n\n    \n\nThe practice of allowing learners to ask their own questions, set their own\ngoals, and find their own path through a subject.\n\nInstructional design\n\n    \n\nThe craft of creating and evaluating specific lessons for specific audiences.\nSee also educational psychology.\n\nIntrinsic load\n\n    \n\nThe cognitive load required to absorb new information.\n\nIntrinsic motivation\n\n    \n\nBeing driven by enjoyment of a task or the satisfaction of doing it for its\nown sake. See also extrinsic motivation.\n\nIntuition\n\n    \n\nThe ability to understand something immediately, without any apparent need for\nconscious reasoning.\n\nJugyokenkyu\n\n    \n\nLiterally \u201clesson study,\u201d a set of practices that includes having teachers\nroutinely observe one another and discuss lessons to share knowledge and\nimprove skills.\n\nLearned helplessness\n\n    \n\nA situation in which people who are repeatedly subjected to negative feedback\nthat they have no way to escape learn not to even try to escape when they\ncould.\n\nLearner persona\n\n    \n\nA brief description of a typical target learner for a lesson that includes\ntheir general background, what they already know, what they want to do, how\nthe lesson will help them, and any special needs they might have.\n\nLearning Management System\n\n    \n\n(LMS): An application for tracking course enrollment, exercise submissions,\ngrades, and other bureaucratic aspects of formal classroom learning.\n\nLearning objective\n\n    \n\nWhat a lesson is trying to achieve.\n\nLearning outcome\n\n    \n\nWhat a lesson actually achieves.\n\nLegitimate peripheral participation\n\n    \n\nNewcomers\u2019 participation in simple, low-risk tasks that a community of\npractice recognizes as valid contributions.\n\nLive coding\n\n    \n\nThe act of teaching programming by writing software in front of learners as\nthe lesson progresses.\n\nLong-term memory\n\n    \n\nThe part of memory that stores information for long periods of time. Long-term\nmemory is very large, but slow. See also short-term memory.\n\nManual\n\n    \n\nReference material intended to help someone who already understands a subject\nfill in (or remind themselves of) details.\n\nMarketing\n\n    \n\nThe craft of seeing things from other people\u2019s perspective, understanding\ntheir wants and needs, and finding ways to meet them\n\nMassive Open Online Course\n\n    \n\n(MOOC) An online course designed for massive enrollment and asynchronous\nstudy, typically using recorded videos and automated grading.\n\nMental model\n\n    \n\nA simplified representation of the key elements and relationships of some\nproblem domain that is good enough to support problem solving.\n\nMetacognition\n\n    \n\nThinking about thinking.\n\nMinimal manual\n\n    \n\nAn approach to training that breaks every task into single-page instructions\nthat also explain how to diagnose and correct common errors.\n\nMinute cards\n\n    \n\nA feedback technique in which learners spend a minute writing one positive\nthing about a lesson (e.g. one thing they\u2019ve learned) and one negative thing\n(e.g. a question that still hasn\u2019t been answered).\n\nNear transfer\n\n    \n\nTransfer of learning between closely-related domains, e.g. improvement in\nunderstanding of decimals as a result of doing exercises with fractions.\n\nNotional machine\n\n    \n\nA general, simplified model of how a particular family of programs executes.\n\nNovice\n\n    \n\nSomeone who has not yet built a usable mental model of a domain. See also\ncompetent practitioner and expert.\n\nObjects first\n\n    \n\nAn approach to teaching programming in which objects and classes are\nintroduced early.\n\nPair programming\n\n    \n\nA software development practice in which two programmers share one computer.\nOne programmer (the driver) does the typing, while the other (the navigator)\noffers comments and suggestions in real time. Pair programming is often used\nas a teaching practice in programming classes.\n\nParsons Problem\n\n    \n\nAn assessment technique developed by Dale Parsons and others in which learners\nrearrange given material to construct a correct answer to a question\n[Pars2006].\n\nPassive learning\n\n    \n\nAn approach to instruction in which learners read, listen, or watch without\nimmediately using new knowledge. Passive learning is less effective than\nactive learning.\n\nPassive teaching\n\n    \n\nAn approach to instruction in which the teacher does not adjust pace or\nexamples, or otherwise act on feedback from learners, during the lesson. See\nalso active teaching.\n\nPedagogical content knowledge\n\n    \n\n(PCK) The understanding of how to teach a particular subject, i.e. the best\norder in which to introduce topics and what examples to use. See also content\nknowledge and general pedagogical knowledge.\n\nPeer instruction\n\n    \n\nA teaching method in which an teacher poses a question and then learners\ncommit to a first answer, discuss answers with their peers, and commit to a\n(revised) answer.\n\nPersistent memory\n\n    \n\nSee long-term memory.\n\nPersonalized learning\n\n    \n\nAutomatically tailoring lessons to meet the needs of individual learners.\n\nPlausible distractor\n\n    \n\nA wrong or less-than-best answer to a multiple-choice question that looks like\nit could be right. See also diagnostic power.\n\nPositioning\n\n    \n\nWhat sets one brand apart from other, similar brands.\n\nPreparatory privilege\n\n    \n\nThe advantage of coming from a background that provides more preparation for a\nparticular learning task than others.\n\nProductive failure\n\n    \n\nA situation in which learners are deliberately given problems that can\u2019t be\nsolved with the knowledge they have and must go out and acquire new\ninformation in order to make progress. See also Zone of Proximal Development.\n\nPull request\n\n    \n\nA set of proposed changes to a GitHub repository that can be reviewed,\nupdated, and eventually merged.\n\nRead-cover-retrieve\n\n    \n\nA study practice in which the learner covers up key facts or terms during a\nfirst pass through material, then checks their recall on a second pass.\n\nReflective practice\n\n    \n\nSee deliberate practice.\n\nReusability Paradox\n\n    \n\nHolds that the more reusable part of a lesson is, the less pedagogically\neffective it is.\n\nScaffolding\n\n    \n\nExtra material provided to early-stage learners to help them solve problems.\n\nSearch engine optimization\n\n    \n\nIncreasing the quantity and quality of web site traffic by making pages more\neasily found by, or seem more important to, search engines.\n\nService board\n\n    \n\nA board whose members take on working roles in the organization.\n\nShort-term memory\n\n    \n\nThe part of memory that briefly stores information that can be directly\naccessed by consciousness.\n\nSituated learning\n\n    \n\nA model of learning that focuses on people\u2019s transition from being newcomers\nto be accepted members of a community of practice.\n\nSplit-attention effect\n\n    \n\nThe decrease in learning that occurs when learners must divide their attention\nbetween multiple concurrent presentations of the same information (e.g.\ncaptions and a voiceover).\n\nStereotype threat\n\n    \n\nA situation in which people feel that they are at risk of being held to\nstereotypes of their social group.\n\nSubgoal labeling\n\n    \n\nGiving names to the steps in a step-by-step description of a problem-solving\nprocess.\n\nSummative assessment\n\n    \n\nAssessment that takes place at the end of a lesson to tell whether the desired\nlearning has taken place.\n\nTangible artifact\n\n    \n\nSomething a learner can work on whose state gives feedback about the learner\u2019s\nprogress and helps the learner diagnose mistakes.\n\nTeaching to the test\n\n    \n\nAny method of \u201ceducation\u201d that focuses on preparing students to pass\nstandardized tests, rather than on actual learning.\n\nTest-driven development\n\n    \n\nA software development practice in which programmers write tests first in\norder to give themselves concrete goals and clarify their understanding of\nwhat \u201cdone\u201d looks like.\n\nThink-pair-share\n\n    \n\nA collaboration method in which each person thinks individually about a\nquestion or problem, then pairs with a partner to pool ideas, and then have\none person from each pair present to the whole group.\n\nTransfer of learning\n\n    \n\nApplying knowledge learned in one context to problems in another context. See\nalso near transfer and far transfer.\n\nTransfer-appropriate processing\n\n    \n\nThe improvement in recall that occurs when practice uses activities similar to\nthose used in testing.\n\nTutorial\n\n    \n\nA lesson intended to help someone improve their general understanding of a\nsubject.\n\nTwitch coding\n\n    \n\nHaving a group of people decide moment by moment or line by line what to add\nto a program next.\n\nWorking memory\n\n    \n\nsee short-term memory.\n\nZone of Proximal Development\n\n    \n\n(ZPD) Includes the set of problems that people cannot yet solve on their own\nbut are able to solve with assistance from a more experienced mentor. See also\nproductive failure.\n\n# Meetings, Meetings, Meetings\n\nMost people are really bad at meetings: they don\u2019t make an agenda, they don\u2019t\ntake minutes, they waffle on or wander off into irrelevancies, they say\nsomething banal or repeat what others have said just so that they\u2019ll have said\nsomething, and they hold side conversations (which pretty much guarantees that\nthe meeting will be a waste of time). Knowing how to run a meeting efficiently\nis a core skill for anyone who wants to get things done; knowing how to take\npart in someone else\u2019s meeting is just as important (though it gets far less\nattention\u2014as a colleague once said, everyone offers leadership training, but\nnobody offers followership training).\n\nThe most important rules for making meetings efficient are not secret, but are\nrarely followed:\n\nDecide if there actually needs to be a meeting.\n\n    \n\nIf the only purpose is to share information, send a brief email instead.\nRemember, you can read faster than anyone can speak: if someone has facts for\nthe rest of the team to absorb, the most polite way to communicate them is to\nwrite them up.\n\nWrite an agenda.\n\n    \n\nIf nobody cares enough about the meeting to write a point-form list of what\u2019s\nto be discussed, the meeting probably doesn\u2019t need to happen.\n\nInclude timings in the agenda.\n\n    \n\nAgendas can also help you prevent early items stealing time from later ones if\nyou include the time to be spent on each item in the agenda. Your first\nestimates with any new group will be wildly optimistic, so revise them upward\nfor subsequent meetings. However, you shouldn\u2019t plan a second or third meeting\nbecause the first one ran over-time: instead, try to figure out why you\u2019re\nrunning over and fix the underlying problem.\n\nPrioritize.\n\n    \n\nEvery meeting is a micro-project, so work should be prioritized in the same\nway that it is for other projects: things that will have high impact but take\nlittle time should be done first, and things that will take lots of time but\nhave little impact should be skipped.\n\nMake one person responsible for keeping things moving.\n\n    \n\nOne person should be tasked with keeping items to time, chiding people who are\nchecking email or having side conversations, asking people who are talking too\nmuch to get to the point, and inviting people who aren\u2019t talking to express an\nopinion. This person should not do all the talking; in fact, whoever is in\ncharge will talk less in a well-run meeting than most other participants.\n\nRequire politeness.\n\n    \n\nNo one gets to be rude, no one gets to ramble, and if someone goes off topic,\nit is both the moderator\u2019s right and responsibility to say, \u201cLet\u2019s discuss\nthat elsewhere.\u201d\n\nNo interruptions.\n\n    \n\nParticipants should raise a finger or put up a sticky note if they want to\nspeak next. If the person speaking doesn\u2019t notice them, the moderator should.\n\nNo technology\n\n    \n\nunless it\u2019s required for accessibility reasons. Insist that everyone put their\nphones, tablets, and laptops into politeness mode (i.e. close them).\n\nRecord minutes.\n\n    \n\nSomeone other than the moderator should take point-form notes about the most\nimportant pieces of information that were shared, every decision that was\nmade, and every task that was assigned to someone.\n\nTake notes.\n\n    \n\nWhile other people are talking, participants should take notes of questions\nthey want to ask or points they want to make. (You\u2019ll be surprised how smart\nit makes you look when it\u2019s your turn to speak.)\n\nEnd early.\n\n    \n\nIf your meeting is scheduled for 10:00-11:00, you should aim to end at 10:50\nto give people time to visit the bathroom on their way to where they need to\ngo next.\n\nAs soon as the meeting is over, email the minutes to everyone or post them on\nthe web:\n\nPeople who weren\u2019t at the meeting can keep track of what\u2019s going on.\n\n    \n\nA web page or email message is a much more efficient way to catch up than\nasking a team mate what you missed.\n\nEveryone can check what was actually said or promised.\n\n    \n\nMore than once, I have looked over the minutes of a meeting I was in and\nthought, \u201cDid I say that?\u201d or, \u201cWait a minute, I didn\u2019t promise to have it\nready then!\u201d Accidentally or not, people will often remember things\ndifferently; writing it down gives team members a chance to correct mistakes,\nwhich can save a lot of anguish later on.\n\nPeople can be held accountable at subsequent meetings.\n\n    \n\nThere\u2019s no point making lists of questions and action items if you don\u2019t\nfollow up on them later. If you\u2019re using some kind of issue tracking system,\ncreate an issue for each new question or task right after the meeting and\nupdate those that are being carried forward, then start each meeting by going\nthrough a list of those issues.\n\n[Brow2007,Broo2016,Roge2018] have lots of advice on running meetings. In my\nexperience, an hour of training on how to be a moderator is one of the best\ninvestments you will ever make.\n\n> #### Sticky Notes and Interruption Bingo\n>\n> Some people are so used to the sound of their own voice that they will\n> insist on talking half the time no matter how many other people are in the\n> room. To combat this, give everyone three sticky notes at the start of the\n> meeting. Every time they speak, they have to take down one sticky note. When\n> they\u2019re out of notes, they aren\u2019t allowed to speak until everyone has used\n> at least one, at which point everyone gets all of their sticky notes back.\n> This ensures that nobody talks more than three times as often as the\n> quietest person in the meeting, and completely changes the dynamics of most\n> groups: people who have given up trying to be heard because they always get\n> trampled suddenly have space to contribute, and the overly-frequent speakers\n> quickly realize just how unfair they have been^13.\n>\n> Another technique is interruption bingo. Draw a grid and label the rows and\n> columns with participants\u2019 names. Add a tally mark to the appropriate cell\n> each time someone interrupts someone else, and take a moment to share the\n> results halfway through the meeting. In most cases, you will see that one or\n> two people are doing all of the interrupting, often without being aware of\n> it. That alone is often enough to get them to throttle back. (Note that this\n> technique is intended to manage interruptions, not speaking time: it may be\n> appropriate for people with more knowledge of a subject to speak about it\n> more often in a meeting, but it is never appropriate to repeatedly cut\n> people off.)\n\n## Martha\u2019s Rules\n\nOrganizations all over the world run their meetings according to Robert\u2019s\nRules of Order, but they are far more formal than most small projects require.\nA lightweight alternative known as \u201cMartha\u2019s Rules\u201d may be much better for\nconsensus-based decision making [Mina1986]:\n\n  1. Before each meeting, anyone who wishes may sponsor a proposal by sharing it with the group. Proposals must be filed at least 24 hours before a meeting in order to be considered at that meeting, and must include:\n\n     * a one-line summary;\n\n     * the full text of the proposal;\n\n     * any required background information;\n\n     * pros and cons; and\n\n     * possible alternatives\n\nProposals should be at most two pages long.\n\n  2. A quorum is established in a meeting if half or more of voting members are present.\n\n  3. Once a person has sponsored a proposal, they are responsible for it. The group may not discuss or vote on the issue unless the sponsor or their delegate is present. The sponsor is also responsible for presenting the item to the group.\n\n  4. After the sponsor presents the proposal, a preliminary vote is cast for the proposal prior to any discussion:\n\n     * Who likes the proposal?\n\n     * Who can live with the proposal?\n\n     * Who is uncomfortable with the proposal?\n\nPreliminary votes can be done thumb up, thumb sideways, or thumb down (in\nperson) or by typing +1, 0, or -1 into online chat (in virtual meetings).\n\n  5. If all or most of the group likes or can live with the proposal, it is immediately moved to a formal vote with no further discussion.\n\n  6. If most of the group is uncomfortable with the proposal, it is postponed for further rework by the sponsor.\n\n  7. If some members are uncomfortable they can briefly state their objections. A timer is then set for a brief discussion moderated by the facilitator. After ten minutes or when no one has anything further to add (whichever comes first), the facilitator calls for a yes-or-no vote on the question: \u201cShould we implement this decision over the stated objections?\u201d If a majority votes \u201cyes\u201d the proposal is implemented. Otherwise, the proposal is returned to the sponsor for further work.\n\n## Online Meetings\n\nChelsea Troy\u2019s discussion of why online meetings are often frustrating and\nunproductive makes an important point: in most online meetings, the first\nperson to speak during a pause gets the floor. The result? \u201cIf you have\nsomething you want to say, you have to stop listening to the person currently\nspeaking and instead focus on when they\u2019re gonna pause or finish so you can\nleap into that nanosecond of silence and be the first to utter something. The\nformat...encourages participants who want to contribute to say more and listen\nless.\u201d\n\nThe solution is to run a text chat beside the video conference where people\ncan signal that they want to speak, The moderator then selects people from the\nwaiting list. If the meeting is large or argumentative, have everyone mute\nthemselves and only allow the moderator to unmute people.\n\n## The Post Mortem\n\nEvery project should end with a post mortem in which participants reflect on\nwhat they just accomplished and what they could do better next time. Its aim\nis not to point the finger of shame at individuals, although if that has to\nhappen, the post mortem is the best place for it.\n\nA post mortem is run like any other meeting with a few additional guidelines\n[Derb2006]:\n\nGet a moderator who wasn\u2019t part of the project\n\n    \n\nand doesn\u2019t have a stake in it.\n\nSet aside an hour, and only an hour.\n\n    \n\nIn my experience, nothing useful is said in the first ten minutes of anyone\u2019s\nfirst post mortem, since people are naturally a bit shy about praising or\ndamning their own work. Equally, nothing useful is said after the first hour:\nif you\u2019re still talking, it\u2019s probably because one or two people have things\nthey want to get off their chests rather than suggestions for improvements.\n\nRequire attendance.\n\n    \n\nEveryone who was part of the project ought to be in the room for the post\nmortem. This is more important than you might think: the people who have the\nmost to learn from the post mortem are often least likely to show up if the\nmeeting is optional.\n\nMake two lists.\n\n    \n\nWhen I\u2019m moderating, I put the headings \u201cDo Again\u201d and \u201cDo Differently\u201d on the\nboard, then ask each person to give me one item for each list in turn without\nrepeating anything that has already been said.\n\nComment on actions rather than individuals.\n\n    \n\nBy the time the project is done, some people may no longer be friends. Don\u2019t\nlet this sidetrack the meeting: if someone has a specific complaint about\nanother member of the team, require them to criticize a particular event or\ndecision. \u201cThey had a bad attitude\u201d does not help anyone improve.\n\nPrioritize the recommendations.\n\n    \n\nOnce everyone\u2019s thoughts are out in the open, sort them according to which are\nmost important to keep doing and which are most important to change. You will\nprobably only be able to tackle one or two from each list in your next\nproject, but if you do that every time, your life will quickly get better.\n\n# Checklists and Templates\n\n[Gawa2007] popularized the idea that using checklists can save lives, and more\nrecent studies have generally supported their effectiveness\n[Avel2013,Urba2014,Rams2019]. We find them useful, particularly when bringing\nnew teachers onto a team; the ones given below can be used as starting points\nfor developing your own.\n\n## Teaching Evaluation\n\nThis rubric is designed to assess people teaching for 5\u201310 minutes with\nslides, live coding, or a mix of both. Rate each item as \u201cYes,\u201d \u201cIffy,\u201d \u201cNo,\u201d\nor \u201cNot Applicable.\u201d\n\nOpening| Exists (use N/A for other responses if not)  \n---|---  \nGood length (10\u201330 seconds)  \nIntroduces self  \nIntroduces topics to be covered  \nDescribes prerequisites  \nContent| Clear goal/narrative arc  \nInclusive language  \nAuthentic tasks/examples  \nTeaches best practices/uses idiomatic code  \nSteers a path between the Scylla of jargon and the Charybdis of over-\nsimplification  \nDelivery| Clear, intelligible voice (use \u201cIffy\u201d or \u201cNo\u201d for strong accent)  \nRhythm: not too fast or too slow, no long pauses or self-interruption, not\nobviously reading from a script  \nSelf-assured: does not stray into the icky tarpit of uncertainty or the\ndungheap of condescension  \nSlides| Exist (use N/A for other responses if not)  \nSlides and speech complement one another (dual coding)  \nReadable fonts and colors/no overwhelming slabs of text  \nFrequent change on screen (something every 30 seconds)  \nGood use of graphics  \nLive Coding| Used (use N/A for other responses if not)  \nCode and speech complement one another  \nReadable fonts and colors/right amount of code on the screen  \nProficient use of tools  \nHighlights key features of code  \nDissects errors  \nClosing| Exists (use N/A for other responses if it doesn\u2019t)  \nGood length (10\u201330 seconds)  \nSummarizes key points  \nOutlines next steps  \nOverall| Points clearly connected/logical flow  \nMake the topic interesting (i.e. not boring)  \nKnowledgeable  \n  \n## Teamwork Evaluation\n\nThis rubric is designed to assess individual performance within a team. You\ncan use it as a starting point for creating a rubric of your own. Rate each\nitem as \u201cYes,\u201d \u201cIffy,\u201d \u201cNo,\u201d or \u201cNot Applicable.\u201d\n\nCommunication| Listens attentively to others without interrupting  \n---|---  \nClarifies what others have said to ensure understanding  \nArticulates ideas clearly and concisely  \nGives good reasons for ideas  \nWins support from others  \nDecision Making| Analyzes problems from different points of view  \nApplies logic in solving problems  \nOffers solutions based on facts rather than \u201cgut feel\u201d or intuition  \nSolicits new ideas from others  \nGenerates new ideas  \nAccepts change  \nCollaboration| Acknowledges issues that the team needs to confront and resolve  \nWorks toward solutions that are acceptable to all involved  \nShares credit for success with others  \nEncourages participation among all participants  \nAccepts criticism openly and non-defensively  \nCooperates with others  \nSelf-Management| Monitors progress to ensure that goals are met  \nPuts top priority on getting results  \nDefines task priorities for work sessions  \nEncourages others to express views even when they are contrary  \nStays focused on the task during meetings  \nUses meeting time efficiently  \nSuggests ways to proceed during work sessions  \n  \n## Event Setup\n\nThe checklists below are used before, during, and after events.\n\n### Scheduling the Event\n\n  * Decide if it will be in person, online for one site, or online for several sites.\n\n  * Talk through expectations with the host and make sure everyone agrees who is covering travel costs.\n\n  * Determine who is allowed to take part: is the event open to all comers, restricted to members of one organization, or something in between?\n\n  * Arrange teachers.\n\n  * Arrange space, including breakout rooms if needed.\n\n  * Choose dates. If it is in person, book travel.\n\n  * Get names and email addresses of attendees from host.\n\n  * Make sure everyone is registered.\n\n### Setting Up\n\n  * Set up a web page with details on the workshop, including date, location, and what participants need to bring.\n\n  * Check whether any attendees have special needs.\n\n  * If the workshop is online, test the video conferencing\u2014twice.\n\n  * Make sure attendees will have network access.\n\n  * Create a page for sharing notes and exercise solutions (e.g. a Google Doc).\n\n  * Email attendees a welcome message with a link to the workshop page, background readings, a description of any setup they need to do, a list of what they need to bring, and a way to contact the host or teacher on the day.\n\n### At the Start of the Event\n\n  * Remind everyone of the code of conduct.\n\n  * Take attendance and create a list of names to paste into the shared page.\n\n  * Distribute sticky notes.\n\n  * Make sure everyone can get online.\n\n  * Make sure everyone can access the shared page.\n\n  * Collect any relevant online account IDs.\n\n### At the End of the Event\n\n  * Update the attendance list.\n\n  * Collect feedback from participants.\n\n  * Make a copy of the shared page.\n\n### Travel Kit\n\nHere are a few things teachers take with them to workshops:\n\nsticky notes| cough drops  \n---|---  \ncomfortable shoes| a small notepad  \na spare power adapter| a spare shirt  \ndeodorant| video adapters  \nlaptop stickers| their notes (printed or on a tablet)  \na granola bar or some other snack| antacid (because road food)  \nbusiness cards| spare glasses/contacts  \na notebook and pen| a laser pointer  \nan insulated cup for tea/coffee| extra whiteboard markers  \na toothbrush or mouthwash| wet wipes (because spills happen)  \n  \nWhen travelling, many teachers also take running shoes, a bathing suit, a yoga\nmat, or whatever else they exercise in or with. Some also bring a portable\nWiFi hub in case the room\u2019s network isn\u2019t working and some USB drives with\ninstallers for the software learners need.\n\n## Lesson Design\n\nThis section summarizes the backward design method developed independently by\n[Wigg2005,Bigg2011,Fink2013]. It lays out a step-by-step progression to help\nyou think about the right things in the right order and provides spaced\ndeliverables so you can re-scope or redirect effort without too many\nunpleasant surprises.\n\nEverything from Step 2 onward goes into your final lesson, so there is no\nwasted effort; as described in Chapter 6, writing sample exercises early helps\nensure that everything you ask your learners to do contributes to the lesson\u2019s\ngoals and that everything they need to know is covered.\n\nThe steps are described in order of increasing detail, but the process itself\nis always iterative. You will frequently go back to revise earlier work as you\nlearn something from your answers to later questions or realize that your\ninitial plan isn\u2019t going to play out the way you first thought.\n\n### Who is this lesson for?\n\nCreate some learner personas (Section 6.1) or (preferably) choose ones that\nyou and your colleagues have drawn up for general use. Each persona should\nhave:\n\n  1. the person\u2019s general background;\n\n  2. what they already know;\n\n  3. what they think they want to do; and\n\n  4. any special needs they have.\n\nDeliverable: brief summaries of who you are trying to help.\n\n### What\u2019s the big idea?\n\nWrite point-form answers to three or four of the questions below to help you\nfigure out the scope of the lesson. You don\u2019t need to answer all of these\nquestions, and you may pose and answer others if you think it\u2019s helpful, but\nyou should always include a couple of answers to the first one. You may also\ncreate a concept map at this stage (Section 3.1).\n\n  * What problems will people learn how to solve?\n\n  * What concepts and techniques will people learn?\n\n  * What technologies, packages, or functions will people use?\n\n  * What terms or jargon will you define?\n\n  * What analogies will you use to explain concepts?\n\n  * What mistakes or misconceptions do you expect?\n\n  * What datasets will you use?\n\nDeliverable: a rough scope for the lesson. Share this with a colleague\u2014a\nlittle bit of feedback at this point can save hours of wasted effort later on.\n\n### What will learners do along the way?\n\nMake the goals in Step 2 firmer by writing full descriptions of a couple of\nexercises that learners will be able to do toward the end of the lesson. Doing\nthis is analogous to test-driven development: rather than working forward from\na (probably ambiguous) set of learning objectives, work backward from concrete\nexamples of where you want your learners to end up. Doing this also helps\nuncover technical requirements that might otherwise not be found until\nuncomfortably late.\n\nTo complement the full exercise descriptions, write brief point-form\ndescriptions of one or two exercises per lecture hour to show how quickly you\nexpect learners to progress. Again, these serve as a good reality check on how\nmuch you\u2019re assuming and help uncover technical requirements. One way to\ncreate these \u201cextra\u201d exercises is to make a point-form list of the skills\nneeded to solve the major exercises and create an exercise that targets each.\n\nDeliverable: 1\u20132 fully explained exercises that use the skills people are to\nlearn, plus half a dozen point-form exercise outlines. Include complete\nsolutions so that you can make sure the software you want learners to use\nactually works.\n\n### How are concepts connected?\n\nPut the exercises you have created in a logical order and then derive a point-\nform lesson outline from them. The outline should have 3\u20134 bullet points for\neach hour with a formative assessment of some kind for each. It is common to\nchange assessments in this stage so that they can build on each other.\n\nDeliverable: a lesson outline. You are likely to discover things you forgot to\nlist earlier during this stage, so don\u2019t be surprised if you have to double\nback a few times.\n\n### Lesson overview\n\nYou can now write a lesson overview with:\n\n  * a one-paragraph description (i.e. a sales pitch to learners);\n\n  * half a dozen learning objectives; and\n\n  * a summary of prerequisites.\n\nDoing this earlier often wastes effort, since material is usually added, cut,\nor moved around in earlier steps.\n\nDeliverable: course description, learning objectives, and prerequisites.\n\n## Pre-Assessment Questionnaire\n\nThis questionnaire helps teachers gauge the prior programming knowledge of\nparticipants in an introductory JavaScript workshop. The questions and answers\nare concrete, and the whole thing is short so that respondents won\u2019t find it\nintimidating.\n\n  1. Which of these best describes your experience with programming in general?\n\n     * I have none.\n\n     * I have written a few lines now and again.\n\n     * I have written programs for my own use that are a couple of pages long.\n\n     * I have written and maintained larger pieces of software.\n\n  2. Which of these best describes your experience with programming in JavaScript?\n\n     * I have none.\n\n     * I have written a few lines now and again.\n\n     * I have written programs for my own use that are a couple of pages long.\n\n     * I have written and maintained larger pieces of software.\n\n  3. Which of these best describes how easily you could write a program in any language to find the largest number in a list?\n\n     * I wouldn\u2019t know where to start.\n\n     * I could struggle through by trial and error with a lot of web searches.\n\n     * I could do it quickly with little or no use of external help.\n\n  4. Which of these best describes how easily you could write a JavaScript program to find and capitalize all of the titles in a web page?\n\n     * I wouldn\u2019t know where to start.\n\n     * I could struggle through by trial and error with a lot of web searches.\n\n     * I could do it quickly with little or no use of external help.\n\n  5. What do you want to know or be able to do after this class that you don\u2019t know or can\u2019t do right now?\n\n# Example Concept Maps\n\nThese concept maps were created by Amy Hodge of Stanford University, and are\nre-used with permission.\n\nLibrary patron concept mapLibrary director concept mapLibrary friends concept\nmap\n\n# Chunking Exercise Solution\n\nSee the last exercise in Chapter 3 for the unchunked representation of these\nsymbols.\n\nChunked representation\n\n# References\n\nAbba2012\n\n    Janet Abbate: Recoding Gender: Women's Changing Participation in Computing. MIT Press, 2012, 9780262534536. Describes the careers and accomplishments of the women who shaped the early history of computing, but have all too often been written out of that history.\nAbel2009\n\n    Andrew Abela: \"Chart Suggestions - A Thought Starter\". http://extremepresentation.typepad.com/files/choosing-a-good-chart-09.pdf, 2009. A graphical decision tree for choosing the right type of chart.\nAdam1975\n\n    Frank Adams and Myles Horton: Unearthing Seeds of Fire: The Idea of Highlander. Blair, 1975, 0895870193. A history of the Highlander Folk School and its founder, Myles Horton.\nAike1975\n\n    Edwin G. Aiken, Gary S. Thomas, and William A. Shennum: \"Memory for a Lecture: Effects of Notes, Lecture Rate, and Informational Density\". Journal of Educational Psychology, 67(3), 1975, doi:10.1037/h0076613. An early landmark study showing that taking notes improved retention.\nAiva2016\n\n    Efthimia Aivaloglou and Felienne Hermans: \"How Kids Code and How We Know\". In 2016 International Computing Education Research Conference (ICER'16), 2016, doi:10.1145/2960310.2960325. Presents an analysis of 250,000 Scratch projects.\nAlin1989\n\n    Saul D. Alinsky: Rules for Radicals: A Practical Primer for Realistic Radicals. Vintage, 1989, 0679721134. A widely-read guide to community organization written by one of the 20th Century's great organizers.\nAlqa2017\n\n    Basma S. Alqadi and Jonathan I. Maletic: \"An Empirical Study of Debugging Patterns Among Novice Programmers\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017761. Reports patterns in the debugging activities and success rates of novice programmers.\nAlvi1999\n\n    Jennifer Alvidrez and Rhona S. Weinstein: \"Early Teacher Perceptions and Later Student Academic Achievement\". Journal of Educational Psychology, 91(4), 1999, doi:10.1037/0022-0663.91.4.731. An influential study of the effects of teachers' perceptions of students on their later achievements.\nAmbr2010\n\n    Susan A. Ambrose, Michael W. Bridges, Michele DiPietro, Marsha C. Lovett, and Marie K. Norman: How Learning Works: Seven Research-Based Principles for Smart Teaching. Jossey-Bass, 2010, 0470484101. Summarizes what we know about education and why we believe it's true, from cognitive psychology to social factors.\nAnde2001\n\n    Lorin W. Anderson and David R. Krathwohl (eds.): A Taxonomy for Learning, Teaching, And Assessing: A Revision of Bloom's Taxonomy of Educational Objectives. Longman, 2001, 080131903X. A widely-used revision to Bloom's Taxonomy.\nArmo2008\n\n    Michal Armoni and David Ginat: \"Reversing: A Fundamental Idea in Computer Science\". Computer Science Education, 18(3), 9 2008, doi:10.1080/08993400802332670. Argues that the notion of reversing things is an unrecognized fundamental concept in computing education.\nAtki2000\n\n    Robert K. Atkinson, Sharon J. Derry, Alexander Renkl, and Donald Wortham: \"Learning from Examples: Instructional Principles from the Worked Examples Research\". Review of Educational Research, 70(2), 6 2000, doi:10.3102/00346543070002181. A comprehensive survey of worked examples research at the time.\nAuro2019\n\n    Valerie Aurora and Mary Gardiner: How to Respond to Code of Conduct Reports. Frame Shift Consulting LLC, 2019, 978-1386922575. A short, practical guide to enforcing a Code of Conduct.\nAvel2013\n\n    Emma-Louise Aveling, Peter McCulloch, and Mary Dixon-Woods: \"A Qualitative Study Comparing Experiences of the Surgical Safety Checklist in Hospitals in High-Income and Low-Income Countries\". BMJ Open, 3(8), 8 2013, doi:10.1136/bmjopen-2013-003039. Reports the effectiveness of surgical checklist implementations in the UK and Africa.\nBacc2013\n\n    Alberto Bacchelli and Christian Bird: \"Expectations, Outcomes, and Challenges of Modern Code Review\". In 2013 International Conference on Software Engineering (ICSE'13), 5 2013. A summary of work on code review.\nBari2017\n\n    Titus Barik, Justin Smith, Kevin Lubick, Elisabeth Holmes, Jing Feng, Emerson Murphy-Hill, and Chris Parnin: \"Do Developers Read Compiler Error Messages?\". In 2017 International Conference on Software Engineering (ICSE'17), 5 2017, doi:10.1109/icse.2017.59. Reports that developers do read error messages and doing so is as hard as reading source code: it takes 13-25\\% of total task time.\nBark2014\n\n    Lecia Barker, Christopher Lynnly Hovey, and Leisa D. Thompson: \"Results of a Large-Scale, Multi-Institutional Study of Undergraduate Retention in Computing\". In 2014 Frontiers in Education Conference (FIE'14), 10 2014, doi:10.1109/fie.2014.7044267. Reports that meaningful assignments, faculty interaction with students, student collaboration on assignments, and (for male students) pace and workload relative to expectations drive retention in computing classes, while interactions with teaching assistants or with peers in extracurricular activities have little impact.\nBark2015\n\n    Lecia Barker, Christopher Lynnly Hovey, and Jane Gruning: \"What Influences CS Faculty to Adopt Teaching Practices?\". In 2015 Technical Symposium on Computer Science Education (SIGCSE'15), 2015, doi:10.1145/2676723.2677282. Describes how computer science educators adopt new teaching practices.\nBasi1987\n\n    Victor R. Basili and Richard W. Selby: \"Comparing the Effectiveness of Software Testing Strategies\". IEEE Transactions on Software Engineering, SE-13(12), 12 1987, doi:10.1109/tse.1987.232881. An early and influential summary of the effectiveness of code review.\nBasu2015\n\n    Soumya Basu, Albert Wu, Brian Hou, and John DeNero: \"Problems Before Solutions: Automated Problem Clarification at Scale\". In 2015 Conference on Learning @ Scale (L@S'15), 2015, doi:10.1145/2724660.2724679. Describes a system in which students have to unlock test cases for their code by answering MCQs, and presents data showing that this is effective.\nBatt2018\n\n    Lina Battestilli, Apeksha Awasthi, and Yingjun Cao: \"Two-Stage Programming Projects: Individual Work Followed by Peer Collaboration\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159486. Reports that learning outcomes were improved by two-stage projects in which students work individually, then re-work the same problem in pairs.\nBaue2015\n\n    Mark S. Bauer, Laura Damschroder, Hildi Hagedorn, Jeffrey Smith, and Amy M. Kilbourne: \"An Introduction to Implementation Science for the Non-Specialist\". BMC Psychology, 3(1), 9 2015, doi:10.1186/s40359-015-0089-9. Explains what implementation science is, using examples from the US Veterans Administration to illustrate.\nBeck2013\n\n    Leland Beck and Alexander Chizhik: \"Cooperative Learning Instructional methods for CS1: Design, Implementation, and Evaluation\". ACM Transactions on Computing Education, 13(3), 8 2013, doi:10.1145/2492686. Reports that cooperative learning enhances learning outcomes and self-efficacy in CS1.\nBeck2014\n\n    Victoria Beck: \"Testing a Model to Predict Online Cheating---Much Ado About Nothing\". Active Learning in Higher Education, 15(1), 1 2014, doi:10.1177/1469787413514646. Reports that cheating is no more likely in online courses than in face-to-face courses.\nBeck2016\n\n    Brett A. Becker, Graham Glanville, Ricardo Iwashima, Claire McDonnell, Kyle Goslin, and Catherine Mooney: \"Effective Compiler Error Message Enhancement for Novice Programming Students\". Computer Science Education, 26(2-3), 7 2016, doi:10.1080/08993408.2016.1225464. Reports that improved error messages helped novices learn faster.\nBeni2017\n\n    Gal Beniamini, Sarah Gingichashvili, Alon Klein Orbach, and Dror G. Feitelson: \"Meaningful Identifier Names: The Case of Single-Letter Variables\". In 2017 International Conference on Program Comprehension (ICPC'17), 5 2017, doi:10.1109/icpc.2017.18. Reports that use of single-letter variable names doesn't affect ability to modify code, and that some single-letter variable names have implicit types and meanings.\nBenn2007a\n\n    Jens Bennedsen and Michael E. Caspersen: \"Failure Rates in Introductory Programming\". ACM SIGCSE Bulletin, 39(2), 6 2007, doi:10.1145/1272848.1272879. Reports that 67\\% of students pass CS1, with variation from 5\\% to 100\\%.\nBenn2007b\n\n    Jens Bennedsen and Carsten Schulte: \"What Does ``Objects-first'' Mean?: An International Study of Teachers' Perceptions of Objects-first\". In 2007 Koli Calling Conference on Computing Education Research (Koli'07), 2007. Teases out three meanings of ``objects first'' in computing education.\nBenn2000\n\n    Patricia Benner: From Novice to Expert: Excellence and Power in Clinical Nursing Practice. Pearson, 2000, 0130325228. A classic study of clinical judgment and the development of expertise.\nBerg2012\n\n    Joseph Bergin, Jane Chandler, Jutta Eckstein, Helen Sharp, Mary Lynn Manns, Klaus Marquardt, Marianna Sipos, Markus V\u00f6lter, and Eugene Wallingford: Pedagogical Patterns: Advice for Educators. CreateSpace, 2012, 9781479171828. A catalog of design patterns for teaching.\nBiel1995\n\n    Katerine Bielaczyc, Peter L. Pirolli, and Ann L. Brown: \"Training in Self-Explanation and Self-Regulation Strategies: Investigating the Effects of Knowledge Acquisition Activities on Problem Solving\". Cognition and Instruction, 13(2), 6 1995, doi:10.1207/s1532690xci1302_3. Reports that training learners in self-explanation accelerates their learning.\nBigg2011\n\n    John Biggs and Catherine Tang: Teaching for Quality Learning at University. Open University Press, 2011, 0335242758. A step-by-step guide to lesson development, delivery, and evaluation for people working in higher education.\nBink2012\n\n    Dave Binkley, Marcia Davis, Dawn Lawrie, Jonathan I. Maletic, Christopher Morrell, and Bonita Sharif: \"The Impact of Identifier Style on Effort and Comprehension\". Empirical Software Engineering, 18(2), 5 2012, doi:10.1007/s10664-012-9201-4. Reports that reading and understanding code is fundamentally different from reading prose, and that experienced developers are relatively unaffected by identifier style, but beginners benefit from the use of camel case (versus pothole case).\nBlik2014\n\n    Paulo Blikstein, Marcelo Worsley, Chris Piech, Mehran Sahami, Steven Cooper, and Daphne Koller: \"Programming Pluralism: Using Learning Analytics to Detect Patterns in the Learning of Computer Programming\". Journal of the Learning Sciences, 23(4), 10 2014, doi:10.1080/10508406.2014.954750. Reports an attempt to categorize novice programmer behavior using machine learning that found interesting patterns on individual assignments.\nBloo1984\n\n    Benjamin S. Bloom: \"The 2 Sigma Problem: The Search for Methods of Group Instruction as Effective as One-to-One Tutoring\". Educational Researcher, 13(6), 6 1984, doi:10.3102/0013189x013006004. Reports that students tutored one-to-one using mastery learning techniques perform two standard deviations better than those who learned through conventional lecture.\nBoll2014\n\n    David Bollier: Think Like a Commoner: A Short Introduction to the Life of the Commons. New Society Publishers, 2014, 0865717680. A short introduction to a widely-used model of governance.\nBoha2011\n\n    Mark Bohay, Daniel P. Blakely, Andrea K. Tamplin, and Gabriel A. Radvansky: \"Note Taking, Review, Memory, and Comprehension\". American Journal of Psychology, 124(1), 2011, doi:10.5406/amerjpsyc.124.1.0063. Reports that note-taking improves retention most at deeper levels of understanding.\nBorr2014\n\n    Maura Borrego and Charles Henderson: \"Increasing the Use of Evidence-Based Teaching in STEM Higher Education: A Comparison of Eight Change Strategies\". Journal of Engineering Education, 103(2), 4 2014, doi:10.1002/jee.20040. Categorizes different approaches to effecting change in higher education.\nBria2015\n\n    Samuel A. Brian, Richard N. Thomas, James M. Hogan, and Colin Fidge: \"Planting Bugs: A System for Testing Students' Unit Tests\". In 2015 Conference on Innovation and Technology in Computer Science Education (ITiCSE'15), 2015, doi:10.1145/2729094.2742631. Describes a tool for assessing students' programs and unit tests and finds that students often write weak tests and misunderstand the role of unit testing.\nBroo2016\n\n    Stephen D. Brookfield and Stephen Preskill: The Discussion Book: 50 Great Ways to Get People Talking. Jossey-Bass, 2016, 9781119049715. Describes fifty different ways to get groups talking productively.\nBrop1983\n\n    Jere E. Brophy: \"Research on the Self-Fulfilling Prophecy and Teacher Expectations\". Journal of Educational Psychology, 75(5), 1983, doi:10.1037/0022-0663.75.5.631. A early, influential study of the effects of teachers' perceptions on students' achievements.\nBrow2007\n\n    Michael Jacoby Brown: Building Powerful Community Organizations: A Personal Guide to Creating Groups that Can Solve Problems and Change the World. Long Haul Press, 2007, 0977151808. A practical guide to creating effective organizations in and for communities.\nBrow2017\n\n    Neil C. C. Brown and Amjad Altadmri: \"Novice Java Programming Mistakes\". ACM Transactions on Computing Education, 17(2), 5 2017, doi:10.1145/2994154. Summarizes the authors' analysis of novice programming mistakes.\nBrow2018\n\n    Neil C. C. Brown and Greg Wilson: \"Ten Quick Tips for Teaching Programming\". PLoS Computational Biology, 14(4), 4 2018, doi:10.1371/journal.pcbi.1006023. A short summary of what we actually know about teaching programming and why we believe it's true.\nBuff2015\n\n    Kevin Buffardi and Stephen H. Edwards: \"Reconsidering Automated Feedback: A Test-Driven Approach\". In 2015 Technical Symposium on Computer Science Education (SIGCSE'15), 2015, doi:10.1145/2676723.2677313. Describes a system that associates failed tests with particular features in a learner's code so that learners cannot game the system.\nBurg2015\n\n    Sheryl E. Burgstahler: Universal Design in Higher Education: From Principles to Practice. Harvard Education Press, 2015, 9781612508160. Describes how to make online teaching materials accessible to everyone.\nBurk2018\n\n    Quinn Burke, Cinamon Bailey, Louise Ann Lyon, and Emily Greeen: \"Understanding the Software Development Industry's Perspective on Coding Boot Camps Versus Traditional 4-Year Colleges\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159485. Compares the skills and credentials that tech industry recruiters are looking for to those provided by 4-year degrees and bootcamps.\nButl2017\n\n    Zack Butler, Ivona Bezakova, and Kimberly Fluet: \"Pencil Puzzles for Introductory Computer Science\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017765. Describes pencil-and-paper puzzles that can be turned into CS1/CS2 assignments, and reports that they are enjoyed by students and encourage meta-cognition.\nByck2005\n\n    Pauli Byckling, Petri Gerdt, and Jorma Sajaniemi: \"Roles of Variables in Object-Oriented Programming\". In 2005 Conference on Object-Oriented Programming, Systems, Languages, and Applications (OOPSLA'05), 2005, doi:10.1145/1094855.1094972. Presents single-variable design patterns common in novice programs.\nCamp2016\n\n    Jennifer Campbell, Diane Horton, and Michelle Craig: \"Factors for Success in Online CS1\". In 2016 Conference on Innovation and Technology in Computer Science Education (ITiCSE'16), 2016, doi:10.1145/2899415.2899457. Compares students who opted in to an online CS1 class online with those who took it in person in a flipped classroom.\nCarr1987\n\n    John Carroll, Penny Smith-Kerker, James Ford, and Sandra Mazur-Rimetz: \"The Minimal Manual\". Human-Computer Interaction, 3(2), 6 1987, doi:10.1207/s15327051hci0302_2. The foundational paper on minimalist instruction.\nCarr2014\n\n    John Carroll: \"Creating Minimalist Instruction\". International Journal of Designs for Learning, 5(2), 11 2014, doi:10.14434/ijdl.v5i2.12887. A look back on the author's work on minimalist instruction.\nCart2017\n\n    Adam Scott Carter and Christopher David Hundhausen: \"Using Programming Process Data to Detect Differences in Students' Patterns of Programming\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017785. Shows that students of different levels approach programming tasks differently, and that these differences can be detected automatically.\nCasp2007\n\n    Michael E. Caspersen and Jens Bennedsen: \"Instructional Design of a Programming Course\". In 2007 International Computing Education Research Conference (ICER'07), 2007, doi:10.1145/1288580.1288595. Goes from a model of human cognition to three learning theories, and from there to the design of an introductory object-oriented programming course.\nCele2018\n\n    Mehmet Celepkolu and Kristy Elizabeth Boyer: \"Thematic Analysis of Students' Reflections on Pair Programming in CS1\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159516. Reports that pair programming has the same learning gains side-by-side programming but higher student satisfaction.\nCeti2016\n\n    Ibrahim Cetin and Christine Andrews-Larson: \"Learning Sorting Algorithms Through Visualization Construction\". Computer Science Education, 26(1), 1 2016, doi:10.1080/08993408.2016.1160664. Reports that people learn more from constructing algorithm visualizations than they do from viewing visualizations constructed by others.\nChen2009\n\n    Nicholas Chen and Maurice Rabb: \"A Pattern Language for Screencasting\". In 2009 Conference on Pattern Languages of Programs (PLoP'09), 2009, doi:10.1145/1943226.1943234. A brief, well-organized collection of tips for making screencasts.\nChen2017\n\n    Nick Cheng and Brian Harrington: \"The Code Mangler: Evaluating Coding Ability Without Writing Any Code\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017704. Reports that student performance on exercises in which they undo code mangling correlates strongly with performance on traditional assessments.\nChen2018\n\n    Chen Chen, Paulina Haduong, Karen Brennan, Gerhard Sonnert, and Philip Sadler: \"The effects of first programming language on college students' computing attitude and achievement: a comparison of graphical and textual languages\". Computer Science Education, 29(1), 11 2018, doi:10.1080/08993408.2018.1547564. Finds that students whose first language was graphical had higher grades than students whose first language was textual when the languages were introduced in or before early adolescent years.\nCher2007\n\n    Mauro Cherubini, Gina Venolia, Rob DeLine, and Amy J. Ko: \"Let's Go to the Whiteboard: How and Why Software Developers Use Drawings\". In 2007 Conference on Human Factors in Computing Systems (CHI'07), 2007, doi:10.1145/1240624.1240714. Reports that developers draw diagrams to aid discussion rather than to document designs.\nCher2009\n\n    Sapna Cheryan, Victoria C. Plaut, Paul G. Davies, and Claude M. Steele: \"Ambient Belonging: How Stereotypical Cues Impact Gender Participation in Computer Science\". Journal of Personality and Social Psychology, 97(6), 2009, doi:10.1037/a0016239. Reports that subtle environmental clues have a measurable impact on the interest that people of different genders have in computing.\nChet2014\n\n    Raj Chetty, John N. Friedman, and Jonah E. Rockoff: \"Measuring the Impacts of Teachers II: Teacher Value-Added and Student Outcomes in Adulthood\". American Economic Review, 104(9), 9 2014, doi:10.1257/aer.104.9.2633. Reports that good teachers have a small but measurable impact on student outcomes.\nChi1989\n\n    Michelene T. H. Chi, Miriam Bassok, Matthew W. Lewis, Peter Reimann, and Robert Glaser: \"Self-Explanations: How Students Study and Use Examples in Learning to Solve Problems\". Cognitive Science, 13(2), 4 1989, doi:10.1207/s15516709cog1302_1. A seminal paper on the power of self-explanation.\nCoco2018\n\n    Center for Community Organizations: \"The ``Problem'' Woman of Colour in the Workplace\". https://coco-net.org/problem-woman-colour-nonprofit-organizations/, 2018. Outlines the experience of many women of color in the workplace.\nColl1991\n\n    Allan Collins, John Seely Brown, and Ann Holum: \"Cognitive Apprenticeship: Making Thinking Visible\". American Educator, 6, 1991. Describes an educational model based on the notion of apprenticeship and master guidance.\nCoom2012\n\n    Norman Coombs: Making Online Teaching Accessible. Jossey-Bass, 2012, 9781458725288. An accessible guide to making online lessons accessible.\nCovi2017\n\n    Martin V. Covington, Linda M. von Hoene, and Dominic J. Voge: Life Beyond Grades: Designing College Courses to Promote Intrinsic Motivation. Cambridge University Press, 2017, 9780521805230. Explores ways of balancing intrinsic and extrinsic motivation in institutional education.\nCraw2010\n\n    Matthew B. Crawford: Shop Class as Soulcraft: An Inquiry into the Value of Work. Penguin, 2010, 9780143117469. A deep analysis of what we learn about ourselves by doing certain kinds of work.\nCrou2001\n\n    Catherine H. Crouch and Eric Mazur: \"Peer Instruction: Ten Years of Experience and Results\". American Journal of Physics, 69(9), 9 2001, doi:10.1119/1.1374249. Reports results from the first ten years of peer instruction in undergraduate physics classes, and describes ways in which its implementation changed during that time.\nCsik2008\n\n    Mihaly Csikszentmihaly: Flow: The Psychology of Optimal Experience. Harper, 2008, 978-0061339202. An influential discussion of what it means to be fully immersed in a task.\nCunn2017\n\n    Kathryn Cunningham, Sarah Blanchard, Barbara J. Ericson, and Mark Guzdial: \"Using Tracing and Sketching to Solve Programming Problems\". In 2017 Conference on International Computing Education Research (ICER'17), 2017, doi:10.1145/3105726.3106190. Found that writing new values near variables' names as they change is the most effective tracing technique.\nCutt2017\n\n    Quintin Cutts, Charles Riedesel, Elizabeth Patitsas, Elizabeth Cole, Peter Donaldson, Bedour Alshaigy, Mirela Gutica, Arto Hellas, Edurne Larraza-Mendiluze, and Robert McCartney: \"Early Developmental Activities and Computing Proficiency\". In 2017 Conference on Innovation and Technology in Computer Science Education (ITiCSE'17), 2017, doi:10.1145/3174781.3174789. Surveyed adult computer users about childhood activities and found strong correlation between confidence and computer use based on reading on one's own and playing with construction toys with no moving parts (like Lego).\nDage2010\n\n    Barth\u00e9l\u00e9my Dagenais, Harold Ossher, Rachel K. E. Bellamy, Martin P. Robillard, and Jacqueline P. de Vries: \"Moving Into a New Software Project Landscape\". In 2010 International Conference on Software Engineering (ICSE'10), 2010, doi:10.1145/1806799.1806842. A look at how people move from one project or domain to another.\nDahl2018\n\n    Sarah Dahlby Albright, Titus H. Klinge, and Samuel A. Rebelsky: \"A Functional Approach to Data Science in CS1\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159550. Describes the design of a CS1 class built around data science.\nDeb2018\n\n    Debzani Deb, Muztaba Fuad, James Etim, and Clay Gloster: \"MRS: Automated Assessment of Interactive Classroom Exercises\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159607. Reports that doing in-class exercises with realtime feedback using mobile devices improved concept retention and student engagement while reducing failure rates.\nDeBr2015\n\n    Pedro De Bruyckere, Paul A. Kirschner, and Casper D. Hulshof: Urban Myths about Learning and Education. Academic Press, 2015, 9780128015377. Describes and debunks some widely-held myths about how people learn.\nDenn2019\n\n    Paul Denny, Brett A. Becker, Michelle Craig, Greg Wilson, and Piotr Banaszkiewicz: \"Research This! Questions that Computing Educators Most Want Computing Education Researchers to Answer\". In 2019 Conference on International Computing Education Research (ICER'19), 2019. Found little overlap between the questions that computing education researchers are most interested in and the questions practitioners want answered.\nDerb2006\n\n    Esther Derby and Diana Larsen: Agile Retrospectives: Making Good Teams Great. Pragmatic Bookshelf, 2006, 0977616649. Describes how to run a good project retrospective.\nDeve2018\n\n    Gabriel A. Devenyi, R\u00e9mi Emonet, Rayna M. Harris, Kate L. Hertweck, Damien Irving, Ian Milligan, and Greg Wilson: \"Ten Simple Rules for Collaborative Lesson Development\". PLoS Computational Biology, 14(3), 3 2018, doi:10.1371/journal.pcbi.1005963. Describes how to develop lessons together.\nDida2016\n\n    David Didau and Nick Rose: What Every Teacher Needs to Know About Psychology. John Catt Educational, 2016, 1909717851. An informative, opinionated explanation of what modern psychology has to say about teaching.\nDiSa2014a\n\n    Betsy DiSalvo, Mark Guzdial, Amy Bruckman, and Tom McKlin: \"Saving Face While Geeking Out: Video Game Testing as a Justification for Learning Computer Science\". Journal of the Learning Sciences, 23(3), 7 2014, doi:10.1080/10508406.2014.893434. Found that 65\\% of male African-American participants in a game testing program went on to study computing.\nDiSa2014b\n\n    Betsy DiSalvo, Cecili Reid, and Parisa Khanipour Roshan: \"They Can't Find Us\". In 2014 Technical Symposium on Computer Science Education (SIGCSE'14), 2014, doi:10.1145/2538862.2538933. Reports that the search terms parents were likely to use for out-of-school CS classes didn't actually find those classes.\nDouc2005\n\n    Christopher Douce, David Livingstone, and James Orwell: \"Automatic Test-Based Assessment of Programming\". Journal on Educational Resources in Computing, 5(3), 9 2005, doi:10.1145/1163405.1163409. Reviews the state of auto-graders at the time.\nDuBo1986\n\n    Benedict Du Boulay: \"Some Difficulties of Learning to Program\". Journal of Educational Computing Research, 2(1), 2 1986, doi:10.2190/3lfx-9rrf-67t8-uvk9. Introduces the idea of a notional machine.\nEdwa2014a\n\n    Stephen H. Edwards, Zalia Shams, and Craig Estep: \"Adaptively Identifying Non-Terminating Code when Testing Student Programs\". In 2014 Technical Symposium on Computer Science Education (SIGCSE'14), 2014, doi:10.1145/2538862.2538926. Describes an adaptive scheme for detecting non-terminating student coding submissions.\nEdwa2014b\n\n    Stephen H. Edwards and Zalia Shams: \"Do Student Programmers All Tend to Write the Same Software Tests?\". In 2014 Conference on Innovation and Technology in Computer Science Education (ITiCSE'14), 2014, doi:10.1145/2591708.2591757. Reports that students wrote tests for the happy path rather than to detect hidden bugs.\nEndr2014\n\n    Stefan Endrikat, Stefan Hanenberg, Romain Robbes, and Andreas Stefik: \"How Do API Documentation and Static Typing Affect API Usability?\". In 2014 International Conference on Software Engineering (ICSE'14), 2014, doi:10.1145/2568225.2568299. Shows that types do add complexity to programs, but it pays off fairly quickly by acting as documentation hints for a method's use.\nEnsm2003\n\n    Nathan L. Ensmenger: \"Letting the ``Computer Boys'' Take Over: Technology and the Politics of Organizational Transformation\". International Review of Social History, 48(S11), 12 2003, doi:10.1017/s0020859003001305. Describes how programming was turned from a female into a male profession in the 1960s.\nEnsm2012\n\n    Nathan L. Ensmenger: The Computer Boys Take Over: Computers, Programmers, and the Politics of Technical Expertise. MIT Press, 2012, 9780262517966. Traces the emergence and rise of computer experts in the 20th Century, and particularly the way that computing became male-gendered.\nEppl2006\n\n    Martin J. Eppler: \"A Comparison Between Concept Maps, Mind Maps, Conceptual Diagrams, and Visual Metaphors as Complementary Tools for Knowledge Construction and Sharing\". Information Visualization, 5(3), 6 2006, doi:10.1057/palgrave.ivs.9500131. Compares concept maps, mind maps, conceptual diagrams, and visual metaphors as learning tools.\nEpst2002\n\n    Lewis Carroll Epstein: Thinking Physics: Understandable Practical Reality. Insight Press, 2002, 0935218084. An entertaining problem-based introduction to thinking like a physicist.\nEric2015\n\n    Barbara J. Ericson, Steven Moore, Briana B. Morrison, and Mark Guzdial: \"Usability and Usage of Interactive Features in an Online Ebook for CS Teachers\". In 2015 Workshop in Primary and Secondary Computing Education (WiPSCE'15), 2015, doi:10.1145/2818314.2818335. Reports that learners are more likely to attempt Parsons Problems than nearby multiple choice questions in an ebook.\nEric2016\n\n    K. Anders Ericsson: \"Summing Up Hours of Any Type of Practice Versus Identifying Optimal Practice Activities\". Perspectives on Psychological Science, 11(3), 5 2016, doi:10.1177/1745691616635600. A critique of a meta-study of deliberate practice based on the latter's overly-broad inclusion of activities.\nEric2017\n\n    Barbara J. Ericson, Lauren E. Margulieux, and Jochen Rick: \"Solving Parsons Problems versus Fixing and Writing Code\". In 2017 Koli Calling Conference on Computing Education Research (Koli'17), 2017, doi:10.1145/3141880.3141895. Reports that solving 2D Parsons problems with distractors takes less time than writing or fixing code but has equivalent learning outcomes.\nFarm2006\n\n    Eugene Farmer: \"The Gatekeeper's Guide, or How to Kill a Tool\". IEEE Software, 23(6), 11 2006, doi:10.1109/ms.2006.174. Ten tongue-in-cheek rules for making sure that a new software tool doesn't get adopted.\nFehi2008\n\n    Chris Fehily: SQL: Visual QuickStart Guide. Peachpit Press, 2008, 0321553578. An introduction to SQL that is both a good tutorial and a good reference guide.\nFinc2007\n\n    Sally Fincher and Josh Tenenberg: \"Warren's Question\". In 2007 International Computing Education Research Conference (ICER'07), 2007, doi:10.1145/1288580.1288588. A detailed look at a particular instance of transferring a teaching practice.\nFinc2012\n\n    Sally Fincher, Brad Richards, Janet Finlay, Helen Sharp, and Isobel Falconer: \"Stories of Change: How Educators Change Their Practice\". In 2012 Frontiers in Education Conference (FIE'12), 10 2012, doi:10.1109/fie.2012.6462317. A detailed look at how educators actually adopt new teaching practices.\nFinc2019\n\n    Sally Fincher and Anthony Robins (eds.): The Cambridge Handbook of Computing Education Research. Cambridge University Press, 2019, 978-1108721899. A 900-page summary of what we know about computing education.\nFink2013\n\n    L. Dee Fink: Creating Significant Learning Experiences: An Integrated Approach to Designing College Courses. Jossey-Bass, 2013, 1118124251. A step-by-step guide to a systematic lesson design process.\nFisc2015\n\n    Lars Fischer and Stefan Hanenberg: \"An empirical investigation of the effects of type systems and code completion on API usability using TypeScript and JavaScript in MS Visual Studio\". In 11th Symposium on Dynamic Languages (DLS'15), 2015, doi:10.1145/2816707.2816720. Found that static typing improved programmer efficiency independently of code completion.\nFisl2014\n\n    Kathi Fisler: \"The Recurring Rainfall Problem\". In 2014 International Computing Education Research Conference (ICER'14), 2014, doi:10.1145/2632320.2632346. Reports that students made fewer low-level errors when solving the Rainfall Problem in a functional language.\nFitz2008\n\n    Sue Fitzgerald, Gary Lewandowski, Ren\u00e9e McCauley, Laurie Murphy, Beth Simon, Lynda Thomas, and Carol Zander: \"Debugging: Finding, Fixing and Flailing, a Multi-Institutional Study of Novice Debuggers\". Computer Science Education, 18(2), 6 2008, doi:10.1080/08993400802114508. Reports that good undergraduate debuggers are good programmers but not necessarily vice versa, and that novices use tracing and testing rather than causal reasoning.\nFord2016\n\n    Denae Ford, Justin Smith, Philip J. Guo, and Chris Parnin: \"Paradise Unplugged: Identifying Barriers for Female Participation on Stack Overflow\". In 2016 International Symposium on Foundations of Software Engineering (FSE'16), 2016, doi:10.1145/2950290.2950331. Reports that lack of awareness of site features, feeling unqualified to answer questions, intimidating community size, discomfort interacting with or relying on strangers, and perception that they shouldn't be slacking were seen as significantly more problematic by female Stack Overflow contributors rather than male ones.\nFoge2005\n\n    Karl Fogel: Producing Open Source Software: How to Run a Successful Free Software Project. O'Reilly Media, 2005, 0596007590. The definite guide to managing open source software development projects.\nFran2018\n\n    Pablo Frank-Bolton and Rahul Simha: \"Docendo Discimus: Students Learn by Teaching Peers Through Video\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159466. Reports that students who make short videos to teach concepts to their peers have a significant increase in their own learning compared to those who only study the material or view videos.\nFree1972\n\n    Jo Freeman: \"The Tyranny of Structurelessness\". The Second Wave, 2(1), 1972. Points out that every organization has a power structure: the only question is whether it's accountable or not.\nFree2014\n\n    S. Freeman, S. L. Eddy, M. McDonough, M. K. Smith, N. Okoroafor, H. Jordt, and M. P. Wenderoth: \"Active learning increases student performance in science, engineering, and mathematics\". Proc. National Academy of Sciences, 111(23), 5 2014, doi:10.1073/pnas.1319030111. Presents a meta-analysis of the benefits of active learning.\nFrie2016\n\n    Marilyn Friend and Lynne Cook: Interactions: Collaboration Skills for School Professionals. Pearson, 2016, 0134168542. A textbook on how teachers can work with other teachers.\nGalp2002\n\n    Vashti Galpin: \"Women in Computing Around the World\". ACM SIGCSE Bulletin, 34(2), 6 2002, doi:10.1145/543812.543839. Looks at female participation in computing in 35 countries.\nGauc2011\n\n    Danielle Gaucher, Justin Friesen, and Aaron C. Kay: \"Evidence that Gendered Wording in Job Advertisements Exists and Sustains Gender Inequality\". Journal of Personality and Social Psychology, 101(1), 2011, doi:10.1037/a0022530. Reports that gendered wording in job recruitment materials can maintain gender inequality in traditionally male-dominated occupations.\nGawa2007\n\n    Atul Gawande: \"The Checklist\". The New Yorker, 12 2007. Describes the life-saving effects of simple checklists.\nGawa2011\n\n    Atul Gawande: \"Personal Best\". The New Yorker, 10 2011. Describes how having a coach can improve practice in a variety of fields.\nGick1987\n\n    Mary L. Gick and Keith J. Holyoak: \"The Cognitive Basis of Knowledge Transfer\". In Transfer of Learning: Contemporary Research and Applications, Elsevier, 1987, doi:10.1016/b978-0-12-188950-0.50008-4. Finds that transference only comes with mastery.\nGorm2014\n\n    Cara Gormally, Mara Evans, and Peggy Brickman: \"Feedback About Teaching in Higher Ed: Neglected Opportunities to Promote Change\". Cell Biology Education, 13(2), 6 2014, doi:10.1187/cbe.13-12-0235. Summarizes best practices for providing instructional feedback, and recommends some specific strategies.\nGree2014\n\n    Elizabeth Green: Building a Better Teacher: How Teaching Works (and How to Teach It to Everyone). W. W. Norton & Company, 2014, 0393351084. Explains why educational reforms in the past fifty years has mostly missed the mark, and what we should do instead.\nGrif2016\n\n    Jean M. Griffin: \"Learning by Taking Apart\". In 2016 Conference on Information Technology Education (SIGITE'16), 2016, doi:10.1145/2978192.2978231. Reports that people learn to program more quickly by deconstructing code than by writing it.\nGrov2017\n\n    Shuchi Grover and Satabdi Basu: \"Measuring Student Learning in Introductory Block-Based Programming\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017723. Reports that middle-school children using blocks-based programming find loops, variables, and Boolean operators difficult to understand.\nGull2004\n\n    Ned Gulley: \"In Praise of Tweaking\". interactions, 11(3), 5 2004, doi:10.1145/986253.986264. Describes an innovative collaborative coding contest.\nGuo2013\n\n    Philip J. Guo: \"Online Python Tutor\". In 2013 Technical Symposium on Computer Science Education (SIGCSE'13), 2013, doi:10.1145/2445196.2445368. Describes the design and use of a web-based execution visualization tool.\nGuo2014\n\n    Philip J. Guo, Juho Kim, and Rob Rubin: \"How Video Production Affects Student Engagement\". In 2014 Conference on Learning @ Scale (L@S'14), 2014, doi:10.1145/2556325.2566239. Measured learner engagement with MOOC videos and reports that short videos are more engaging than long ones and that talking heads are more engaging than tablet drawings.\nGuzd2013\n\n    Mark Guzdial: \"Exploring Hypotheses about Media Computation\". In 2013 International Computing Education Research Conference (ICER'13), 2013, doi:10.1145/2493394.2493397. A look back on ten years of media computation research.\nGuzd2015a\n\n    Mark Guzdial: Learner-Centered Design of Computing Education: Research on Computing for Everyone. Morgan & Claypool Publishers, 2015, 9781627053518. Argues that we must design computing education for everyone, not just people who think they are going to become professional programmers.\nGuzd2015b\n\n    Mark Guzdial: \"Top 10 Myths About Teaching Computer Science\". https://cacm.acm.org/blogs/blog-cacm/189498-top-10-myths-about-teaching-computer-science/fulltext, 2015. Ten things many people believe about teaching computing that simply aren't true.\nGuzd2016\n\n    Mark Guzdial: \"Five Principles for Programming Languages for Learners\". https://cacm.acm.org/blogs/blog-cacm/203554-five-principles-for-programming-languages-for-learners/fulltext, 2016. Explains how to choose a programming language for people who are new to programming.\nHaar2017\n\n    Lassi Haaranen: \"Programming as a Performance - Live-streaming and Its Implications for Computer Science Education\". In 2017 Conference on Innovation and Technology in Computer Science Education (ITiCSE'17), 2017, doi:10.1145/3059009.3059035. An early look at live streaming of coding as a teaching technique.\nHagg2016\n\n    M. S. Hagger, N. L. D. Chatzisarantis, H. Alberts, C. O. Anggono, C. Batailler, A. R. Birt, R. Brand, M. J. Brandt, G. Brewer, S. Bruyneel, D. P. Calvillo, W. K. Campbell, P. R. Cannon, M. Carlucci, N. P. Carruth, T. Cheung, A. Crowell, D. T. D. De Ridder, S. Dewitte, M. Elson, J. R. Evans, B. A. Fay, B. M. Fennis, A. Finley, Z. Francis, E. Heise, H. Hoemann, M. Inzlicht, S. L. Koole, L. Koppel, F. Kroese, F. Lange, K. Lau, B. P. Lynch, C. Martijn, H. Merckelbach, N. V. Mills, A. Michirev, A. Miyake, A. E. Mosser, M. Muise, D. Muller, M. Muzi, D. Nalis, R. Nurwanti, H. Otgaar, M. C. Philipp, P. Primoceri, K. Rentzsch, L. Ringos, C. Schlinkert, B. J. Schmeichel, S. F. Schoch, M. Schrama, A. Sch\u00fctz, A. Stamos, G. Tingh\u00f6g, J. Ullrich, M. vanDellen, S. Wimbarti, W. Wolff, C. Yusainy, O. Zerhouni, and M. Zwienenberg: \"A Multilab Preregistered Replication of the Ego-Depletion Effect\". Perspectives on Psychological Science, 11(4), 2016, doi:10.1177/1745691616652873. A meta-analysis that found insufficient evidence to substantiate the ego depletion effect.\nHake1998\n\n    Richard R. Hake: \"Interactive Engagement versus Traditional Methods: A Six-Thousand-Student Survey of Mechanics Test Data for Introductory Physics Courses\". American Journal of Physics, 66(1), 1 1998, doi:10.1119/1.18809. Reports the use of a concept inventory to measure the benefits of interactive engagement as a teaching technique.\nHamo2017\n\n    Sally Hamouda, Stephen H. Edwards, Hicham G. Elmongui, Jeremy V. Ernst, and Clifford A. Shaffer: \"A Basic Recursion Concept Inventory\". Computer Science Education, 27(2), 4 2017, doi:10.1080/08993408.2017.1414728. Reports early work on developing a concept inventory for recursion.\nHank2011\n\n    Brian Hanks, Sue Fitzgerald, Ren\u00e9e McCauley, Laurie Murphy, and Carol Zander: \"Pair Programming in Education: a Literature Review\". Computer Science Education, 21(2), 6 2011, doi:10.1080/08993408.2011.579808. Reports increased success rates and retention with pair programming, with some evidence that it is particularly beneficial for women, but finds that scheduling and partner compatibility can be problematic.\nHann2009\n\n    Jo Erskine Hannay, Tore Dyb\u00e5, Erik Arisholm, and Dag I. K. Sj\u00f8berg: \"The Effectiveness of Pair Programming: A Meta-analysis\". Information and Software Technology, 51(7), 7 2009, doi:10.1016/j.infsof.2009.02.001. A comprehensive meta-analysis of research on pair programming.\nHann2010\n\n    Jo Erskine Hannay, Erik Arisholm, Harald Engvik, and Dag I. K. Sj\u00f8berg: \"Effects of Personality on Pair Programming\". IEEE Transactions on Software Engineering, 36(1), 1 2010, doi:10.1109/tse.2009.41. Reports weak correlation between the ``Big Five'' personality traits and performance in pair programming.\nHans2015\n\n    John D. Hansen and Justin Reich: \"Democratizing education? Examining access and usage patterns in massive open online courses\". Science, 350(6265), 12 2015, doi:10.1126/science.aab3782. Reports that MOOCs are mostly used by the affluent.\nHarm2016\n\n    Kyle James Harms, Jason Chen, and Caitlin L. Kelleher: \"Distractors in Parsons Problems Decrease Learning Efficiency for Young Novice Programmers\". In 2016 International Computing Education Research Conference (ICER'16), 2016, doi:10.1145/2960310.2960314. Shows that adding distractors to Parsons Problems does not improve learning outcomes but increases solution times.\nHarr2018\n\n    Brian Harrington and Nick Cheng: \"Tracing vs. Writing Code: Beyond the Learning Hierarchy\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159530. Finds that the gap between being able to trace code and being able to write it has largely closed by CS2, and that students who still have a gap (in either direction) are likely to do poorly in the course.\nHazz2014\n\n    Orit Hazzan, Tami Lapidot, and Noa Ragonis: Guide to Teaching Computer Science: An Activity-Based Approach. Springer, 2014, 9781447166290. A textbook for teaching computer science at the K-12 level with dozens of activities.\nHend2015a\n\n    Charles Henderson, Ren\u00e9e Cole, Jeff Froyd, Debra Friedrichsen, Raina Khatri, and Courtney Stanford: Designing Educational Innovations for Sustained Adoption. Increase the Impact, 2015, 0996835210. A detailed analysis of strategies for getting institutions in higher education to make changes.\nHend2015b\n\n    Charles Henderson, Ren\u00e9e Cole, Jeff Froyd, Debra Friedrichsen, Raina Khatri, and Courtney Stanford: \"Designing Educational Innovations for Sustained Adoption (Executive Summary)\". http://www.increasetheimpact.com/resources.html, 2015. A short summary of key points from the authors' work on effecting change in higher education.\nHend2017\n\n    Carl Hendrick and Robin Macpherson: What Does This Look Like In The Classroom?: Bridging The Gap Between Research And Practice. John Catt Educational, 2017, 9781911382379. A collection of responses by educational experts to questions asked by classroom teachers, with prefaces by the authors.\nHenr2010\n\n    Joseph Henrich, Steven J. Heine, and Ara Norenzayan: \"The Weirdest People in the World?\". Behavioral and Brain Sciences, 33(2-3), 6 2010, doi:10.1017/s0140525x0999152x. Points out that the subjects of most published psychological studies are Western, educated, industrialized, rich, and democratic.\nHest1992\n\n    David Hestenes, Malcolm Wells, and Gregg Swackhamer: \"Force Concept Inventory\". The Physics Teacher, 30(3), 3 1992, doi:10.1119/1.2343497. Describes the Force Concept Inventory's motivation, design, and impact.\nHick2018\n\n    Marie Hicks: Programmed Inequality: How Britain Discarded Women Technologists and Lost Its Edge in Computing. MIT Press, 2018, 9780262535182. Describes how Britain lost its early dominance in computing by systematically discriminating against its most qualified workers: women.\nHofm2017\n\n    Johannes Hofmeister, Janet Siegmund, and Daniel V. Holt: \"Shorter Identifier Names Take Longer to Comprehend\". In 2017 Conference on Software Analysis, Evolution and Reengineering (SANER'17), 2 2017, doi:10.1109/saner.2017.7884623. Reports that using words for variable names makes comprehension faster than using abbreviations or single-letter names for variables.\nHoll1960\n\n    Jack Hollingsworth: \"Automatic Graders for Programming Classes\". Communications of the ACM, 3(10), 10 1960, doi:10.1145/367415.367422. A brief note describing what may have been the world's first auto-grader.\nHu2017\n\n    Helen H. Hu, Cecily Heiner, Thomas Gagne, and Carl Lyman: \"Building a Statewide Computer Science Teacher Pipeline\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017788. Reports that a six-month program for high school teachers converting to teach CS quadruples the number of teachers without noticeable reduction of student outcomes and increases teachers' belief that anyone can program.\nHust2012\n\n    Therese Huston: Teaching What You Don't Know. Harvard University Press, 2012, 0674066170. A pointed, funny, and very useful exploration of exactly what the title says.\nIhan2010\n\n    Petri Ihantola, Tuukka Ahoniemi, Ville Karavirta, and Otto Sepp\u00e4l\u00e4: \"Review of Recent Systems for Automatic Assessment of Programming Assignments\". In 2010 Koli Calling Conference on Computing Education Research (Koli'10), 2010, doi:10.1145/1930464.1930480. Reviews auto-grading tools of the time.\nIhan2011\n\n    Petri Ihantola and Ville Karavirta: \"Two-dimensional Parson's Puzzles: The Concept, Tools, and First Observations\". Journal of Information Technology Education: Innovations in Practice, 10, 2011, doi:10.28945/1394. Describes a 2D Parsons Problem tool and early experiences with it that confirm that experts solve outside-in rather than line-by-line.\nIhan2016\n\n    Petri Ihantola, Kelly Rivers, Miguel \u00c1ngel Rubio, Judy Sheard, Bronius Skupas, Jaime Spacco, Claudia Szabo, Daniel Toll, Arto Vihavainen, Alireza Ahadi, Matthew Butler, J\u00fcrgen B\u00f6rstler, Stephen H. Edwards, Essi Isohanni, Ari Korhonen, and Andrew Petersen: \"Educational Data Mining and Learning Analytics in Programming: Literature Review and Case Studies\". In 2016 Conference on Innovation and Technology in Computer Science Education (ITiCSE'16), 2016, doi:10.1145/2858796.2858798. A survey of methods used in mining and analyzing programming data.\nIjss2000\n\n    Wijnand A. IJsselsteijn, Huib de Ridder, Jonathan Freeman, and Steve E. Avons: \"Presence: Concept, Determinants, and Measurement\". In 2000 Conference on Human Vision and Electronic Imaging, 6 2000, doi:10.1117/12.387188. Summarizes thinking of the time about real and virtual presence.\nIrib2009\n\n    Alicia Iriberri and Gondy Leroy: \"A Life-Cycle Perspective on Online Community Success\". ACM Computing Surveys, 41(2), 2 2009, doi:10.1145/1459352.1459356. Reviews research on online communities organized according to a five-stage lifecycle model.\nJuss2005\n\n    Lee Jussim and Kent D. Harber: \"Teacher Expectations and Self-Fulfilling Prophecies: Knowns and Unknowns, Resolved and Unresolved Controversies\". Personality and Social Psychology Review, 9(2), 5 2005, doi:10.1207/s15327957pspr0902_3. A survey of the effects of teacher expectations on student outcomes.\nKaly2003\n\n    Slava Kalyuga, Paul Ayres, Paul Chandler, and John Sweller: \"The Expertise Reversal Effect\". Educational Psychologist, 38(1), 3 2003, doi:10.1207/s15326985ep3801_4. Reports that instructional techniques that work well with inexperienced learners lose their effectiveness or have negative consequences when used with more experienced learners.\nKaly2015\n\n    Slava Kalyuga and Anne-Marie Singh: \"Rethinking the Boundaries of Cognitive Load Theory in Complex Learning\". Educational Psychology Review, 28(4), 12 2015, doi:10.1007/s10648-015-9352-0. Argues that cognitive load theory is basically micro-management within a broader pedagogical context.\nKang2016\n\n    Sean H. K. Kang: \"Spaced Repetition Promotes Efficient and Effective Learning\". Policy Insights from the Behavioral and Brain Sciences, 3(1), 1 2016, doi:10.1177/2372732215624708. Summarizes research on spaced repetition and what it means for classroom teaching.\nKapu2016\n\n    Manu Kapur: \"Examining Productive Failure, Productive Success, Unproductive Failure, and Unproductive Success in Learning\". Educational Psychologist, 51(2), 4 2016, doi:10.1080/00461520.2016.1155457. Looks at productive failure as an alternative to inquiry-based learning and approaches based on cognitive load theory.\nKarp2008\n\n    Jeffrey D. Karpicke and Henry L. Roediger: \"The Critical Importance of Retrieval for Learning\". Science, 319(5865), 2 2008, doi:10.1126/science.1152408. Reports that repeated testing improves recall of word lists from 35\\% to 80\\%, even when learners can still access the material but are not tested on it.\nKauf2000\n\n    Deborah B. Kaufman and Richard M. Felder: \"Accounting for Individual Effort in Cooperative Learning Teams\". Journal of Engineering Education, 89(2), 2000. Reports that self-rating and peer ratings in undergraduate courses agree, that collusion isn't significant, that students don't inflate their self-ratings, and that ratings are not biased by gender or race.\nKeme2009\n\n    Chris F. Kemerer and Mark C. Paulk: \"The Impact of Design and Code Reviews on Software Quality: An Empirical Study Based on PSP Data\". IEEE Transactions on Software Engineering, 35(4), 7 2009, doi:10.1109/tse.2009.27. Uses individual data to explore the effectiveness of code review.\nKepp2008\n\n    Jeroen Keppens and David Hay: \"Concept Map Assessment for Teaching Computer Programming\". Computer Science Education, 18(1), 3 2008, doi:10.1080/08993400701864880. A short review of ways concept mapping can be used in CS education.\nKern1978\n\n    Brian W. Kernighan and P. J. Plauger: The Elements of Programming Style. McGraw-Hill, 1978, 0070342075. An early and influential description of the Unix programming philosophy.\nKern1983\n\n    Brian W. Kernighan and Rob Pike: The Unix Programming Environment. Prentice-Hall, 1983, 013937681X. An influential early description of Unix.\nKern1988\n\n    Brian W. Kernighan and Dennis M. Ritchie: The C Programming Language. Prentice-Hall, 1988, 0131103628. The book that made C a popular programming language.\nKern1999\n\n    Brian W. Kernighan and Rob Pike: The Practice of Programming. Addison-Wesley, 1999, 9788177582482. A programming style manual written by two of the creators of modern computing.\nKeun2016a\n\n    Hieke Keuning, Johan Jeuring, and Bastiaan Heeren: \"Towards a Systematic Review of Automated Feedback Generation for Programming Exercises\". In 2016 Conference on Innovation and Technology in Computer Science Education (ITiCSE'16), 2016, doi:10.1145/2899415.2899422. Reports that auto-grading tools often do not give feedback on what to do next, and that teachers cannot easily adapt most of the tools to their needs.\nKeun2016b\n\n    Hieke Keuning, Johan Jeuring, and Bastiaan Heeren: \"Towards a Systematic Review of Automated Feedback Generation for Programming Exercises - Extended Version\". Technical Report UU-CS-2016-001, Utrecht University, 2016. An extended look at feedback messages from auto-grading tools.\nKim2017\n\n    Ada S. Kim and Amy J. Ko: \"A Pedagogical Analysis of Online Coding Tutorials\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017728. Reports that online coding tutorials largely teach similar content, organize content bottom-up, and provide goal-directed practices with immediate feedback, but are not tailored to learners' prior coding knowledge and usually don't tell learners how to transfer and apply knowledge.\nKing1993\n\n    Alison King: \"From Sage on the Stage to Guide on the Side\". College Teaching, 41(1), 1 1993, doi:10.1080/87567555.1993.9926781. An early proposal to flip the classroom.\nKirk1994\n\n    Donald L. Kirkpatrick: Evaluating Training Programs: The Four Levels. Berrett-Koehle, 1994, 1881052494. Defines a widely-used four-level model for evaluating training.\nKirs2006\n\n    Paul A. Kirschner, John Sweller, and Richard E. Clark: \"Why Minimal Guidance During Instruction does not Work: An Analysis of the Failure of Constructivist, Discovery, Problem-Based, Experiential, and Inquiry-Based Teaching\". Educational Psychologist, 41(2), 6 2006, doi:10.1207/s15326985ep4102_1. Argues that inquiry-based learning is less effective for novices than guided instruction.\nKirs2013\n\n    Paul A. Kirschner and Jeroen J. G. van Merri\u00ebnboer: \"Do Learners Really Know Best? Urban Legends in Education\". Educational Psychologist, 48(3), 7 2013, doi:10.1080/00461520.2013.804395. Argues that three learning myths---digital natives, learning styles, and self-educators---all reflect the mistaken belief that learners know what is best for them, and cautions that we may be in a downward spiral in which every attempt by education researchers to rebut these myths confirms their opponents' belief that learning science is pseudo-science.\nKirs2018\n\n    Paul A. Kirschner, John Sweller, Femke Kirschner, and Jimmy Zambrano R.: \"From Cognitive Load Theory to Collaborative Cognitive Load Theory\". International Journal of Computer-Supported Collaborative Learning, 4 2018, doi:10.1007/s11412-018-9277-y. Extends cognitive load theory to include collaborative aspects of learning.\nKoed2015\n\n    Kenneth R. Koedinger, Jihee Kim, Julianna Zhuxin Jia, Elizabeth A. McLaughlin, and Norman L. Bier: \"Learning is Not a Spectator Sport: Doing is Better than Watching for Learning from a MOOC\". In 2015 Conference on Learning @ Scale (L@S'15), 2015, doi:10.1145/2724660.2724681. Measures the benefits of doing rather than watching.\nKoeh2013\n\n    Matthew J. Koehler, Punya Mishra, and William Cain: \"What is Technological Pedagogical Content Knowledge (TPACK)?\". Journal of Education, 193(3), 2013, doi:10.1177/002205741319300303. Refines the discussion of PCK by adding technology, and sketches strategies for building understanding of how to use it.\nKohn2017\n\n    Tobias Kohn: \"Variable Evaluation: An Exploration of Novice Programmers' Understanding and Common Misconceptions\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017724. Reports that students often believe in delayed evaluation or that entire equations are stored in variables.\nKoll2015\n\n    Michael K\u00f6lling: \"Lessons From the Design of Three Educational Programming Environments\". International Journal of People-Oriented Programming, 4(1), 1 2015, doi:10.4018/ijpop.2015010102. Compares three generations of programming environments intended for novice use.\nKrau2016\n\n    Robert E. Kraut and Paul Resnick: Building Successful Online Communities: Evidence-Based Social Design. MIT Press, 2016, 0262528916. Sums up what we actually know about making thriving online communities and why we believe it's true.\nKrug1999\n\n    Justin Kruger and David Dunning: \"Unskilled and Unaware of it: How Difficulties in Recognizing One's Own Incompetence Lead to Inflated Self-Assessments\". Journal of Personality and Social Psychology, 77(6), 1999, doi:10.1037/0022-3514.77.6.1121. The original report on the Dunning-Kruger effect: the less people know, the less accurate their estimate of their knowledge.\nKuch2011\n\n    Marc J. Kuchner: Marketing for Scientists: How to Shine in Tough Times. Island Press, 2011, 1597269948. A short, readable guide to making people aware of, and care about, your work.\nKuit2004\n\n    Marja Kuittinen and Jorma Sajaniemi: \"Teaching Roles of Variables in Elementary Programming Courses\". ACM SIGCSE Bulletin, 36(3), 9 2004, doi:10.1145/1026487.1008014. Presents a few patterns used in novice programming and the pedagogical value of teaching them.\nKulk2013\n\n    Chinmay Kulkarni, Koh Pang Wei, Huy Le, Daniel Chia, Kathryn Papadopoulos, Justin Cheng, Daphne Koller, and Scott R. Klemmer: \"Peer and Self Assessment in Massive Online Classes\". ACM Transactions on Computer-Human Interaction, 20(6), 12 2013, doi:10.1145/2505057. Shows that peer grading can be as effective at scale as expert grading.\nLaba2008\n\n    David F. Labaree: \"The Winning Ways of a Losing Strategy: Educationalizing Social Problems in the United States\". Educational Theory, 58(4), 11 2008, doi:10.1111/j.1741-5446.2008.00299.x. Explores why the United States keeps pushing the solution of social problems onto educational institutions, and why that continues not to work.\nLach2018\n\n    Michael Lachney: \"Computational Communities: African-American Cultural Capital in Computer Science Education\". Computer Science Education, 2 2018, doi:10.1080/08993408.2018.1429062. Explores use of community representation and computational integration to bridge computing and African-American cultural capital in CS education.\nLake2018\n\n    George Lakey: How We Win: A Guide to Nonviolent Direct Action Campaigning. Melville House, 2018, 978-1612197531. A short experience-based guide to effective campaigning.\nLang2013\n\n    James M. Lang: Cheating Lessons: Learning from Academic Dishonesty. Harvard University Press, 2013, 0674724631. Explores why students cheat, and how courses often give them incentives to do so.\nLang2016\n\n    James M. Lang: Small Teaching: Everyday Lessons from the Science of Learning. Jossey-Bass, 2016, 9781118944493. Presents a selection of accessible evidence-based practices that teachers can adopt when they have little time and few resources.\nLazo1993\n\n    Ard W. Lazonder and Hans van der Meij: \"The Minimal Manual: Is Less Really More?\". International Journal of Man-Machine Studies, 39(5), 11 1993, doi:10.1006/imms.1993.1081. Reports that the minimal manual approach to instruction outperforms traditional approaches regardless of prior experience with computers.\nLeak2017\n\n    Mackenzie Leake and Colleen M. Lewis: \"Recommendations for Designing CS Resource Sharing Sites for All Teachers\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017780. Explores why CS teachers don't use resource sharing sites and recommends ways to make them more appealing.\nLee2013\n\n    Cynthia Bailey Lee: \"Experience Report: CS1 in MATLAB for Non-Majors, with Media Computation and Peer Instruction\". In 2013 Technical Symposium on Computer Science Education (SIGCSE'13), 2013, doi:10.1145/2445196.2445214. Describes an adaptation of media computation to a first-year MATLAB course.\nLee2017\n\n    Cynthia Bailey Lee: \"What Can I Do Today to Create a More Inclusive Community in CS?\". http://bit.ly/2oynmSH, 2017. A practical checklist of things instructors can do to make their computing classes more inclusive.\nLemo2014\n\n    Doug Lemov: Teach Like a Champion 2.0: 62 Techniques that Put Students on the Path to College. Jossey-Bass, 2014, 1118901851. Presents 62 classroom techniques drawn from intensive study of thousands of hours of video of good teachers in action.\nLewi2015\n\n    Colleen M. Lewis and Niral Shah: \"How Equity and Inequity Can Emerge in Pair Programming\". In 2015 International Computing Education Research Conference (ICER'15), 2015, doi:10.1145/2787622.2787716. Reports a study of pair programming in a middle-grade classroom in which less equitable pairs were ones that sought to complete the task quickly.\nList2004\n\n    Raymond Lister, Otto Sepp\u00e4l\u00e4, Beth Simon, Lynda Thomas, Elizabeth S. Adams, Sue Fitzgerald, William Fone, John Hamer, Morten Lindholm, Robert McCartney, Jan Erik Mostr\u00f6m, and Kate Sanders: \"A Multi-National Study of Reading and Tracing Skills in Novice Programmers\". In 2004 Conference on Innovation and Technology in Computer Science Education (ITiCSE'04), 2004, doi:10.1145/1044550.1041673. Reports that students are weak at both predicting the outcome of executing a short piece of code and at selecting the correct completion for short pieces of code.\nList2009\n\n    Raymond Lister, Colin Fidge, and Donna Teague: \"Further Evidence of a Relationship Between Explaining, Tracing and Writing Skills in Introductory Programming\". ACM SIGCSE Bulletin, 41(3), 8 2009, doi:10.1145/1595496.1562930. Replicates earlier studies showing that students who cannot trace code usually cannot explain code and that students who tend to perform reasonably well at code writing tasks have also usually acquired the ability to both trace code and explain code.\nLitt2004\n\n    Dennis Littky: The Big Picture: Education Is Everyone's Business. Association for Supervision & Curriculum Development (ASCD), 2004, 0871209713. Essays on the purpose of education and how to make schools better.\nLuxt2009\n\n    Andrew Luxton-Reilly: \"A Systematic Review of Tools That Support Peer Assessment\". Computer Science Education, 19(4), 12 2009, doi:10.1080/08993400903384844. Surveys peer assessment tools that may be of use in computing education.\nLuxt2017\n\n    Andrew Luxton-Reilly, Jacqueline Whalley, Brett A. Becker, Yingjun Cao, Roger McDermott, Claudio Mirolo, Andreas M\u00fchling, Andrew Petersen, Kate Sanders, and Simon: \"Developing Assessments to Determine Mastery of Programming Fundamentals\". In 2017 Conference on Innovation and Technology in Computer Science Education (ITiCSE'17), 2017, doi:10.1145/3174781.3174784. Synthesizes work from many previous works to determine what CS instructors are actually teaching, how those things depend on each other, and how they might be assessed.\nMacn2014\n\n    Brooke N. Macnamara, David Z. Hambrick, and Frederick L. Oswald: \"Deliberate Practice and Performance in Music, Games, Sports, Education, and Professions: A Meta-Analysis\". Psychological Science, 25(8), 7 2014, doi:10.1177/0956797614535810. A meta-study of the effectiveness of deliberate practice.\nMagu2018\n\n    Phil Maguire, Rebecca Maguire, and Robert Kelly: \"Using Automatic Machine Assessment to Teach Computer Programming\". Computer Science Education, 2 2018, doi:10.1080/08993408.2018.1435113. Reports that weekly machine-evaluated tests are a better predictor of exam scores than labs (but that students didn't like the system).\nMalo2010\n\n    John Maloney, Mitchel Resnick, Natalie Rusk, Brian Silverman, and Evelyn Eastmond: \"The Scratch Programming Language and Environment\". ACM Transactions on Computing Education, 10(4), 11 2010, doi:10.1145/1868358.1868363. Summarizes the design of the first generation of Scratch.\nMajo2015\n\n    Claire Howell Major, Michael S. Harris, and Tod Zakrajsek: Teaching for Learning: 101 Intentionally Designed Educational Activities to Put Students on the Path to Success. Routledge, 2015, 0415699363. Catalogs a hundred different kinds of exercises to do with students.\nMann2015\n\n    Mary Lynn Manns and Linda Rising: Fearless Change: Patterns for Introducing New Ideas. Addison-Wesley, 2015, 9780201741575. A catalog of patterns for making change happen in large organizations.\nMarc2011\n\n    Guillaume Marceau, Kathi Fisler, and Shriram Krishnamurthi: \"Measuring the Effectiveness of Error Messages Designed for Novice Programmers\". In 2011 Technical Symposium on Computer Science Education (SIGCSE'11), 2011, doi:10.1145/1953163.1953308. Looks at edit-level responses to error messages, and introduces a useful rubric for classifying user responses to errors.\nMarg2015\n\n    Anoush Margaryan, Manuela Bianco, and Allison Littlejohn: \"Instructional Quality of Massive Open Online Courses (MOOCs)\". Computers & Education, 80, 1 2015, doi:10.1016/j.compedu.2014.08.005. Reports that instructional design quality in MOOCs poor, but that the organization and presentation of material is good.\nMarg2003\n\n    Jane Margolis and Allan Fisher: Unlocking the Clubhouse: Women in Computing. MIT Press, 2003, 0262632691. A groundbreaking report on the gender imbalance in computing, and the steps Carnegie Mellon took to address the problem.\nMarg2010\n\n    Jane Margolis, Rachel Estrella, Joanna Goode, Jennifer Jellison Holme, and Kim Nao: Stuck in the Shallow End: Education, Race, and Computing. MIT Press, 2010, 0262514044. Dissects the school structures and belief systems that lead to under-representation of African American and Latinx students in computing.\nMarg2012\n\n    Lauren E. Margulieux, Mark Guzdial, and Richard Catrambone: \"Subgoal-labeled Instructional Material Improves Performance and Transfer in Learning to Develop Mobile Applications\". In 2012 International Computing Education Research Conference (ICER'12), 2012, doi:10.1145/2361276.2361291. Reports that labelled subgoals improve outcomes and transference when learning about mobile app development.\nMarg2016\n\n    Lauren E. Margulieux, Richard Catrambone, and Mark Guzdial: \"Employing Subgoals in Computer Programming Education\". Computer Science Education, 26(1), 1 2016, doi:10.1080/08993408.2016.1144429. Reports that labelled subgoals improve learning outcomes in introductory computing courses.\nMark2018\n\n    Rebecca A. Markovits and Yana Weinstein: \"Can Cognitive Processes Help Explain the Success of Instructional Techniques Recommended by Behavior Analysts?\". NPJ Science of Learning, 3(1), 1 2018, doi:10.1038/s41539-017-0018-1. Points out that behavioralists and cognitive psychologists differ in approach, but wind up making very similar recommendations about how to teach, and gives two specific examples.\nMars2002\n\n    Herbert W. Marsh and John Hattie: \"The Relation Between Research Productivity and Teaching Effectiveness: Complementary, Antagonistic, or Independent Constructs?\". Journal of Higher Education, 73(5), 2002, doi:10.1353/jhe.2002.0047. One study of many showing there is zero correlation between research ability and teaching effectiveness.\nMasa2018\n\n    Susana Masapanta-Carri\u00f3n and J. \u00c1ngel Vel\u00e1zquez-Iturbide: \"A Systematic Review of the Use of Bloom's Taxonomy in Computer Science Education\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159491. Reports that even experienced educators have trouble agreeing on the correct classification for a question or idea using Bloom's Taxonomy.\nMaso2016\n\n    Raina Mason, Carolyn Seton, and Graham Cooper: \"Applying Cognitive Load Theory to the Redesign of a Conventional Database Systems Course\". Computer Science Education, 26(1), 1 2016, doi:10.1080/08993408.2016.1160597. Reports how redesigning a database course using cognitive load theory reduced exam failure rate while increasing student satisfaction.\nMatt2019\n\n    Eric Matthes: Python Flash Cards: Syntax, Concepts, and Examples. No Starch Press, 2019, 978-1593278960. Handy flashcards summarizing the core of Python 3.\nMaye2003\n\n    Richard E. Mayer and Roxana Moreno: \"Nine Ways to Reduce Cognitive Load in Multimedia Learning\". Educational Psychologist, 38(1), 3 2003, doi:10.1207/s15326985ep3801_6. Shows how research into how we absorb and process information can be applied to the design of instructional materials.\nMaye2004\n\n    Richard E. Mayer: \"Teaching of Subject Matter\". Annual Review of Psychology, 55(1), 2 2004, doi:10.1146/annurev.psych.55.082602.133124. An overview of how and why teaching and learning are subject-specific.\nMaye2009\n\n    Richard E. Mayer: Multimedia Learning. Cambridge University Press, 2009, 9780521735353. Presents a cognitive theory of multimedia learning.\nMazu1996\n\n    Eric Mazur: Peer Instruction: A User's Manual. Prentice-Hall, 1996. A guide to implementing peer instruction.\nMcCa2008\n\n    Ren\u00e9e McCauley, Sue Fitzgerald, Gary Lewandowski, Laurie Murphy, Beth Simon, Lynda Thomas, and Carol Zander: \"Debugging: A Review of the Literature from an Educational Perspective\". Computer Science Education, 18(2), 6 2008, doi:10.1080/08993400802114581. Summarizes research about why bugs occur, why types there are, how people debug, and whether we can teach debugging skills.\nMcCr2001\n\n    Michael McCracken, Tadeusz Wilusz, Vicki Almstrum, Danny Diaz, Mark Guzdial, Dianne Hagan, Yifat Ben-David Kolikant, Cary Laxer, Lynda Thomas, and Ian Utting: \"A Multi-National, Multi-Institutional Study of Assessment of Programming Skills of First-Year CS Students\". In 2001 Conference on Innovation and Technology in Computer Science Education (ITiCSE'01), 2001, doi:10.1145/572133.572137. Reports that most students still struggle to solve even basic programming problems at the end of their introductory course.\nMcDo2006\n\n    Charlie McDowell, Linda Werner, Heather E. Bullock, and Julian Fernald: \"Pair Programming Improves Student Retention, Confidence, and Program Quality\". Communications of the ACM, 49(8), 8 2006, doi:10.1145/1145287.1145293. A summary of research showing that pair programming improves retention and confidence.\nMcGu2015\n\n    Saundra Yancey McGuire: Teach Students How to Learn: Strategies You Can Incorporate Into Any Course to Improve Student Metacognition, Study Skills, and Motivation. Stylus Publishing, 2015, 162036316X. Explains how metacognitive strategies can improve learning.\nMcMi2017\n\n    Tressie McMillan Cottom: Lower Ed: The Troubling Rise of For-Profit Colleges in the New Economy. The New Press, 2017, 1620970600. Lays bare the dynamics of the growing educational industry to show how it leads to greater inequality rather than less.\nMcTi2013\n\n    Jay McTighe and Grant Wiggins: \"Understanding by Design Framework\". http://www.ascd.org/ASCD/pdf/siteASCD/publications/UbD_WhitePaper0312.pdf, 2013. Summarizes the backward instructional design process.\nMetc2016\n\n    Janet Metcalfe: \"Learning from Errors\". Annual Review of Psychology, 68(1), 1 2016, doi:10.1146/annurev-psych-010416-044022. Summarizes work on the hypercorrection effect in learning.\nMeys2018\n\n    Mark Meysenburg, Tessa Durham Brooks, Raychelle Burks, Erin Doyle, and Timothy Frey: \"DIVAS: Outreach to the Natural Sciences Through Image Processing\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159537. Describes early results from a programming course for science undergrads built around image processing.\nMidw2010\n\n    Midwest Academy: Organizing for Social Change: Midwest Academy Manual for Activists. The Forum Press, 2010, 0984275215. A training manual for people building progressive social movements.\nMill1956\n\n    George A. Miller: \"The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information\". Psychological Review, 63(2), 1956, doi:10.1037/h0043158. The original paper on the limited size of short-term memory.\nMill2013\n\n    Kelly Miller, Nathaniel Lasry, Kelvin Chu, and Eric Mazur: \"Role of Physics Lecture Demonstrations in Conceptual Learning\". Physical Review Special Topics - Physics Education Research, 9(2), 9 2013, doi:10.1103/physrevstper.9.020113. Reports a detailed study of what students learn during demonstrations and why.\nMill2015\n\n    David I. Miller and Jonathan Wai: \"The Bachelor's to Ph.D. STEM Pipeline No Longer Leaks More Women Than Men: a 30-year Analysis\". Frontiers in Psychology, 6, 2 2015, doi:10.3389/fpsyg.2015.00037. Shows that the ``leaky pipeline'' metaphor stopped being accurate some time in the 1990s.\nMill2016a\n\n    Michelle D. Miller: Minds Online: Teaching Effectively with Technology. Harvard University Press, 2016, 0674660021. Describes ways that insights from neuroscience can be used to improve online teaching.\nMill2016b\n\n    Craig S. Miller and Amber Settle: \"Some Trouble with Transparency: An Analysis of Student Errors with Object-Oriented Python\". In 2016 International Computing Education Research Conference (ICER'16), 2016, doi:10.1145/2960310.2960327. Reports that students have difficulty with self in Python.\nMilt2018\n\n    Kate M. Miltner: \"Girls Who Coded: Gender in Twentieth Century U.K. and U.S. Computing\". Science, Technology, & Human Values, 5 2018, doi:10.1177/0162243918770287. A review of three books about how women were systematically pushed out of computing.\nMina1986\n\n    Anne Minahan: \"Martha's Rules\". Affilia, 1(2), 6 1986, doi:10.1177/088610998600100206. Describes a lightweight set of rules for consensus-based decision making.\nMiya2018\n\n    Toshiya Miyatsu, Khuyen Nguyen, and Mark A. McDaniel: \"Five Popular Study Strategies: Their Pitfalls and Optimal Implementations\". Perspectives on Psychological Science, 13(3), 5 2018, doi:10.1177/1745691617710510. Explains how learners mis-use common study strategies and what they should do instead.\nMlad2017\n\n    Monika Mladenovi\u0107, Ivica Boljat, and \u017dana \u017danko: \"Comparing Loops Misconceptions in Block-Based and Text-Based Programming Languages at the K-12 Level\". Education and Information Technologies, 11 2017, doi:10.1007/s10639-017-9673-3. Reports that K-12 students have fewer misconceptions about loops using Scratch than using Logo or Python, and fewer misconceptions about nested loops with Logo than with Python.\nMore2019\n\n    Kayla Morehead, John Dunlosky, and Katherine A. Rawson: \"How Much Mightier Is the Pen than the Keyboard for Note-Taking? A Replication and Extension of Mueller and Oppenheimer (2014)\". Educational Psychology Review, 2 2019, doi:10.1007/s10648-019-09468-2. Reports a failure to replicate an earlier study comparing note-taking by hand and with computers.\nMorr2016\n\n    Briana B. Morrison, Lauren E. Margulieux, Barbara J. Ericson, and Mark Guzdial: \"Subgoals Help Students Solve Parsons Problems\". In 2016 Technical Symposium on Computer Science Education (SIGCSE'16), 2016, doi:10.1145/2839509.2844617. Reports that students using labelled subgoals solve Parsons Problems better than students without labelled subgoals.\nMuel2014\n\n    Pam A. Mueller and Daniel M. Oppenheimer: \"The Pen is Mightier than the Keyboard\". Psychological Science, 25(6), 4 2014, doi:10.1177/0956797614524581. Presents evidence that taking notes by hand is more effective than taking notes on a laptop.\nMull2007a\n\n    Derek A. Muller, James Bewes, Manjula D. Sharma, and Peter Reimann: \"Saying the Wrong Thing: Improving Learning with Multimedia by Including Misconceptions\". Journal of Computer Assisted Learning, 24(2), 7 2007, doi:10.1111/j.1365-2729.2007.00248.x. Reports that including explicit discussion of misconceptions significantly improves learning outcomes: students with low prior knowledge benefit most and students with more prior knowledge are not disadvantaged.\nMull2007b\n\n    Orna Muller, David Ginat, and Bruria Haberman: \"Pattern-Oriented Instruction and Its Influence on Problem Decomposition and Solution Construction\". In 2007 Technical Symposium on Computer Science Education (SIGCSE'07), 2007, doi:10.1145/1268784.1268830. Reports that explicitly teaching solution patterns improves learning outcomes.\nMurp2008\n\n    Laurie Murphy, Gary Lewandowski, Ren\u00e9e McCauley, Beth Simon, Lynda Thomas, and Carol Zander: \"Debugging: The Good, the Bad, and the Quirky - A Qualitative Analysis of Novices' Strategies\". ACM SIGCSE Bulletin, 40(1), 2 2008, doi:10.1145/1352322.1352191. Reports that many CS1 students use good debugging strategies, but many others don't, and students often don't recognize when they are stuck.\nNara2018\n\n    Sathya Narayanan, Kathryn Cunningham, Sonia Arteaga, William J. Welch, Leslie Maxwell, Zechariah Chawinga, and Bude Su: \"Upward Mobility for Underrepresented Students\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159551. Describes an intensive 3-year bachelor's program based on tight-knit cohorts and administrative support that tripled graduation rates.\nNath2003\n\n    Mitchell J. Nathan and Anthony Petrosino: \"Expert Blind Spot Among Preservice Teachers\". American Educational Research Journal, 40(4), 1 2003, doi:10.3102/00028312040004905. Early work on expert blind spot.\nHpl2018\n\n    National Academies of Sciences, Engineering, and Medicine: How People Learn II: Learners, Contexts, and Cultures. National Academies Press, 2018, 978-0309459648. A comprehensive survey of what we know about learning.\nNils2017\n\n    Linda B. Nilson and Ludwika A. Goodson: Online Teaching at Its Best: Merging Instructional Design with Teaching and Learning Research. Jossey-Bass, 2017, 1119242290. A guide for college instructors that focuses on online teaching.\nNord2017\n\n    Emily Nordmann, Colin Calder, Paul Bishop, Amy Irwin, and Darren Comber: \"Turn Up, Tune In, Don't Drop Out: The Relationship Between Lecture Attendance, Use of Lecture Recordings, and Achievement at Different Levels of Study\". https://psyarxiv.com/fd3yj, 2017, doi:10.17605/OSF.IO/FD3YJ. Reports on the pros and cons of recording lectures.\nNutb2016\n\n    Stephen Nutbrown and Colin Higgins: \"Static Analysis of Programming Exercises: Fairness, Usefulness and a Method for Application\". Computer Science Education, 26(2-3), 5 2016, doi:10.1080/08993408.2016.1179865. Describes ways auto-grader rules were modified and grades weighted to improve correlation between automatic feedback and manual grades.\nNuth2007\n\n    Graham Nuthall: The Hidden Lives of Learners. NZCER Press, 2007, 1877398241. Summarizes a lifetime of work looking at what students actually do in classrooms and how they actually learn.\nOjos2015\n\n    Bobby Ojose: Common Misconceptions in Mathematics: Strategies to Correct Them. UPA, 2015, 0761858857. A catalog of K-12 misconceptions in mathematics and what to do about them.\nOrnd2015\n\n    Harold N. Orndorff III: \"Collaborative Note-Taking: The Impact of Cloud Computing on Classroom Performance\". International Journal of Teaching and Learning in Higher Education, 27(3), 2015. Reports that taking notes together online is more effective than solo note-taking.\nOstr2015\n\n    Elinor Ostrom: Governing the Commons: The Evolution of Institutions for Collective Action. Cambridge University Press, 2015, 978-1107569782. A masterful description and analysis of cooperative governance.\nPape1993\n\n    Seymour A. Papert: Mindstorms: Children, Computers, and Powerful Ideas. Basic Books, 1993, 0465046746. The foundational text on how computers can underpin a new kind of education.\nPare2008\n\n    Dwayne E. Par\u00e9 and Steve Joordens: \"Peering Into Large Lectures: Examining Peer and Expert Mark Agreement Using peerScholar, an Online Peer Assessment Tool\". Journal of Computer Assisted Learning, 24(6), 10 2008, doi:10.1111/j.1365-2729.2008.00290.x. Shows that peer grading by small groups can be as effective as expert grading once accountability features are introduced.\nPark2015\n\n    Thomas H. Park, Brian Dorn, and Andrea Forte: \"An Analysis of HTML and CSS Syntax Errors in a Web Development Course\". ACM Transactions on Computing Education, 15(1), 3 2015, doi:10.1145/2700514. Describes the errors students make in an introductory course on HTML and CSS.\nPark2016\n\n    Miranda C. Parker, Mark Guzdial, and Shelly Engleman: \"Replication, Validation, and Use of a Language Independent CS1 Knowledge Assessment\". In 2016 International Computing Education Research Conference (ICER'16), 2016, doi:10.1145/2960310.2960316. Describes construction and replication of a second concept inventory for basic computing knowledge.\nParn1986\n\n    David Lorge Parnas and Paul C. Clements: \"A Rational Design Process: How and Why to Fake It\". IEEE Transactions on Software Engineering, SE-12(2), 2 1986, doi:10.1109/tse.1986.6312940. Argues that using a rational design process is less important than looking as though you had.\nParn2017\n\n    Chris Parnin, Janet Siegmund, and Norman Peitek: \"On the Nature of Programmer Expertise\". In Psychology of Programming Interest Group Workshop 2017, 2017. An annotated exploration of what ``expertise'' means in programming.\nPars2006\n\n    Dale Parsons and Patricia Haden: \"Parson's Programming Puzzles: A Fun and Effective Learning Tool for First Programming Courses\". In 2006 Australasian Conference on Computing Education (ACE'06), 2006. The first description of Parson's Problems.\nPart2011\n\n    Anu Partanen: \"What Americans Keep Ignoring About Finland's School Success\". https://www.theatlantic.com/national/archive/2011/12/what-americans-keep-ignoring-about-finlands-school-success/250564/, 2011. Explains that other countries struggle to replicate the success of Finland's schools because they're unwilling to tackle larger social factors.\nPati2016\n\n    Elizabeth Patitsas, Jesse Berlin, Michelle Craig, and Steve Easterbrook: \"Evidence that Computer Science Grades are not Bimodal\". In 2016 International Computing Education Research Conference (ICER'16), 2016, doi:10.1145/2960310.2960312. Presents a statistical analysis and an experiment which jointly show that grades in computing classes are not bimodal.\nPea1986\n\n    Roy D. Pea: \"Language-Independent Conceptual ``Bugs'' in Novice Programming\". Journal of Educational Computing Research, 2(1), 2 1986, doi:10.2190/689t-1r2a-x4w4-29j2. First named the \"superbug\" in coding: most newcomers think the computer understands what they want, in the same way that a human being would.\nPetr2016\n\n    Marian Petre and Andr\u00e9 van der Hoek: Software Design Decoded: 66 Ways Experts Think. MIT Press, 2016, 0262035189. A short illustrated overview of how expert software developers think.\nPign2016\n\n    Alessandra Pigni: The Idealist's Survival Kit: 75 Simple Ways to Prevent Burnout. Parallax Press, 2016, 1941529348. A guide to staying sane and healthy while doing good.\nPort2013\n\n    Leo Porter, Mark Guzdial, Charlie McDowell, and Beth Simon: \"Success in Introductory Programming: What Works?\". Communications of the ACM, 56(8), 8 2013, doi:10.1145/2492007.2492020. Summarizes the evidence that peer instruction, media computation, and pair programming can significantly improve outcomes in introductory programming courses.\nPort2016\n\n    Leo Porter, Dennis Bouvier, Quintin Cutts, Scott Grissom, Cynthia Bailey Lee, Robert McCartney, Daniel Zingaro, and Beth Simon: \"A Multi-Institutional Study of Peer Instruction in Introductory Computing\". In 2016 Technical Symposium on Computer Science Education (SIGCSE'16), 2016, doi:10.1145/2839509.2844642. Reports that students in introductory programming classes value peer instruction, and that it improves learning outcomes.\nQian2017\n\n    Yizhou Qian and James Lehman: \"Students' Misconceptions and Other Difficulties in Introductory Programming\". ACM Transactions on Computing Education, 18(1), 10 2017, doi:10.1145/3077618. Summarizes research on student misconceptions about computing.\nRago2017\n\n    Noa Ragonis and Ronit Shmallo: \"On the (Mis)understanding of the this Reference\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017715. Reports that most students do not understood when to use this, and that teachers are also often not clear on the subject.\nRaj2018\n\n    Adalbert Gerald Soosai Raj, Jignesh M. Patel, Richard Halverson, and Erica Rosenfeld Halverson: \"Role of Live-Coding in Learning Introductory Programming\". In 2018 Koli Calling International Conference on Computing Education Research (Koli'18), 2018, doi:10.1145/3279720.3279725. A grounded theory analysis of live coding that includes references to previous works.\nRams2019\n\n    G. Ramsay, A. B. Haynes, S. R. Lipsitz, I. Solsky, J. Leitch, A. A. Gawande, and M. Kumar: \"Reducing surgical mortality in Scotland by use of the WHO Surgical Safety Checklist\". BJS, 4 2019, doi:10.1002/bjs.11151. Found that the introduction of surgical checklists in Scottish hospitals significantly reduced mortality rates.\nRaws2014\n\n    Katherine A. Rawson, Ruthann C. Thomas, and Larry L. Jacoby: \"The Power of Examples: Illustrative Examples Enhance Conceptual Learning of Declarative Concepts\". Educational Psychology Review, 27(3), 6 2014, doi:10.1007/s10648-014-9273-3. Reports that presenting examples helps students understand definitions, so long as examples and definitions are interleaved.\nRay2014\n\n    Eric J. Ray and Deborah S. Ray: Unix and Linux: Visual QuickStart Guide. Peachpit Press, 2014, 0321997549. An introduction to Unix that is both a good tutorial and a good reference guide.\nRice2018\n\n    Gail Taylor Rice: Hitting Pause: 65 Lecture Breaks to Refresh and Reinforce Learning. Stylus Publishing, 2018, 9781620366530. Justifies and catalogs ways to take a pause in class to help learning.\nRich2017\n\n    Kathryn M. Rich, Carla Strickland, T. Andrew Binkowski, Cheryl Moran, and Diana Franklin: \"K-8 learning Trajectories Derived from Research Literature\". In 2017 International Computing Education Research Conference (ICER'17), 2017, doi:10.1145/3105726.3106166. Presents learning trajectories for K-8 computing classes for Sequence, Repetition, and Conditions gleaned from the literature.\nRitz2018\n\n    Anna Ritz: \"Programming the Central Dogma: An Integrated Unit on Computer Science and Molecular Biology Concepts\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159590. Describes an introductory computing course for biologists whose problems are drawn from the DNA-to-protein processes in cells.\nRobe2017\n\n    Eric Roberts: \"Assessing and Responding to the Growth of Computer Science Undergraduate Enrollments: Annotated Findings\". http://cs.stanford.edu/people/eroberts/ResourcesForTheCSCapacityCrisis/files/AnnotatedFindings.pptx, 2017. Summarizes findings from a National Academies study about computer science enrollments.\nRobi2005\n\n    Evan Robinson: \"Why Crunch Mode Doesn't Work: 6 Lessons\". http://www.igda.org/articles/erobinson_crunch.php, 2005. Summarizes research on the effects of overwork and sleep deprivation.\nRoge2018\n\n    Steven G. Rogelberg: The Surprising Science of Meetings. Oxford University Press, 2018, 978-0190689216. A short summary of research on effective meetings.\nRohr2015\n\n    Doug Rohrer, Robert F. Dedrick, and Sandra Stershic: \"Interleaved Practice Improves Mathematics Learning\". Journal of Educational Psychology, 107(3), 2015, doi:10.1037/edu0000001. Reports that interleaved practice is more effective than monotonous practice when learning.\nRubi2013\n\n    Marc J. Rubin: \"The Effectiveness of Live-coding to Teach Introductory Programming\". In 2013 Technical Symposium on Computer Science Education (SIGCSE'13), 2013, doi:10.1145/2445196.2445388. Reports that live coding is as good as or better than using static code examples.\nRubi2014\n\n    Manuel Rubio-S\u00e1nchez, P\u00e4ivi Kinnunen, Crist\u00f3bal Pareja-Flores, and J. \u00c1ngel Vel\u00e1zquez-Iturbide: \"Student Perception and Usage of an Automated Programming Assessment Tool\". Computers in Human Behavior, 31, 2 2014, doi:10.1016/j.chb.2013.04.001. Describes use of an auto-grader for student assignments.\nSahl2015\n\n    Pasi Sahlberg: Finnish Lessons 2.0: What Can the World Learn from Educational Change in Finland?. Teachers College Press, 2015, 978-0807755853. A frank look at the success of Finland's educational system and why other countries struggle to replicate it.\nSaja2006\n\n    Jorma Sajaniemi, Mordechai Ben-Ari, Pauli Byckling, Petri Gerdt, and Yevgeniya Kulikova: \"Roles of Variables in Three Programming Paradigms\". Computer Science Education, 16(4), 12 2006, doi:10.1080/08993400600874584. A detailed look at the authors' work on roles of variables.\nSala2017\n\n    Giovanni Sala and Fernand Gobet: \"Does Far Transfer Exist? Negative Evidence From Chess, Music, and Working Memory Training\". Current Directions in Psychological Science, 26(6), 10 2017, doi:10.1177/0963721417712760. A meta-analysis showing that far transfer rarely occurs.\nSand2013\n\n    Kate Sanders, Jaime Spacco, Marzieh Ahmadzadeh, Tony Clear, Stephen H. Edwards, Mikey Goldweber, Chris Johnson, Raymond Lister, Robert McCartney, and Elizabeth Patitsas: \"The Canterbury QuestionBank: Building a Repository of Multiple-Choice CS1 and CS2 Questions\". In 2013 Conference on Innovation and Technology in Computer Science Education (ITiCSE'13), 2013, doi:10.1145/2543882.2543885. Describes development of a shared question bank for introductory CS, and patterns for multiple choice questions that emerged from entries.\nScan1989\n\n    David A. Scanlan: \"Structured Flowcharts Outperform Pseudocode: An Experimental Comparison\". IEEE Software, 6(5), 9 1989, doi:10.1109/52.35587. Reports that students understand flowcharts better than pseudocode if both are equally well structured.\nScho1984\n\n    Donald A. Sch\u00f6n: The Reflective Practitioner: How Professionals Think In Action. Basic Books, 1984, 0465068782. A groundbreaking look at how professionals in different fields actually solve problems.\nSchw2013\n\n    Viviane Schwarz: Welcome to Your Awesome Robot. Flying Eye Books, 2013, 978-1909263000. A wonderful illustrated guide to building wearable cardboard robot suits. Not just for kids.\nScot1987\n\n    James C. Scott: Weapons of the Weak: Everyday Forms of Peasant Resistance. Yale University Press, 1987, 978-0300036411. Describes the techniques of evasion and resistance that the weak use to resist the strong.\nScot1998\n\n    James C. Scott: Seeing Like a State: How Certain Schemes to Improve the Human Condition Have Failed. Yale University Press, 1998, 0300078153. Argues that large organizations consistently prefer uniformity over productivity.\nSent2018\n\n    Sue Sentance, Erik Barendsen, and Carsten Schulte (eds.): Computer Science Education: Perspectives on Teaching and Learning in School. Bloomsbury Press, 2018, 135005710X. A collection of academic survey articles on teaching computing.\nSent2019\n\n    Sue Sentance, Jane Waite, and Maria Kallia: \"Teachers' Experiences of using PRIMM to Teach Programming in School\". In 2019 Technical Symposium on Computer Science Education (SIGCSE'19), 2019, doi:10.1145/3287324.3287477. Describes PRIMM and its effectiveness.\nSepp2015\n\n    Otto Sepp\u00e4l\u00e4, Petri Ihantola, Essi Isohanni, Juha Sorva, and Arto Vihavainen: \"Do We Know How Difficult the Rainfall Problem Is?\". In 2015 Koli Calling Conference on Computing Education Research (Koli'15), 2015, doi:10.1145/2828959.2828963. A meta-study of the Rainfall Problem.\nShap2007\n\n    Jenessa R. Shapiro and Steven L. Neuberg: \"From Stereotype Threat to Stereotype Threats: Implications of a Multi-Threat Framework for Causes, Moderators, Mediators, Consequences, and Interventions\". Personality and Social Psychology Review, 11(2), 5 2007, doi:10.1177/1088868306294790. Explores the ways the term ``stereotype threat'' has been used.\nShel2017\n\n    Duane F. Shell, Leen-Kiat Soh, Abraham E. Flanigan, Markeya S. Peteranetz, and Elizabeth Ingraham: \"Improving Students' Learning and Achievement in CS Classrooms Through Computational Creativity Exercises that Integrate Computational and Creative Thinking\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017718. Reports that having students work in small groups on computational creativity exercises improves learning outcomes.\nShol2019\n\n    Dan Sholler, Igor Steinmacher, Denae Ford, Mara Averick, Mike Hoye, and Greg Wilson: \"Ten Simple Rules for Helping Newcomers Become Contributors to Open Source Projects\". https://github.com/gvwilson/10-newcomers/, 2019. Evidence-based practices for helping newcomers become productive in open projects.\nSimo2013\n\n    Simon: \"Soloway's Rainfall Problem has Become Harder\". In 2013 Conference on Learning and Teaching in Computing and Engineering, 3 2013, doi:10.1109/latice.2013.44. Argues that the Rainfall Problem is harder for novices than it used to be because they're not used to handling keyboard input, so direct comparison with past results may be unfair.\nSing2012\n\n    Vandana Singh: \"Newcomer integration and learning in technical support communities for open source software\". In 2012 ACM International Conference on Supporting Group Work - GROUP'12, 2012, doi:10.1145/2389176.2389186. An early study of onboarding in open source.\nSirk2012\n\n    Teemu Sirki\u00e4 and Juha Sorva: \"Exploring Programming Misconceptions: An Analysis of Student Mistakes in Visual Program Simulation Exercises\". In 2012 Koli Calling Conference on Computing Education Research (Koli'12), 2012, doi:10.1145/2401796.2401799. Analyzes data from student use of an execution visualization tool and classifies common mistakes.\nSisk2018\n\n    Victoria F. Sisk, Alexander P. Burgoyne, Jingze Sun, Jennifer L. Butler, and Brooke N. Macnamara: \"To What Extent and Under Which Circumstances Are Growth Mind-Sets Important to Academic Achievement? Two Meta-Analyses\". Psychological Science, 3 2018, doi:10.1177/0956797617739704. Reports meta-analyses of the relationship between mind-set and academic achievement, and the effectiveness of mind-set interventions on academic achievement, and finds that overall effects are weak for both, but some results support specific tenets of the theory.\nSkud2014\n\n    Ben Skudder and Andrew Luxton-Reilly: \"Worked Examples in Computer Science\". In 2014 Australasian Computing Education Conference, (ACE'14), 2014. A summary of research on worked examples as applied to computing education.\nSmar2018\n\n    Benjamin L. Smarr and Aaron E. Schirmer: \"3.4 Million Real-World Learning Management System Logins Reveal the Majority of Students Experience Social Jet Lag Correlated with Decreased Performance\". Scientific Reports, 8(1), 3 2018, doi:10.1038/s41598-018-23044-8. Reports that students who have to work outside their natural body clock cycle do less well.\nSmit2009\n\n    Michelle K. Smith, William B. Wood, Wendy K. Adams, Carl E. Wieman, Jennifer K. Knight, N. Guild, and T. T. Su: \"Why Peer Discussion Improves Student Performance on In-class Concept Questions\". Science, 323(5910), 1 2009, doi:10.1126/science.1165919. Reports that student understanding increases during discussion in peer instruction, even when none of the students in the group initially know the right answer.\nSolo1984\n\n    Elliot Soloway and Kate Ehrlich: \"Empirical Studies of Programming Knowledge\". IEEE Transactions on Software Engineering, SE-10(5), 9 1984, doi:10.1109/tse.1984.5010283. Proposes that experts have programming plans and rules of programming discourse.\nSolo1986\n\n    Elliot Soloway: \"Learning to Program = Learning to Construct Mechanisms and Explanations\". Communications of the ACM, 29(9), 9 1986, doi:10.1145/6592.6594. Analyzes programming in terms of choosing appropriate goals and constructing plans to achieve them, and introduces the Rainfall Problem.\nSond2012\n\n    Harald S\u00f8ndergaard and Raoul A. Mulder: \"Collaborative Learning Through Formative Peer Review: Pedagogy, Programs and Potential\". Computer Science Education, 22(4), 12 2012, doi:10.1080/08993408.2012.728041. Surveys literature on student peer assessment, distinguishing grading and reviewing as separate forms, and summarizes features a good peer review system needs to have.\nSorv2013\n\n    Juha Sorva: \"Notional Machines and Introductory Programming Education\". ACM Transactions on Computing Education, 13(2), 6 2013, doi:10.1145/2483710.2483713. Reviews literature on programming misconceptions, and argues that instructors should address notional machines as an explicit learning objective.\nSorv2014\n\n    Juha Sorva and Otto Sepp\u00e4l\u00e4: \"Research-based Design of the First Weeks of CS1\". In 2014 Koli Calling Conference on Computing Education Research (Koli'14), 2014, doi:10.1145/2674683.2674690. Proposes three cognitively plausible frameworks for the design of a first CS course.\nSorv2018\n\n    Juha Sorva: \"Misconceptions and the Beginner Programmer\". In Computer Science Education: Perspectives on Teaching and Learning in School, Bloomsbury Press, 2018. Summarizes what we know about what novices misunderstand about computing.\nSpal2014\n\n    Dan Spalding: How to Teach Adults: Plan Your Class, Teach Your Students, Change the World. Jossey-Bass, 2014, 1118841360. A short guide to teaching adult free-range learners informed by the author's social activism.\nSpoh1985\n\n    James C. Spohrer, Elliot Soloway, and Edgar Pope: \"A Goal/Plan Analysis of Buggy Pascal Programs\". Human-Computer Interaction, 1(2), 6 1985, doi:10.1207/s15327051hci0102_4. One of the first cognitively plausible analyses of how people program, which proposes a goal/plan model.\nSrid2016\n\n    Sumukh Sridhara, Brian Hou, Jeffrey Lu, and John DeNero: \"Fuzz Testing Projects in Massive Courses\". In 2016 Conference on Learning @ Scale (L@S'16), 2016, doi:10.1145/2876034.2876050. Reports that fuzz testing student code catches errors that are missed by handwritten test suite, and explains how to safely share tests and results.\nStam2013\n\n    Eliane Stampfer and Kenneth R. Koedinger: \"When Seeing Isn't Believing: Influences of Prior Conceptions and Misconceptions\". In 2013 Annual Meeting of the Cognitive Science Society (CogSci'13), 2013. Explores why giving children more information when they are learning about fractions can lower their performance.\nStam2014\n\n    Eliane Stampfer Wiese and Kenneth R. Koedinger: \"Investigating Scaffolds for Sense Making in Fraction Addition and Comparison\". In 2014 Annual Conference of the Cognitive Science Society (CogSci'14), 2014. Looks at how to scaffold learning of fraction operations.\nStar2014\n\n    Philip Stark and Richard Freishtat: \"An Evaluation of Course Evaluations\". ScienceOpen Research, 9 2014, doi:10.14293/s2199-1006.1.sor-edu.aofrqa.v1. Yet another demonstration that teaching evaluations don't correlate with learning outcomes, and that they are frequently statistically suspect.\nStas1998\n\n    John Stasko, John Domingue, Mark H. Brown, and Blaine A. Price (eds.): Software Visualization: Programming as a Multimedia Experience. MIT Press, 1998, 0262193957. A survey of program and algorithm visualization techniques and results.\nStee2011\n\n    Claude M. Steele: Whistling Vivaldi: How Stereotypes Affect Us and What We Can Do. W. W. Norton & Company, 2011, 0393339726. Explains and explores stereotype threat and strategies for addressing it.\nStef2013\n\n    Andreas Stefik and Susanna Siebert: \"An Empirical Investigation into Programming Language Syntax\". ACM Transactions on Computing Education, 13(4), 11 2013, doi:10.1145/2534973. Reports that curly-brace languages are as hard to learn as a language with randomly-designed syntax, but others are easier.\nStef2017\n\n    Andreas Stefik, Patrick Daleiden, Diana Franklin, Stefan Hanenberg, Antti-Juhani Kaijanaho, Walter Tichy, and Brett A. Becker: \"Programming Languages and Learning\". https://quorumlanguage.com/evidence.html, 2017. Summarizes what we actually know about designing programming languages and why we believe it's true.\nSteg2014\n\n    Martijn Stegeman, Erik Barendsen, and Sjaak Smetsers: \"Towards an Empirically Validated Model for Assessment of Code Quality\". In 2014 Koli Calling Conference on Computing Education Research (Koli'14), 2014, doi:10.1145/2674683.2674702. Presents a code quality rubric for novice programming courses.\nSteg2016a\n\n    Martijn Stegeman, Erik Barendsen, and Sjaak Smetsers: \"Designing a Rubric for Feedback on Code Quality in Programming Courses\". In 2016 Koli Calling Conference on Computing Education Research (Koli'16), 2016, doi:10.1145/2999541.2999555. Describes several iterations of a code quality rubric for novice programming courses.\nSteg2016b\n\n    Martijn Stegeman, Erik Barendsen, and Sjaak Smetsers: \"Rubric for Feedback on Code Quality in Programming Courses\". http://stgm.nl/quality, 2016. Presents a code quality rubric for novice programming.\nStei2013\n\n    Igor Steinmacher, Igor Wiese, Ana Paula Chaves, and Marco Aurelio G\u00e9rosa: \"Why do newcomers abandon open source software projects?\". In 2013 International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE'13), 5 2013, doi:10.1109/chase.2013.6614728. Explores why new members \\emphdon't stay in open source projects.\nStei2016\n\n    Igor Steinmacher, Tayana Uchoa Conte, Christoph Treude, and Marco Aur\u00e9lio Gerosa: \"Overcoming open source project entry barriers with a portal for newcomers\". In 2016 International Conference on Software Engineering (ICSE'16), 2016, doi:10.1145/2884781.2884806. Reports the effectiveness of a portal specifically designed to help newcomers.\nStei2018\n\n    Igor Steinmacher, Gustavo Pinto, Igor Scaliante Wiese, and Marco Aur\u00e9lio Gerosa: \"Almost There: A Study on Quasi-Contributors in Open-Source Software Projects\". In 2018 International Conference on Software Engineering (ICSE'18), 2018, doi:10.1145/3180155.3180208. Look at why external developers fail to get their contributions accepted into open source projects.\nStoc2018\n\n    Jean Stockard, Timothy W. Wood, Cristy Coughlin, and Caitlin Rasplica Khoury: \"The Effectiveness of Direct Instruction Curricula: A Meta-analysis of a Half Century of Research\". Review of Educational Research, 1 2018, doi:10.3102/0034654317751919. A meta-analysis that finds significant positive benefit for Direct Instruction.\nSung2012\n\n    Eunmo Sung and Richard E. Mayer: \"When Graphics Improve Liking but not Learning from Online Lessons\". Computers in Human Behavior, 28(5), 9 2012, doi:10.1016/j.chb.2012.03.026. Reports that students who receive any kind of graphics give significantly higher satisfaction ratings than those who don't, but only students who get instructive graphics perform better than groups that get no graphics, seductive graphics, or decorative graphics.\nSved2016\n\n    Maria Svedin and Olle B\u00e4lter: \"Gender Neutrality Improved Completion Rate for All\". Computer Science Education, 26(2-3), 7 2016, doi:10.1080/08993408.2016.1231469. Reports that redesigning an online course to be gender neutral improves completion probability in general, but decreases it for students with a superficial approach to learning.\nTedr2008\n\n    Matti Tedre and Erkki Sutinen: \"Three Traditions of Computing: What Educators Should Know\". Computer Science Education, 18(3), 9 2008, doi:10.1080/08993400802332332. Summarizes the history and views of three traditions in computing: mathematical, scientific, and engineering.\nTew2011\n\n    Allison Elliott Tew and Mark Guzdial: \"The FCS1: A Language Independent Assessment of CS1 Knowledge\". In 2011 Technical Symposium on Computer Science Education (SIGCSE'11), 2011, doi:10.1145/1953163.1953200. Describes development and validation of a language-independent assessment instrument for CS1 knowledge.\nThay2017\n\n    Kyle Thayer and Amy J. Ko: \"Barriers Faced by Coding Bootcamp Students\". In 2017 International Computing Education Research Conference (ICER'17), 2017, doi:10.1145/3105726.3106176. Reports that coding bootcamps are sometimes useful, but quality is varied, and formal and informal barriers to employment remain.\nUbel2017\n\n    Robert Ubell: \"How the Pioneers of the MOOC got It Wrong\". http://spectrum.ieee.org/tech-talk/at-work/education/how-the-pioneers-of-the-mooc-got-it-wrong, 2017. A brief exploration of why MOOCs haven't lived up to initial hype.\nUrba2014\n\n    David R. Urbach, Anand Govindarajan, Refik Saskin, Andrew S. Wilton, and Nancy N. Baxter: \"Introduction of Surgical Safety Checklists in Ontario, Canada\". New England Journal of Medicine, 370(11), 3 2014, doi:10.1056/nejmsa1308261. Reports a study showing that the introduction of surgical checklists did not have a significant effect on operative outcomes.\nUtti2013\n\n    Ian Utting, Juha Sorva, Tadeusz Wilusz, Allison Elliott Tew, Michael McCracken, Lynda Thomas, Dennis Bouvier, Roger Frye, James Paterson, Michael E. Caspersen, and Yifat Ben-David Kolikant: \"A Fresh Look at Novice Programmers' Performance and Their Teachers' Expectations\". In 2013 Conference on Innovation and Technology in Computer Science Education (ITiCSE'13), 2013, doi:10.1145/2543882.2543884. Replicates an earlier study showing how little students learn in their first programming course.\nUttl2017\n\n    Bob Uttl, Carmela A. White, and Daniela Wong Gonzalez: \"Meta-analysis of Faculty's Teaching Effectiveness: Student Evaluation of Teaching Ratings and Student Learning are not Related\". Studies in Educational Evaluation, 54, 9 2017, doi:10.1016/j.stueduc.2016.08.007. Summarizes studies showing that how students rate a course and how much they actually learn are not related.\nVarm2015\n\n    Roli Varma and Deepak Kapur: \"Decoding Femininity in Computer Science in India\". Communications of the ACM, 58(5), 4 2015, doi:10.1145/2663339. Reports female participation in computing in India.\nVell2017\n\n    Mickey Vellukunnel, Philip Buffum, Kristy Elizabeth Boyer, Jeffrey Forbes, Sarah Heckman, and Ketan Mayer-Patel: \"Deconstructing the Discussion Forum: Student Questions and Computer Science Learning\". In 2017 Technical Symposium on Computer Science Education (SIGCSE'17), 2017, doi:10.1145/3017680.3017745. Found that students mostly ask constructivist and logistical questions in forums, and that the former correlate with grades.\nViha2014\n\n    Arto Vihavainen, Jonne Airaksinen, and Christopher Watson: \"A Systematic Review of Approaches for Teaching Introductory Programming and Their Influence on Success\". In 2014 International Computing Education Research Conference (ICER'14), 2014, doi:10.1145/2632320.2632349. Consolidates studies of CS1-level teaching changes and finds media computation the most effective, while introducing a game theme is the least effective.\nWall2009\n\n    Thorbjorn Walle and Jo Erskine Hannay: \"Personality and the Nature of Collaboration in Pair Programming\". In 2009 International Symposium on Empirical Software Engineering and Measurement (ESER'09), 10 2009, doi:10.1109/esem.2009.5315996. Reports that pairs with different levels of a given personality trait communicated more intensively.\nWang2018\n\n    April Y. Wang, Ryan Mitts, Philip J. Guo, and Parmit K. Chilana: \"Mismatch of Expectations: How Modern Learning Resources Fail Conversational Programmers\". In 2018 Conference on Human Factors in Computing Systems (CHI'18), 2018, doi:10.1145/3173574.3174085. Reports that learning resources don't really help conversational programmers (those who learn coding to take part in technical discussions).\nWard2015\n\n    James Ward: Adventures in Stationery: A Journey Through Your Pencil Case. Profile Books, 2015, 1846686164. A wonderful look at the everyday items that would be in your desk drawer if someone hadn't walked off with them.\nWats2014\n\n    Christopher Watson and Frederick W. B. Li: \"Failure Rates in Introductory Programming Revisited\". In 2014 Conference on Innovation and Technology in Computer Science Education (ITiCSE'14), 2014, doi:10.1145/2591708.2591749. A larger version of an earlier study that found an average of one third of students fail CS1.\nWatt2014\n\n    Audrey Watters: The Monsters of Education Technology. CreateSpace, 2014, 1505225051. A collection of essays about the history of educational technology and the exaggerated claims repeatedly made for it.\nWein2018a\n\n    Yana Weinstein, Christopher R. Madan, and Megan A. Sumeracki: \"Teaching the Science of Learning\". Cognitive Research: Principles and Implications, 3(1), 1 2018, doi:10.1186/s41235-017-0087-y. A tutorial review of six evidence-based learning practices.\nWein2018b\n\n    Yana Weinstein, Megan Sumeracki, and Oliver Caviglioli: Understanding How We Learn: A Visual Guide. Routledge, 2018, 978-1138561724. A short graphical summary of effective learning strategies.\nWein2017\n\n    David Weintrop and Uri Wilensky: \"Comparing Block-Based and Text-Based Programming in High School Computer Science Classrooms\". ACM Transactions on Computing Education, 18(1), 10 2017, doi:10.1145/3089799. Reports that students learn faster and better with blocks than with text.\nWeng2015\n\n    Etienne Wenger-Trayner and Beverly Wenger-Trayner: \"Communities of Practice: A Brief Introduction\". http://wenger-trayner.com/intro-to-cops/, 2015. A brief summary of what communities of practice are and aren't.\nWibu2016\n\n    Karin Wiburg, Julia Parra, Gaspard Mucundanyi, Jennifer Green, and Nate Shaver (eds.): The Little Book of Learning Theories. CreateSpace, 2016, 1537091808. Presents brief summaries of various theories of learning.\nWigg2005\n\n    Grant Wiggins and Jay McTighe: Understanding by Design. Association for Supervision & Curriculum Development (ASCD), 2005, 1416600353. A lengthy presentation of reverse instructional design.\nWilc2018\n\n    Chris Wilcox and Albert Lionelle: \"Quantifying the Benefits of Prior Programming Experience in an Introductory Computer Science Course\". In 2018 Technical Symposium on Computer Science Education (SIGCSE'18), 2018, doi:10.1145/3159450.3159480. Reports that students with prior experience outscore students without in CS1, but there is no significant difference in performance by the end of CS2; also finds that female students with prior exposure outperform their male peers in all areas, but are consistently less confident in their abilities.\nWile2002\n\n    David Wiley: \"The Reusability Paradox\". http://opencontent.org/docs/paradox.html, 2002. Summarizes the tension between learning objects being effective and reusable.\nWilk2011\n\n    Richard Wilkinson and Kate Pickett: The Spirit Level: Why Greater Equality Makes Societies Stronger. Bloomsbury Press, 2011, 1608193411. Presents evidence that inequality harms everyone, both economically and otherwise.\nWill2010\n\n    Daniel T. Willingham: Why Don't Students Like School?: A Cognitive Scientist Answers Questions about How the Mind Works and What It Means for the Classroom. Jossey-Bass, 2010, 047059196X. A cognitive scientist looks at how the mind works in the classroom.\nWils2007\n\n    Karen Wilson and James H. Korn: \"Attention During Lectures: Beyond Ten Minutes\". Teaching of Psychology, 34(2), 6 2007, doi:10.1080/00986280701291291. Reports little support for the claim that students only have a 10--15 minute attention span (though there is lots of individual variation).\nWils2016\n\n    Greg Wilson: \"Software Carpentry: Lessons Learned\". F1000Research, 1 2016, doi:10.12688/f1000research.3-62.v2. A history and analysis of Software Carpentry.\nWlod2017\n\n    Raymond J. Wlodkowski and Margery B. Ginsberg: Enhancing Adult Motivation to Learn: A Comprehensive Guide for Teaching All Adults. Jossey-Bass, 2017, 1119077990. The standard reference for understanding adult motivation.\nXie2019\n\n    Benjamin Xie, Dastyni Loksa, Greg L. Nelson, Matthew J. Davidson, Dongsheng Dong, Harrison Kwik, Alex Hui Tan, Leanne Hwa, Min Li, and Amy J. Ko: \"A theory of instruction for introductory programming skills\". Computer Science Education, 29(2-3), 1 2019, doi:10.1080/08993408.2019.1565235. Lays out a four-part theory for teaching novices based on reading vs. writing and code vs. templates.\nYada2016\n\n    Aman Yadav, Sarah Gretter, Susanne Hambrusch, and Phil Sands: \"Expanding Computer Science Education in Schools: Understanding Teacher Experiences and Challenges\". Computer Science Education, 26(4), 12 2016, doi:10.1080/08993408.2016.1257418. Summarizes feedback from K-12 teachers on what they need by way of preparation and support.\nYang2015\n\n    Yu-Fen Yang and Yuan-Yu Lin: \"Online Collaborative Note-Taking Strategies to Foster EFL Beginners' Literacy Development\". System, 52, 8 2015, doi:10.1016/j.system.2015.05.006. Reports that students using collaborative note taking when learning English as a foreign language do better than those who don't.\n\n  1. This is definitely not how our brains work, but it\u2019s a useful metaphor.\u21a9\ufe0e\n\n  2. To paraphrase Oscar Wilde\u2019s Lady Windermere, people often don\u2019t know what they\u2019re thinking until they\u2019ve heard themselves say it.\u21a9\ufe0e\n\n  3. My thanks to Warren Code for introducing me to this example.\u21a9\ufe0e\n\n  4. A more complete model would also include your senses of touch, smell, and taste, but we\u2019ll ignore those for now.\u21a9\ufe0e\n\n  5. Named after one of its creators.\u21a9\ufe0e\n\n  6. For a long time, I believed that the variable holding the value a function was going to return had to be called result because my teacher always used that name in examples.\u21a9\ufe0e\n\n  7. For a while, I was so worried about playing in tune that I completely lost my sense of timing.\u21a9\ufe0e\n\n  8. A colleague once told me that the basic unit of teaching is the bladder. When I said I\u2019d never thought of that, she said, \u201cYou\u2019ve obviously never been pregnant.\u201d\u21a9\ufe0e\n\n  9. \u201cAnd Linux!\u201d someone shouts from the back of the room.\u21a9\ufe0e\n\n  10. People who prefer the latter are often only interested in arguing...\u21a9\ufe0e\n\n  11. This is one of the times when having ties with local government or other like-minded organizations pays off.\u21a9\ufe0e\n\n  12. And the prevalence of fixed mindset among faculty when it comes to teaching, i.e. the belief that some people are \u201cjust better teachers.\u201d\u21a9\ufe0e\n\n  13. I certainly did when this was done to me...\u21a9\ufe0e\n\n", "frontpage": false}
