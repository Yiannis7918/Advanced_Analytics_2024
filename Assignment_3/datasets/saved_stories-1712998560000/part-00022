{"aid": "40020035", "title": "Hostnames and Usernames to Reserve", "url": "https://ldpreload.com/blog/names-to-reserve", "domain": "ldpreload.com", "votes": 1, "user": "goranmoomin", "posted_at": "2024-04-13 02:45:08", "comments": 0, "source_title": "Hostnames and usernames to reserve", "source_text": "Hostnames and usernames to reserve - Geoffrey Thomas (geofft)\n\nhome \u00b7 blog \u00b7 @geofft\n\n# Hostnames and usernames to reserve\n\nIf you're setting up a service where people can register their own usernames\nto be used as a hostname (username.example.com), email address\n(username@example.com), or URL path (example.com/username) within your domain,\nthere are some common names you should avoid letting the general public\nregister.\n\nMany Internet protocols make the assumption that a domain is manually managed\nby its owners, and in particular assume that a name like admin must have been\nregistered or approved by the actual owners. Automatic registration breaks\nthis assumption, and has been the source of some attacks. Microsoft Live has\nfallen victim to this multiple times: in 2008, a researcher signed up for\nsslcertificates@live.com and used it to get a login.live.com certificate, and\nas late as this March, the same problem happened to live.fi, the Finnish\nversion of the service, when an IT professional tried registering the email\naccount hostmaster@live.fi as his personal Live account, and then found he\ncould receive a certificate for that domain.\n\nThis is a list of all the names I know that should be restricted from\nregistration in automated systems. If you know of others, please let me know\nand I'll update this page.\n\ntl;dr: Regardless of how you're currently using usernames, restrict them to\nlowercase letters, digits, and hyphens, starting with a letter and not ending\nwith a hyphen (that is, /^[a-z]([a-z0-9-]*[a-z0-9])?$/ as an extended regex).\nBan all the names in this file (last updated 2015-11-21). Get yourself listed\nas a public suffix: see below for directions and implications.\n\n## Hostnames\n\nMost of these problems involve a computer on the domain doing an unqualified\nlookup: when a computer named a.example.com looks for b, it will usually find\nb.example.com. If you're running a simple hosting service, or similar, you may\nnot need to block all of these, but these names are extremely unlikely to be\nused by legitimate users anyway. So you may as well block all of them to allow\nexpanding in the future.\n\n  * localhost, localdomain, and broadcasthost: these are usually present in /etc/hosts, and applications or scripts might hard-code an assumption about them having their usual value (especially for localhost).\n  * www: Browsers will often prepend this if the domain itself does not resolve as a hostname.\n  * wpad: Web Proxy Auto-Discovery in several browsers; someone who owns this (unqualified) name can act as a proxy for all web traffic.\n  * isatap: IPv6 tunnel autodiscovery, primarily on Windows. Similarly to WPAD, someone who owns this (unqualified) name can act as a proxy for all IPv6-capable traffic. Windows Server has a built-in blacklist of domain names that defaults to WPAD and ISATAP.\n  * autoconfig: Thunderbird's spec for autoconfiguration. Thunderbird will query the website at autoconfig.example.com for settings when attempting to set up example.com email. Good way to harvest passwords.\n  * Along those lines, imap, pop, pop3, smtp, mail, for email clients that make guesses about what your email servers are. (This includes Thunderbird but also many others.)\n\nNote that valid hostnames are restricted in syntax: they must only contain\nletters, digits, or hyphens, and cannot start or end with a hyphen. DNS is\ncase-insensitive, so make sure there are no case collisions. An older standard\nprevents hostnames from starting with a digit, which is a straightforward way\nto prevent all-numeric usernames (which can cause problems with tools that\naccept either names or UIDs). Dots separate portions of a domain name and\ncause various problems (wildcard certificates only apply to one level,\na.b.example.com can read and write cookies for b.example.com, etc.), so\nthey're usually more trouble than they're worth. DNS records are much more\nliberal, but names that don't follow these rules will generally not resolve as\nhostnames: you can look them up with dig/host/etc., but you can't use them in\napplications. Checking hostname syntax also prevents you from worrying about\nnames like _tcp or _udp, which are used in SRV records.\n\n### Become a public suffix\n\nMost parts of the web platform consider two pages with different origins, that\nis, scheme (http / https), hostname, and port number, to be unrelated websites\nthat cannot interact with each other by default. However, there are a few\nexceptions, most notably cookies. Web pages at www.example.com and\nlogin.example.com are allowed to set cookies with a scope of example.com,\ndespite not sharing the same hostname / origin. The simple rule of allowing\nparent domains created the problem of supercookies: example.com could set a\ncookie scoped to .com, which would then be sent to all sites ending in .com.\nThere are two big problems with this: the first is privacy (being tracked\nacross websites), and the second is session-fixation attacks, where an\nattacker can overwrite your session cookie with their own, and have your\nactions (including logging in or sending private data) happen within the\nattacker's session.\n\nThe immediate fix was to ban top-level domains, but this still allowed setting\ncookies for publicly-registrable suffixes like .co.uk that weren't at the top\nlevel. So browser vendors created the public suffix list to track which\nsuffixes are open for public registration. The public suffix list now includes\nnot only \"ICANN\" entries, such as .com and .co.uk, but also \"private\" entries,\nsuch as .herokuapp.com and .github.io, since the same problems exist with\nallowing users to set cookies for all Heroku or GitHub Pages users.\n\nSo, if you are letting users register hostnames in your domain, you should get\nit listed as a public suffix, which requires just sending a pull request or an\nemail. It takes some time for the update to reach browsers (the list is\ncompiled into browsers, so it's only updated by a browser version update), so\nyou should try to do this as far in advance as possible before launching.\n\nNote that by making example.com a public suffix, nobody, not even code on\nexample.com itself, can set a cookie for example.com. If you have a website of\nyour own that needs cookies (analytics, registration, etc.), you'll need to\nrun it at e.g. www.example.com, and make example.com just a redirect.\nAlternatively, you can use a completely separate domain for your own site vs.\nyour users' sites, as with the Heroku and GitHub examples: their own websites\nare heroku.com and github.com.\n\n## Email addresses\n\nThe CA/Browser Forum Baseline Requirements, section 3.2.2.4 item 4, requires\nthat if a CA is going to validate a domain by coming up with an administrative\nemail address on its own, it may only use admin, administrator, webmaster,\nhostmaster, or postmaster. Reserve all of those names, regardless of whether\nthey go somewhere useful.\n\nAll CAs are supposed to be compliant with that these days, but for safety's\nsake, also reserve root, info, ssladmin, ssladministrator, sslwebmaster,\nsysadmin, is, it, and mis (see this 2009 comment on Mozilla's bug tracker).\n\nRFC 2142 defines the names info, marketing, sales, support, abuse, noc,\nsecurity, postmaster, hostmaster, usenet, news, webmaster, www, uucp, and ftp.\nYou won't need most of these to actually reach a useful mailbox, though you\nshould reserve all of them.\n\nYou may want to reserve mailer-daemon, nobody (a default UNIX user account),\nnoreply, no-reply, etc. for automated processes that send email.\n\nAgain, as these names are unlikely to be used by legitimate users, it's\nusually worth blocking them now and keeping your options open, even if you're\nnot currently offering email service. You may add an email service in the\nfuture (Amazon launched Send to Kindle by email over a decade after\nintroducing user accounts). As always, you can manually register these names\nto trusted or internal users.\n\n## URLs\n\nFor many websites with user-provided content, like Twitter, Facebook, or\nGitHub, user-chosen usernames become part of the URL at top level\n(https://twitter.com/geofft, https://github.com/geofft). If you're building a\nwebsite like this, the easiest approach is to restrict these usernames as if\nthey were hostnames. This has two advantages: the first is that it's easy to\nlaunch a hostname-based system later (e.g. GitHub Pages now supports\ngeofft.github.io) if you know that all your usernames are valid hostnames.\n\nThe second is that there are several URL paths you need to reserve at top\nlevel, and all of them happen to contain dots and are therefore invalid\nhostnames. If you do permit dots, you need to block the following names:\n\n  * robots.txt, for the Robots Exclusion Protocol, used to tell well-behaved crawlers how to well-behave.\n  * favicon.ico, for the shortcut icon displayed in the tab bar and other places.\n  * crossdomain.xml, which allows the Flash plugin to make cross-origin requests. Java and Silverlight also look for and trust crossdomain.xml.\n  * clientaccesspolicy.xml, a Silverlight-specific version of crossdomain.xml.\n  * .well-known, specified in RFC 5785 as a place for these sorts of things so they don't keep cluttering the root level. Thunderbird autoconfiguration looks in here, as do ACME, the automatic certificate enrollment spec from Let's Encrypt; BrowserID / Mozilla Persona; and RFC 7711, a new standard for providing certificates for third-party non-HTTP services. So there are a number of security issues with an unauthorized user being able to create files under /.well-known/.\n\n(These are URLs, not filenames. You should of course also disallow users from\ncreating files named e.g. .htaccess if your web server respects those.)\n\nAll of these are invalid hostnames, so simply requiring usernames to be valid\nhostnames avoids having to check for these specific cases. If you're only\nallowing users to choose some portion of the URL, and inserting other text\n(e.g., example.com/user/geofft, example.edu/~geofft), then you don't have to\nworry about this, but again it may still be useful to keep your options open\nfor other URL, hostname, or email schemes in the future.\n\nDo not allow users to publish custom HTML, especially not custom scripts, at\nthese sorts of URLs. https://example.com/user1, https://example.com/user2, and\nhttps://example.com/login all share the same origin, so by the same-origin\npolicy, these web pages can freely interact with each other and mess with each\nother's content. A few JavaScript interfaces, including service workers, make\nit very easy to attack another site on the same origin. If you want users to\nbe able to publish custom HTML and JS, use separate hostnames within a public\nsuffix. https://user1.example.com and https://user2.example.com are separate\norigins, and if you have made example.com a public suffix as mentioned\nearlier, you can safely let them publish custom scripts, since the sites are\nno more able to interact with each other than two separate .com websites\ncould.\n\nThis post was inspired by a GitHub issue for Sandstorm's sandcats.io dynamic\nDNS service; thanks to Asheesh Laroia for pointing me at that thread and\nreviewing a draft of this article.\n\n26 November 2015\n\n", "frontpage": false}
