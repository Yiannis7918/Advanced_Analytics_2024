{"aid": "39961453", "title": "How to Design an ISA", "url": "https://cacm.acm.org/practice/how-to-design-an-isa/", "domain": "acm.org", "votes": 1, "user": "PaulHoule", "posted_at": "2024-04-07 15:35:47", "comments": 0, "source_title": "How to Design an ISA \u2013 Communications of the ACM", "source_text": "How to Design an ISA \u2013 Communications of the ACM\n\nSkip to content\n\nSearch Sign In\n\nJoin ACM\n\nPractice\n\nArchitecture and Hardware\n\n# How to Design an ISA\n\nThe popularity of RISC-V has led many to try designing instruction sets.\n\nBy David Chisnall\n\nPosted Mar 22 2024\n\n  * Share\n\n    * Twitter\n    * Reddit\n    * Hacker News\n  * Download PDF\n  * Print\n  * Join the Discussion\n  * View in the ACM Digital Library\n\n     * No Such Thing as a General-Purpose ISA\n     * Business Is Not a Separable Concern\n     * Architecture Matters\n     * What Do Small Cores Want?\n     * What Do Big Cores Want?\n     * You Don\u2019t Win Points for Purity\n     * Some Source Languages Are Not Really Source Languages\n     * Always Measure\n     * References\n\nOver the past decade I have been involved in several projects that have\ndesigned either instruction set architecture (ISA) extensions or clean-slate\nISAs for various kinds of processors (you will even find my name in the\nacknowledgments for the RISC-V spec, right back to the first public version).\nWhen I started, I had very little idea about what makes a good ISA, and, as\nfar as I can tell, this is not formally taught anywhere. With the rise of\nRISC-V as an open base for custom instruction sets, however, the barrier to\nentry has become much lower and the number of people trying to design some, or\nall, an instruction set has grown immeasurably.\n\nAn instruction set is a lingua franca between compilers and microarchitecture.\nAs such, it has a lot in common with compiler intermediate languages, a\nsubject on which Fred Chow has written an excellent overview.^2\n\nProgrammers see details of the target platform at three levels:\n\n  * The application binary interface (ABI) is a set of conventions that define how compilers use visible hardware features. This may be private to a single compiler or shared as a convention between multiple interoperable compilers.\n\n  * The architecture defines everything the hardware guarantees. This is a contract between the people implementing compilers and operating systems and those implementing the hardware. The architecture includes mechanisms for enumerating devices, configuring interrupts, and so on. The ISA is the core part of the architecture that defines the encoding and behavior of instructions and the operands they consume.\n\n  * The microarchitecture is a specific implementation of the architecture. Ideally, programmers do not care about the specific details of microarchitectures, but these details often leak. For example, cache-line sizes may be a microarchitectural detail, but they impact false sharing and so can have a large performance impact. If you care about side channels, then you may find the microarchitecture is very important.\n\nConventions can often live in either the ABI or ISA. There is no hard-and-fast\nrule for where any of these should live, but here are a couple of helpful\nrules of thumb:\n\n  * If different languages are going to want to do something different, it should be in the ABI.\n\n  * If software needs to do a specific task to take advantage of a microarchitectural feature, that belongs in the ISA and not the ABI.\n\n## No Such Thing as a General-Purpose ISA\n\nI have written before that there is no such thing as a general-purpose\nprocessor,^1 but there is also no such thing as a general-purpose ISA. An ISA\nmust be efficient for compilers to translate a set of source languages into.\nIt must also be efficient to implement in the kinds of microarchitecture that\nhardware will adopt.\n\nDesigning an ISA for all possible source languages is difficult. For example,\nconsider C, Erlang, and Compute Unified Device Architecture (CUDA). Each has a\nvery different abstract machine. C has large amounts of mutable state and a\nbolted-on concurrency model that relies on shared everything, locking, and,\ntypically, small numbers of threads. Erlang has a shared-nothing concurrency\nmodel and scales to very large numbers of processes. CUDA has a complex\nsharing model that is tightly coupled to its parallelism model.\n\nYou can compile any of these languages to any Turing-complete target (by\ndefinition), but that may not be effective. If it were easy to compile C code\nto GPUs (and take advantage of the parallelism), then CUDA would not need to\nexist. Any family of languages has a set of implicit assumptions that drive\ndecisions about the most efficient targets.\n\nAlgol-family languages, including C, typically have good locality of reference\n(both spatial and temporal), but somewhat random-access patterns. They have a\nsingle stack, and a large proportion of memory accesses will be to the current\nstack frame. They allocate memory in objects that are typically small, and\nmost are not shared between threads. Object-oriented languages typically do\nmore indirect branches and more pointer chasing. Array-processing languages\nand shading languages typically do a lot of memory accesses with predictable\naccess patterns.\n\nIf you do not articulate the properties of the source languages you are\noptimizing for, then you are almost certainly baking in some implicit\nassumptions that may or may not actually hold.\n\nSimilarly, looking down toward the microarchitecture, a good ISA for a small,\nembedded microcontroller may be a terrible ISA for a large superscalar out-of-\norder processor or a massively parallel accelerator. There are good reasons\nwhy 32-bit Arm failed to compete with Intel for performance, and why x86 has\nfailed to displace Arm in low-power markets. The things that you want to\noptimize for at different sizes are different.\n\nDesigning an ISA that scales to both very large and very small cores is\ndifficult. Arm\u2019s decision to separate its 32- and 64-bit ISAs meant it could\nassume a baseline of register renaming and speculative execution in its 64-bit\nA profile and in-order execution in its 32-bit M profile, and tune both,\nassuming a subset of possible implementations. RISC-V aims to scale from tiny\nmicrocontrollers up to massive server processors. It\u2019s an open research\nquestion whether this is possible (certainly no prior architecture has\nsucceeded).\n\n## Business Is Not a Separable Concern\n\nOne kind of generality does matter: Is the ISA a stable contract? This is more\na business question than a technical one. A stable ISA can enter a feedback\ncycle where people buy it because they have software that runs on it and\npeople write software to run on it because they have it. Motorola benefited\nfrom this with its 68000 line for a long time, Intel with its x86 line for\neven longer.\n\nThis comes with a cost: In every future product you will be stuck with any\ndesign decision you made in the current generation. When it started testing\nsimulations of early Pentium prototypes, Intel discovered that a lot of game\ndesigners had found they could shave one instruction off a hot loop by relying\non a bug in the flag-setting behavior of Intel\u2019s 486 microprocessor. This bug\nhad to be made part of the architecture: If the Pentium did not run popular\n486 games, customers would blame Intel, not the game authors.\n\nIf you buy an NVIDIA GPU, you do not get a document explaining the instruction\nset. It, and many other parts of the architecture, are secret. If you want to\nwrite code for it and do not want to use NVIDIA\u2019s toolchain, you are expected\nto generate PTX, which is a somewhat portable intermediate language that the\nNVIDIA drivers can consume. This means that NVIDIA can completely change the\ninstruction set between GPU revisions without breaking your code. In contrast,\nan x86 CPU is expected to run the original PC DOS (assuming it has BIOS\nemulation in the firmware) and every OS and every piece of user-space software\nreleased for PC platforms since 1978.\n\nThis difference impacts the degree to which you can overfit your ISA to the\nmicroarchitecture. Both x86 and 32-bit Arm were heavily influenced by what was\nfeasible to build at the time they were created. If you are designing a GPU or\nworkload-specific accelerator, however, then the ISA may change radically\nbetween releases. Early AMD GPUs were very long instruction word (VLIW)\narchitectures; modern ones are not but can still run shaders written for the\nolder designs.\n\nA stable ISA also impacts how experimental you can be. If you add an\ninstruction that might not be useful (or might be difficult to implement in\nfuture microarchitectures) to x86 or AArch64, then you will find that some\npopular bit of code uses it in some critical place and you will be stuck with\nit. If you do the same in a GPU or AI accelerator, then you can quietly remove\nit in the next generation.\n\n## Architecture Matters\n\nA belief that has gained some popularity in recent years is that the ISA does\nnot matter. This belief is largely the result of an oversimplification of an\nobservation that is obviously true: Microarchitecture makes more of a\ndifference than architecture in performance. A simple in-order pipeline may\nexecute around 0.7 instructions per cycle. A complex out-of-order pipeline may\nexecute five or more per cycle (per core), giving almost an order of magnitude\ndifference between two implementations of the same ISA. In contrast, in most\nof the projects that I have worked on, I have seen the difference between a\nmediocre ISA and a good one giving no more than a 20% performance difference\non comparable microarchitectures.\n\nTwo parts of this comparison are worth pointing out. The first is that\ndesigning a good ISA is a lot cheaper than designing a good microarchitecture.\nThese days, if you go to a CPU vendor and say, \u201cI have a new technique that\nwill produce a 20% performance improvement,\u201d they will probably not believe\nyou. That kind of overall speedup does not come from a single technique; it\ncomes from applying a load of different bits of very careful design. Leaving\nthat on the table is incredibly wasteful.\n\nThe second key point is contained in the caveat at the end: \u201c... on comparable\nmicroarchitectures.\u201d The ISA constrains the design space of possible\nimplementations. It\u2019s possible to add things to the architecture that either\nenable or prevent specific microarchitectural optimizations.\n\nFor example, consider an arbitrary-length vector extension that operates with\nthe source and destination operands in memory. If the user writes a + b * c\n(where all three operands are large vectors), then a pipelined implementation\nis going to want to load from all three locations, perform the add, perform\nthe multiply, and then store the result. If you have to take an interrupt in\nthe middle and you are only halfway down, what do you do? You might just say,\n\u201cWell, add and multiply are idempotent, so we can restart and everything is\nfine,\u201d but that introduces additional constraints. In particular, the hardware\nmust ensure the destination does not alias any of the source values. If these\nvalues overlap, simply restarting is difficult. You can expose registers that\nreport the progress through the add, but that prevents the pipelined operation\nbecause you cannot report that you are partway through the add and the\nmultiply. If you are building a GPU, then this is less important because\ntypically, you are not handling interrupts within kernels (and if you are,\nthen waiting a few hundred cycles to flush all in-flight state is fine).\n\nThe same problem applies to microcode. You must be able to take an interrupt\nimmediately before or after a microcoded instruction. A simple microcode\nengine pauses the pipeline, issues a set of instructions expanded from the\nmicrocoded instruction, and then resumes. On a simple pipeline, this is fine\n(aside from the impact on interrupt latency) and may give you better code\ndensity. On a more complex pipeline, this prevents speculative execution\nacross microcode and will come with a big performance penalty. If you want\nmicrocode and good performance from a high-end core, you need to use much more\ncomplicated techniques for implementing the microcode engine. This then\napplies pressure back on the ISA: If you have invested a lot of silicon in the\nmicrocode engine, then it makes sense to add new microcoded instructions.\n\n## What Do Small Cores Want?\n\nIf you are designing an ISA for a simple single-issue in-order core, you have\na clear set of constraints. In-order cores do not worry much about data\ndependencies; each instruction runs with the results of the previous one\navailable. Only the larger ones do register renaming, so using lots of\ntemporaries is fine.\n\nThey typically do care about decoder complexity. The original RISC\narchitectures had simple decoders because CISC (complex instruction set\ncomputer) decoders took a large fraction of total area. An in-order core may\nconsist of a few tens of thousands of gates, whereas a complex decoder can\neasily double the size (and, therefore, cost and power consumption). Simple\ndecoding is important on this scale.\n\nSmall code is also important. A small microcontroller core may be as small as\n10KB of SRAM (static random-access memory). A small decrease in encoding\nefficiency can dwarf everything when considering the total area cost: If you\nneed 20% more SRAM for your code, then that can be equivalent to doubling the\ncore area. Unfortunately, this constraint almost directly contradicts the\nprevious one. This is why Thumb-2 and RISC-V focused on a variable length\nencoding that is simple to decode: They save code size without significantly\nincreasing decoder complexity.\n\nThis is a complex tradeoff that is made even more complicated when considering\nmultiple languages. For example, Arm briefly supported Jazelle DBX (direct\nbytecode execution) on some of its mobile cores. This involved decoding Java\nbytecode directly, with Java VM (virtual machine) state mapped into specific\nregisters. A Java add instruction, implemented in a software interpreter,\nrequires at least one load to read the instruction, a conditional branch to\nfind the right handler, and then another to perform the add. With Jazelle, the\nload happens via instruction fetch, and the add would add the two registers\nthat represented the top of the Java stack. This was far more efficient than\nan interpreter but did not perform as well as a JIT (just-in-time) compiler,\nwhich could do a bit more analysis between Java bytecodes.\n\nJazelle DBX is an interesting case study because it made sense only in the\ncontext of a specific set of source languages and microarchitectures. It\nprovided no benefits for languages that did not run in a Java VM. By the time\ndevices had more than about 4MB of RAM, Jazelle was outperformed by a JIT.\nWithin that envelope, however, it was a good design choice.\n\nJazelle DBX should serve as a reminder that optimizations for one size of core\ncan be incredibly bad choices for other cores.\n\n## What Do Big Cores Want?\n\nAs cores get bigger, other factors start to dominate. We have seen the end of\nDennard scaling but not of Moore\u2019s Law. Each generation still gets more\ntransistors for a fixed price, but if you try to power them all, then your\nchip catches fire (the so-called \u201cdark silicon\u201d problem). This is part of the\nreason that on-SoC (system-on-a-chip) accelerators have become popular in\nrecent years. If you can add hardware that makes a particular workload faster\nbut is powered off entirely at other times, then that can be a big win for\npower consumption. Components that need to be powered all of the time are the\nmost likely to become performance-limiting factors.\n\nOn a lot of high-end cores, the register rename logic is often the single\nbiggest consumer of power. Register rename is what enables speculative and\nout-of-order execution. Rename registers are similar to the static single\nassignment (SSA) form that compilers use. When an instruction is dispatched, a\nnew rename register is allocated to hold the result. When another instruction\nwants to consume that result, it is dispatched to use this rename register.\nArchitectural registers are just names for mapping to SSA registers.\n\nA rename register consumes space from the point at which an instruction that\ndefines it enters speculative execution until another instruction that writes\nto the same rename register exits speculation (that is, definitely happens).\nIf a temporary value is live at the end of a basic block, then it continues to\nconsume a rename register. The branch at the end of the basic block will start\nspeculatively issuing instructions somewhere else, but until that branch is no\nlonger speculative and a following instruction has written to the register,\nthe core may need to roll back everything up to that branch and restore that\nvalue. The ISA can have a big impact on the likelihood of encountering this\nkind of problem.\n\nComplex addressing modes often end up being useful on big cores. AArch64 and\nx86-64 both benefit from them, and the T-Head extensions add them to RISC-V.\nIf you are doing address calculation in a loop (for example, iterating over an\narray), then folding this into the load-store pipeline provides two key\nbenefits: First, there is no need to allocate a rename register for the\nintermediate value; second, this computed value is never accidentally live\nacross loop iterations. The power consumption of an extra add is less than\nthat of allocating a new rename register.\n\nNote that this is less the case for very complex addressing modes, such as the\npre- and post-increment addressing modes on Arm, which update the base and\nthus still require a rename register. These modes still win to a degree\nbecause it\u2019s cheaper (particularly for pre-increment) to forward the result to\nthe next stage in a load-store pipeline than to send it via the rename logic.\n\nOne microarchitect building a high-end RISC-V core gave a particularly\ninsightful critique of the RISC-V C extension, observing that it optimizes for\nthe smallest encoding of instructions rather than for the smallest number of\ninstructions. This is the right thing to do for small embedded cores, but\nlarge cores have a lot of fixed overheads associated with each executed\ninstruction. Executing fewer instructions to do the same work is usually a\nwin. This is why SIMD (single instruction, multiple data) instructions have\nbeen so popular: The fixed overheads are amortized over a larger amount of\nwork.\n\nEven if you do not make the arithmetic logic units (ALUs) the full width of\nthe registers and take two cycles to push each half through the execution\npipeline, you still save a lot of the bookkeeping overhead. SIMD instructions\nare a good use of longer encodings in a variable-length instruction set: For\nfour instructions\u2019 worth of work, a 48-bit encoding is probably still a big\nsavings in code size, leaving the denser encodings available for more frequent\noperations.\n\nComplex instruction scheduling causes additional pain. Even moderately large\nin-order cores suffer from branch misprediction penalties. The original\nBerkeley RISC project analyzed the output of C compilers and found that, on\naverage, there was one branch per seven instructions. This has proven to be a\nsurprisingly durable heuristic for C/C++ code.\n\nWith a seven-stage dual-issue pipeline, you might have 14 instructions in\nflight at a time. If you incorrectly predict a branch, half of these will be\nthe wrong ones and will need to be rolled back, making your real throughput\nonly half of your theoretical throughput. Modern high-end cores typically have\naround 200 in-flight instructions\u2014that is over 28 basic blocks, so a 95%\nbranch predictor accuracy rate gives less than a 24% probability of correctly\npredicting every branch being executed. Big cores really like anything that\ncan reduce the cost of misprediction penalties.\n\nThe 32-bit Arm ISA allowed any instruction to be predicated (conditionally\nexecuted depending on the value in a condition-code register). This was great\nfor small to medium in-order cores because they could avoid branches, but the\ncomplexity of making everything predicated was high for big cores. The\nencoding space consumed by predication was large. For AArch64, Arm considered\neliminating predicated execution entirely, but conditional move and a few\nother conditional instructions provided such a large performance win that Arm\nkept them.\n\n## You Don\u2019t Win Points for Purity\n\nBjarne Stroustrup said, \u201cThere are only two kinds of languages: the ones\npeople complain about and the ones nobody uses.\u201d This holds for instruction\nsets (the lowest-level programming languages most people will encounter) just\nas much as for higher-level ones. Good instruction sets are always\ncompromises.\n\nFor example, consider the jump-and-link instructions in RISC-V. These let you\nspecify an arbitrary register as a link register. RISC-V has 32 registers, so\nspecifying one requires a full five-bit operand in a 32-bit instruction.\nAlmost 1% of the total 32-bit encoding space is consumed by the RISC-V jump-\nand-link instruction. RISC-V is, as far as I am aware, unique in this\ndecision.\n\nArm, MIPS, and PowerPC all have a designated link register that their branch-\nand-link instructions use. Thus, they require one bit to differentiate between\njump-and-link and plain jump. RISC-V chooses to avoid baking the ABI into the\nISA but, as a result, requires 16 times as much encoding space for this\ninstruction.\n\nThis decision is even worse because the ABI leaks into the microarchitecture\nbut not the architecture. RISC-V does not have a dedicated return instruction,\nbut implementations will typically (and the ISA specification notes that this\nis a good idea) treat a jump-register instruction with the ABI-defined link\nregister as a return. This means that using any link register other than the\none defined in the ABI will likely result in branch mispredictions. The result\nis dealing with all of the downsides of baking the ABI into the ISA but\nenjoying none of the benefits.\n\nThis kind of reasoning applies even more strongly to the stack pointer.\nAArch64 and x86 both have special instructions for operating on the stack. In\nmost code from C-like languages, the stack pointer is modified only in\nfunction prologs and epilogs, but there are many loads and stores relative to\nit. This has the potential for optimization in the encoding, which can lead to\nfurther optimization in the microarchitecture. For example, modern x86 chips\naccumulate the stack-pointer displacement for push and pop instructions,\nemitting them as offsets to the rename register that contains the stack\npointer (so they are independent and can be issued in parallel) and then doing\na single update to the stack pointer at the end.\n\nThis kind of optimization is possible even if the stack pointer is just an ABI\nconvention, but this again is a convention that is shared by the ABI and the\nmicroarchitecture, so why not take advantage of it to improve encoding\nefficiency in the ISA?\n\nFinally, big cores really care about parallel decoding. Apple\u2019s M2, for\nexample, benefits hugely from the fixed-width ISA because it can fetch a block\nof instructions and start decoding them in parallel. The x86 instruction set,\nat the opposite extreme, needs more of a parser than a decoder. Each\ninstruction is between one and 15 bytes, which may include a number of\nprefixes. High-end x86 chips cache decoded instructions (particularly in hot\nloops), but this consumes power and area that could be used for execution.\n\nThis is not necessarily a bad idea. As with small cores and instruction\ndensity, a variable-length instruction encoding may permit a smaller\ninstruction cache, and that savings may offset the cost of the complex\ndecoder.\n\nAlthough RISC-V uses variable-length encoding, it\u2019s very cheap to determine\nthe length. This makes it possible to build an extra pipeline stage that reads\na block of words and forwards a set of instructions to the real decoder. This\nis nowhere near as complex as decoding x86.\n\n## Some Source Languages Are Not Really Source Languages\n\nA new ISA often takes a long time to gain widespread adoption. The simplest\nway of bootstrapping a software ecosystem is to be a good emulation target.\nEfficient emulation of x86 was an explicit design goal of both AArch64 and\nPowerPC for precisely this reason (although AArch64 had the advantage of a\ncouple of decades more research in binary translation to draw on in its\ndesign). Apple\u2019s Rosetta 2 manages to translate most x86-64 instructions into\none or two AArch64 ones.\n\nA few of its features make AArch64 (and, especially, Apple\u2019s slight variation\non it) amenable to fast and lightweight x86-64 emulation. The first is having\nmore registers, which allows all x86-64 state to be stored in registers.\nSecond, Apple has an opt-in TSO (total store ordering) model, which makes the\nmemory model the same as x86. (RISC-V has this as an option as well, although\nI am not aware of an extension that allows dynamically switching between the\nrelaxed memory model and TSO, as Apple\u2019s hardware permits.)\n\nWithout this mode, you either need variants of all of your loads and stores\nthat can provide the relevant barriers or you need to insert explicit fences\naround all of them. The former consumes a huge amount of encoding space (loads\nand stores make up the largest single consumer of encoding space on AArch64)\nthe latter, many more instructions.\n\nAfter TSO, flags are the second-most annoying feature of x86 from the\nperspective of an emulator. Lots of x86 instructions set flags. Virtual PC for\nMac (x86 on PowerPC) puts a lot of effort into dynamically avoiding setting\nflags if nothing has consumed them (for example, if two flag-setting\ninstructions were back to back).\n\nQEMU does something similar, preserving the source operands and the opcode of\noperations that set flags and computing the flags only when something checks\nthe flags\u2019 value. AArch64 has a similar set of flags to x86, so flag-setting\ninstructions can be translated into one or two instructions. Arm did not get\nthis right (from an emulation perspective) in the first version of the ISA.\nBoth Microsoft and Apple (two companies that ship operating systems that run\non Arm and need to run a lot of legacy x86 code) provided feedback, and\nARMv8.4-CondM and ARMv8.5-CondM added extra modes and instructions for setting\nthese flags differently. Apple goes further with an extension that sets the\ntwo flags present in x86 but not Arm in some unused bits of the flags\nregister, where they can be extracted and moved into other flag bits when\nneeded.\n\nRISC-V made the decision not to have condition codes. These have always been a\nfeature that microarchitects hate\u2014for a few reasons. In the worst case (and,\nsomehow, the worst case is always x86), instructions can set some flags. In\nthe case of x86, this is particularly painful because the carry flag and the\ninterrupts-disabled flag are in the same word (which led to some very\nentertaining operating-system bugs, because the ABI states that the flags\nregister is not preserved across calls, so calling a function to disable\ninterrupts in the kernel was followed by the compiler helpfully reenabling\nthem to restore the flags).\n\nAnything that updates part of a register is painful because it means\nallocating a new rename register and then doing the masked update from the old\nvalue. Even without that, condition codes mean that a lot of instructions\nupdate more than one register.\n\nArm, even in AArch32 days, made this a lot less painful by having variants of\ninstructions that set flags and not setting them for most operations. RISC-V\ndecided to avoid this and instead folds comparisons into branches and has\ninstructions that set a register to a value (typically one or zero) that can\nthen be used with a compare-and-branch instruction such as branch if [not]\nequal (which can be used with register zero to mean branch of [not] zero).\n\nEmulating x86-64 quickly on RISC-V is likely to be much harder because of this\nchoice.\n\nAvoiding flags also has some interesting effects on encoding density.\nConditional branch on zero is incredibly common in C/C++ code for checking\nthat parameters are not null. On x86-64, this is done as a testq (three-byte)\ninstruction, followed by a je (jump if the test set the condition flags for\nequality), which is a two-byte instruction. This incurs all the annoyances of\nallocating a new rename register for the flags mentioned previously, including\nthe fact the flags register remains live until the next flag-setting\ninstruction exits speculation.\n\nThe decision to avoid condition codes also makes adding other predicated\noperations much more difficult. The Arm conditional select and increment\ninstruction looks strange at first glance, but using it provides more than a\n10% speedup on some compression benchmarks. This is a moderately large\ninstruction in AArch64: three registers and a four-bit field indicating the\ncondition to test. This means that it consumes 19 bits in operand space. An\nequivalent RISC-V instruction would either need an additional source register\nand variants for the comparisons to perform or take a single-source operand\nbut need a comparison instruction to set that register to zero or non-zero\nfirst.\n\n## Always Measure\n\nIn 2015, I supervised an undergraduate student extending an in-order RISC-V\ncore with a conditional move and extending the LLVM back end to take advantage\nof it. His conclusion was that, for simple in-order pipelines, the conditional\nmove instruction had a 20% performance increase on several benchmarks, no\nperformance reduction on any of them, and a tiny area overhead. Or, examining\nthe results in the opposite direction, achieving the same performance without\na conditional move required around four times as much branch predictor state.\n\nThis result, I am told, reflected the analysis that Arm conducted (although\ndidn\u2019t publish) on larger and wider pipelines when designing AArch64. This is,\napparently, one of the results that every experienced CPU designer knows but\nno one bothers to write down.\n\nAArch64 removed almost all the predication but kept a few instructions that\nhad a disproportionately high benefit relative to the microarchitectural\ncomplexity. The RISC-V decision to omit conditional move was based largely on\na paper by the authors of the Alpha, who regretted adding conditional move\nbecause it required an extra read port on their register file. This is because\na conditional move must write back either the argument or the original value.\n\nThe interesting part of this argument is that it applies to an incredibly\nnarrow set of microarchitectures. Anything that is small enough to not do\nforwarding does not need to read the old value; it just does not write back a\nvalue. Anything that is doing register renaming can fold the conditional move\ninto the register rename logic and get it almost for free. The Alpha happened\nto be in the narrow gap between the two.\n\nIt\u2019s very easy to gain intuition about what makes an ISA fast or slow based on\nimplementations for a particular scale. These can rapidly go wrong (or start\nout wrong if you are working on a completely different scale or different\nproblem space). New techniques, such as the way that NVIDIA Project Denver and\nApple M-series chips can forward outputs from one instruction to another in\nthe same bundle, can have a significant impact on performance and change the\nimpact of different ISA decisions. Does your ISA encourage compilers to\ngenerate code the new technique can accelerate?\n\nIf you come back to this article in five to 10 years, remember that technology\nadvances. Any suggestions that I have made here may have been rendered untrue\nby newer techniques. If you have a good idea, measure it on simulations of\ndifferent microarchitectures and see whether it makes a difference.\n\n## References\n\n    * 1\\. Chisnall, D. There\u2019s no such thing as a general-purpose processor. acmqueue 12, 10, (2014); https://queue.acm.org/detail.cfm?id=2687011.\n\n    * 2\\. Chow, F. The challenge of cross-language interoperability. acmqueue 11, 10 (2013); https://queue.acm.org/detail.cfm?id=2544374.\n\nDavid Chisnall is the director of systems architecture at SCI Semiconductor,\nCambridge, U.K., where he leads the evolution of the CHERIoT platform. He is a\nformer principal researcher at Microsoft, where he worked on a variety of ISA\ndesign projects. He is also a visiting researcher at the University of\nCambridge.\n\n  * Share\n\n    * Twitter\n    * Reddit\n    * Hacker News\n  * Download PDF\n  * Print\n  * Join the Discussion\n\nSubmit an Article to CACM\n\nCACM welcomes unsolicited submissions on topics of relevance and value to the\ncomputing community.\n\nYou Just Read\n\n#### How to Design an ISA\n\nView in the ACM Digital Library\n\nThis work is licensed under a Creative Commons Attribution International 4.0\nLicense.\n\n### DOI\n\n10.1145/3640538\n\n### Related Reading\n\n  * Research and Advances\n\nA New Golden Age for Computer Architecture\n\nArchitecture and Hardware\n\n  * News\n\nWill RISC-V Revolutionize Computing?\n\nArchitecture and Hardware\n\n  * Research and Advances\n\nComputing Needs Time\n\nArchitecture and Hardware\n\n  * News\n\nProtecting Industrial Control Systems\n\nComputing Profession\n\nAdvertisement\n\nAdvertisement\n\n### Join the Discussion (0)\n\n#### Become a Member or Sign In to Post a Comment\n\nSign In Sign Up\n\n### The Latest from CACM\n\nExplore More\n\nNews Apr 4 2024\n\nSafety Fears Raised Over Risks of \u2018Penetrative AI\u2019\n\nPaul Marks\n\nArtificial Intelligence and Machine Learning\n\nNews Apr 2 2024\n\nThe Risks of Source Code Breaches\n\nDavid Geer\n\nSecurity and Privacy\n\nNews Mar 28 2024\n\nConversations with AI\n\nBennie Mols\n\nArtificial Intelligence and Machine Learning\n\n### Shape the Future of Computing\n\nACM encourages its members to take a direct hand in shaping the future of the\nassociation. There are more ways than ever to get involved.\n\nGet Involved\n\n### Communications of the ACM (CACM) is now a fully Open Access publication.\n\nBy opening CACM to the world, we hope to increase engagement among the broader\ncomputer science community and encourage non-members to discover the rich\nresources ACM has to offer.\n\nLearn More\n\nTopics\n\n  * Architecture and Hardware\n  * Artificial Intelligence and Machine Learning\n  * Computer History\n  * Computing Applications\n  * Computing Profession\n  * Data and Information\n  * Education\n  * HCI\n  * Philosophy of Computing\n  * Security and Privacy\n  * Society\n  * Software Engineering and Programming Languages\n  * Systems and Networking\n  * Theory\n\nMagazine\n\n  * Latest Issue\n  * Magazine Archive\n  * Editorial Staff and Board\n  * Submit an Article\n  * Alerts & Feeds\n  * Author Guidelines\n\nCommunications of the ACM\n\n  * About Us\n  * Frequently Asked Questions\n  * Contact Us\n  * For Advertisers\n  * Join ACM\n\n\u00a9 2024 Communications of the ACM. All Rights Reserved.\n\n  * Cookie Notice\n  * Privacy Policy\n\nBy continuing to use our website, you are agreeing to our use of cookies. To\nfind out more, please see our Privacy Policy.\n\n", "frontpage": false}
