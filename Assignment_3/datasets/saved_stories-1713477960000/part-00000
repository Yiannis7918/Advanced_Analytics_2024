{"aid": "40077601", "title": "Meta Releases Llama 3", "url": "https://ai.meta.com/blog/meta-llama-3/", "domain": "meta.com", "votes": 22, "user": "mchiang", "posted_at": "2024-04-18 16:03:52", "comments": 2, "source_title": "Introducing Meta Llama 3: The most capable openly available LLM to date", "source_text": "Introducing Meta Llama 3: The most capable openly available LLM to date\n\n  * Our approach\n\n  * Research\n\n  * Meta AI\n\n  * Meta Llama\n\n  * Blog\n\n  * Try Meta AI\n\nBACK\n\n  * About us\n  * Responsibility\n  * People\n  * Careers\n\n  * Overview\n  * Infrastructure\n  * Resources\n  * Demos\n\nClear\n\n  * Clear\n\n  * Our approach\n\n>\n\n  * Research\n\n>\n\n  * Meta AI\n  * Meta Llama\n  * Blog\n\nTry Meta AI\n\nLarge Language Model\n\nIntroducing Meta Llama 3: The most capable openly available LLM to date\n\nApril 18, 2024\n\nTakeaways:\n\nRECOMMENDED READS\n\n  * 5 Steps to Getting Started with Llama 2\n\n  * The Llama Ecosystem: Past, Present, and Future\n\n  * Introducing Code Llama, a state-of-the-art large language model for coding\n\n  * Meta and Microsoft Introduce the Next Generation of Llama\n\n  * Today, we\u2019re introducing Meta Llama 3, the next generation of our state-of-the-art open source large language model.\n  * Llama 3 models will soon be available on AWS, Databricks, Google Cloud, Hugging Face, Kaggle, IBM WatsonX, Microsoft Azure, NVIDIA NIM, and Snowflake, and with support from hardware platforms offered by AMD, AWS, Dell, Intel, NVIDIA, and Qualcomm.\n  * We\u2019re dedicated to developing Llama 3 in a responsible way, and we\u2019re offering various resources to help others use it responsibly as well. This includes introducing new trust and safety tools with Llama Guard 2, Code Shield, and CyberSec Eval 2.\n  * In the coming months, we expect to introduce new capabilities, longer context windows, additional model sizes, and enhanced performance, and we\u2019ll share the Llama 3 research paper.\n  * Meta AI, built with Llama 3 technology, is now one of the world\u2019s leading AI assistants that can boost your intelligence and lighten your load\u2014helping you learn, get things done, create content, and connect to make the most out of every moment. You can try Meta AI here.\n\nToday, we\u2019re excited to share the first two models of the next generation of\nLlama, Meta Llama 3, available for broad use. This release features pretrained\nand instruction-fine-tuned language models with 8B and 70B parameters that can\nsupport a broad range of use cases. This next generation of Llama demonstrates\nstate-of-the-art performance on a wide range of industry benchmarks and offers\nnew capabilities, including improved reasoning. We believe these are the best\nopen source models of their class, period. In support of our longstanding open\napproach, we\u2019re putting Llama 3 in the hands of the community. We want to\nkickstart the next wave of innovation in AI across the stack\u2014from applications\nto developer tools to evals to inference optimizations and more. We can\u2019t wait\nto see what you build and look forward to your feedback.\n\nOur goals for Llama 3\n\nWith Llama 3, we set out to build the best open models that are on par with\nthe best proprietary models available today. We wanted to address developer\nfeedback to increase the overall helpfulness of Llama 3 and are doing so while\ncontinuing to play a leading role on responsible use and deployment of LLMs.\nWe are embracing the open source ethos of releasing early and often to enable\nthe community to get access to these models while they are still in\ndevelopment. The text-based models we are releasing today are the first in the\nLlama 3 collection of models. Our goal in the near future is to make Llama 3\nmultilingual and multimodal, have longer context, and continue to improve\noverall performance across core LLM capabilities such as reasoning and coding.\n\nState-of-the-art performance\n\nOur new 8B and 70B parameter Llama 3 models are a major leap over Llama 2 and\nestablish a new state-of-the-art for LLM models at those scales. Thanks to\nimprovements in pretraining and post-training, our pretrained and instruction-\nfine-tuned models are the best models existing today at the 8B and 70B\nparameter scale. Improvements in our post-training procedures substantially\nreduced false refusal rates, improved alignment, and increased diversity in\nmodel responses. We also saw greatly improved capabilities like reasoning,\ncode generation, and instruction following making Llama 3 more steerable.\n\n*Please see evaluation details for setting and parameters with which these evaluations are calculated.\n\nIn the development of Llama 3, we looked at model performance on standard\nbenchmarks and also sought to optimize for performance for real-world\nscenarios. To this end, we developed a new high-quality human evaluation set.\nThis evaluation set contains 1,800 prompts that cover 12 key use cases: asking\nfor advice, brainstorming, classification, closed question answering, coding,\ncreative writing, extraction, inhabiting a character/persona, open question\nanswering, reasoning, rewriting, and summarization. To prevent accidental\noverfitting of our models on this evaluation set, even our own modeling teams\ndo not have access to it. The chart below shows aggregated results of our\nhuman evaluations across of these categories and prompts against Claude\nSonnet, Mistral Medium, and GPT-3.5.\n\nPreference rankings by human annotators based on this evaluation set highlight\nthe strong performance of our 70B instruction-following model compared to\ncompeting models of comparable size in real-world scenarios.\n\nOur pretrained model also establishes a new state-of-the-art for LLM models at\nthose scales.\n\n*Please see evaluation details for setting and parameters with which these evaluations are calculated.\n\nTo develop a great language model, we believe it\u2019s important to innovate,\nscale, and optimize for simplicity. We adopted this design philosophy\nthroughout the Llama 3 project with a focus on four key ingredients: the model\narchitecture, the pretraining data, scaling up pretraining, and instruction\nfine-tuning.\n\nModel architecture\n\nIn line with our design philosophy, we opted for a relatively standard\ndecoder-only transformer architecture in Llama 3. Compared to Llama 2, we made\nseveral key improvements. Llama 3 uses a tokenizer with a vocabulary of 128K\ntokens that encodes language much more efficiently, which leads to\nsubstantially improved model performance. To improve the inference efficiency\nof Llama 3 models, we\u2019ve adopted grouped query attention (GQA) across both the\n8B and 70B sizes. We trained the models on sequences of 8,192 tokens, using a\nmask to ensure self-attention does not cross document boundaries.\n\nTraining data\n\nTo train the best language model, the curation of a large, high-quality\ntraining dataset is paramount. In line with our design principles, we invested\nheavily in pretraining data. Llama 3 is pretrained on over 15T tokens that\nwere all collected from publicly available sources. Our training dataset is\nseven times larger than that used for Llama 2, and it includes four times more\ncode. To prepare for upcoming multilingual use cases, over 5% of the Llama 3\npretraining dataset consists of high-quality non-English data that covers over\n30 languages. However, we do not expect the same level of performance in these\nlanguages as in English.\n\nTo ensure Llama 3 is trained on data of the highest quality, we developed a\nseries of data-filtering pipelines. These pipelines include using heuristic\nfilters, NSFW filters, semantic deduplication approaches, and text classifiers\nto predict data quality. We found that previous generations of Llama are\nsurprisingly good at identifying high-quality data, hence we used Llama 2 to\ngenerate the training data for the text-quality classifiers that are powering\nLlama 3.\n\nWe also performed extensive experiments to evaluate the best ways of mixing\ndata from different sources in our final pretraining dataset. These\nexperiments enabled us to select a data mix that ensures that Llama 3 performs\nwell across use cases including trivia questions, STEM, coding, historical\nknowledge, etc.\n\nScaling up pretraining\n\nTo effectively leverage our pretraining data in Llama 3 models, we put\nsubstantial effort into scaling up pretraining. Specifically, we have\ndeveloped a series of detailed scaling laws for downstream benchmark\nevaluations. These scaling laws enable us to select an optimal data mix and to\nmake informed decisions on how to best use our training compute. Importantly,\nscaling laws allow us to predict the performance of our largest models on key\ntasks (for example, code generation as evaluated on the HumanEval\nbenchmark\u2014see above) before we actually train the models. This helps us ensure\nstrong performance of our final models across a variety of use cases and\ncapabilities.\n\nWe made several new observations on scaling behavior during the development of\nLlama 3. For example, while the Chinchilla-optimal amount of training compute\nfor an 8B parameter model corresponds to ~200B tokens, we found that model\nperformance continues to improve even after the model is trained on two orders\nof magnitude more data. Both our 8B and 70B parameter models continued to\nimprove log-linearly after we trained them on up to 15T tokens. Larger models\ncan match the performance of these smaller models with less training compute,\nbut smaller models are generally preferred because they are much more\nefficient during inference.\n\nTo train our largest Llama 3 models, we combined three types of\nparallelization: data parallelization, model parallelization, and pipeline\nparallelization. Our most efficient implementation achieves a compute\nutilization of over 400 TFLOPS per GPU when trained on 16K GPUs\nsimultaneously. We performed training runs on two custom-built 24K GPU\nclusters. To maximize GPU uptime, we developed an advanced new training stack\nthat automates error detection, handling, and maintenance. We also greatly\nimproved our hardware reliability and detection mechanisms for silent data\ncorruption, and we developed new scalable storage systems that reduce\noverheads of checkpointing and rollback. Those improvements resulted in an\noverall effective training time of more than 95%. Combined, these improvements\nincreased the efficiency of Llama 3 training by ~three times compared to Llama\n2.\n\nInstruction fine-tuning\n\nTo fully unlock the potential of our pretrained models in chat use cases, we\ninnovated on our approach to instruction-tuning as well. Our approach to post-\ntraining is a combination of supervised fine-tuning (SFT), rejection sampling,\nproximal policy optimization (PPO), and direct policy optimization (DPO). The\nquality of the prompts that are used in SFT and the preference rankings that\nare used in PPO and DPO has an outsized influence on the performance of\naligned models. Some of our biggest improvements in model quality came from\ncarefully curating this data and performing multiple rounds of quality\nassurance on annotations provided by human annotators.\n\nLearning from preference rankings via PPO and DPO also greatly improved the\nperformance of Llama 3 on reasoning and coding tasks. We found that if you ask\na model a reasoning question that it struggles to answer, the model will\nsometimes produce the right reasoning trace: The model knows how to produce\nthe right answer, but it does not know how to select it. Training on\npreference rankings enables the model to learn how to select it.\n\nBuilding with Llama 3\n\nOur vision is to enable developers to customize Llama 3 to support relevant\nuse cases and to make it easier to adopt best practices and improve the open\necosystem. With this release, we\u2019re providing new trust and safety tools\nincluding updated components with both Llama Guard 2 and Cybersec Eval 2, and\nthe introduction of Code Shield\u2014an inference time guardrail for filtering\ninsecure code produced by LLMs.\n\nWe\u2019ve also co-developed Llama 3 with torchtune, the new PyTorch-native library\nfor easily authoring, fine-tuning, and experimenting with LLMs. torchtune\nprovides memory efficient and hackable training recipes written entirely in\nPyTorch. The library is integrated with popular platforms such as Hugging\nFace, Weights & Biases, and EleutherAI and even supports Executorch for\nenabling efficient inference to be run on a wide variety of mobile and edge\ndevices. For everything from prompt engineering to using Llama 3 with\nLangChain we have a comprehensive getting started guide and takes you from\ndownloading Llama 3 all the way to deployment at scale within your generative\nAI application.\n\nA system-level approach to responsibility\n\nWe have designed Llama 3 models to be maximally helpful while ensuring an\nindustry leading approach to responsibly deploying them. To achieve this, we\nhave adopted a new, system-level approach to the responsible development and\ndeployment of Llama. We envision Llama models as part of a broader system that\nputs the developer in the driver\u2019s seat. Llama models will serve as a\nfoundational piece of a system that developers design with their unique end\ngoals in mind.\n\nInstruction fine-tuning also plays a major role in ensuring the safety of our\nmodels. Our instruction-fine-tuned models have been red-teamed (tested) for\nsafety through internal and external efforts. Our red teaming approach\nleverages human experts and automation methods to generate adversarial prompts\nthat try to elicit problematic responses. For instance, we apply comprehensive\ntesting to assess risks of misuse related to Chemical, Biological, Cyber\nSecurity, and other risk areas. All of these efforts are iterative and used to\ninform safety fine-tuning of the models being released. You can read more\nabout our efforts in the model card.\n\nLlama Guard models are meant to be a foundation for prompt and response safety\nand can easily be fine-tuned to create a new taxonomy depending on application\nneeds. As a starting point, the new Llama Guard 2 uses the recently announced\nMLCommons taxonomy, in an effort to support the emergence of industry\nstandards in this important area. Additionally, CyberSecEval 2 expands on its\npredecessor by adding measures of an LLM\u2019s propensity to allow for abuse of\nits code interpreter, offensive cybersecurity capabilities, and susceptibility\nto prompt injection attacks (learn more in our technical paper). Finally,\nwe\u2019re introducing Code Shield which adds support for inference-time filtering\nof insecure code produced by LLMs. This offers mitigation of risks around\ninsecure code suggestions, code interpreter abuse prevention, and secure\ncommand execution.\n\nWith the speed at which the generative AI space is moving, we believe an open\napproach is an important way to bring the ecosystem together and mitigate\nthese potential harms. As part of that, we\u2019re updating our Responsible Use\nGuide (RUG) that provides a comprehensive guide to responsible development\nwith LLMs. As we outlined in the RUG, we recommend that all inputs and outputs\nbe checked and filtered in accordance with content guidelines appropriate to\nthe application. Additionally, many cloud service providers offer content\nmoderation APIs and other tools for responsible deployment, and we encourage\ndevelopers to also consider using these options.\n\nDeploying Llama 3 at scale\n\nLlama 3 will soon be available on all major platforms including cloud\nproviders, model API providers, and much more. Llama 3 will be everywhere.\n\nOur benchmarks show the tokenizer offers improved token efficiency, yielding\nup to 15% fewer tokens compared to Llama 2. Also, Group Query Attention (GQA)\nnow has been added to Llama 3 8B as well. As a result, we observed that\ndespite the model having 1B more parameters compared to Llama 2 7B, the\nimproved tokenizer efficiency and GQA contribute to maintaining the inference\nefficiency on par with Llama 2 7B.\n\nFor examples of how to leverage all of these capabilities, check out Llama\nRecipes which contains all of our open source code that can be leveraged for\neverything from fine-tuning to deployment to model evaluation.\n\nWhat\u2019s next for Llama 3?\n\nThe Llama 3 8B and 70B models mark the beginning of what we plan to release\nfor Llama 3. And there\u2019s a lot more to come.\n\nOur largest models are over 400B parameters and, while these models are still\ntraining, our team is excited about how they\u2019re trending. Over the coming\nmonths, we\u2019ll release multiple models with new capabilities including\nmultimodality, the ability to converse in multiple languages, a much longer\ncontext window, and stronger overall capabilities. We will also publish a\ndetailed research paper once we are done training Llama 3.\n\nTo give you a sneak preview for where these models are today as they continue\ntraining, we thought we could share some snapshots of how our largest LLM\nmodel is trending. Please note that this data is based on an early checkpoint\nof Llama 3 that is still training and these capabilities are not supported as\npart of the models released today.\n\n*Please see evaluation details for setting and parameters with which these evaluations are calculated.\n\nWe\u2019re committed to the continued growth and development of an open AI\necosystem for releasing our models responsibly. We have long believed that\nopenness leads to better, safer products, faster innovation, and a healthier\noverall market. This is good for Meta, and it is good for society.We\u2019re taking\na community-first approach with Llama 3, and starting today, these models are\navailable on the leading cloud, hosting, and hardware platforms with many more\nto come.\n\nTry Meta Llama 3 today\n\nWe\u2019ve integrated our latest models into Meta AI, which we believe is the\nworld\u2019s leading AI assistant. It\u2019s now built with Llama 3 technology and it\u2019s\navailable in more countries across our apps.\n\nYou can use Meta AI on Facebook, Instagram, WhatsApp, Messenger, and the web\nto get things done, learn, create, and connect with the things that matter to\nyou. You can read more about the Meta AI experience here.\n\nVisit the Llama 3 website to download the models and reference the Getting\nStarted Guide for the latest list of all available platforms.\n\nYou\u2019ll also soon be able to test multimodal Meta AI on our Ray-Ban Meta smart\nglasses.\n\nAs always, we look forward to seeing all the amazing products and experiences\nyou will build with Meta Llama 3.\n\nShare:\n\nOur latest updates delivered to your inbox\n\nSubscribe to our newsletter to keep up with Meta AI news, events, research\nbreakthroughs, and more.\n\nJoin us in the pursuit of what\u2019s possible with AI.\n\nSee all open positions\n\nRelated Posts\n\nComputer Vision\n\nIntroducing Segment Anything: Working toward the first foundation model for\nimage segmentation\n\nApril 5, 2023\n\nRead post\n\nFEATURED\n\nResearch\n\nMultiRay: Optimizing efficiency for large-scale AI models\n\nNovember 18, 2022\n\nRead post\n\nFEATURED\n\nML Applications\n\nMuAViC: The first audio-video speech translation benchmark\n\nMarch 8, 2023\n\nRead post\n\nOur approach\n\nAbout AI at Meta\n\nResponsibility\n\nPeople\n\nCareers\n\nResearch\n\nInfrastructure\n\nResources\n\nDemos\n\nProduct experiences\n\nMeta AI\n\nLatest news\n\nBlog\n\nNewsletter\n\nFoundational models\n\nMeta Llama\n\nOur approach\n\nOur approachAbout AI at MetaResponsibilityPeopleCareers\n\nResearch\n\nResearchInfrastructureResourcesDemos\n\nProduct experiences\n\nMeta AI\n\nLatest news\n\nLatest newsBlogNewsletter\n\nFoundational models\n\nMeta Llama\n\nPrivacy Policy\n\nTerms\n\nCookies\n\nMeta \u00a9 2024\n\nAllow the use of cookies from Meta on this browser?\n\nWe use essential cookies and similar technologies to help:\n\nProvide and improve content on Meta Products\n\nProvide a safer experience by using information we receive from cookies on and\noff Meta Products\n\nProvide and improve Meta Company Products for people using a Meta or Oculus\naccount\n\nWe use tools on Meta from other companies that also use cookies. These tools\nare used for things like:\n\n  * Advertising and measurement services off of Meta Products\n  * Analytics\n  * Providing certain features\n  * Improving our services\n\nYou can allow the use of all cookies, just essential cookies or you can choose\nmore options below. You can learn more about cookies and how we use them, and\nreview or change your choice at any time in our Cookie Policy.\n\nEssential cookies\n\nThese cookies are required to use Meta Company Products. They\u2019re necessary for\nMeta websites to work as intended.\n\nOptional cookies\n\nOptional cookies from other companies\n\nWe use tools from other companies for advertising and measurement services off\nof Meta Company Products, analytics, and to provide certain features and\nimprove our services for you. These companies also use cookies.\n\nIf you allow these cookies:\n\n  * We\u2019ll be able to better personalize ads for you off of Meta Products, and measure their performance\n  * Features on our products will not be affected\n  * Other companies will receive information about you when you use cookies\n\nIf you don\u2019t allow these cookies:\n\n  * We won\u2019t use cookies from other companies to help personalize ads for you off of Meta Products or measure ads performance\n  * Some features on our products may not work\n\nOther ways you can control tracking\n\nAd settings\n\nIf you have added your Meta or Oculus account to the same Accounts Center as\nyour Facebook or Instagram account, you can manage how different data is used\nto personalize ads in ad settings. To show you better ads, we use data that\nadvertisers and other partners provide us about your activity off Meta Company\nProducts, including websites and apps. You can control whether we use this\ndata to show you ads in your ad settings.\n\nThe Facebook Audience Network is a way for advertisers to show you ads in apps\nand websites off the Meta Company Products. One of the ways Audience Network\nshows relevant ads is by using your ad preferences to determine which ads you\nmay be interested in seeing.\n\nAd preferences\n\nIn Ad preferences, you can choose whether we show you ads and make choices\nabout the information used to show you ads.\n\nYou can opt out of seeing online interest-based ads from Meta and other\nparticipating companies through the Digital Advertising Alliance in the US,\nthe Digital Advertising Alliance of Canada in Canada or the European\nInteractive Digital Advertising Alliance in Europe, or through your mobile\ndevice settings, if you are using Android, iOS 13 or an earlier version of\niOS. Please note that ad blockers and tools that restrict our cookie use may\ninterfere with these controls.The advertising companies we work with generally\nuse cookies and similar technologies as part of their services. To learn more\nabout how advertisers generally use cookies and the choices they offer, you\ncan review the following resources:\n\n  * Digital Advertising Alliance\n  * Digital Advertising Alliance of Canada\n  * European Interactive Digital Advertising Alliance\n\nYour browser or device may offer settings that allow you to choose whether\nbrowser cookies are set and to delete them. These controls vary by browser,\nand manufacturers may change both the settings they make available and how\nthey work at any time. As of 5 October 2020, you may find additional\ninformation about the controls offered by popular browsers at the links below.\nCertain parts of Meta Products may not work properly if you have disabled\nbrowser cookies. Please be aware these controls are distinct from the controls\nthat Instagram and Facebook offer.\n\n  * Google Chrome\n  * Internet Explorer\n  * Firefox\n  * Safari\n  * Safari Mobile\n  * Opera\n\n", "frontpage": true}
