{"aid": "40010232", "title": "Chess: ChatGPT vs. Gemini", "url": "https://www.chess.com/article/view/chatgpt-gemini-play-chess", "domain": "chess.com", "votes": 2, "user": "FergusArgyll", "posted_at": "2024-04-12 07:31:36", "comments": 0, "source_title": "Which AI Is Better At Chess, ChatGPT Or Gemini?", "source_text": "Which AI Is Better At Chess, ChatGPT Or Gemini? - Chess.com\n\nOpens in a new window Opens an external website Opens an external website in a\nnew window\n\nThis website stores and accesses information on your device, such as cookies.\nPersonal data may be processed, such as cookie identifiers, unique device\nidentifiers, and browser information. Third parties may store and access\ninformation on your device and process this personal data. You may change or\nwithdraw your preferences by clicking on the cookie icon or link; however, as\na consequence, you may not see relevant ads or personalized content. You can\nchange your settings at any time. You can close this banner to continue with\nonly essential cookies. Privacy Policy\n\nStorage Preferences Third Parties\n\nHome Play\n\nPuzzles\n\nLearn\n\nWatch\n\nNews\n\nSocial\n\nSign Up\n\nLog In\n\nSign Up Log In\n\nArticles\n\n# Which AI Is Better At Chess, ChatGPT Or Gemini?\n\nNathanielGreen\n\nMar 11, 2024, 7:00 AM | 63 | Amazing Games\n\nEnglish\n\nDeutsch\n\nEnglish\n\nItaliano\n\nLast time we talked chess with ChatGPT, it had all sorts of weird ideas and\nterrible advice about chess. So, of course we left it at that, right?\n\nAu contraire. We doubled down\u2014literally. We added another AI, Google's Gemini,\ninto the mix and had the two of them duke it out in a battle of the \"wits\" to\nsee which model is better at chess.\n\nSo who won? Read on to find out!\n\n  * The Game\n  * The Analysis\n  * The Method\n  * Conclusion\n\n## The Game\n\nWhat better way to test out the AIs than have them play a game against each\nother? First, here is the result by itself with no commentary. How many\nhilarious mistakes can you find?\n\nAnd now here is the game with our favorite moments, including statements made\nby the AIs themselves, and some of the funnier backstories behind a few of the\nmoves.\n\nThe \"brilliant\" move by ChatGPT which led Gemini to believe it had no legal\nreplies, forcing \"resignation\".\n\nYou can play around with the game yourself at this analysis page.\n\n## The Analysis\n\nWhat did Game Review have to say about all this in terms of accuracy?\n\nAnd so not just the result, but the accuracy paints the picture: GPT is better\nat chess.\n\nHere's what percentages those moves break into (book moves removed).\n\nMove| ChatGPT| Gemini  \n---|---|---  \nBrilliant| 0%| 0%  \nGreat| 0%| 0%  \nBest| 11%| 11%  \nExcellent| 18%| 14%  \nGood| 14%| 14%  \nInaccuracy| 11%| 14%  \nMistake| 4%| 29%  \nMiss| 39%| 7%  \nBlunder| 4%| 11%  \n  \nA particularly exciting portion of the game from moves 17-23.\n\nGemini's mistakes and ChatGPT's misses tell a lot of the story. One AI kept\ngiving the other one opportunities, the other kept refusing those gifts. The\ngood news for ChatGPT is that it made more \"Good\" or better moves than Gemini\nmade mistakes and blunders. The bad news for Gemini is, well, almost\neverything that happened.\n\n> With White's 21.Ra1 entering the Poisoned Pawn variation, Black has a few\n> options. The most important thing is to not be tempted to take the poisoned\n> pawn on b5.\n>\n> \\- Gemini, with no enemy pawn on b5, just before hanging a bishop\n\n## The Method\n\nChatGPT was asked for a move to start a chess game. Gemini was asked for a\nresponse. After that, moves were asked for in the following formulation:\n\"White/Black replied [1...c5, 2.Nf3, etc.]. Play White/Black's nth move.\" They\ntook place in a single conversation thread each, so the AI could remember the\ngame so far.\n\nTo be fair to the AIs, this method effectively has them playing blindfold\nchess. But to be fair to us, they should be able to recreate the position much\nmore easily than a human.\n\nAn empty board, or a game of blindfold chess?\n\nShould be. But the model is based on language, which makes it hard to\ntranslate text into a geometrical position. However, this problem persists\nwhen they get the whole game at once, and we know from the last article that\nChatGPT can't even recreate a position from the FEN itself.\n\nAnother problem: These AIs are both designed to equivocate, which works well\nif a user asks them a deep philosophical question, but less well if you just\nwant it to play a darned chess move. If an AI listed multiple moves without\nrecommending one, it was asked for a recommendation. If it recommended\nmultiple moves, it was asked to pick one.\n\nHere's the fun part: what about illegal moves, or moves that don't even exist,\nwhere it tries to make a capture with a piece it doesn't have on the board?\nWith board vision this bad, both AIs tried to make a lot of both types. If one\ndid, it was told the move was illegal, and to pick another one. If it made\nillegal moves three straight times, it was given every move of the full game,\nwhich would usually finally trigger a legal move, albeit still not a good one.\n\nOn its 17th move, Gemini tried this whole mess (plus Nd7... twice) before\nfinding a legal move (17...Rfe8). This was the first time during the game that\nillegal moves appeared, but it wasn't the last.\n\nThe final illegal move tally was Gemini 32, ChatGPT 6. That makes sense; it\nwould have been crazy if the AI good enough to win was also bad enough to make\nmore illegal moves. But it also means Gemini only went 50% in picking a legal\nmove, while ChatGPT was over 80%.\n\n## Conclusion\n\nSo that is what happens when two language learning models try to play chess.\nDo any of the results really surprise you? As the winner of this game, should\nwe try ChatGPT vs. other, actual chess bots? Do you think it could beat\nMartin? Or, how quickly do you think Stockfish would win?\n\nAll we know for now is that you would not want to bet your life on ChatGPT\nfinding a hanging queen. But if you had to choose between ChatGPT and Gemini,\nyou know which one to pick.\n\nFeel free to repeat this exercise yourself and share the results in the\ncomments!\n\nNathaniel Green\n\nNathaniel Green is a staff writer for Chess.com who writes articles, player\nbiographies, Titled Tuesday reports, video scripts, and more. He has been\nplaying chess for about 30 years and resides near Washington, DC, USA.\n\nMore from NathanielGreen\n\n## Who The Stats Say Will Be The Next World Championship Challenger\n\n## ChatGPT Gives Terrible Chess Advice\n\nRemove Ads\n\nArticles\n\nFor Beginners\n\nStrategy\n\nTactics\n\nScholastics\n\nOpening Theory\n\nMiddlegame\n\nEndgames\n\nAmazing Games\n\nChess Players\n\nFun & Trivia\n\nOther\n\nChess.com Help\n\nAuthors\n\nStudy Plans\n\nCurriculum for Kids\n\nRemove Ads\n\nHelp Chess Terms About Students Jobs Developers User Agreement Privacy Fair\nPlay Partners Compliance Cookies Chess.com \u00a9 2024\n\n### Ready to Play Chess?\n\n  * Play Online\n  * Play Friends\n  * vs Computer\n  * Tournaments\n\n", "frontpage": false}
