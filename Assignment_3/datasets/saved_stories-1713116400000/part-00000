{"aid": "40030402", "title": "RSS is cool Some RSS feed readers are not (yet)", "url": "https://linux-audit.com/rss-is-cool-but-some-rss-feed-readers-are-not-yet/", "domain": "linux-audit.com", "votes": 2, "user": "mboelen", "posted_at": "2024-04-14 11:38:08", "comments": 0, "source_title": "RSS is cool! Some RSS feed readers are not (yet)...", "source_text": "RSS is cool! Some RSS feed readers are not (yet)... | Linux Audit\n\n  * blog\n  * data compression\n  * feed\n  * rss\n\n# RSS is cool! Some RSS feed readers are not (yet)...\n\n## Fresh look at RSS after a migration\n\nThis blog had a RSS feed since its inception about 10 years ago. It was (and\nis) an easy way for readers to quickly discover released and updated articles.\nAlthough a lot has changed in 10 years, including a migration from WordPress\nto Hugo, the RSS feed is still available. Recently, as part of the migration,\nwe looked again at all individual layers that makes this blog possible. From\nthe web server configuration, up to the final HTML output, everything got a\nreview.\n\nInstead of just copying the old configuration, we set everything up from\nscratch. A fresh start, questioning all choices. With each change, we looked\nwhat we could tune and improve. Things that could improve availability and\nperformance. For example, the SSL/TLS configuration settings were updated,\nincluding enabling 0-RTT handshakes. The blog was already somewhat static and\nquick, but there was still room for improvement. This time everything is\nreally static output and we let the web server focus on what it is good at:\ndelivering content at a high speed! Upon on our analysis we discovered a few\nthings, and that is what this article is about.\n\n## Bad bots\n\nLike every website on the internet, our logs getting spammed with bad bots. We\nalready had some measures implemented, but we decided to optimize this even\nfurther. So this means not just blocking bad bots, but also blocking badly\nbehaving clients. Using still the HTTP/1.0 protocol? That\u2019s fine, but not on\nthis website. Not offering to accept compressed data transfers, sorry, no data\nfor you. That is where things got interesting.\n\nLet\u2019s have a look together at some of the things we recently observed,\nincluding our thoughts. As we are in favor of RSS, we will also add the\nrelevant actions that we took to see if things can be improved. Not just for\nus, but for the whole RSS community.\n\n## Examples of issues and improvements\n\n### Different types of requests from Slackbot\n\n    \n    \n    2024-04-13T11:56:26+00:00 200 1.2.3.4 \"HEAD /feed/ HTTP/2.0\" 0 \"-\" \"Slackbot 1.0 (+https://api.slack.com/robots)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-13T11:56:26+00:00 200 2.3.4.5 \"GET /feed/ HTTP/1.1\" 19046 \"-\" \"Slackbot 1.0 (+https://api.slack.com/robots)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 .\n\nThis is interesting. It looks like Slack first queries some basic details\nabout the feed by using a HEAD. The assumption was that this is feedback for\ndecided to pull in the feed (or not). However if we look at the timing, we see\nsomething else. In the very same second that the first request came in,\nanother system does an actual GET. I doubt they got the chance to process the\ninformation from the first request before firing up the second. Bad\nimplementation? Not sure. Another interesting thing is that the used TLS\nprotocol and ciphers are the same, but the HEAD request was done with an older\nHTTP protocol version. Might be a thing related to reducing overhead?\n\n### Multiple requests from the same system\n\nSome clients seem to request the feed a few times per minute.\n\n    \n    \n    2024-04-13T11:58:13+00:00 200 1.2.3.4 \"GET /atom.xml HTTP/1.1\" 14697 \"https://linux-audit.com/\" \"Inoreader/1.0 (+http://www.inoreader.com/feed-fetcher; 1 subscribers; )\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-13T11:58:29+00:00 200 1.2.3.4 \"GET /atom.xml HTTP/1.1\" 14697 \"https://linux-audit.com/\" \"Inoreader/1.0 (+http://www.inoreader.com/feed-fetcher; 1 subscribers; )\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 .\n\nWhile this client only had two requests, it is a waste of 50 percent. After\nall, nothing changed in this short time. It\u2019s not fully clear why this client\ndid this, especially as it is not continuously doing this. If it had, our\nrate-limit would kick in.\n\n#### Action: cause unclear, more research needed\n\nActions:\n\n  * None, more research needed to see if this is a one-time event or common issue\n\n### Newsboat: Too many requests\n\nWith rate-limiting in place, we noticed that the Newsboat client got picked\nup. Example from the logs:\n\n    \n    \n    2024-04-14T09:07:39+00:00 304 1.2.3.4 \"GET /feed/ HTTP/2.0\" 0 \"-\" \"Newsboat/r2.35 (Linux x86_64)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-14T09:07:39+00:00 304 1.2.3.4 \"GET /feed/ HTTP/2.0\" 0 \"-\" \"Newsboat/r2.35 (Linux x86_64)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-14T09:07:39+00:00 304 1.2.3.4 \"GET /feed/ HTTP/2.0\" 0 \"-\" \"Newsboat/r2.35 (Linux x86_64)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-14T09:07:39+00:00 304 1.2.3.4 \"GET /feed/ HTTP/2.0\" 0 \"-\" \"Newsboat/r2.35 (Linux x86_64)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-14T09:07:40+00:00 429 1.2.3.4 \"GET /feed/ HTTP/2.0\" 74 \"-\" \"Newsboat/r2.35 (Linux x86_64)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 .\n\nThese requests were interesting, as a 304 was reported for the first four,\nthen followed by a 429 error. The HTTP 304 status means that content was most\nlikely not modified compared with the copy that the client has. This is done\nby comparing the last-modified header. So bonus points for implementing this,\nas this saves a lot of unneeded data traffic. With zero bytes being sent, that\nis a perfect outcome. At the same time, we see that multiple requests are made\nin the same second. So in the end, the client and web server are still\nprocessing useless requests. When the rate-limit kicks in, a 429 status is\nreturned and the conversion stops. That is, until the next set of requests.\n\n#### Status: issue acknowledged\n\nActions:\n\n  * Created issue\n  * Issue acknowledged\n\nThe issue was reported and one of the developers quickly picked it up.\nAwesome! This one needs to be monitored and hopefully next release will no\nlonger be responsible for unneeded requests.\n\n### Selfoss: Not supporting data compression\n\nThe next one is Selfoss. We have seen it showing up in the logs and nothing\nspecial so far. Until we toggled the switch to disallow requests that don\u2019t\nsupport compression (accept-encoding header).\n\n    \n    \n    2024-04-13T10:05:26+00:00 426 1.2.3.4 \"GET /atom.xml HTTP/1.1\" 16 \"https://linux-audit.com/atom.xml\" \"Selfoss/2.19 (+https://selfoss.aditu.de)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-13T12:02:24+00:00 426 2.3.4.5 \"GET /feed/ HTTP/1.1\" 16 \"https://linux-audit.com/feed/\" \"Selfoss/2.19 (+https://selfoss.aditu.de)\" TLSv1.2/ECDHE-ECDSA-AES256-GCM-SHA384 0.000 .\n\nSo here we have two different clients, about two hours apart from each other.\nOne uses the /atom.xml link, the other the alias /feed/. Same file, different\npath. Both clients use a different set of TLS protocol and ciphers, so I\nassume that has to do with the underlying operating system and libraries. The\nSelfoss software itself looks to be the same when looking at the version\nnumber. The used HTTP protocol is also the same. Maybe the HTTP/1.1 is\nsomewhat outdated, but that\u2019s fine.\n\nThe interesting part in this case is that the requests both got blocked. This\ncan be seen as we returned a 426 message, telling the client to upgrade. As it\nis not due to the HTTP protocol version, it is related to the lack of\ncompression support. For modern software this is somewhat surprising. Well,\nthat\u2019s a shame, as this in conflict with our stance that we want clients to\nsupport compressed data transfers.\n\n#### Status: issue acknowledged\n\nActions:\n\n  * Open an issue on GitHub\n  * Project implemented changes to improve this, including upstream to the Guzzle (PHP HTTP client)\n\nWith the actions taken by the project, most likely this issue will be resolved\nin the upcoming update!\n\n### Feedbin: Sometimes supporting date compression?\n\nLike the example with Selfoss, we came also across clients that behave\ndifferently per request.\n\n    \n    \n    2024-04-13T12:06:35+00:00 200 1.2.3.4 \"GET /feed/ HTTP/1.1\" 17863 \"-\" \"Feedbin feed-id:MASKED - MASKED subscribers\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-13T12:06:36+00:00 426 1.2.3.4 \"GET /web/nginx-log-only-some-requests/ HTTP/1.1\" 16 \"-\" \"Down/5.4.1\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 .\n\nIn this example we see that the RSS feed is pulled in. A second later, the\nlatest blog post is retrieved. It came from the same IP address, but with a\ndifferent user agent. The HTTP protocol, TLS protocols, and ciphers, all the\nsame. So probably different components are at work. One that tracks RSS feeds,\nwhile the other pulls in the data related to the article? Not sure what it is\nand this needs more research.\n\n#### Status: more research needed\n\nActions:\n\n  * None so far, need more samples\n\n### Tiny Tiny RSS: Not supporting data compression\n\n2024-04-13T13:18:56+00:00 426 5.51.85.65 \u201cGET / HTTP/1.1\u201d 16 \u201c-\u201d \u201cTiny Tiny\nRSS/24.03-435c321c (https://tt-rss.org/)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000\n.\n\nAfter looking in the code, it seems that Tiny Tiny RSS is using Guzzle as its\nHTTP client. But wait, that is the same component as in Selfoss. So it might\nbe possible that without any changes to Tiny Tiny RSS, it will inherit the\nchanges.\n\n#### Status: probably fixed soon\n\nActions:\n\n  * None, monitoring future releases\n\n### Miniflux: supporting Gzip, but not Brotli (yet)\n\nIn the log we also discovered different file sizes for the feed. Example of a\nfew requests:\n\n    \n    \n    2024-04-13T13:30:02+00:00 200 1.2.3.4 \"GET /feed/ HTTP/1.1\" 17183 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 . 2024-04-13T13:31:22+00:00 200 2.3.4.5 \"GET /feed/ HTTP/2.0\" 20621 \"-\" \"Mozilla/5.0 (compatible; Miniflux/2.1.2; +https://miniflux.app)\" TLSv1.3/TLS_AES_256_GCM_SHA384 0.000 .\n\nThe first request looks to be a normal browser, while the second one is\nanother RSS reader named Miniflux. It already uses compression, but it needed\nmore data traffic to receive the same file. When we look at the disk, we can\nsee the related values for the feed (at that very moment, it changes daily).\n\n    \n    \n    -rw-r--r-- 1 www-data www-data 72474 Apr 13 13:18 atom.xml -rw-r--r-- 1 www-data www-data 17183 Apr 13 13:18 atom.xml.br -rw-r--r-- 1 www-data www-data 20621 Apr 13 13:18 atom.xml.gz\n\nThis RSS reader is already a good job. It uses a modern HTTP protocol version\nand has data encoding implemented. BY using a different compression method, it\ncould save (in this case) 3438 bytes. That doesn\u2019t sound like a lot, but we\nlimited the number of entries in our feed. There are many more feeds that are\nmuch bigger in size and then the differences add up.\n\nActions:\n\n  * Opened a feature request\n\nIn this case a feature request was opened. Let\u2019s see if they are interested in\nadding protocol support for Brotli.\n\n## Conclusion\n\nWhile most RSS feed readers seem to continue to work properly after adjusting\nour web server configuration, a few unexpected issues came up. So far,\nmultiple open source projects used these insights to improve and made changes\nright away.\n\n## What\u2019s next?\n\nIn the upcoming months we will continue to monitor our log and specifically\nlook at the RSS feed. Hopefully more clients can be upgraded to use modern\nprotocols, content encoding, and reduce the number of requests by using the\nLast-Modified header. When we receive updates, this blog post will be updated.\n\n## Tips for a better RSS community\n\n### Developers of RSS readers\n\n  * Implement the usage of the headers If-Modified-Since or If-Unmodified-Since to leverage the Last-Modified status\n  * Use data encoding methods to reduce the file size that needs to be sent\n\n### Publishers of RSS feeds\n\n  * Reduce the number of entries in the feed. More is not always better.\n  * Compress your feeds with different methods (e.g. Gzip and Brotli)\n  * Ensure that a Last-Modified header is available\n\n### Tips for users of RSS feeds\n\nIf you want to be a good net citizen, reduce the time that you refresh your\nfeeds. Is it really needed to request them multiple times a day? Consider\nrefreshing the ones that are not updated daily with a lower interval. Also\ncheck if your RSS reader is up-to-date.\n\n## Feedback?\n\nGot something to share based on the results that we saw recently? Let it know!\n\n## Webserver hardening\n\nWant to secure your web server and websites even further? Perform a system\naudit with Lynis, including a configuration test of Apache, nginx, and others.\n\nLynis is a battle-tested technical security audit tool. It is open source,\nfreely available, and used by system administrators all over the world. Other\nusers include IT auditors, security professionals, like pentesters.\n\n### Tool Information\n\n  * Initial release: 2007\n  * Cost: Free\n  * License: GPLv3\n  * Links\n\n    * GitHub\n    * Packages (deb/rpm)\n    * Tarball\n\nVisit project page\n\n## Questions or discovered a possible improvement?\n\nSee the contact page for details. All feedback is very welcome.\n\n## Page details and related articles\n\n\u25c4 Previous article: Sustainable Web Design\n\n### Similar articles\n\n  * How to become a Linux security expert?\n  * The Most Influential Linux Security Blogs\n  * How to log only some requests to a log file in nginx\n  * Making scripts (more) secure and safe\n  * Pre-compress static assets with Brotli and Gzip\n\n### Page information\n\nThis article has a word count of 1799 and last changed or reviewed at\n2024-04-14.\n\n### Topics\n\n  * Software\n  * Web\n\nPrivacy first, no tracking, no cookies!\n\nOur green initiative: Sustainable Web Design\n\nUseful links\n\nRSS Atom feed or JSON Feed\n\nEverything related to Linux security and maintaining Linux systems.\n\nContact\n\n", "frontpage": false}
