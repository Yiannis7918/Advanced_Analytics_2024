{"aid": "40015575", "title": "SDMetrics: Library for evaluating synthetic data quality", "url": "https://github.com/sdv-dev/SDMetrics", "domain": "github.com/sdv-dev", "votes": 2, "user": "skadamat", "posted_at": "2024-04-12 17:44:19", "comments": 0, "source_title": "GitHub - sdv-dev/SDMetrics: Metrics to evaluate quality and efficacy of synthetic datasets.", "source_text": "GitHub - sdv-dev/SDMetrics: Metrics to evaluate quality and efficacy of\nsynthetic datasets.\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\nsdv-dev / SDMetrics Public\n\n  * Notifications\n  * Fork 43\n  * Star 188\n\nMetrics to evaluate quality and efficacy of synthetic datasets.\n\n### License\n\nMIT license\n\n188 stars 43 forks Branches Tags Activity\n\nStar\n\nNotifications\n\n# sdv-dev/SDMetrics\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n13 Branches\n\n33 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\nsdv-teamandamontanez24Latest Code Analysis (#563)0351fa6 \u00b7\n\n## History\n\n535 Commits  \n  \n### .github\n\n|\n\n### .github\n\n| Add bandit workflow (#556)  \n  \n### conda\n\n|\n\n### conda\n\n| Bump version: 0.14.0 \u2192 0.14.1.dev0  \n  \n### docs/images\n\n|\n\n### docs/images\n\n| Update readme (#231)  \n  \n### resources\n\n|\n\n### resources\n\n| v0.1.0 (#32)  \n  \n### sdmetrics\n\n|\n\n### sdmetrics\n\n| Bump version: 0.14.0 \u2192 0.14.1.dev0  \n  \n### tests\n\n|\n\n### tests\n\n| Update pandas and scikit-learn versions (#562)  \n  \n### .editorconfig\n\n|\n\n### .editorconfig\n\n| Project scaffolding  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Initial code cleanup / refactor. (#1)  \n  \n### AUTHORS.rst\n\n|\n\n### AUTHORS.rst\n\n| Add release notes for v0.0.1  \n  \n### CONTRIBUTING.rst\n\n|\n\n### CONTRIBUTING.rst\n\n| Migrate to pyproject.toml (#537)  \n  \n### HISTORY.md\n\n|\n\n### HISTORY.md\n\n| 0.14.0 Release Notes (#560)  \n  \n### INSTALL.md\n\n|\n\n### INSTALL.md\n\n| Add Python 3.12 support (#550)  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Project scaffolding  \n  \n### Makefile\n\n|\n\n### Makefile\n\n| Update pandas and scikit-learn versions (#562)  \n  \n### README.md\n\n|\n\n### README.md\n\n| Switch default branch from master to main (#454)  \n  \n### RELEASE.md\n\n|\n\n### RELEASE.md\n\n| Switch default branch from master to main (#454)  \n  \n### latest_requirements.txt\n\n|\n\n### latest_requirements.txt\n\n| Automated Latest Dependency Updates (#561)  \n  \n### pyproject.toml\n\n|\n\n### pyproject.toml\n\n| Bump version: 0.14.0 \u2192 0.14.1.dev0  \n  \n### setup.cfg\n\n|\n\n### setup.cfg\n\n| Update pandas and scikit-learn versions (#562)  \n  \n### static_code_analysis.txt\n\n|\n\n### static_code_analysis.txt\n\n| Latest Code Analysis (#563)  \n  \n### tasks.py\n\n|\n\n### tasks.py\n\n| Update pandas and scikit-learn versions (#562)  \n  \n### tox.ini\n\n|\n\n### tox.ini\n\n| Add Python 3.12 support (#550)  \n  \n## Repository files navigation\n\nThis repository is part of The Synthetic Data Vault Project, a project from\nDataCebo.\n\n# Overview\n\nThe SDMetrics library evaluates synthetic data by comparing it to the real\ndata that you're trying to mimic. It includes a variety of metrics to capture\ndifferent aspects of the data, for example quality and privacy. It also\nincludes reports that you can run to generate insights, visualize data and\nshare with your team.\n\nThe SDMetrics library is model-agnostic, meaning you can use any synthetic\ndata. The library does not need to know how you created the data.\n\n# Install\n\nInstall SDMetrics using pip or conda. We recommend using a virtual environment\nto avoid conflicts with other software on your device.\n\n    \n    \n    pip install sdmetrics\n    \n    \n    conda install -c conda-forge sdmetrics\n\nFor more information about using SDMetrics, visit the SDMetrics Documentation.\n\n# Usage\n\nGet started with SDMetrics Reports using some demo data,\n\n    \n    \n    from sdmetrics import load_demo from sdmetrics.reports.single_table import QualityReport real_data, synthetic_data, metadata = load_demo(modality='single_table') my_report = QualityReport() my_report.generate(real_data, synthetic_data, metadata)\n    \n    \n    Creating report: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00, 5.22it/s] Overall Quality Score: 82.84% Properties: Column Shapes: 82.78% Column Pair Trends: 82.9%\n\nOnce you generate the report, you can drill down on the details and visualize\nthe results.\n\n    \n    \n    my_report.get_visualization(property_name='Column Pair Trends')\n\nSave the report and share it with your team.\n\n    \n    \n    my_report.save(filepath='demo_data_quality_report.pkl') # load it at any point in the future my_report = QualityReport.load(filepath='demo_data_quality_report.pkl')\n\nWant more metrics? You can also manually apply any of the metrics in this\nlibrary to your data.\n\n    \n    \n    # calculate whether the synthetic data respects the min/max bounds # set by the real data from sdmetrics.single_column import BoundaryAdherence BoundaryAdherence.compute( real_data['start_date'], synthetic_data['start_date'] )\n    \n    \n    0.8503937007874016\n    \n    \n    # calculate whether the synthetic data is new or whether it's an exact copy of the real data from sdmetrics.single_table import NewRowSynthesis NewRowSynthesis.compute( real_data, synthetic_data, metadata )\n    \n    \n    1.0\n\n# What's next?\n\nTo learn more about the reports and metrics, visit the SDMetrics\nDocumentation.\n\nThe Synthetic Data Vault Project was first created at MIT's Data to AI Lab in\n2016. After 4 years of research and traction with enterprise, we created\nDataCebo in 2020 with the goal of growing the project. Today, DataCebo is the\nproud developer of SDV, the largest ecosystem for synthetic data generation &\nevaluation. It is home to multiple libraries that support synthetic data,\nincluding:\n\n  * \ud83d\udd04 Data discovery & transformation. Reverse the transforms to reproduce realistic data.\n  * \ud83e\udde0 Multiple machine learning models -- ranging from Copulas to Deep Learning -- to create tabular, multi table and time series data.\n  * \ud83d\udcca Measuring quality and privacy of synthetic data, and comparing different synthetic data generation models.\n\nGet started using the SDV package -- a fully integrated solution and your one-\nstop shop for synthetic data. Or, use the standalone libraries for specific\nneeds.\n\n## About\n\nMetrics to evaluate quality and efficacy of synthetic datasets.\n\n### Topics\n\nquality metrics synthetic-data\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\nCustom properties\n\n### Stars\n\n188 stars\n\n### Watchers\n\n13 watching\n\n### Forks\n\n43 forks\n\nReport repository\n\n## Releases 32\n\nv0.14.0 - 2024-04-11 Latest\n\nApr 11, 2024\n\n\\+ 31 releases\n\n## Packages 0\n\nNo packages published\n\n## Used by 216\n\n\\+ 208\n\n## Contributors 15\n\n## Languages\n\n  * Python 99.2%\n  * Makefile 0.8%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
