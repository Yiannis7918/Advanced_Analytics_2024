{"aid": "40090151", "title": "AI Product Management", "url": "https://www.svpg.com/ai-product-management/", "domain": "svpg.com", "votes": 1, "user": "kiyanwang", "posted_at": "2024-04-19 18:09:48", "comments": 0, "source_title": "AI Product Management - Silicon Valley Product Group", "source_text": "AI Product Management - Silicon Valley Product Group : Silicon Valley Product\nGroup\n\nSVPG stores cookies to improve our website, and for analytics and metrics\nabout our visitors. We never sell your information. Please see our Privacy\nPolicy for more information.\n\nNEW - June SVPG Product Masterclass - Early Bird Registration Available Here\n\nback to all articles\n\nProduct Management April 16, 2024 Marty Cagan\n\n  * share:\n  * Share on Twitter\n  * Share on LinkedIn\n  * Share via Email\n  * Copy the Link\n\n# AI Product Management\n\nBy Marty Cagan and Marily Nika\n\nRecently I have co-authored a few articles allowing me to highlight different\nproduct coaches, and in this article, I\u2019d like to highlight Marily Nika.\nMarily specializes in helping product teams create AI-powered products and\nservices. She has a PhD in machine learning, and has had an impressive career\nbuilding AI products at both Meta and Google, and she runs a popular course\nteaching product managers what they need to know to build effective AI-powered\nproducts.\n\nIn an earlier article, I wrote about how we can expect AI to impact product\nteams in general, and the product management role in particular (and Marily\nserved as an expert reviewer in that article). In this article, we discuss the\nproducts that these teams build.\n\nSo to be clear on nomenclature, when we refer to \u201cAI Product Management\u201d we\nare referring to the creation of AI-powered products. In very much the same\nway as \u201cMobile Product Management\u201d refers to creation of mobile products. And\njust as how \u201cMobile PM\u201d was an especially in-demand skill when mobile was new,\nand now most PM\u2019s are expected to have the skills to develop products for\nmobile, we expect the same to become true for AI Product Managers. In a few\nyear\u2019s time, we expect most PM\u2019s will need to be skilled at building AI-\npowered products and services.\n\n## Infrastructure vs Applications\n\nAnother important distinction is to clarify that we are focusing here on AI-\npowered applications, and not on the underlying AI infrastructure, which\ninvolves the model training process itself.\n\nThe distinction is similar to the difference between a platform product and an\nexperience product. The platform product enables the experience products. Both\ntypes of products are interesting and important, but the vast majority of AI\nproduct managers will be responsible for experience products \u2013 the\napplications \u2013 so that\u2019s what we\u2019ll focus on here.\n\n## The Nature of AI-Powered Products\n\nMost products have significant risks, and product teams are cross-functional\nso that they have the range of skills needed to address those risks. Few\nproducts highlight the critical need for strong product management more than\nAI-powered products.\n\nBy \u201cAI-powered products,\u201d we mean products that utilize AI technologies to\ncreate experiences that solve problems for our customers or our company.\n\nThe term \u201c\u2019AI\u201d includes both traditional AI, such as machine learning, and\ngenerative AI. These technologies enable a wide range of capabilities,\nincluding smart suggestions, personalized experiences, or matching two sides\nof a marketplace.\n\nExamples of AI applications include smart home devices that employ speech and\nnatural language understanding to process human voices, fraud detection\nsystems, and, in the case of generative AI, advanced functions like content\ncreation, summarization, and synthesis.\n\nAI-powered products are especially challenging when it comes to the product\nrisks.\n\nAnd this means that the product manager, the product designer, and the tech\nlead will need to collaborate closely to come up with effective solutions.\n\nNote that while AI product managers may not have ML scientists as dedicated\nmembers of their core product team, especially in the context of AI\napplication products, they will frequently want to consult with ML scientists.\nThis collaboration can be crucial for leveraging underlying AI technologies\neffectively.\n\nThis article tries to make clear the reasons why AI-powered products can be\nespecially challenging.\n\n## Feasibility Risk\n\nGenerative AI, by its nature, is probabilistic, not deterministic. For\nconventional solutions, we can generally count on the fact that if a program\nis given the same inputs, it will generate a consistent output.\n\nFor generative AI powered solutions, there can be literally billions of\ninputs, and weightings can change as a result of learning, potentially\nresulting in different outputs over time.\n\nCertain types of products and capabilities are very well suited to\nprobabilistic solutions, and others are not. This is perhaps the most\nfundamental consideration.\n\nIf the product is a personalized news feed, then if, on occasion, a\nrecommendation is not perfectly aligned with the user\u2019s stated preferences,\nthis can likely be managed in the user experience.\n\nHowever, if the product is controlling a dose of medication, such as insulin,\nthen a dosage outside of medical guidelines would be unacceptable.\n\nSo it\u2019s critical that the AI product manager ensures that the technology is a\ngood match for the specific product or solution.\n\nThis leads directly to the critical topic of quality assurance. What are\nacceptable error rates? What are the possible types of mistakes? How will the\nproduct handle each type of mistake? Are there ways to mitigate mistakes with\nthe user experience?\n\nSpeaking of mistakes, much of the time the focus will be on the training data.\nThe quality of the data used to train the AI model is critical. Product\nmanagers need to have a clear and deep understanding of the training data, and\nhow the model has been trained and tuned.\n\nAll large data sets have potential biases and limitations. The ethical\nimplications of biases in the data are discussed in viability risk below, but\nthe AI product manager needs to be on top of these issues, and understand how\nthe issues may manifest in the final product.\n\nMore generally, for many AI powered product efforts today, the major stumbling\nblock is the training data itself. There may not yet be sufficient volume or\nquality of training data to power a feasible commercial product.\n\nWhen it comes to feasibility, the AI product manager will need to work closely\nwith the tech lead, and possibly consult with an ML scientist if your company\nhas one, to determine the most appropriate trade-offs.\n\nFor example, a highly accurate model might require larger investments in\ntraining data, significant processing power and time, and computational\nresources, impacting the user experience, the scalability and the cost.\n\nIt is also important to mention technical debt and infrastructure and address\nquestions such as: Does the company have the necessary technical\ninfrastructure to support the AI product? Consider factors like data storage,\nprocessing power, and ongoing maintenance costs. High technical debt can\nhinder scalability, and overall feasibility and viability.\n\n## Usability Risk\n\nThe customer experience is important for any product, but with AI, it takes on\na new level of importance and complexity.\n\nFor AI products, we need to design user experiences that clearly set\nexpectations about what the technology can and can\u2019t do, and at least\nconceptually, how the product works. This transparency is key to building\ntrust and avoiding frustration when encountering limitations.\n\nTraditionally, product managers lean heavily on the product designers in terms\nof building user trust. However, AI introduces an additional layer of\nconstraints and complexities, many of which are coming from the product\nmanager.\n\nWe need users and customers to feel comfortable with how their data is used,\nand what the AI\u2019s capabilities are. This can mean new types of user\ninteractions.\n\nThe product designer will need to work hand in glove with the AI product\nmanager to ensure that AI-powered experiences are easy to learn, use,\nunderstand and trust.\n\nFurthermore, in many cases, explaining the \u201cwhy\u201d behind the AI\u2019s decisions and\nbehaviors can become essential in certain applications. This transparency\nbuilds trust, and helps users build confidence in their interactions with the\nproduct. What is the level of explainability needed to generate the necessary\ntrust?\n\nAs with assessing feasibility, the AI product manager will need to collaborate\nclosely with the product designer to analyze the trade-offs that can impact\nthe user experience. For example, a highly accurate AI recommendation system\nmight take longer to produce results, leading to user frustration. Similarly,\na simpler AI model designed for faster processing might struggle with complex\nuser interactions, or less accuracy.\n\nFinding the right balance between accuracy, speed, operational cost, and user\nexperience is essential.\n\n## Value Risk\n\nValue is always a critical risk. AI-powered products hold the promise of\nsignificant value, which is why so much of the world is rushing towards\napplying this technology.\n\nBut we can also see many examples today of AI-products that are AI in name\nonly. So the AI product manager\u2019s first responsibility is ensuring that the\nAI-powered features and products deliver genuine, incremental value to users\nand customers.\n\nThis means solving real problems in ways that are demonstrably better than\nexisting solutions, or even solving problems that otherwise wouldn\u2019t be\npossible without the new enabling AI technologies.\n\nWe want to avoid the temptation to implement AI solely for the sake of\nmarketing or competitive parity. Our job is to ensure the perceived value is\nclear and compelling.\n\nAs with most complex product capabilities, we want to use our range of tools\nto evaluate value. Normally this means combining quantitative evidence (e.g.\nA/B testing) with qualitative insights (e.g. user testing).\n\nWe also need to collaborate closely with product marketing to ensure we can\ncommunicate this value effectively. While on the subject of product marketing,\nbelow we discuss important viability work around user privacy and ethical data\nusage, and we want to be sure that, if appropriate, we message these points\nclearly and effectively as well.\n\n## Viability Risk\n\nWhile AI holds immense potential especially in terms of providing real value\nto users and customers, the business viability challenges are often\nsubstantial, and mistakes and oversights regarding viability risk tend to\ndominate today\u2019s news headlines.\n\nFor any product, we need to ensure that the product is something that can be\neffectively marketed, sold, serviced, funded, monetized, and is legal and\ncompliant with any relevant regulatory constraints.\n\nBut for AI products, these viability risks can be especially important and\nchallenging.\n\nIt is still very early in terms of the unit economics of AI-powered products,\nbut today the costs can be quite high.\n\nFurther, for several types of products, there are genuine questions about data\nprovenance and copyright for the training data, biases in that data, and the\nramifications of recommendations based on this data.\n\nMore generally, companies are still working to understand the legal\nresponsibilities and implications of providing probabilistic solutions to\ncustomers.\n\nLast but not least, ethical considerations are an ongoing and growing concern.\nThis goes beyond potential biases in the training data. If users misunderstand\na result, or the model hallucinates in a way that creates a danger, what are\nthe legal and ethical ramifications?\n\nRealize that with probabilistic solutions, it is very possible for an AI-\npowered system to both save lives (by performing a critical task more\naccurately than humans), yet also put lives in danger (by making a mistake).\nCompanies today must deal proactively with these ethical considerations.\n\nSimilarly, the AI product manager must strive to anticipate the consequences\nof bad actors, using the products in illegal or inappropriate ways. An\nimportant part of business viability is protecting the assets and reputation\nof the company. There may also be societal or environmental impacts, depending\non the application. The AI product manager is expected to consider and analyze\nthese risks, and work with the company\u2019s legal team to protect customers as\nwell as the company.\n\nAnd to be clear, these critical viability risk questions fall squarely on the\nshoulders of the AI product manager.\n\n## Summary\n\nHopefully this note makes clear how the product risks are impacted with AI\nproducts, and how the AI product manager likely has only more responsibility\nand obligations to deal with the uncertainties.\n\nThe successful AI product manager will require deep knowledge of the users and\ncustomers, the data, the business, and the market in order to perform the\ndifficult role that\u2019s required. Moreover, AI literacy is yet another example\nof the reason why product managers need a strong foundation in technology.\n\nAs with mobile PM, over time our expectation is that all PM\u2019s will need to\nhave at least a foundation level of these skills. Most product managers will\nbe expected to be AI product managers in the future, in the sense that it will\nbe expected that product managers understand how the enabling AI technology\nworks, what are the range of risks involved, and the work required to mitigate\nthe risks.\n\nMarty Cagan\n\nFounder, Partner - Product at SVPG\n\nLearn more by attending our next workshop.\n\n  * share:\n  * Share on Twitter\n  * Share on LinkedIn\n  * Share via Email\n  * Copy the Link\n\n## featured content\n\nProduct Management January 30, 2024 Marty Cagan\n\n## Product Management Theater\n\nFair warning that for many of you, this article is going to feel like a heavy\ndose of tough love....\n\narticle\n\nread more\n\nProduct Management December 19, 2023 Marty Cagan\n\n## Product Predictions 2024\n\nRecently I was invited by Productboard to give a talk on the topic of what\n2024 might have in store...\n\narticle\n\nread more\n\nProduct Management June 21, 2023 Marty Cagan\n\n## Pledge To Stakeholders\n\nNote: As a company moves from stakeholder-driven feature teams to empowered\nproduct teams, there are some fairly significant changes to...\n\narticle\n\nread more\n\ndiscover more articles\n\n###### subscribe to newsletter\n\n###### contact\n\nEmail: info@svpg.com\n\nPrivacy Policy\n\n\u00a9 2024 SVPG. All Rights Reserved.\n\n", "frontpage": false}
