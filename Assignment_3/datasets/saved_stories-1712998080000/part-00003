{"aid": "40017514", "title": "Invisibility Cloak", "url": "https://www.cs.umd.edu/~tomg/projects/invisible/", "domain": "umd.edu", "votes": 6, "user": "chippy", "posted_at": "2024-04-12 20:51:11", "comments": 0, "source_title": "Invisibility cloak", "source_text": "Invisibility cloak\n\nInvisibility cloak - go to homepage\n\n  * Home\n  * Research\n  * Publications\n  * Group\n  * Teaching\n  * Contact\n\n# Invisibility cloak\n\n### Overview\n\nThis paper studies the art and science of creating adversarial attacks on\nobject detectors. Most work on real-world adversarial attacks has focused on\nclassifiers, which assign a holistic label to an entire image, rather than\ndetectors which localize objects within an image. Detectors work by\nconsidering thousands of \u201cpriors\u201d (potential bounding boxes) within the image\nwith different locations, sizes, and aspect ratios. To fool an object\ndetector, an adversarial example must fool every prior in the image, which is\nmuch more difficult than fooling the single output of a classifier.\n\nIn this work, we present a systematic study of adversarial attacks on state-\nof-the-art object detection frameworks. Using standard detection datasets, we\ntrain patterns that suppress the objectness scores produced by a range of\ncommonly used detectors, and ensembles of detectors. Our ultimate goal is to\nbuild a wearable \u201cinvisibility\u201d cloak that renders the wearer imperceptible to\ndetectors.\n\n> Making an Invisibility Cloak: Real World Adversarial Attacks on Object\n> Detectors\n\nThis stylish pullover is a great way to stay warm this winter, whether in the\noffice or on-the-go. It features a stay-dry microfleece lining, a modern fit,\nand adversarial patterns the evade most common object detectors. In this\ndemonstration, the YOLOv2 detector is evaded using a pattern trained on the\nCOCO dataset with a carefully constructed objective.\n\n### Video Demo\n\nWhile a full-scale demo had been delayed due to COVID, here\u2019s a short\ncomposite of some of our test footage.\n\n### Approach\n\nWe load images from the COCO detection dataset, and pass them through a\ndetector. When a person is detected, and pattern is rendered over that person\nwith random perspective, brightness, and contrast deformations. A gradient\ndescent algorithm is then used to find the pattern that minimizes the\n\u201cobjectness scores\u201d (confidence in the presence of an object) for every object\nprior.\n\n### Gallery\n\n### Thanks\n\nThanks to Facebook AI for their support on this project!\n\n### Search\n\n### Categories\n\n  * adversarial-learning (5)\n  * audio (1)\n  * image-processing (1)\n  * machine-learning (13)\n  * medical-imaging (1)\n  * optimization (8)\n  * recurrance (1)\n  * thinking (1)\n\nWeb Accessibility\n\nCopyright (c) 2015 - 2018, Tom Goldstein.\n\n#### Recent projects\n\n##### Deep Thinking\n\n##### Sonification\n\n##### Invisibility cloak\n\n#### Contact\n\nTom Goldstein Iribe Center Department of Computer Science Office 4212 College\nPark, MD 20742\n\nGo to contact page\n\n", "frontpage": true}
