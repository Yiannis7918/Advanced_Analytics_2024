{"aid": "40034680", "title": "Evidence that LLMs are reaching a point of diminishing returns", "url": "https://garymarcus.substack.com/p/evidence-that-llms-are-reaching-a", "domain": "garymarcus.substack.com", "votes": 22, "user": "simonebrunozzi", "posted_at": "2024-04-14 21:33:30", "comments": 20, "source_title": "Evidence that LLMs are reaching a point of diminishing returns - and what that might mean", "source_text": "Evidence that LLMs are reaching a point of diminishing returns - and what that\nmight mean\n\n# Marcus on AI\n\nShare this post\n\n#### Evidence that LLMs are reaching a point of diminishing returns \u2014 and what\nthat might mean\n\ngarymarcus.substack.com\n\n#### Discover more from Marcus on AI\n\n\u201cAmongst the myriad of opinions, one voice stands out as a rational and\nimpartial advocate: Gary Marcus.\u201d \u2014Candice Clark\n\nOver 36,000 subscribers\n\nContinue reading\n\nSign in\n\n# Evidence that LLMs are reaching a point of diminishing returns \u2014 and what\nthat might mean\n\n### A lot could change quickly, if we are approaching a plateau\n\nGary Marcus\n\nApr 13, 2024\n\n86\n\nShare this post\n\n#### Evidence that LLMs are reaching a point of diminishing returns \u2014 and what\nthat might mean\n\ngarymarcus.substack.com\n\n27\n\nShare\n\nThe conventional wisdom, well captured recently by Ethan Mollick, is that LLMs\nare advancing exponentially. A few days ago, in a popular blog post, Mollick\nclaimed that \u201cthe current best estimates of the rate of improvement in Large\nLanguage Models show capabilities doubling every 5 to 14 months\u201d:\n\nThe study Mollick linked to doesn\u2019t actually show what he claims. If you read\nit carefully, it says literally nothing about capabilities improving. It shows\nthat models are getting more efficient in terms of the computational resources\nthey require to get to given level of performance, \u201cthe level of compute\nneeded to achieve a given level of performance has halved roughly every 8\nmonths, with a 95% confidence interval of 5 to 14 months.\u201d But (a) past\nperformance doesn\u2019t always predict future performance, and (b) most of the\ndata in the study are old, none from this year.\n\nAnd here\u2019s the thing \u2013 we all know that GPT-3 was vastly better than GPT-2.\nAnd we all know that GPT-4 (released thirteen months ago) was vastly better\nthan GPT-3. But what has happened since?\n\nI could be persuaded that on some measures there was a doubling of\ncapabilities for some set of months in 2020-2023, but I don\u2019t see that case at\nall for the last 13 months.\n\nInstead, I see numerous signs that we have reached a period of diminishing\nreturns.\n\n\u00a7\n\nWhat really got me to thinking about all this was a graph from OpenAI a couple\ndays ago, touting their latest model, GPT 4 Turbo, which I have always\nsuspected was a failed attempt at GPT-5. Looks good - progress! but look\nclosely.\n\nWhat it actually shows is some improvements, mostly modest, over the last few\nmonths for a bunch of different measures. It also totally tripped off my\nspidey sense.\n\nWhat I immediately didn\u2019t like about this graph is that it arbitrarily showed\ntwo very recent models, and none of the history before. So yes, on some\nmeasures there was progress, but what we really need to see is growth over a\nlonger period. That set me to thinking. And plotting. For a lot of measures, I\ncouldn\u2019t find any data on GPT-2 or 3 at at all, or even sometimes for GPT-4.\n(On some new measures both GPT-2 and GPT-3 would effectively be at zero.) But\nfor a common benchmark, called MMLU, I was able to find historical data for\nGPT-2, GPT-3, and GPT-4 (but not GPT 3.5).\n\nHere\u2019s what I found (y- axis is percent accuracy):\n\nHuge jump from GPT-2 to GPT-3. Huge jump from GPT-3 to GPT-4 ... and not so\nmuch for GPT-4 (13 months ago) to GPT-4 Turbo (just released). It\u2019s hard not\nto see this plot as tentative evidence for the hypothesis of diminishing\nreturns. Whatever doubling there might have been, has perhaps come to an end.\n\nOf course, there\u2019s a problem here: when you get near the top of a graph, you\nhave something statisticians call \u201crestriction of range\u201d. You can\u2019t go from 85\nto 115 on MMLU; 100% is the maximum possible score. And a lot of benchmarks\nare fiddly and imperfect. A score of 100 might actually be suspicious, because\nit might suggest that the model in question had simply memorized the data.\nMaybe the real practical ceiling is 95%.\n\nMy gut sense is that we haven\u2019t reached the real ceiling on MMLU yet, and that\nthis is a genuine sign of diminishing returns. But ok, let\u2019s look around for\nanother measure.\n\nSomeone on X pointed me to The New York Times Connections game. Bright humans\ncan probably get something like 90%+ on any given data, but current models\naren\u2019t close. So here, there is no restriction of range problem. And thanks to\nLech Mazur, I was able to find data across a reasonably wide range of\nhistorical models, though not back to GPT-2 or GPT-3. But enough to get some\nidea what might be going on:\n\nA big leap from GPT 3.5 Turbo to 4, but (once again) a modest leap from GPT-4\nto two different versions of GPT-4 Turbo. Restriction of range is not the\nissue, yet again we see signs of diminishing returns.\n\nIf two graphs I plotted are remotely correct, Mollick\u2019s claim that \u201cthe rate\nof improvement in Large Language models show capabilities doubling every 5 to\n14 months\u201d is no longer holding true.\n\nThe wall that I once warned about, in 2022, may finally be approaching.\n\nOne more way to look at this, is this graph I just saw: enormous convergence\non GPT-4 level performance, in multiple models released since, yet nothing\ndecisively ahead.\n\n\u00a7\n\nWhat about qualitative data? In many ways the qualitative data are looking the\nsame. One way to think about is to ask whether any of the problems I warned\nabout in 2022 (such as hallucinations and stupid errors) have been solved.\n\nI think it\u2019s fair to say that they have not. GPT-Turbo released this week\nstill produces its share of groaners, like this interchange Phil Libin just\nsent:\n\nOne of the most striking things I read this week was in The Information. Word\nhas gotten out, and the problems clearly have not been solved:\n\nAnother way to think about this (see third graph above) is that there about 5\n- 7 recent models are on a par with GPT-4, but none is clearly and decisively\nahead.\n\nAnd of course advancing on benchmarks isn\u2019t itself enough anyway; few\nbenchmarks capture the complexity of the real world. Even if LLMs could max\nout on all existing benchmark, we might still have a long way to go.\n\n\u00a7\n\nIf we really have changed regimes, from rapid progress to diminishing returns,\nand hallucinations and stupid errors do linger, LLMs may never be ready for\nprime time.\n\nInstead, as I warned in August, we may well be in for a correction. In the\nmost extreme case, OpenAI\u2019s $86 billion valuation could look in hindsight like\na WeWork moment for AI.\n\nAlready in recent weeks, Inflection AI largely closed shop, Stability AI is\nstruggling, and LLM-based autonomous vehicle company called Ghost closed shop,\nand a software engineer on YouTube raised quite serious questions about the\nwildly-hyped AI coding system Devin.\n\nIf enthusiasm for GenAI dwindles and market valuations plummet, AI won\u2019t\ndisappear, and LLMs won\u2019t disappear; they will still have their place as tools\nfor statistical approximation.\n\nBut that place may be smaller; it is entirely possible that LLMs on their own\nwill never live up to last year\u2019s wild expectations.\n\nReliable, trustworthy AI is surely achievable, but we may need to go back to\nthe drawing board to get there.\n\nGary Marcus can\u2019t wait to see how the current era in AI history is viewed a\ndecade hence.\n\nMarcus on AI is a reader-supported publication. To receive new posts and\nsupport my work, consider becoming a free or paid subscriber.\n\n86 Likes\n\n\u00b7\n\n3 Restacks\n\n86\n\nShare this post\n\n#### Evidence that LLMs are reaching a point of diminishing returns \u2014 and what\nthat might mean\n\ngarymarcus.substack.com\n\n27\n\nShare\n\n27 Comments\n\nPaul ToppingApr 13Liked by Gary MarcusI find the initial statement strange and\na tell of sorts. What would \"doubling of capabilities\" really even mean? Will\nLLMs double their score on some test? Will they do twice as many things in a\ngiven time period? Consume half the power for a given task? It all sounds like\nBS coming right out of the gate.Expand full commentLike (8)ReplyShare  \n---  \n  \n5 replies\n\nHerbert Roitblat24 hrs agoLiked by Gary MarcusYou recently wrote about a paper\nthat I think better makes the case you are raising here.\nhttps://arxiv.org/abs/2404.04125. Exponential increases in data are needed for\nlinear improvements in models.Expand full commentLike (4)ReplyShare  \n---  \n  \n25 more comments...\n\nThings are about to get a lot worse for Generative AI\n\nA full of spectrum of infringment\n\nDec 29, 2023 \u2022\n\nGary Marcus\n\n236\n\nShare this post\n\n#### Things are about to get a lot worse for Generative AI\n\ngarymarcus.substack.com\n\n161\n\nWhat if Generative AI turned out to be a Dud?\n\nSome possible economic and geopolitical implications\n\nAug 13, 2023 \u2022\n\nGary Marcus\n\n298\n\nShare this post\n\n#### What if Generative AI turned out to be a Dud?\n\ngarymarcus.substack.com\n\n134\n\nChatGPT has gone berserk\n\nNot a joke\n\nFeb 21 \u2022\n\nGary Marcus\n\n136\n\nShare this post\n\n#### ChatGPT has gone berserk\n\ngarymarcus.substack.com\n\n88\n\nReady for more?\n\n\u00a9 2024 Gary Marcus\n\nPrivacy \u2219 Terms \u2219 Collection notice\n\nStart WritingGet the app\n\nSubstack is the home for great culture\n\nShare\n\n## Create your profile\n\n## Only paid subscribers can comment on this post\n\nAlready a paid subscriber? Sign in\n\n#### Check your email\n\nFor your security, we need to re-authenticate you.\n\nClick the link we sent to , or click here to sign in.\n\n", "frontpage": false}
