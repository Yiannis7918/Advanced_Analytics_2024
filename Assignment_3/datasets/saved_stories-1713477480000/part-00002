{"aid": "40077514", "title": "What danah boyd told us about AI and ethics", "url": "https://civic-texts.ghost.io/what-danah-boyd-told-us-about-ai-and-ethics/", "domain": "civic-texts.ghost.io", "votes": 1, "user": "CharlesW", "posted_at": "2024-04-18 15:55:54", "comments": 0, "source_title": "What danah boyd told us about AI and ethics", "source_text": "What danah boyd told us about AI and ethics\n\nCivic Texts\n\nSign in Subscribe\n\n# What danah boyd told us about AI and ethics\n\n#### Alex Howard\n\nApr 18, 2024 \u2014 7 min read\n\nGood morning from Washington, where the Senate dismissed impeachment charges\nagainst DHS Secretary Mayorkas on a party-line vote, the House will consider\nforeign aid to Ukraine, Taiwan, and Israel, privacy legislation seems to be\nmoving forward, and NPR staffers. (Jury selection is ongoing in an\n\"unpresidented\" criminal trial in New York City, if you've somehow missed th\nnews.)\n\nAlex Howard here, back in your inbox with another edition of Civic Texts. I'm\ncontinuing to think through the best pace, frequency, and formats for these\nnewsletter, so stay tuned. If you have suggestions, questions, comments, tips,\nor concerns, you can find me online as @digiphile across social media, or\nemail alex@governing.digital. If you find these newsletters valuable, I hope\nyou'll consider sharing them with your social networks, forwarding to\ncolleagues, and upgrading to a paid subscription to support my work. Thank you\nfor your continued support!\n\n## Who will be in AI's \"Moral Crumple Zones\" ?\n\nLast week, I cycled back over at Georgetown to see danah boyd give a talk at\nthe university's newish Center for Digital Ethics in anticipation of her\nmaking some sense of what\u2019s happening with artificial intelligence right now\nand she anticipates unfolding all around us in the year to come. It was\nmarvelous to see her again after so many years and enjoy her perspective.\n\nAs usual, danah gave me a LOT to think about in a chewy talk. Georgetown may\npost video or slides. I'm hopeful that she'll publish her remarks as prepared\nfor delivery on her blog. In the interim, I've summarized what I heard using\nmy notes and hope it will prove useful.\n\nHer core lesson to us was an exhortation to think \"sociotechnically,\" and\navoid determinism or techno-solutionism. As a trained sociologist and\nrecovering technology journalist, this is both welcome and strikes right next\nto the bone, as it has for a decade.\n\nAs she noted to a hall full of Washingtonians, policymaking is rife with\nsolutionism \u2014 using legislation or regulation to solve a societal problem.\nIt's also deeply embedded in the logic and code of Silicon Valley, where\ntechno-solutionism \u2013 the idea that the right technology can solve a societal\nproblem \u2013 has been scaling for years. Deja vu, all over again.\n\ndanah gave us an important concept to consider for the rapidly expanding,\nemergent uses of AI, using the ways the USA regulates air travel as a useful\nprompt. When the ability to make decisions has shifted to a private industry\nwithout accountability, beware.\n\nIn airplanes, humans must remain in the loop, but sometimes the automated\nsystems can get in their way, as with Boeing and the Max 8 disaster \u2013 long\nbefore the current rash of problems with the aerospace giant. danah noted that\nwhen it comes to Captain \"Sully\" and the Miracle on the Hudson, he has to make\nobjections to save people\u2019s lives.\n\nCiting Madeline Elish, she talked about \"moral crumple zones,\" citing\nMadeleine Elish's evocative concept that describe \"how responsibility for an\naction may be misattributed to a human actor who had limited control over the\nbehavior of an automated or autonomous system.\"\n\nWhen there's no ability for pilots to override systems, it results in crashes.\ndanah says the pattern is consistent: people would have been saved if pilots\ncould override a technical system that wasn\u2019t up to snuff. She's concerned\nthat we currently don\u2019t have structures in place to hold tech companies\naccountable over time for similar issues.\n\nThe question of who gets to define acceptable outcomes in policy, programs,\nand services is always about power and whose values are reflected in them.\n\n)This is why I've spent years advocating for liberal democratic values to be\nembedded in American tech companies code and governance, lest authoritarian\nvalues from alternative systems of government become the defaults. Privacy-\nenhancing technologies are great. Coercive theofascism, not so much.)\n\ndanah gave us a mundane but profound example of this dynamic: scheduling\nsoftware. This is the software anyone who schedules workers for shifts uses.\nAs she observed, the companies who make such software can optimize for many\ndifferent things.\n\nThe question is whose values are centered. If the goal is staff happiness,\nwhat would you look for? Might that mean regular shifts, near home, with\npeople they want?\n\nBut this software is sold to people who have power, not workers. What if an\nemployer wants to ensure no that one hits full time work to avoid paying\nbenefits? Or to avoid staff having the same shifts, to avoid unionizing? Or to\nkeep shifts irregular, so staff can't get other work, ensuring an on-demand,\ncontingent labor pool?\n\nThese kinds of systems have knock-on effects, as boyd noted, citing research\nthat found the children of parents in these kinds of jobs are a grade-level\nbehind.\n\nIt's not that applying technology to improve wicked societal problems in\ninherently wrong, though. boyd cited Crisis Text Line, where she was a\nfounding board member, of a successful attempt at making mental health\nsoftware that serves people in need, along with those seeking to help.\n\nThe better questions is that if we use tech, to what ends? As boyd said, using\nthe science and technology studies, arrangements matter. There are the\neconomic and political conditions that technology is built and experienced\nwithin, which shape both the development and uses of technology and our\nexpectations around it.\n\nboyd says in the current framing around generative AI, everything is about\nefficiency and productivity, not making work more joyous. It's about\nminimizing cost \u2013 and eliminating humans, which has been a vision of\ncapitalism for over a century.\n\nAnd here danah gave us something lovely to chew on: whether we've been\nthinking about Luddites and Luddism the wrong way. Luddism was a movement in\n1810-1817, when new manufacturing technologies were changing entire areas of\nthe United Kingdom. Before, danah said, tech empowered workers. Then automated\nlooms in textile manufacturing took power away and add increased risks of\ninjury.\n\nPeople were angry at machines and attacked them, which led to murder by\nsoldiers and then Luddites hung in town squares. Criminalization of attacking\nindustrial machines and backlash ended that movement, but Luddism endures,\nsaid boyd.\n\nThe Luddites introduced the questions of what workers rights should be, which\nthen permeated pop culture of the time. Shelley's \"Frankenstein\" is a story in\na response: it's not about if you can build tech, but if it will fit into\nsociety. Literature moved ideas forward.\n\nMany modern arrangements look more like outsourcing than automation. More\nrecently Amazon's amazing \"just walk out tech\" turns out to depend on many\nhumans watching humans \u2013 a classic mechanical Turk. What's now at hand could\nbe a rearrangement of workers and work, not replacement, per se. Within these\nnew systems of software-mediated employment, new inequalities can emerge.\n\nboyd explained why is fascinated by generative AI, due to its implications for\nthe arrangements across society. We are now seeing trust degrade in\norganizational settings, with awareness of who is gifting others a sense of\ntime. It depends on arrangement or power! There are amazing success stories,\nlike people who speak English as a second language having a system to check\ntheir writing, or using the tool to write and rewrite difficult, complex\nemotional messages to get it right. There's also humor, where poor results\nlead groups to find solidarity in collective hatred of AI tools.\n\ndanah focused us on being cautious about designing models and applying them\nwithout thinking about the broader social system and how to make it\ncollectively beneficial, using the example of a tool designed to detect when\nsepsis is likely at Duke that took for granted that nurses would constantly\nprovide feedback in the system when they had no time or incentive to do so.\n\nPeople seeking to apply AI and automation need to take into account social\nimpact and include repair costs downstream of changes in arrangements or\n\nFinally, danah called on all of us to attend to externalities and be\nresponsible for the future, as with tracking down the environmental costs of\nthe energy demands and cooling needs of the data centers that power generative\nAI. As she notes, citing recent investigative journalism, there's no question\nthat the increasing strains on energy grid and the environmental costs are\nsignificant. As electric grids reach capacity and the water situation becomes\nmore serious, the externalities won't be theoretical to communities, as\nopposed to the hazy metaphor of \u201cthe cloud.\"\n\nOn warming planet, she challenged us, how do we think about the ethics of\nchewing up the resources required for computing? How do we include\nenvironmental factors, or consider costs of maintenance and repair?\n\nIf we think about our political and economic environment, and take a\nsociotechnical approach, we can see some tools are fun, and some are useful.\nWhat matters is how these things are configured, and by whom.\n\nWe need to look beyond hype, as with the folks who said AI will end humanity\nin 2023 or reclaim AI more important than electricity or fire, and invite some\nform of resistance \u2014 friction \u2013 to widespread development.\n\nThese are not inevitable outcomes. They are choices. We need nuanced\nconversation, to avoid determinism, a learn from history, focus on\narrangements that are are robust & sensitive, and remember we all have agency\nto help create the future\n\nWhen I asked her about what states and nations should do, citing the example\nof the imposition of the catalytic converter to address smog and acid rain,\ndanah said the right frame is interventions.\n\nWe aren't going to fix OpenAI by going right at them. Instead, make the\neconomic cost of it egregious, so they have to pay environmental costs up\nfront.\n\nMuch to chew through.\n\nIt's an interesting provocation! As always, feel free to let me know what you\nthink about it at alex@governing.digital.\n\n## Read more\n\n### Will (overdue) Congressional interest change U.S. participation in open\ngovernment?\n\nHello from Washington, where the climate already resembles New England summer\nthan spring. Life in DC, redux. Alex Howard here, back in your inbox with\nanother edition of Civic Texts. If you find these valuable, I hope you'll\nconsider sharing them with your social networks, forwarding to colleagues,\n\nBy Alex Howard Apr 16, 2024\n\n### What I learned after Meta's algorithms silenced me, and then Adam Mosseri\nlistened\n\nGood morning from sunny Washington, where spring is now accelerating into a\nclimate that resembles of New England summer, the Senate is back in session,\nand I'm getting ready to go up to Maine to sing in an acappella reunion again.\nDeja vue, all over again. Thanks to\n\nBy Alex Howard Apr 11, 2024\n\n### Don't look up! Astronomical privacy news in the USA is being eclipsed\ntoday.\n\nGood afternoon from sunny DC, a condition I expect that to change dramatically\naround 3:20 today for people across the United States where the sun is\n(mostly) blocked by the moon in the first total eclipse since 2017. (NASA has\nall of the details about where, when, and how\n\nBy Alex Howard Apr 8, 2024\n\n### Why do an open Internet and net neutrality matter? Access to information\nis a human right.\n\nHello there! Alex Howard here again. I hope your Friday is going well and that\nyou're staying safe and well, given that April snowstorms and earthquakes are\nin the zeitgeist in the eastern regions of the United States today. Thank you\nto everyone who has subscribed since I\n\nBy Alex Howard Apr 6, 2024\n\nCivic Texts\n\nPowered by Ghost\n\n## Civic Texts\n\nWho, what, where, when, how, and why humans and technologies are changing\ndemocracy \u2013 and vice versa, from civic tech to authoritarian abuses.\n\n", "frontpage": false}
