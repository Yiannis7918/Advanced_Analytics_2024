{"aid": "40009881", "title": "\u03b4zd Is the Best", "url": "https://justine.lol/sizetricks/#dzd", "domain": "justine.lol", "votes": 2, "user": "metadat", "posted_at": "2024-04-12 06:18:54", "comments": 0, "source_title": "Size Optimization Tricks", "source_text": "Size Optimization Tricks\n\nJune 10^th, 2022 @ justine's web page\n\n# Size Optimization Tricks\n\nThis blog post will cover some of the tricks I've used in the past to make c /\nc++ / python binaries smaller using x86 assembly. Much of it will revolve\naround the Cosmopolitan codebase, since I recently received feedback from the\nELKS project that they love the code and want to hear more about how the\ntricks cosmo uses can potentially improve projects as intriguing as a i8086\nLinux port. In many ways I feel a kinship with the ELKS project, since the\nfirst thing I had to do, to build Cosmopolitan, was write an i8086 bootloader\ncalled Actually Portable Executable. Plus it pleased me to hear that people\nwho've been focusing on the problem a lot longer than I have are pleased with\nwhat they've read in Cosmopolitan so far. So I figured it'd be nice to share\nwith a broader audience.\n\n## Table of Contents\n\n  1. Why It Matters\n  2. Look at the Binary\n  3. Field Arrangement\n  4. Run Length Encoding\n  5. Decentralized Sections\n  6. Dead Code Elimination\n  7. \u03b4zd Encoding\n  8. Overlapping Functions\n  9. Optimizing Printf\n  10. Tiny Portable ELF\n  11. Funding\n  12. See Also\n\n## Why It Matters\n\nI like the UNIX philosphy of having lots of small programs. I like it so much,\nthat the Cosmopolitan repository builds hundreds of them.\n\n    \n    \n    $ git clone https://github.com/jart/cosmopolitan $ cd cosmopolitan $ make -j16 MODE=tiny $ find o/tiny -name \\*.com | wc -l 741\n\nThe whole repository takes about fifty seconds to build from scratch on my PC.\nOut of those 741 executables, 403 are test executables. It's nice to have each\nset of tests be in a separate executable, to reduce the chance of a bad test\nmessing up the global state, and leading to hard to diagnose unrelated\nfailures somewhere else. It also means htop can serve as a test status free\ndashboard. Each dot com file is a static binary which behaves sort of like a\nDocker container, since they're usually zip files too which vendor assets\n(e.g. tzinfo data). Did I mention each executable also runs on seven operating\nsystems?\n\n    \n    \n    # testing process for f in $(find o/tiny/test -name \\*_test.com); do for os in freebsd openbsd netbsd rhel7 rhel5 win7 win10 xnu; do scp $f $os: ssh $os ./${f##*/} done done\n\nSo all I have to do to test all 400 programs on all 8 supported systems (3,200\ntests total!) is simply scp them onto each host and run them. That takes about\n15 seconds thanks to runit and runitd. It's been a big productivity boost and\nenables test-driven development (also known as TDD) with rapid feedback.\n\nWhat makes this workflow manageable in that binaries are small. The tinier\nsomething is, the more instances we can have of it at scale. So it really\nisn't just about running on old computers. It's not necessarily about code\ngolfing. It's about having infinitely more of a good thing on the cheap with a\npleasant coding lifestyle. Here's some concrete examples of how small actually\nportable executables built with Cosmopolitan Libc can be:\n\n    \n    \n    16K o/tiny/examples/hello2.com # calls write (links syscall) 20K o/tiny/examples/hello.com # calls fputs (links stdio) 24K o/tiny/examples/hello3.com # calls printf (links fmt+stdio) 100K o/tiny/test/libc/calls/access_test.com # links test library 216K o/tiny/tool/net/redbean-original.com # http/1.1 server 1.8M o/tiny/examples/pyapp/pyapp.com # statically linked python app\n\nWould my isolated hermetic testing workflow have been possible if I was using\na language that needs at minimum 3mb to build a binary? My LAN only has\ngigabit ethernet. I don't need to work at a big company with industrial fabric\nswitches to transfer these ~100kb test binaries over the wire. Let's do some\nback of the envelope calculations:\n\n    \n    \n    # theoretic minimum seconds transferring cosmo test binaries w/ 1gbps lan uncompressed >>: (400*8 * 16*1000) / (1024*1024*1024/8) 0.3814697265625 # theoretic minimum seconds transferring go test binaries w/ 1gbps lan uncompressed >>: (400*8 * 3*1000*1000) / (1024*1024*1024/8) 71.52557373046875\n\nThat's a lot of time to be spending transfering files. Tiny isn't just about\nscale, but surviving long enough to scale. Cosmopolitan is a scrappy\noperation. The repo right now only has about 1.5 million lines of code. What\nI'm thinking about is how we're going to host the next billion lines of code,\nwhile everyone else is drowning in technical debt. Tiny is about the efficient\nuse of resources. Big things must have small beginnings, because no one wants\nto build an empire of code on a tooling foundation that ravages their budget\nwith cloud provider fees. Altavista ran an entire search engine on a single\ncomputer, and now you're telling me we need to plug our Full Story Elecron\nIDEs into a Kubernetes cluster to compile a C++ app that does math. How does\nthat add up?\n\nLosers always whine about how their bloat is a calculated tradeoff. The\nimportant thing to consider is that there is no tradeoff. Just engineers\nwho've been victimized by the accidental complexity of modern software, chose\nto stop caring, and yearn for another break while their code compiles\u2014like\nDennis from Jurassic Park. Bloat is like the fake jobs version of scalability,\nin the sense that bloat offers hungry devs the thrill of complexity without\nthe advantages. I used to operate a storage system with exabytes of data, and\nit honestly didn't feel that different from what I'm doing now, working on the\ntiniest software in the world. It's the stuff in the middle I just don't find\nas appealing.\n\nIn any case, as an avid reader of codebases, bloat is unpleasant. I think\ncodebases have been lacking in a woman's touch for decades; and that\nespecially applies to open source, which has never really had a woman's touch\nat all. We can fix that, but overall, the best way to improve software\ndevelopment is to make it more fun. There's few things more fun than size\ncoding.\n\n## Look at the Binary\n\nI think the biggest disadvantage of anyone looking to size optimize\nsystemically is the difficulty of intuitive thinking. Especially for guys who\nuse traditional hex editors. Here's what run-length encoded data looks like:\n\n    \n    \n    0002d0b0 01 00 01 03 01 06 01 09 01 0c 01 0f 01 12 14 1e |................| 0002d0c0 01 15 04 1e 01 18 17 1e 01 1e 1c 1e 01 1b 00 00 |................| 0002d0d0 21 01 01 00 02 01 01 00 01 01 09 00 01 01 0a 00 |!...............| 0002d0e0 01 01 01 00 01 01 01 00 03 01 1a 00 04 01 01 00 |................| 0002d0f0 01 01 1a 00 03 01 01 00 81 01 00 00 00 00 00 00 |................| 0002d100 21 01 01 00 02 01 01 00 01 01 16 00 01 01 01 00 |!...............| 0002d110 01 01 1c 00 04 01 01 00 01 01 1a 00 03 01 01 00 |................| 0002d120 81 01 00 00 00 00 00 00 21 01 01 00 02 01 01 00 |........!.......| 0002d130 01 01 09 00 01 01 0c 00 01 01 01 00 03 01 1a 00 |................|\n\nHex editors are a really good tool when you're looking for a specific thing\nand need a specific answer, but they reveal little visually about the shape\nand form of a binary. You're not actually looking. You're just studying\nempirical data with a razor sharp focus that can easily become tunnel-vision.\nBlinkenlights solves this problem by using IBM Code Page 437. If we use it to\nvisualize the same run-length encoded data above, and it's able to give us a\nbetter glance.\n\nPlease keep in mind, this is a purely intuitive display. It's going to look\nlike gobbledygook to anyone who's unfamiliar with CP437, but surely anyone can\nagree it's better than a wall of period marks, in terms of the richness and\ncomplexity of the information it succinctly conveys. CP437 can be thought of\nas an alphabet with 256 letters. You can scroll through pages and pages of\nthis stuff and your mind will magically spot and identify patterns. For\nexample, you'll gain an intuition for what data does. For example, here's an\nindirect jump table:\n\nHere's what a struct looks like when it's compiled with\n__attribute__((__packed__)):\n\nHere's what x86-64 code looks like:\n\nHere's what /dev/urandom looks like:\n\nAnd here's what binaries built with UBSAN (Undefined Behavior Sanitizer) look\nlike. As we can see, it's got plenty of room for improvement, and obviously\nexplains why UBSAN binaries are so enormous. It's poor struct packing.\n\nCosmopolitan is an ex nihilo codebase. I started this project with an empty\nfile and an assembler. Pretty much every byte that's gone into APE binaries\nsince then, I've had some role in either creating and/or monitoring. As such,\nthe two very first tools I wrote with Cosmopolitan Libc were intended to help\nme do just that.\n\n    \n    \n    -rwxr-xr-x 1 501 jart 52K Jun 9 09:08 bing.com (see bing.c) -rwxr-xr-x 1 501 jart 32K Jun 9 09:08 fold.com (see fold.c)\n\nI use them with the following shell script wrapper named ~/bin/bf.\n\n    \n    \n    #!/bin/sh bing.com <\"$1\" | fold.com | exec less\n\nSo whenever I want to take a peek inside a file, I just type a command like:\n\n    \n    \n    bf o//examples/hello.com\n\nI've written a few other scripts that come in handy. For instance, here's\n~/bin/bloat which shows which symbols in a .com.dbg file are the biggest.\n\n    \n    \n    #!/bin/sh nm -C --size \"$@\" | sort -r | grep ' [bBtTRr] ' | exec less\n\n## Field Arrangement\n\nStruct packing is a nice wholesome size optimization that's not the least bit controversial. One good example is something I once noticed about Python 3.6 when viewing it through bing | fold. A core Python parser struct has suboptimal field arrangement.\n    \n    \n    typedef struct { int s_narcs; arc *s_arc; int s_lower; int s_upper; int *s_accel; int s_accept; } state;\n\nI wouldn't have noticed this if I was reading the code, since sometimes the\nstuff underneath the iceberg isn't always clear. That struct above, is\nactually equivalent to the following at the binary level:\n\n    \n    \n    typedef struct { int s_narcs; int __pad1; // four wasted bytes arc *s_arc; int s_lower; int s_upper; int *s_accel; int s_accept; int __pad2; // four wasted bytes } state;\n\nSo I moved the s_accept field to a different line, and it shaved 4kb off every\nPython binary.\n\n    \n    \n    typedef struct { int s_narcs; int s_accept; arc *s_arc; int s_lower; int s_upper; int *s_accel; } state;\n\nEverything counts in small amounts. I also imagine there's some corporate\nstyleguides at various companies where the latter code would be preferred,\nstrictly for policy reasons. Since it's not great from a readability\nstandpoint to have people scratching their heads wondering where the gaps are\nin your data structures, if they need assurances at the application binary\ninterface level. So we're not only saving space but leading to better code\nhygeine too.\n\n## Run Length Encoding\n\nThere are so many outstanding compression algorithms in the news, based on\nmachine learning and even classical algorithms, that I imagine many self-\ntaught programmers might not be familiar with the really simple primitive ones\nthat, in certain cases, get the job done. One such example is run-length\nencoding. The way it works, is if you have a sequence such as:\n\n    \n    \n    1,1,1,1,1,1,1,1,2,2,2,3\n\nThen you'd encode it as sequence of {count, thing} tuples with a {0,0}\nterminator.\n\n    \n    \n    8,1, 3,2, 1,3, 0,0\n\nWhat I love about run-length encoding is (1) it's so simple that the\ncompressed data stream can be edited by hand; and (2) its decompressor only\nrequires 14 bytes of code.\n\n    \n    \n    / Fourteen byte decompressor. / / @param di points to output buffer / @param si points to uint8_t {len1,byte1}, ..., {0,0} / @arch x86-64,i386,i8086 / @see libc/nexgen32e/rldecode.S rldecode: 31 c9 xor %ecx,%ecx ac0: lodsb 86 c1 xchg %al,%cl ac lodsb e3 05 jrcxz 2f aa1: stosb e2 fd loop 1b eb f5 jmp 0b c32: ret .type rldecode,@function .size rldecode,.-rldecode .globl rldecode\n\nProTip: You can hover over instructions with a wavy line for an explanation of\nwhat it does.\n\nThat particular example is beautiful, since it's binary compatible with i8086,\ni386, and x86-64. However assembly doesn't always mean fast. For better\nexplainability and performance, the following C code should do the trick:\n\n    \n    \n    struct RlDecode { uint8_t repititions; uint8_t byte; }; void rldecode2(uint8_t *p, const struct RlDecode *r) { for (; r->repititions; ++r) { memset(p, r->byte, r->repititions); p += r->repititions; } }\n\nRun-length encoding is only appropriate for compressing sparse data. For\ndenser data, RLE, will double its size! However it just so happens that, when\nwe're making binaries smaller, there's usually many sparse data structures\nthat can be efficiently run-length encoded.\n\nOne such example are the character translation tables used by the redbean web\nserver, when parsing URIs and HTTP messages. One thing most C/C++ developers\nfigure out eventually is that it's really efficient to perform a character\nlookup in a table with 256 entries. Why? Because your C compiler will turn C\ncode like rdi[al & 255] into assembly that looks like this:\n\n    \n    \n    movzbl %al,%eax mov (%rdi,%rax),%al\n\nThat's super fast, and memory safe too. Hardware engineers would call it a\nLookUp Table or LUT for short. It's quite integral to the workings of\nmicroprocessors. The x86 architecture even has a deprecated instruction called\nXLAT that's dedicated to this very thing. With HTTP, the most important use\ncase for LUTs is to check if characters are legal. For example, many of the\ncomponents of an HTTP message are required to be \"tokens\" quoth RFC2616:\n\n    \n    \n    CHAR = <any US-ASCII character (octets 0 - 127)> SP = <US-ASCII SP, space (32)> HT = <US-ASCII HT, horizontal-tab (9)> CTL = <any US-ASCII control character (octets 0 - 31) and DEL (127)> token = 1*<any CHAR except CTLs or separators> separators = \"(\" | \")\" | \"<\" | \">\" | \"@\" | \",\" | \";\" | \":\" | \"\\\" | <\"> | \"/\" | \"[\" | \"]\" | \"?\" | \"=\" | \"{\" | \"}\" | SP | HT\n\nAs plain C code, we could write our token LUT as follows:\n\n    \n    \n    const char kHttpToken[256] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0x00 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0x10 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, // 0x20 ! #$%&\u2018 *+ -. 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, // 0x30 0123456789 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 0x40 ABCDEFGHIJKLMNO 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, // 0x50 PQRSTUVWXYZ ^_ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, // 0x60 `abcdefghijklmno 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, // 0x70 pqrstuvwxyz | ~ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0x80 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0x90 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xa0 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xb0 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xc0 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xd0 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xe0 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, // 0xf0 };\n\nThat way we can just say kHttpToken[c & 255] to check if a character is valid\nin a token. But if we wanted to save 200 bytes of binary size, we could use\nrun-length encoding.\n\n    \n    \n    .globl kHttpToken .section .bss.sort.100.kHttpToken,\"aw\",@nobits / @see net/http/khttptoken.S kHttpToken: .zero 256 .section .rodata.sort.100.kHttpToken,\"a\",@progbits .byte 33,0 # 00-20 \u2205-\u2420 .byte 1,1 # 21-21 !-! .byte 1,0 # 22-22 \u201c-\u201c .byte 5,1 # 23-27 #-\u2018 .byte 2,0 # 28-29 (-) .byte 2,1 # 2a-2b *-+ .byte 1,0 # 2c-2c ,-, .byte 2,1 # 2d-2e --. .byte 1,0 # 2f-2f /-/ .byte 10,1 # 30-39 0-9 .byte 7,0 # 3a-40 :-@ .byte 26,1 # 41-5a A-Z .byte 3,0 # 5b-5d [-] .byte 29,1 # 5e-7a ^-z .byte 1,0 # 7b-7b {-{ .byte 1,1 # 7c-7c |-| .byte 1,0 # 7d-7d }-} .byte 1,1 # 7e-7e ~-~ .byte 129,0 # 7f-ff \u2302-\u03bb .byte 0,0 # terminator .section .init.sort.100.kHttpToken,\"a\",@progbits call rldecode\n\nThere's a tool in the Cosmopolitan codebase for automatically generating these\nassembly files.\n\n    \n    \n    o//tool/build/xlat.com -TiC ' ()<>@,;:\\\"/[]?={}' -iskHttpToken\n\n## Decentralized Sections\n\nThe assembly code in the previous section that's generated by xlat.com might\nseem a bit strange, even for experienced x86 assembly programmers. It's a\ntechnique somewhat uniquely resurrected for Cosmopolitan, based on a reading\nof old code from the 70's and 80's. We'll call it \"decentralized sections\".\n\nDecentralized sections are a way by which we can write a single function whose\ncode spans multiple files. The canonical example of this, is the classic UNIX\n_init() function, which you'll find empty in nearly every modern codebase,\nbecause _init() is somewhat of a lost art intended to be assembled by the\nlinker script.\n\nThe way this works is your libc defines the stubs for the prologue and\nepilogue of the _init() function. Here's how Cosmopolitan Libc defines it\n(with some slight edits to reduce macro usage in order to improve\ncopy/pastability):\n\n    \n    \n    .section .init_prologue,\"ax\",@progbits .globl _init / @param r12 is argc (still callee saved) / @param r13 is argv (still callee saved) / @param r14 is envp (still callee saved) / @param r15 is envp (still callee saved) / @note rdi is __init_bss_start (callee monotonic lockstep) / @note rsi is __init_rodata_start (callee monotonic lockstep) / @see libc/runtime/init.S _init: push %rbp mov %rsp,%rbp lea __init_bss_start(%rip),%rdi lea __init_rodata_start(%rip),%rsi .previous/* ... decentralized content ... */.section .init_epilogue,\"ax\",@progbits _woot: leave ret .previous\n\nYour libc also needs to declare stubs for the data sections. These technically\ncould be declared in the linker script, but it's nicer to write them in a .S\nfile so the symbols don't get defined unless they're being linked.\n\n    \n    \n    .section .init_rodata_prologue,\"a\",@progbits .globl __init_rodata_start,__init_rodata_end .align __SIZEOF_POINTER__ __init_rodata_start: .previous/* ... decentralized content ... */.section .init_rodata_epilogue,\"a\",@progbits __init_rodata_end: .byte 0x90 .previous .section .init_bss_prologue,\"aw\",@nobits .globl __init_bss_start,__init_bss_end .align __SIZEOF_POINTER__ __init_bss_start: .previous/* ... decentralized content ... */.section .init_bss_epilogue,\"aw\",@nobits __init_bss_end: .byte 0 .previous\n\nWe then configure our linker script as follows:\n\n    \n    \n    /* see ape/ape.lds */ SECTIONS { .text . : { KEEP(*(.init_prologue)) KEEP(*(SORT_BY_NAME(.init.sort.*))) KEEP(*(.init)) KEEP(*(.init_epilogue)) *(.text .text.*) KEEP(*(SORT_BY_NAME(.rodata.sort.*))) *(.rodata .rodata.*) } .bss . : { KEEP(*(SORT_BY_NAME(.bss.sort.*))) *(SORT_BY_ALIGNMENT(.bss)) *(SORT_BY_ALIGNMENT(.bss.*)) *(COMMON) } }\n\nIt's now possible to write assembly files that insert content into the _init()\nfunction, along with the concomitant __init_rodata_start and __init_bss_start\ndata structures. Both the read-only data and the uninitialized data (BSS)\nsections are optional. The only thing that's mandatory is that, unlike the\nnormal System V Application Binary Interface, our _init() code isn't allowed\nto clobber RDI and RSI. Because they store lockstep pointers to the rodata and\nbss.\n\nHere's an example than of how it can be used, that's simpler than the\nkHttpToken example above. Let's say I need to support the AMD K8 aand\nBarcelona microarchitectures, but I want to take advantage of SSSE3 (which is\nthe best SSE). The industry practice here is to perform a CPUID check behind a\ndouble-checked pthread_once() guard, because the CPUID instruction takes 50\nnanoseconds each time, whereas the once guard averages out over many calls to\ncost half a nanosecond. However the _init() function provides a better\nsolution, since it obfuscates the need for synchronization libraries, due to\nhow _init() is called before all other constructors, thereby making it highly\nunlikely that any threads to have been created.\n\n    \n    \n    .section .bss.sort.100.kCpuid1,\"aw\",@nobits / uint32_t kCpuid1[4]; / @see libc/nexgen32e/kcpuids.S kCpuid1:.long 0,0,0,0 .globl kCpuid1 .type kCpuid1,@object .size kCpuid1,.-kCpuid1 .section .init.sort.100.kCpuid1,\"a\",@progbits 53 push %rbx 6a 01 push $1 58 pop %rax 0f a2 cpuid ab stosl 93 xchg %eax,%ebx ab stosl 91 xchg %eax,%ecx ab stosl 92 xchg %eax,%edx ab stosl 5b pop %rbx\n\nNote: If you've ever felt mystified by Intel's marketing and wondered which\nCPUs have which features based on their true microarchitectural name, then\nthere's an executive summary in microarch.txt.\n\nThe code above only adds 14 bytes of content to the binary. It scales in terms\nof development model; any number of libraries throughout your codebase can\nfollow this process without stepping on each others toes. As a model,\ndecentralized sections really gives us a sweet spot that caters to the\ngigantic codebases big companies respect, while creating the tiny binaries\nindie developers adore. It's also much lighter weight than needing to pull in\na dependency on -lpthread. Now, when I want to check if SSSE3 is available,\nall I have to do is check if the 9th bit of the ECX we stored earlier is set:\n\n    \n    \n    if (kCpuid1[2][1<<9]) { // we have ssse3! } else { // it's k8 or barcelona }\n\nIf you're using a different libc from cosmo (e.g. musl, glibc) then you can\nstill use this same technique, today, with some slight alteration.\n\n    \n    \n    .bss kCpuid1:.long 0,0,0,0 .globl kCpuid1 .type kCpuid1,@object .size kCpuid1,.-kCpuid1 .section .init,\"a\",@progbits 53 push %rbx 48 8d 3d 00 00 00 00 lea kCpuid1(%rip),%rdi 6a 01 push $1 58 pop %rax 0f a2 cpuid ab stosl 93 xchg %eax,%ebx ab stosl 91 xchg %eax,%ecx ab stosl 92 xchg %eax,%edx ab stosl 5b pop %rbx\n\nHere we need to pay for 7 additional bytes (21 bytes total), because the\nlockstep cooperation between _init() / rodata / bss is unique to Cosmo and not\nimplemented by other C libraries. But in either case, both assembly solutions\nare a clear win over the C/C++ equivalent, which needs 42 bytes.\n\n    \n    \n    uint32_t kCpuid1[4]; __attribute__((__constructor__)) static void kCpuid1Init() { uint32_t ax, bx, cx, dx; asm(\"cpuid\" : \"=a\"(ax), \"=b\"(bx), \"=c\"(cx), \"=d\"(dx) : \"0\"(1)); kCpuid1[0] = ax; kCpuid1[1] = bx; kCpuid1[2] = cx; kCpuid1[3] = dx; }\n\nNote: If you're bewildered by the Richard Stallman Math 55 notation used by\nthe asm() keyword, you can find an executive summary in rmsiface.txt.\n\nIf there's one thing I've learned working on Cosmopolitan, it's that with the\nright finesse, the C compiler can produce really tiny code if we're willing to\nwrite assembly inside string literals. The following code shows how to get GCC\nand Clang to do it in 30 bytes. Whether or not it's worth it versus just\nwriting assembly is up to the reader.\n\n    \n    \n    uint32_t kCpuid1[4]; __attribute__((__constructor__)) static void kCpuid1Init() { uint32_t ax, *di; asm volatile(\"cpuid\\r\\n\" \"stosl\\r\\n\" \"xchg\\t%%ebx,%%eax\\r\\n\" \"stosl\\r\\n\" \"xchg\\t%%ecx,%%eax\\r\\n\" \"stosl\\r\\n\" \"xchg\\t%%edx,%%eax\\r\\n\" \"stosl\" : \"=a\"(ax), \"=D\"(di) : \"0\"(1), \"1\"(kCpuid1) : \"rbx\", \"rcx\", \"rdx\", \"memory\"); }\n\nThe main thing that makes the C code clunkier is it needs to generate an 8\nbyte function pointer in a .ctors section which needs to be added to the\nlinker script separately. Your C library will normally call ctors after\n_init() is finished. There really aren't any acceptable solutions for getting\na modern C compiler to generate \"decentralized section\" style code. The\nclosest we can get is the following, using GCC (but certainly not Clang, which\nclaims dominion over all registers).\n\n    \n    \n    register long di asm(\"rdi\"); register long si asm(\"rsi\"); __attribute__((__section__(\".bss.sort.100.kCpuid1,\\\"aw\\\",@nobits #\"))) uint32_t kCpuid1[4]; __attribute__((__used__, __section__(\".init.sort.100.kCpuid1,\\\"a\\\",@progbits #\"))) static void kCpuid1Init(void) { uint32_t ax; asm volatile(\"push\\t%%rbx\\r\\n\" \"cpuid\\r\\n\" \"stosl\\r\\n\" \"xchg\\t%%ebx,%%eax\\r\\n\" \"stosl\\r\\n\" \"xchg\\t%%ecx,%%eax\\r\\n\" \"stosl\\r\\n\" \"xchg\\t%%edx,%%eax\\r\\n\" \"stosl\\r\\n\" \"push\\t%%rbx\" : \"=a\"(ax), \"+D\"(di) : \"0\"(1) : \"rcx\", \"rdx\", \"memory\"); __builtin_unreachable(); // prevent generation of RET instruction }\n\nThe problem with the above code is it's brittle. You need to pass compiler\nflags like -ffixed-rdi -ffixed-rsi -fomit-frame-pointer -O -fno-sanitize=all\nfor it to work properly. The value of a C compiler is being able to bloat our\ncode with debugging tools (like ASAN) when we want them. So with code like\nthis, where that can't happen, it's usually best to just write assembly.\n\n## Dead Code Elimination\n\nNaturally, if you're a Cosmopolitan Libc user, all the stuff in the CPUID\nexamples above would would be taken care of for you, and you need to say is\nthis:\n\n    \n    \n    // see libc/nexgen32e/x86feature.h if (X86_HAVE(SSSE3)) { // we have ssse3! } else { // it's k8 or barcelona }\n\nIt's worth taking a look at its implementation in x86feature.h since it's\nquite possibly the most beautiful abstraction created with the C preprocessor\nyou're likely to find in the entire codebase. It also embodies one of the most\nimportant patterns of Cosmopolitan macros, which is the hybridization of\ncompile-time and runtime checking. It's needed by Actually Portable Executable\n(which relies heavily on runtime dispatch) while still granting all the\ntraditional compile-time define flag tuning that developers love. For example,\nthe #ifdef model could be implemented here as follows:\n\n    \n    \n    #if X86_REQUIRE(SSSE3) // we have ssse3! #else // it's k8 or barcelona #endif\n\nIn that case, your program can only support SSSE3 if the user passes the\n-mssse3 flag to the compiler. It's better to use the X86_HAVE() macro because\nit does the same thing as X86_REQUIRE(SSSE3) except it has a runtime check\ntoo. By default, if you pass no microarchitecture flags to GCC or Clang, both\nbranches get included in the binary.\n\n    \n    \n    if (X86_HAVE(SSSE3)) { // do some wild ssse3 assembly hacks } else { // fallback to slow ansi c code }\n\nBut if the user chooses to pass the -mssse3 flag, then the fallback bloat for\nsupporting old CPU models gets removed by a compiler optimization pass, along\nwith the runtime check itself.\n\n    \n    \n    if (X86_HAVE(SSSE3)) { // do some wild ssse3 assembly hacks } else { // fallback to slow ansi c code }\n\nThis is what MODE=opt does with the Makefile build config by default. It\npasses the -march=native flag to the compiler, which asks it to figure out\nwhat features the CPU in your host machine has, and then Cosmopolitan and GCC\nwork together to produce a binary that's just right and optimally fast your\nmachine. The tradeoff is you won't be able to distribute any such binaries,\nsince they might not run on other x86 CPU models.\n\nThe basic idea behind how the hybrid model to dead code elimination and\nruntime branching works, is most simply and elegantly expressed in\nape/loader.c and libc/dce.c.\n\n    \n    \n    #define LINUX 1 #define METAL 2 #define WINDOWS 4 #define XNU 8 #define OPENBSD 16 #define FREEBSD 32 #define NETBSD 64 #define SupportsLinux() (SUPPORT_VECTOR & LINUX) #define SupportsXnu() (SUPPORT_VECTOR & XNU) #define SupportsFreebsd() (SUPPORT_VECTOR & FREEBSD) #define SupportsOpenbsd() (SUPPORT_VECTOR & OPENBSD) #define SupportsNetbsd() (SUPPORT_VECTOR & NETBSD) #define IsLinux() (SupportsLinux() && os == LINUX) #define IsXnu() (SupportsXnu() && os == XNU) #define IsFreebsd() (SupportsFreebsd() && os == FREEBSD) #define IsOpenbsd() (SupportsOpenbsd() && os == OPENBSD) #define IsNetbsd() (SupportsNetbsd() && os == NETBSD)\n\nSo one of the flexibilities of APE is the build can be tuned like this:\n\n    \n    \n    make MODE=tiny CPPFLAGS+=-DSUPPORT_VECTOR=0b00000001\n\nIf you want a 4kb hello world binary that only runs on Linux, and leaves out\nthat hefty 12kb of bloat that's normally included to support Windows, MacOS,\nFreeBSD, NetBSD, OpenBSD, and booting from BIOS on bare metal. One sweet spot\nis to only target the ELF operating systems. Simply set the appropriate bits\nfor Linux + BSD.\n\n    \n    \n    make MODE=tiny CPPFLAGS+=-DSUPPORT_VECTOR=0b01110001\n\n## \u03b4zd Encoding\n\nOne of the most size optimized pieces of code in the Cosmopolitan codebase is\nPython. This is where we really had to go beyond code golfing and pull out the\nartillery when it comes to size coding. One of the greatest weapons in our\narsenal (which helped us get statically linked Python binaries down to 2mb in\nsize) is what we call the Delta Zig-Zag Deflate compression scheme, or \u03b4zd for\nshort.\n\nThis isn't a generalized compression algorithm like DEFLATE, which employs\nHuffman coding (along with an RLE very similar to LZ4). It's only profitable\non certain kinds of executable content and while programming we need to use\nour best judgement to figure out which technique is most appropriate. But \u03b4zd\nin particular has produced some considerable gains.\n\nConsider the following dilemma. The Chinese, Korean, and Japanese languages\nare enormous. They don't even all agree on UTF-8 yet, and have a variety of\none-off character sets, all of which are supported by Python. The UNICODE\nstandard and its information tables also need to be enormous too, in order to\nsupport CJK. Most people outside those three countries don't need this\ninformation in their binaries, but we like to keep it there anyway, in the\ninterest of inclusiveness and enabling languages like Python to erect a big\ntent that welcomes everyone.\n\nBy using \u03b4zd packing, we can make these lookup tables significantly tinier,\nthereby ensuring that the user only needs to pay for the features they\nactually use. One of the many symbols in the Python codebase that needed this\ntreatment is _PyUnicode_PhrasebookOffset2 which was originally 178kb in size,\nbut apply delta encoding, zig-zag encoding, and then finally DEFLATE, we got\nit down to 12kb. That's a nearly 10x advantage over DEFLATE's Huffman encoding\nalone, and BZIP2's Burrows-Wheeler transform!\n\n    \n    \n    _PyUnicode_PhrasebookOffset2: size is 178,176 bytes _PyUnicode_PhrasebookOffset2: packed size is 100,224 bytes _PyUnicode_PhrasebookOffset2: rle size is 282,216 bytes _PyUnicode_PhrasebookOffset2: deflate size is 52,200 bytes _PyUnicode_PhrasebookOffset2: bz2 size is 76,876 bytes _PyUnicode_PhrasebookOffset2: \u03b4leb size is 47,198 bytes _PyUnicode_PhrasebookOffset2: \u03b4zd size is 12,748 bytes\n\nIn third_party/python/Tools/unicode/makeunicodedata.py you can read more about\nhow we regenerated these tables. The Python implementation for Delta-ZigZag-\nDEFLATE encoding is also as follows:\n\n    \n    \n    def uleb(a, x): while True: b = x & 127 x >>= 7 if x: a.append(b | 128) else: a.append(b) break def zig(x): m = (2 << x.bit_length()) - 1 return ((x & (m >> 1)) << 1) ^ (m if x < 0 else 0) def zleb(a, x): return uleb(a, zig(x)) def \u03b4zd(data): n = 0; i = 0 p = 0 a = bytearray() for x in data: zleb(a, x - p) p = x return deflate(a), len(a)\n\nYou can read the C code that unpacks the Python compressed data in\nlibc/x/xloadzd.c, libc/fmt/unzleb64.c, libc/runtime/inflate.c, and\nthird_party/zlib/puff.c. Puff is particularly nice. It's a size optimized (but\nslower) version of zlib that Mark Adler wrote that only does DEFLATE\ndecompression, and it has a binary footprint of 2kb. One thing Cosmopolitan\nLibc core libraries do quite frequently (since they can't depend on things\nlike malloc) whenever the need arises for proper DEFLATE decompression, is\nstrongly link Puff, and weakly link zlib (which is more on the order of 60kb\nin size) so that Puff is used by default, unless the faster zlib library is\nstrongly linked by something else.\n\n## Overlapping Functions\n\nIf high-level programming languages like C are the Ice Hotel and assembly is\nthe tip of the iceberg, then the hidden dimension of complexity lurking\nbeneath would be Intel's variable length encoding. This is where boot sectors\nget esoteric real fast, since tools can't easily visualize it. for example,\nconsider the following:\n\n    \n    \n    / %ip is 0 mov $0xf4,%al ret\n\n|\n\n    \n    \n    / %ip is 1 .byte 0xb0 wut: hlt # and catch fire ret  \n  \n---|---  \n  \nSimilar to how a Chess game may unfold very differently if a piece is moved to\nan unintended adjacent square, an x86 program can take on an entirely\ndifferent meaning if the instruction pointer becomes off by one. We were able\nto use this to our advantage, since that lets us code functions in such a way\nthat they overlap with one another.\n\n    \n    \n    / SectorLISP code. 89 D6 Assoc: mov %dx,%si 8B 3C 1: mov (%si),%di 8B 30 mov (%bx,%si),%si AF scasw 75 F9 jne 1b F6 .byte 0xF6 8B 39 Cadr: mov (%bx,%di),%di 3C .byte 0x3C AF Cdr: scasw 8B 05 Car: mov (%di),%ax C3 ret\n\n|\n\n    \n    \n    89 D6 Assoc: mov %dx,%si 8B 3C 1: mov (%si),%di 8B 30 mov (%bx,%si),%si AF scasw 75 F9 jne 1b F6 8B 39 3C AF testw $0xaf,0x3c39(%bp,%di) 8B 05 mov (%di),%ax C3 ret 8B 39 Cadr: mov (%bx,%di),%di 3C AF cmp $0xaf,%al 8B 05 mov (%di),%ax C3 ret AF Cdr: scasw 8B 05 mov (%di),%ax C3 ret 8B 05 Car: mov (%di),%ax C3 ret  \n  \n---|---  \n  \n## Optimizing Printf\n\nOne of the issues with printf() from a size coding perspective, is it pulls in\na lot of heavy-weight dependencies:\n\n  * gdtoa is needed to format double and long double via %f, %g, etc. There's so much depth (and potentially memory allocation) when it comes to formatting floating point. As such, linking gdtoa adds about 32kb to the binary size.\n  * In order to format width-aligned strings (via %*s etc.) in a way that supports UNICODE, we need the CJK wides table, which lets us know if a character in the terminal takes up two cells. Some such examples of variable width monospace would be Emoji and Chinese.\n  * Formatting the GNU %m directive for strerror() is a little more costly with Cosmopolitan, because we use symbols rather than defines for system magic numbers. Therefore strerror() needs to yoink all the errnos at once. It also needs to embed a bunch of error string and tools for obtaining them via the WIN32 API. It adds about ~8k to the binary size.\n\nYet somehow, despite all the bloat in printf(), binaries that casually link it\n(e.g. examples/hello3.c) can be as small as 24kb in size. This is thanks to\nthe PFLINK() macro.\n\n    \n    \n    /* see libc/fmt/pflink.h */ /* see libc/stdio/stdio.h */ #define printf(FMT, ...) (printf)(PFLINK(FMT), ##__VA_ARGS__) #define PFLINK(...) _PFLINK(__VA_ARGS__) #define _PFLINK(FMT, ...) \\ ({ \\ if (___PFLINK(FMT, strpbrk, \"faAeg\")) STATIC_YOINK(\"__fmt_dtoa\"); \\ if (___PFLINK(FMT, strpbrk, \"cmrqs\")) { \\ if (___PFLINK(FMT, strstr, \"%m\")) STATIC_YOINK(\"strerror\"); \\ if (!IsTiny() && (___PFLINK(FMT, strstr, \"%*\") || \\ ___PFLINK(FMT, strpbrk, \"0123456789\"))) { \\ STATIC_YOINK(\"strnwidth\"); \\ STATIC_YOINK(\"strnwidth16\"); \\ STATIC_YOINK(\"wcsnwidth\"); \\ } \\ } \\ FMT; \\ }) #define ___PFLINK(FMT, FN, C) \\ !__builtin_constant_p(FMT) || ((FMT) && __builtin_##FN(FMT, C) != NULL)\n\nThis only works with GCC and not Clang. It works because the first argument to\nprintf() is almost always a string literal, and GCC is smart enough to run\nfunctions like __builtin_strstr() at compile time, sort of like a C++\nconstexpr. Once GCC has identified that we need a heavyweight feature, it then\ndoes what we call \"yoinking\" the appropriate symbol.\n\nHere's how yoinking works. There's a trick with ELF binaries called weak\nlinking. The printf() implementation has code like this:\n\n    \n    \n    case 'm': p = weaken(strerror) ? weaken(strerror)(lasterr) : \"?\"; signbit = 0; goto FormatString;\n\nWhen a function is weakened, then it won't get pulled into the final binary\nunless some other module references it the strong or normal way. Yoinking is\none way to do that. However yoinking is intended for the special situation\nwhere don't have any code that actually uses the symbol, but we still want to\npull it into the binary.\n\n    \n    \n    .section .yoink nopl symbol .previous\n\nSo what we do with the yoink macro is is generate a reference inside a section\nthat's explicitly discarded by the linker script.\n\n    \n    \n    /DISCARD/ : { *(.yoink) }\n\nSo even though that reference is ultimately discarded, it's still enough to\ncause ld.bfd to pull the referenced module into the final binary.\n\nThis isn't a perfect technique, even though it's a worthwhile one. Large\nprograms will implicitly yoink everything on a long enough timeline. So for\nbig programs, this isn't a problem. But it's sometimes necessary for tiny\nprograms to help the linker out explicitly. For example, you may be committing\nthe security sin of using non-literal format strings. In that case the macro\nmagic will cause everything to be yoinked, since it has no visibility into the\nstring at compile time. If you still want to stay on the tinier side, then you\ncan disable the magic by calling printf() as such:\n\n    \n    \n    (printf)(\"last error is %m\\n\");\n\nThen, any features you need which are listed in the PFLINK() macro can be\nyoinked explicitly by your main() module.\n\n    \n    \n    STATIC_YOINK(\"strerror\");\n\n## Tiny Portable ELF\n\nPlease take a look at the How Fat Does a Fat Binary Need To Be? page which\nlets you interactively build online Cosmopolitan Actually Portable Executable\nbinaries. As we can see, features like SUPPORT_VECTOR provide all the power\nand configurability any user should need, to make their programs as tiny as\nthey want them to be.\n\nBut let's say for a moment you only cared about ELF targets like Linux,\nFreeBSD, NetBSD, and OpenBSD. Let's furthermore imagine that you wanted to\nbuild a binary that runs on all four of these operating systems, from scratch,\nwithout the assistance of APE and Cosmo. It turns out that's relatively easy\nto do, and this section will show you how it works. What's also cool is that\nit's only 386 bytes in size, using an idiomatic best practices approach.\n\nThroughout the history of computing, it's been convention that each operating\nsystems should provide its own tools that let you build software for the\nplatform. This made sense in the past, since operating systems were usually\nbuilt by the same companies that designed the microprocessors on which they\noperated. Things changed in recent decades. As of August 2022, 485 out of the\nTop 500 supercomputers run x86-64. The x86 architecture also represents the\nlion's share of personal computers and backend servers. Yet, due to tradition,\nprogrammers still believe that if we want to release an app for four different\noperating systems, we need to build four separate binaries. That doesn't make\nsense anymore, because all four binaries share the same architecture.\n\nFor example, let's say you build the following function:\n\n    \n    \n    int add(int x, int y) { return x + y; }\n\nThe output of your compiler should be the same, regardless of whether you're\nrunning on Linux, FreeBSD, NetBSD, or OpenBSD:\n\n    \n    \n    add: lea (%rdi,%rsi,1),%eax ret\n\nSo why doesn't something like a Linux binary run out of the box on other\nsystems like OpenBSD? There are a few reasons. First, the ELF format itself\nrequires us to specify the OS ABI (convention for how functions interact at a\nbinary/register level). Fortunately we can get around this by just setting it\nto the FreeBSD ABI. This is because FreeBSD is the only UNIX operating system\nthat checks this field. It turned out that NetBSD and OpenBSD check for binary\ncompatibility using a separate ELF PT_NOTE data structure instead. As for\nLinux, it just doesn't care. So it turns out, if we say it's a FreeBSD binary,\nand we put the NetBSD and OpenBSD notes in there too, then our binary will run\non all four.\n\nThere's a few other minor differences in how the operating systems interpret\nELF fields. For example, PT_LOAD is used to tell the operating system which\nparts of the executable file should be loaded into memory, and at which\naddresses they should reside. These PT_LOAD segments are allowed to have a\nsize of zero, in terms of the file. That's basically equivelent to allocating\nzero'd memory. However if the size in memory is zero too, then OpenBSD will\nrefuse to run the progarm, whereas the other kernels just don't care.\n\nThe executable header incantations below are designed to walk the narrow path\nthat meets the intersection of requirements for all four operating systems.\nThey'll then load our identical x86 code into memory, and run it.\n\n    \n    \n    /* reallytiny-elf.S */ #define ELFCLASS64 2 #define ELFDATA2LSB 1 #define ELFOSABI_FREEBSD 9 #define ET_EXEC 2 #define EM_NEXGEN32E 62 #define PT_LOAD 1 #define PT_NOTE 4 #define PF_X 1 #define PF_W 2 #define PF_R 4 .align 8 ehdr: .ascii \"\\177ELF\" .byte ELFCLASS64 .byte ELFDATA2LSB .byte 1 .byte ELFOSABI_FREEBSD .quad 0 .word ET_EXEC # e_type .word EM_NEXGEN32E # e_machine .long 1 # e_version .quad _start # e_entry .quad phdrs - ehdr # e_phoff .quad 0 # e_shoff .long 0 # e_flags .word 64 # e_ehsize .word 56 # e_phentsize .word 2 # e_phnum .word 0 # e_shentsize .word 0 # e_shnum .word 0 # e_shstrndx .globl ehdr .align 8 phdrs: .long PT_LOAD # p_type .long PF_R|PF_X # p_flags .quad 0 # p_offset .quad ehdr # p_vaddr .quad ehdr # p_paddr .quad filesz # p_filesz .quad filesz # p_memsz .quad 64 # p_align #if 0 // will break openbsd unless we actually use bss .long PT_LOAD # p_type .long PF_R|PF_W # p_flags .quad 0 # p_offset .quad bss # p_vaddr .quad bss # p_paddr .quad 0 # p_filesz .quad bsssize # p_memsz .quad 64 # p_align #endif .long PT_NOTE # p_type .long PF_R # p_flags .quad note - ehdr # p_offset .quad note # p_vaddr .quad note # p_paddr .quad notesize # p_filesz .quad notesize # p_memsz .quad 8 # p_align note: .long 2f-1f .long 4f-3f .long 1 1: .asciz \"OpenBSD\" 2: .align 4 3: .long 0 4: .long 2f-1f .long 4f-3f .long 1 1: .asciz \"NetBSD\" 2: .align 4 3: .long 901000000 4: notesize = . - note _start: mov %rsp,%rsi jmp Start .globl _start\n\nAt that point we can just put our code in the Start() function and it'll work!\nBut a second issue occurs when we actually want to print the result.\n\nTo print a string on UNIX systems, we must invoke the int write(fd, data,\nsize) system call, where fd is normally specified as 1, which means standard\noutput. Once again, due to the similarities of the post-shakeout operating\nsystem landscape, all four systems happen to implement the exact same\nfunction. However, in order to actually call it, there's another number we\nmust specify that exists beneath the iceberg of what we see in terms of C\ncode. That number is the system call magic number, or \"magnum\", and it's part\nof what's known as the Application Binary Interface (ABI). Unfortunately,\noperating systems don't agree on magnums. For example, on Linux write() is 1,\nbut on the BSDs it's 4. So if we ran Linux's write() on BSD, it would actually\ncall exit() \u2013 not what we want!\n\nUNIX SYSCALL Magnums (x86-64)  \n---  \nFunction| Linux| FreeBSD| OpenBSD| NetBSD  \nexit| 60| 1| 1| 1  \nfork| 57| 2| 2| 2  \nread| 0| 3| 3| 3  \nwrite| 1| 4| 4| 4  \nopen| 2| 5| 5| 5  \nclose| 3| 6| 6| 6  \nstat| 4| n/a| 38| 439  \nfstat| 5| 551| 53| 440  \npoll| 7| 209| 252| 209  \n  \nYou'll notice there's a subset of numbers on which all systems agree,\nparticularly among the BSDs. Those tend to be the really old functions that\nwere designed for the original UNIX operating system written at Bell Labs. In\nfact, numbers such as 1 for exit() were copied straight out of the Bell System\nFive codebase. That's why we call it the System V Application Binary\nInterface. There even used to be more consensus if we look at past editions.\n\nUNIX SYSCALL Magnums (i386)  \n---  \nFunction| Linux| FreeBSD| OpenBSD| NetBSD  \nexit| 1| 1| 1| 1  \nfork| 2| 2| 2| 2  \nread| 3| 3| 3| 3  \nwrite| 4| 4| 4| 4  \nopen| 5| 5| 5| 5  \nclose| 6| 6| 6| 6  \nstat| 18| n/a| 38| 439  \nfstat| 108| 551| 53| 440  \npoll| 168| 209| 252| 209  \n  \nSo in order to know which magnum to use, we need some way of detecting the\nx86-64 OS at runtime. There's many ways of doing this. For example, we could\nsearch for a magnum where we pass invalid parameters and then tell the systems\napart by the returned error code. However system calls are costly, taking\nupwards of a microsecond to execute, rather than nanoseconds like ordinary\nfunctions. So we'll be showing a different technique below, which detects the\noperating system based entirely on values that've already been passed to us by\nthe operating system when it loaded our executable.\n\n    \n    \n    /* reallytiny.c */ #define LINUX 1 #define OPENBSD 16 #define FREEBSD 32 #define NETBSD 64 #ifndef SUPPORT_VECTOR #define SUPPORT_VECTOR (LINUX | FREEBSD | NETBSD | OPENBSD) #endif #define SupportsLinux() (SUPPORT_VECTOR & LINUX) #define SupportsFreebsd() (SUPPORT_VECTOR & FREEBSD) #define SupportsOpenbsd() (SUPPORT_VECTOR & OPENBSD) #define SupportsNetbsd() (SUPPORT_VECTOR & NETBSD) #define IsLinux() (SupportsLinux() && os == LINUX) #define IsFreebsd() (SupportsFreebsd() && os == FREEBSD) #define IsOpenbsd() (SupportsOpenbsd() && os == OPENBSD) #define IsNetbsd() (SupportsNetbsd() && os == NETBSD) __attribute__((__noreturn__)) static void Exit(int rc, int os) { asm volatile(\"syscall\" : /* no outputs */ : \"a\"(IsLinux() ? 60 : 1), \"D\"(rc) : \"memory\"); __builtin_unreachable(); } static int Write(int fd, const void *data, int size, int os) { char cf; int ax, dx; asm volatile(\"clc\\n\\t\" \"syscall\" : \"=a\"(ax), \"=d\"(dx), \"=@ccc\"(cf) : \"0\"(IsLinux() ? 1 : 4), \"D\"(fd), \"S\"(data), \"1\"(size) : \"rcx\", \"r11\", \"r8\", \"r9\", \"r10\", \"memory\", \"cc\"); if (cf) ax = -ax; return ax; } static int Main(int argc, char **argv, char **envp, long *auxv, int os) { Write(1, \"hello world\\n\", 12, os); return 0; } __attribute__((__noreturn__)) void Start(long di, long *sp) { long *auxv; int i, os, argc; char **argv, **envp, *page; // detect freebsd if (SupportsFreebsd() && di) { os = FREEBSD; sp = (long *)di; } else { os = 0; } // extract arguments argc = *sp; argv = (char **)(sp + 1); envp = (char **)(sp + 1 + argc + 1); auxv = (long *)(sp + 1 + argc + 1); for (;;) { if (!*auxv++) { break; } } // detect openbsd if (SupportsOpenbsd() && !os && !auxv[0]) { os = OPENBSD; } // detect netbsd if (SupportsNetbsd() && !os) { for (; auxv[0]; auxv += 2) { if (auxv[0] == 2014 /* AT_EXECFN */) { os = NETBSD; break; } } } // default operating system if (!os) { os = LINUX; } Exit(Main(argc, argv, envp, auxv, os), os); }\n\nFreeBSD likes to have %RDI (which means first parameter in System V ABI) be\nthe same as %RSP on initialization. That's because they prefer C code, and\ndon't want to require that people write the assembly thunk we did earlier,\nthat moves the %RSP register and jumps to the real entrypoint. On the other\noperating systems, %RDI is always zero.\n\nWe then have to scrape the real parameters to our function off the stack.\nThat's because x86-64 _start() is a weird function that still follows the old\ni386 ABI, which passed parameters on the stack (rather than in registers). Now\nwe have argc, argv, and environ.\n\nHowever there's a little known fourth parameter to C programs, called auxv,\nwhich is short for auxiliary values. OpenBSD never implemented this feature,\nso if they're not there, then we know it's OpenBSD. As for NetBSD, we know it\nalways passes auxiliary values with much larger magnums than any other system,\nso by testing the values, we can tell NetBSD apart from Linux. Then we're\ndone! We can now issues SYSCALLs.\n\nBut there's one more minor problem. BSDs don't conform to the System V ABI\ndocumentation, which says that error numbers should be returned by the kernel\nas a negative number. BSDs instead follow the the 386BSD convention of using\nthe carry flag to indicate that RAX contains an error code instead of a\nresult. Since we know that Linux always saves and restores the EFLAGS register\nduring SYSCALL, all we have to do is use CLC to clear the carry flag before\nusing SYSCALL. Then we know for certain that if the carry flag is set\nafterwards, that it's BSD and the SYSCALL failed, in which case we just flip\nthe sign to make the result conform to System V.\n\nThere's some other quirks too. In our inline asm notation, we tell GCC that\nthe the RDX register may be clobbered. This can only happen on XNU and NetBSD,\nbut never on Linux, and highly unlikely on the other ones. FreeBSD usually\nclobbers R8, R9, and R10. It's generally best to assume with BSDs that they\nwant you to wrap SYSCALL with a function call, so the call-clobbered register\nrule applies, i.e. RAX, RCX, RDX, RDI, RSI, R8, R9, R10, and R11 are volatile.\nBSDs system calls in some cases might even accept parameters on the stack,\nwhereas Linux never uses more than six parameters, all of which go in the\nregisters RDI, RSI, RDX, R10, R8, and R9.\n\nNow that we've written all our code, we need a linker script to glue our C and\nassembly code together into a simple binary file, that doesn't have any of the\nplatform-specific boilerplate.\n\n    \n    \n    /* reallytiny.lds */ ENTRY(_start) SECTIONS { . = 0x400000; .text : { *(.text) *(.rodata .rodata.*) } filesz = . - ehdr; textsz = . - _start; .bss ALIGN(4096) : { bss = .; *(.bss) . = ALIGN(4096); } memsz = . - ehdr; /DISCARD/ : { *(.*) } } bsssize = SIZEOF(.bss); textoff = _start - ehdr;\n\nYou can then build your program as such:\n\n    \n    \n    gcc -static -no-pie -g -Os \\ -o reallytiny.elf.dbg \\ -Wl,-T,reallytiny.lds \\ reallytiny-elf.S \\ reallytiny.c objcopy -S -O binary \\ reallytiny.elf.dbg \\ reallytiny.elf\n\nHere's your binary visualized:\n\nHere's what happens when you run it:\n\n    \n    \n    linux$ ./reallytiny.elf hello world freebsd$ ./reallytiny.elf hello world netbsd$ ./reallytiny.elf hello world openbsd$ ./reallytiny.elf hello world\n\nFour operating systems is under 400 bytes is pretty good!\n\nYou may also download the examples above in the following files:\n\n  * reallytiny-elf.S\n  * reallytiny.c\n  * reallytiny.lds\n\n## Funding\n\nFunding for this blog post was crowdsourced from Justine Tunney's GitHub\nsponsors and Patreon subscribers. Your support is what makes projects like\nCosmopolitan Libc possible. Thank you.\n\n## See Also\n\n  * cosmopolitan libc\n  * justine's web page\n\ntwitter.com/justinetunney\n\ngithub.com/jart\n\nWritten by Justine Tunney\n\njtunney@gmail.com\n\n", "frontpage": false}
