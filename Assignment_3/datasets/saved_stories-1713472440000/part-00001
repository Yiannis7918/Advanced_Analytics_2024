{"aid": "40076702", "title": "Llama 3 8B and 70B pricing on replicate, also on Azure", "url": "https://replicate.com/pricing", "domain": "replicate.com", "votes": 6, "user": "ibaikov", "posted_at": "2024-04-18 14:32:36", "comments": 2, "source_title": "Pricing \u2013 Replicate", "source_text": "Pricing \u2013 Replicate\n\n## Pricing\n\nYou only pay for what you use on Replicate, billed by the second. When you\ndon\u2019t run anything, it scales to zero and you don\u2019t pay a thing.\n\nHardware| Price| GPU| CPU| GPU RAM| RAM  \n---|---|---|---|---|---  \nCPU| $0.000100/sec ($0.36/hr)| -| 4x| -| 8GB  \nNvidia T4 GPU| $0.000225/sec ($0.81/hr)| 1x| 4x| 16GB| 16GB  \nNvidia A40 GPU| $0.000575/sec ($2.07/hr)| 1x| 4x| 48GB| 16GB  \nNvidia A40 (Large) GPU| $0.000725/sec ($2.61/hr)| 1x| 10x| 48GB| 72GB  \nNvidia A100 (40GB) GPU| $0.001150/sec ($4.14/hr)| 1x| 10x| 40GB| 72GB  \nNvidia A100 (80GB) GPU| $0.001400/sec ($5.04/hr)| 1x| 10x| 80GB| 144GB  \n8x Nvidia A40 (Large) GPU| $0.005800/sec ($20.88/hr)| 8x| 48x| 8x 48GB| 680GB  \n  \nIf you\u2019re new to Replicate, you can try us out for free, but eventually you\u2019ll\nneed to enter a credit card.\n\n#### Public models\n\nThousands of open-source machine learning models have been contributed by our\ncommunity and more are added every day. When running or training one of these\nmodels, you only pay for time it takes to process your request.\n\nEach model runs on different hardware and takes a different amount of time to\nrun. You\u2019ll find estimates for how much they cost under \"Run time and cost\" on\nthe model\u2019s page. For example, for stability-ai/sdxl:\n\nThis model costs approximately $0.012 to run on Replicate, but this varies\ndepending on your inputs.\n\nPredictions run on Nvidia A40 (Large) GPU hardware, which costs $0.000725 per\nsecond. Predictions typically complete within 17 seconds.\n\n#### Language models\n\nReplicate hosts a selection of language models, including Llama 2 and Mistral,\nwhich are priced per token.\n\nModel| Input| Output  \n---|---|---  \nmeta/llama-2-70b| $0.65 / 1M tokens| $2.75 / 1M tokens  \nmeta/llama-2-13b| $0.10 / 1M tokens| $0.50 / 1M tokens  \nmeta/llama-2-7b| $0.05 / 1M tokens| $0.25 / 1M tokens  \nmeta/llama-2-70b-chat| $0.65 / 1M tokens| $2.75 / 1M tokens  \nmeta/llama-2-13b-chat| $0.10 / 1M tokens| $0.50 / 1M tokens  \nmeta/llama-2-7b-chat| $0.05 / 1M tokens| $0.25 / 1M tokens  \nmistralai/mistral-7b-v0.1| $0.05 / 1M tokens| $0.25 / 1M tokens  \nmistralai/mistral-7b-instruct-v0.2| $0.05 / 1M tokens| $0.25 / 1M tokens  \nmistralai/mixtral-8x7b-instruct-v0.1| $0.30 / 1M tokens| $1.00 / 1M tokens  \n  \nCheck out our docs for more information about how per-token pricing works on\nReplicate.\n\n#### Private models\n\nYou aren\u2019t limited to the public models on Replicate: you can deploy your own\ncustom models using Cog, our open-source tool for packaging machine learning\nmodels.\n\nWe automatically generate an API server for your model and deploy it on a big\ncluster of GPUs. If you get a ton of traffic, we automatically scale to handle\nthe demand. If you don\u2019t get any traffic, we scale down to zero and don\u2019t\ncharge you a thing.\n\nUnlike public models, you\u2019ll pay for setup and idle time in addition to the\ntime it spends processing your requests.\n\n#### Learn more\n\nFor a deeper dive, check out how billing works on Replicate.\n\n#### \ud83d\ude80 Ready to use Replicate for real?\n\nExplore models to run or learn how to deploy a custom model.\n\nReplicate\n\nAbout Guides Terms Privacy Status GitHub X Discord Support\n\n", "frontpage": false}
