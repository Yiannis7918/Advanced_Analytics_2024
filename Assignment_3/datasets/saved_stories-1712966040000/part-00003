{"aid": "40015681", "title": "Comparing Multiple Large Language Models in One Pass", "url": "https://dezoito.github.io/2024/03/28/comparing-from-multiple-LLMs.html", "domain": "dezoito.github.io", "votes": 2, "user": "dezoito", "posted_at": "2024-04-12 17:53:01", "comments": 0, "source_title": "Comparing Multiple Large Language Models in one Pass \u00b7 Analyst 18", "source_text": "Comparing Multiple Large Language Models in one Pass \u00b7 Analyst 18\n\nArticles on web-centric development that may or may not be related to\nIntelligence Analysis software.\n\n\u00a9 2024. All rights reserved.\n\n### Analyst 18 Software Engineering and other random() subjects\n\n# Comparing Multiple Large Language Models in one Pass\n\n28 Mar 2024\n\nThis article aims to demonstrate how Ollama Grid Search can streamline the\nprocess of comparing and selecting Large Language Models (LLMs) for various\ntasks and provide answers to common questions such as:\n\n> What is the best model for for story telling?\n\n> I want to use LLMs to generate RPG scripts, which model should I use?\n\n## Getting started\n\nThe automation process we propose requires a few moving parts:\n\n  * Ollama installed and running (either on localhost or on a server the user has access to).\n  * Ollama Grid Search needs to be installed in the users machine.\n\nBoth dependencies above are free and can be installed in all major platforms.\n\nFinally:\n\n  * The models for comparison need to have been pulled into the Ollama server.\n\n## Running tests\n\n### UPDATE:\n\n> As of v0.0.3, Ollama Grid Search lets you generate multiple responses for\n> each single combination of parameters!\n\nIn this example, I\u2019m building a RAG Fusion agent, and I need to decide between\nthree models, which is the best at generating alternative, complementary\nqueries to a prompt such as:\n\n    \n    \n    Consider the initial prompt: \"List the most relevant information we have on John Doe\". The person above may or may not be connected to criminal activities. Write a list of three concise prompts that can complement the query above.\n\nOllama Grid Search is a Large Large Language Model testing desktop\napplication. It lets us select the models we want to use, from a list of those\ninstalled on the server:\n\nAfter selecting the three models above, we can enter the prompt:\n\nWe can also click on the \u201cgear icon\u201d and use the \u201csettings\u201d options to set a\ncustom system prompt:\n\nSkip the temptation of messing with other parameters and hit \u201cStart\nExperiment\u201d.\n\nThe software will send the prompt (along with the system prompt and default\ninference paramenter) to each of the selected models sequentially and present\nan output similar to:\n\n    \n    \n    1/3 - gemma:2b-instruct Sure, here are three complementary prompts that can be used to gather more relevant information about John Doe: 1. **What are John Doe's known affiliations and social media presence?** 2. **What are John Doe's past criminal records and legal cases?** 3. **What are John Doe's current whereabouts and living conditions?**\n    \n    \n    2/3 - starling-lm:7b 1. \"Determine if John Doe has any known affiliations with criminal organizations.\" 2. \"Investigate John Doe's financial and employment history for irregularities.\" 3. \"Analyze John Doe's online presence and social media activity for potential threats or suspicious behavior.\"<|end_of_turn|>\n    \n    \n    3/3 - tinydolphin:1.1b-v2.8-q4_0 1. Who is John Doe, and what are his primary areas of interest? 2. What sources of information do you have on John's activities? 3. What conclusions can we draw from the available data regarding John's involvement in criminal activities?<|im_end|>\n\nAt first glance all results look pretty good!\n\nBut if we click on the \"Expand Inference metadata\" option (or in \"Results\nMetadata\", below each result), we can get a little more insight on how each\nmodel performed:\n\n    \n    \n    1/3 - gemma:2b-instruct ... Created at: Thu, 28 Mar 2024 18:52:35 GMT Eval Count: 74 tokens Eval Duration: 0 hours, 0 minutes, 8 seconds Total Duration: 0 hours, 0 minutes, 13 seconds Throughput: 5.64 tokens/s\n    \n    \n    2/3 - starling-lm:7b ... Created at: Thu, 28 Mar 2024 18:52:57 GMT Eval Count: 65 tokens Eval Duration: 0 hours, 0 minutes, 12 seconds Total Duration: 0 hours, 0 minutes, 21 seconds Throughput: 3.04 tokens/s\n    \n    \n    3/3 - tinydolphin:1.1b-v2.8-q4_0 ... Created at: Thu, 28 Mar 2024 18:53:01 GMT Eval Count: 58 tokens Eval Duration: 0 hours, 0 minutes, 2 seconds Total Duration: 0 hours, 0 minutes, 4 seconds Throughput: 13.29 tokens/s\n\nFor this particular experiment, tinydolphin\u2019s throughput (the rate at which\nthe model produces output) was 3 to 5x higher than the other models, while\nstill delivering competitive results!\n\n## Running a lot more tests\n\nBut what if the results above were just a fluke?\n\nOllama Grid Search gives us the option of re-running iterations or\nexperiments, but we can also set multiple combinations of parameters.\n\nLet\u2019s make the following changes:\n\n  * set Temperature List to 0.5, 0.7\n  * set Repeat Penalty List to 1.1, 1.5\n  * set Top_K List to 20,40\n\nThat\u2019s 2 x 2 x 2 combinations of parameters for each of the 3 selected models,\nso we can expect 24 iterations for this new experiment.\n\nHit the \u201cStart Experiment\u201d button, optionally go get a cup of coffee, and wait\nfor all iterations to run:\n\nAfter inspecting the results we can see that throughput for all models stays\nconsistent, but the quality and length of the output varies quite a lot,\ndepending on the parameter combination selected for each iteration.\n\nStarling-lm:7b, for example, returned some really verbose output:\n\nFor most combinations, however, Tinydolphin:1.1b-v2.8-q4_0 still returns good\nresponses while remaining the fastest model!\n\nWe could now perform similar tests using a different prompt, or focus on that\nsingle model and perform a \u201cgrid search\u201d experiment to determine its optimal\ncombination of parameters (as discussed in Grid Search on Large Language\nModels using Ollama and Rust).\n\n## Conclusion\n\nManually testing multiple models can be a time drain and produce confusing\nresults... there must be a method to the madness (this is a whisky reference,\nby the way)!\n\nAn automation tool like Ollama Grid Search helps us perform dozens of\niterations in a single run, allowing us to see not only how models compare to\neach other, but also how they behave under a range of different parameters.\n\nWhen we are pretty sure to have \u201cwinner\u201d model, \u201cgrid search\u201d experiments can\nbe used to determine what set of parameters produces the best output for that\nmodel, and again save us from the hell of manual experiments.\n\n## Related Posts\n\n  * ### Limited Concurrency for Multiple API calls in React 21 Mar 2024\n\n  * ### Grid Search on Large Language Models using Ollama and Rust 27 Dec 2023\n\n  * ### Rust Todo SQL Example Application 01 Nov 2023\n\n", "frontpage": false}
