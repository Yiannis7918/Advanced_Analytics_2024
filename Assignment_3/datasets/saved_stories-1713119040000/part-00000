{"aid": "40030620", "title": "Instructions Is All You Need: Why AI agents need custom programming languages", "url": "https://blog.lemeb.net/articles/24/Instructions-is-All-You-Need", "domain": "lemeb.net", "votes": 1, "user": "mebazaa", "posted_at": "2024-04-14 12:21:14", "comments": 0, "source_title": "When LLMs meet DSLs", "source_text": "When LLMs meet DSLs\n\nApril 14, 2024 L\u00e9opold Mebazaa\n\n## Instructions is all you need\n\n# When LLMs meet DSLs\n\n## AI agents may need custom programming languages to succeed\n\nAI agents promise a future where repetitive tasks that are traditionally\nperformed manually are automated. But, in the present, these agents are slow,\nclunky, and error-prone. Why is that?\n\nSome believe the current failures of AI agents will disappear as LLMs increase\nin size and reliability. I suspect that won\u2019t be sufficient: AI agents, as\nthey\u2019re designed today, are conceptually flawed.\n\n### The impasse of the \u201cChoose Your Own Adventure\u201d agents\n\nFor those familiar, there are two main types of AI agents. I refer to the\nfirst type as a \u201cChoose Your Own Adventure\u201d agent. One seminal example would\nbe natbot \u2013 which is a CYOA agent that controls the web browser. There have\nbeen many successors to natbot, but the core mechanics tend to stay the same.\n\nCYOA agents require the user, at the outset, to provide a series of actions,\nsuch as clicking, scrolling, or typing, that the agent will use to accomplish\nthe prompted task. At each step, the agent chooses one of these actions until\nit succeeds. For example, one could request the CYOA agent to book a flight\nbetween San Francisco and Hawaii. The agent would work by selecting one of the\npredefined actions at every step (in this case, on every page), until the\nplane ticket is booked and the task is deemed accomplished.\n\nWhile these agents are quite impressive, they have not proven to be useful.\nWhy not?\n\nFirst, CYOA agents are inefficient. These agents, in general, take several\nseconds to decide on the best course of action. Performing the same tasks\nmanually is faster, especially given how error-prone these agents still are.\n\nMoreover, CYOA agents are not designed for repetition. Automating tasks is\nonly useful if one can repeat actions efficiently. Unfortunately, there has\nbeen very little development in this area. Currently, execution of the same\ntask requires the user to ask the CYOA the same thing, every time. This is a\nlengthy and expensive process, even if the agent is successful every time. As\nit stands, at scale, writing a script is still cheaper and more efficient.\n\nFinally, CYOA agents don\u2019t model complex behavior. They are designed to mimic\nhuman behavior, and can thus only execute a sequence of actions. This means\nthey don\u2019t handle things like loops or control flow.\n\n### The perils of code-generating agents\n\nThe second type of AI agents are those that generate code (e.g. Python) before\nexecuting it. Currently, the most ubiquitous code-generating agent is OpenAI\u2019s\nCode Interpreter. Code Interpreter is generally used for math and data\nanalysis, but it can do many other tasks.\n\nCode-generating agents are theoretically more powerful than CYOA agents\nbecause they are not limited to performing a series of predefined actions. But\nthese agents also present significant problems.\n\nFirst, code-generating agents do not have enough formal guardrails. Code that\nis written and executed by AI with little human supervision presents the\npossibility of a security disaster. While OpenAI\u2019s Code Interpreter operates\nwithin the confines of some guardrails, other code-generating agents might not\ndo so.\n\nGuardrails around AI agents are essential for more than simply preventing a\nrogue AI. For example, companies that wish to automate their customer service\nsystems will want to ensure that these agents comply with all of the company\u2019s\ninternal policies. Code-generating agents will therefore not be widely adopted\nwithout strong guarantees of formal guardrails. Agents that freestyle in\nPython simply cannot promise these guarantees.\n\nSecondly, code-generating agents, like CYOA agents, are inefficient. Take the\nexample of web browsing. Code that is intended to scrape and crawl websites\nusually consists of hundreds of lines or more. Large parts of that code are\nboilerplate and unoptimized, not to mention unsafe. And because the first pass\nof code is often rife with error, the process of correcting it through trial\nand error becomes long and costly. Using Code Interpreter through OpenAIs API\ncurrently costs five cents per session.\n\nThirdly, bigger and better code-generating models might in fact create new\nproblems. As AI code-generating agents advance, we may reach a point where\nthese agents produce so much code that manual review becomes all but\nimpossible. This problem will exist even if formal guardrails are implemented,\nand even if these LLMs are able to produce safe, optimized code on the cheap.\nTraditional programming languages might not be the right tool for agents to\ncode in, as they will produce code that is too long for human review.\n\n### Why custom programming languages might be the missing piece\n\nI think that AI agents might be improved with the introduction of domain-\nspecific programming languages (DSLs). More specifically, there should be a\ncollection of domain-focused DSLs that can be used for whatever agent is\ntasked.\n\nAn agent that would generate code in a DSL would synthesize both types of\nagents in the following way:\n\n  * Is the agent fast and efficient?\n\n    * CYOA: No, because the agent can only perform one action at a time.\n    * Code generating: No, because code is not functional, full of errors, too long, and too expensive and time consuming to fix.\n    * DSL: Yes, because it would iterate on concise, domain-specific code.\n  * Is the agent able to model complex behavior?\n\n    * CYOA: No (again, the agent can only perform one action at a time).\n    * Code generating: Yes, because it can generate arbitrary code.\n    * DSL: Yes, because a DSL is code-like (i.e. has control flow)\n  * Does the agent have formal guardrails?\n\n    * CYOA: Yes, because only predefined actions are executed.\n    * Code generating: No (or at least, not in any sufficient capacity)\n    * DSL: Yes, because the design of the DSL can be controlled.\n  * Is the agent designed for repeatability?\n\n    * CYOA: No, as they require repeated prompting every time.\n    * Code generating: Yes, as it generates code that can be executed later.\n    * DSL: Yes, as it generates code that can be executed later.\n  * Does the agent generate code that is easy to review?\n\n    * CYOA: Yes, as long as you consider the actions to be code.\n    * Code generating: No, because the code could be too long/verbose/specialized.\n    * DSL: Yes, because the code would probably be easier to read and debug.\n\nOver the past decades, as the need to understand the internal workings of the\ncomputer has declined, computer programming has become far more abstract. We\nwent from zeros and ones to assembly to C to Python. Many settled on the\nlatter because it is a good choice for manually written code that is\nreviewable by others. As we enter a new era with AI, we might need to reach a\nnew level: DSLs for AI-written code that is reviewable by the rest of us. And\nI\u2019m working for Columbia University until this fall to build precisely that.\n\nIf you want to chat \u2013 My email is lemeb \u2018at\u2019 this domain.\n\nThanks to Natasha Esponda, Fred Kjolstad, Alex Ozdemir, Eric Pennington, and\nMichael V\u00f6lske for their feedback.\n\n", "frontpage": false}
