{"aid": "40030071", "title": "Containernet: Use Docker containers as hosts in Mininet emulations", "url": "https://containernet.github.io/", "domain": "containernet.github.io", "votes": 1, "user": "teleforce", "posted_at": "2024-04-14 10:18:53", "comments": 0, "source_title": "Containernet", "source_text": "Containernet | Use Docker containers as hosts in Mininet emulations.\n\n# Containernet\n\n## Use Docker containers as hosts in Mininet emulations.\n\nInstallation Get started Documentation Research GitHub\n\nContainernet is a fork of the famous Mininet network emulator and allows to\nuse Docker containers as hosts in emulated network topologies. This enables\ninteresting functionalities to build networking/cloud emulators and testbeds.\nContainernet is actively used by the research community, focussing on\nexperiments in the field of cloud computing, fog computing, network function\nvirtualization (NFV) and multi-access edge computing (MEC). One example for\nthis is the NFV multi-PoP infrastructure emulator which was created by the\nSONATA-NFV project and is now part of the OpenSource MANO (OSM) project.\n\n## Features\n\n  * Add, remove Docker containers to Mininet topologies\n  * Connect Docker containers to topology (to switches, other containers, or legacy Mininet hosts)\n  * Execute commands inside containers by using the Mininet CLI\n  * Dynamic topology changes\n\n    * Add hosts/containers to a running Mininet topology\n    * Connect hosts/docker containers to a running Mininet topology\n    * Remove Hosts/Docker containers/links from a running Mininet topology\n  * Resource limitation of Docker containers\n\n    * CPU limitation with Docker CPU share option\n    * CPU limitation with Docker CFS period/quota options\n    * Memory/swap limitation\n    * Change CPU/mem limitations at runtime!\n  * Expose container ports and set environment variables of containers through Python API\n  * Traffic control links (delay, bw, loss, jitter)\n  * Automated installation based on Ansible playbook\n\n## Installation\n\nContainernet comes with two installation and deployment options.\n\n### Option 1: Bare-metal installation\n\nThis option is the most flexible. Your machine should run Ubuntu 20.04 LTS and\nPython3.\n\nFirst install Ansible:\n\n    \n    \n    sudo apt-get install ansible\n\nThen clone the repository:\n\n    \n    \n    git clone https://github.com/containernet/containernet.git\n\nFinally run the Ansible playbook to install required dependencies:\n\n    \n    \n    sudo ansible-playbook -i \"localhost,\" -c local containernet/ansible/install.yml\n\nAfter the installation finishes, you should be able to get started.\n\n### Option 2: Nested Docker deployment\n\nContainernet can be executed within a privileged Docker container (nested\ncontainer deployment). There is also a pre-build Docker image available on\nDocker Hub.\n\nAttention: Container resource limitations, e.g. CPU share limits, are not\nsupported in the nested container deployment. Use bare-metal installations if\nyou need those features.\n\nYou can build the container locally:\n\n    \n    \n    docker build -t containernet/containernet .\n\nor alternatively pull the latest pre-build container:\n\n    \n    \n    docker pull containernet/containernet\n\nYou can then directly start the default containernet example:\n\n    \n    \n    docker run --name containernet -it --rm --privileged --pid='host' -v /var/run/docker.sock:/var/run/docker.sock containernet/containernet\n\nor run an interactive container and drop to the shell:\n\n    \n    \n    docker run --name containernet -it --rm --privileged --pid='host' -v /var/run/docker.sock:/var/run/docker.sock containernet/containernet /bin/bash\n\n## Get started\n\nUsing Containernet is very similar to using Mininet.\n\n### Running a basic example\n\nMake sure you are in the containernet directory. You can start an example\ntopology with some empty Docker containers connected to the network:\n\n    \n    \n    sudo python3 examples/containernet_example.py\n\nAfter launching the emulated network, you can interact with the involved\ncontainers through Mininet\u2019s interactive CLI. You can for example:\n\n  * use containernet> d1 ifconfig to see the config of container d1\n  * use containernet> d1 ping -c4 d2 to ping between containers\n\nYou can exit the CLI using containernet> exit.\n\n### Running a client-server example\n\nLet\u2019s simulate a webserver and a client making requests. For that, we need a\nserver and client image. First, change into the\ncontainernet/examples/basic_webserver directory.\n\nContainernet already provides a simple Python server for testing purposes. To\nbuild the server image, just run\n\n    \n    \n    docker build -f Dockerfile.server -t test_server:latest .\n\nIf you have not added your user to the docker group as described here, you\nwill need to prepend sudo.\n\nWe further need a basic client to make a CURL request. Containernet provides\nthat as well. Please run\n\n    \n    \n    docker build -f Dockerfile.client -t test_client:latest .\n\nNow that we have a server and client image, we can create hosts using them.\nYou can either checkout the topology script demo.py first or run it directly:\n\n    \n    \n    sudo python3 demo.py\n\nIf everything worked, you should be able to see following output:\n\n    \n    \n    Execute: client.cmd(\"time curl 10.0.0.251\") Hello world.\n\n### Customizing topologies\n\nYou can also add hosts with resource restrictions or mounted volumes:\n\n    \n    \n    # ... d1 = net.addDocker('d1', ip='10.0.0.251', dimage=\"ubuntu:trusty\") d2 = net.addDocker('d2', ip='10.0.0.252', dimage=\"ubuntu:trusty\", cpu_period=50000, cpu_quota=25000) d3 = net.addHost('d3', ip='11.0.0.253', cls=Docker, dimage=\"ubuntu:trusty\", cpu_shares=20) d4 = net.addDocker('d4', dimage=\"ubuntu:trusty\", volumes=[\"/:/mnt/vol1:rw\"]) # ...\n\n## Documentation\n\nContainernet\u2019s documentation can be found in the GitHub wiki. The\ndocumentation for the underlying Mininet project can be found on the Mininet\nwebsite.\n\n## Research\n\nContainernet has been used for a variety of research tasks and networking\nprojects. If you use Containernet, let us know!\n\n### Cite this work\n\nIf you use Containernet for your work, please cite the following publication:\n\nM. Peuster, H. Karl, and S. v. Rossem: MeDICINE: Rapid Prototyping of\nProduction-Ready Network Services in Multi-PoP Environments. IEEE Conference\non Network Function Virtualization and Software Defined Networks (NFV-SDN),\nPalo Alto, CA, USA, pp. 148-153. doi: 10.1109/NFV-SDN.2016.7919490. (2016)\n\nBibtex:\n\n    \n    \n    @inproceedings{peuster2016medicine, author={M. Peuster and H. Karl and S. van Rossem}, booktitle={2016 IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN)}, title={MeDICINE: Rapid prototyping of production-ready network services in multi-PoP environments}, year={2016}, volume={}, number={}, pages={148-153}, doi={10.1109/NFV-SDN.2016.7919490}, month={Nov} }\n\n### Publications\n\n  * M. Peuster, H. Karl, and S. v. Rossem: MeDICINE: Rapid Prototyping of Production-Ready Network Services in Multi-PoP Environments. IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN), Palo Alto, CA, USA, pp. 148-153. doi: 10.1109/NFV-SDN.2016.7919490. IEEE. (2016)\n\n  * S. v. Rossem, W. Tavernier, M. Peuster, D. Colle, M. Pickavet and P. Demeester: Monitoring and debugging using an SDK for NFV-powered telecom applications. IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN), Palo Alto, CA, USA, Demo Session. IEEE. (2016)\n\n  * Qiao, Yuansong, et al. Doopnet: An emulator for network performance analysis of Hadoop clusters using Docker and Mininet. Computers and Communication (ISCC), 2016 IEEE Symposium on. IEEE. (2016)\n\n  * M. Peuster, S. Dr\u00e4xler, H. Razzaghi, S. v. Rossem, W. Tavernier and H. Karl: A Flexible Multi-PoP Infrastructure Emulator for Carrier-grade MANO Systems. In IEEE 3rd Conference on Network Softwarization (NetSoft) Demo Track . (2017) Best demo award!\n\n  * M. Peuster and H. Karl: Profile Your Chains, Not Functions: Automated Network Service Profiling in DevOps Environments. IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN), Berlin, Germany. IEEE. (2017)\n\n  * M. Peuster, H. K\u00fcttner and H. Karl: Let the state follow its flows: An SDN-based flow handover protocol to support state migration. In IEEE 4th Conference on Network Softwarization (NetSoft). IEEE. (2018) Best student paper award!\n\n  * M. Peuster, J. Kampmeyer and H. Karl: Containernet 2.0: A Rapid Prototyping Platform for Hybrid Service Function Chains. In IEEE 4th Conference on Network Softwarization (NetSoft) Demo, Montreal, Canada. (2018)\n\n  * M. Peuster, M. Marchetti, G. Garc\u00eda de Blas, H. Karl: Emulation-based Smoke Testing of NFV Orchestrators in Large Multi-PoP Environments. In IEEE European Conference on Networks and Communications (EuCNC), Lubljana, Slovenia. (2018)\n\n  * S. Schneider, M. Peuster,Wouter Tvernier and H. Karl: A Fully Integrated Multi-Platform NFV SDK. In IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN) Demo, Verona, Italy. (2018)\n\n  * M. Peuster, S. Schneider, Frederic Christ and H. Karl: A Prototyping Platform to Validate and Verify Network Service Header-based Service Chains. In IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN) 5GNetApp, Verona, Italy. (2018)\n\n  * S. Schneider, M. Peuster and H. Karl: A Generic Emulation Framework for Reusing and Evaluating VNF Placement Algorithms. In IEEE Conference on Network Function Virtualization and Software Defined Networks (NFV-SDN), Verona, Italy. (2018)\n\n  * M. Peuster, S. Schneider, D. Behnke, M. M\u00fcller, P-B. B\u00f6k, and H. Karl: Prototyping and Demonstrating 5G Verticals: The Smart Manufacturing Case. In IEEE 5th Conference on Network Softwarization (NetSoft) Demo, Paris, France. (2019)\n\n  * M. Peuster, M. Marchetti, G. Garcia de Blas, Holger Karl: Automated testing of NFV orchestrators against carrier-grade multi-PoP scenarios using emulation-based smoke testing. In EURASIP Journal on Wireless Communications and Networking (2019)\n\n## Other projects and links\n\nThere is an extension of Containernet called vim-emu which is a full-featured\nmulti-PoP emulation platform for NFV scenarios. Vim-emu was developed as part\nof the SONATA-NFV project and is now hosted by the OpenSource MANO project:\n\nFor running Mininet or Containernet distributed in a cluster, checkout\nMaxinet.\n\nYou can also find an alternative/teaching-focused approach for Container-based\nNetwork Emulation by TU Dresden in their repository.\n\n## Contact\n\n### Support\n\nIf you have any questions, please use GitHub\u2019s issue system.\n\n### Contribute\n\nYour contributions are very welcome! Please fork the GitHub repository and\ncreate a pull request.\n\nPlease make sure to test your code using\n\n    \n    \n    sudo make test\n\n### Lead developer\n\nManuel Peuster\n\n  * Mail: <manuel (at) peuster (dot) de>\n  * Twitter: @ManuelPeuster\n  * GitHub: @mpeuster\n  * Website: https://peuster.de\n\nThis page was generated by GitHub Pages.\n\n", "frontpage": false}
