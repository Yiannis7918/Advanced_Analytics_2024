{"aid": "40034201", "title": "Show HN: Bot that tests the UI / UX of your website", "url": "https://github.com/pateli18/betatester", "domain": "github.com/pateli18", "votes": 1, "user": "itsskiseason", "posted_at": "2024-04-14 20:30:56", "comments": 0, "source_title": "GitHub - pateli18/betatester", "source_text": "GitHub - pateli18/betatester\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\npateli18 / betatester Public\n\n  * Notifications\n  * Fork 1\n  * Star 1\n\n### License\n\nApache-2.0 license\n\n1 star 1 fork Branches Tags Activity\n\nStar\n\nNotifications\n\n# pateli18/betatester\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n0 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\npateli18fixed typo36290c9 \u00b7\n\n## History\n\n23 Commits  \n  \n### .vscode\n\n|\n\n### .vscode\n\n| move core scraping execution to separate package  \n  \n### backend\n\n|\n\n### backend\n\n| enable scrape spec reuse across runs  \n  \n### frontend\n\n|\n\n### frontend\n\n| enable scrape spec reuse across runs  \n  \n### images\n\n|\n\n### images\n\n| base documentation setup  \n  \n### python_package\n\n|\n\n### python_package\n\n| fixed typo  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| build cleanup  \n  \n### Dockerfile\n\n|\n\n### Dockerfile\n\n| build cleanup  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| add apache license to main project  \n  \n### README.md\n\n|\n\n### README.md\n\n| fixed typo  \n  \n### docker-compose.dev.yaml\n\n|\n\n### docker-compose.dev.yaml\n\n| add persistence to the web service  \n  \n### docker-compose.prod.yaml\n\n|\n\n### docker-compose.prod.yaml\n\n| base documentation setup  \n  \n### render.yaml\n\n|\n\n### render.yaml\n\n| base documentation setup  \n  \n## Repository files navigation\n\n# BetaTester\n\nBetaTester is a simple tool to help you automatically test the UI / UX of your\nweb application on different browsers and devices without having to write\nbrittle front-end tests. It uses LLMs to plan and select actions and\nPlaywright to execute those actions.\n\nAs you develop and change your web application, you can specify BetaTester to\ncontinuously test high level flows like \"Sign up\", \"Login\", \"Add to cart\",\netc. Failures can indicate either a bug in the UI or potentially non-intuitive\nUX, which you can investigate further using the application or the Playwright\ntrace it automatically generates.\n\nIf you don't want to keep using LLMs for every test, BetaTester generates a\nscrape spec from an LLM run that can be run deterministically.\n\n## Contents\n\n  * Python Package\n  * CLI\n  * Application\n  * Extensions\n  * Debugging Prompts\n\n## Python Package\n\n### Installation\n\n  1. Install the package\n\n    \n    \n    pip install betatester\n\n  2. If you have not run Playwright before, you will need to install the browser dependencies. This only needs to be done once per system\n\n    \n    \n    playwright install --with-deps chromium`\n\n  3. Make sure to retrieve an your OpenAI API key if you have not already done so.\n\n### Usage\n\nRun the test using LLMs. See the docstring here for more information on the\navaiable parameters.\n\n    \n    \n    from betatester import ScrapeAiExecutor from betatester.file.local import LocalFileClient file_client = LocalFileClient(\"./app-data/\") scrape_executor = ScrapeAiExecutor( url=\"https://google.com\", high_level_goal=\"Find images of cats\", openai_api_key=\"...\", file_client=file_client, ) scrape_spec = await scrape_executor.run()\n\nRun the test using a scrape spec (with no LLM calls) generated from a previous\nLLM run. See the docstring here for more information on the avaiable\nparameters.\n\n    \n    \n    from betatester import ScrapeSpecExecutor scrape_spec_executor = ScrapeSpecExecutor( scrape_spec=scrape_spec, ) await scrape_spec_executor.run()\n\n## CLI\n\n### Installation\n\n  1. Install the package\n\n    \n    \n    pip install betatester[cli]\n\n  2. If you have not run Playwright before, you will need to install the browser dependencies. This only needs to be done once per system\n\n    \n    \n    playwright install --with-deps chromium`\n\n  3. Make sure to retrieve an your OpenAI API key if you have not already done so and set it as an environment variable OPENAI_API_KEY.\n\n### Usage\n\nRun the test using LLMs. Use betatester start_ai --help for more information\non the avaiable parameters.\n\n    \n    \n    betatester start_ai --url \"https://google.com\" --high-level-goal \"Find images of cats\" > \"/path/to/scrape_spec.json\"\n\nRun the test using a scrape spec (with no LLM calls) generated from a previous\nLLM run. Use betatester start_spec --help for more information on the avaiable\nparameters.\n\n    \n    \n    betatester start_spec --scrape-spec-path \"/path/to/scrape_spec.json\"\n\n## Application\n\n### Quickstart\n\nNote: The provided render.yaml does not have a persistent disk attached, which\nmeans if the service is restarted and you are using the local file provider\nthe output assets for a given test will be lost. If you want to persist this\ndata, you will need to upgrade the instance type and attach a persistent disk\nto the service.\n\n#### Run Locally\n\n  1. Set Environment Variables\n\n     * Required: OPENAI_API_KEY - Your OpenAI API key\n  2. Start the application\n\n    \n    \n    docker compose -f docker-compose.prod.yaml up --build\n\nThe application is served on http://localhost:8080\n\n#### Run Development Environment Locally\n\n  1. Set Environment Variables\n\n     * Required: OPENAI_API_KEY - Your OpenAI API key\n  2. Start the backend\n\n    \n    \n    docker compose -f docker-compose.dev.yaml up --build\n\nThe backend is served on http://localhost:8080\n\n  3. Install frontend packages (this only needs to be done once)\n\n    \n    \n    cd frontend; npm install\n\n  4. Start the frontend\n\n    \n    \n    cd frontend; npm run start\n\nThe frontend is served on http://localhost:3000\n\n### Using the Application\n\n  1. Create a test by clicking the New Test button. As part of creating the test, you wiwll need to provide:\n\n  * Name\n  * Url - The url of the page you want to test.\n  * High Level Goal- A high level goal that the bot will try to achieve. For example, if you are testing a sign up flow, you can specify \"Sign up\" as the high level goal.\n  * [Optional] Variables - These are variables that can be used by the bot during the test. For example, if you have a username and password field, you can specify these as variables and the bot will automatically fill them in for you.\n  * [Optional] Files - These are files that can be used by the bot during the test. For example, if you have a file upload field, you can specify a file and the bot will automatically upload it for you.\n  * [Optional] Limits - Various settings that will ensure the bot does not infinitely loop or run for too long.\n  * [Optional] Viewport - The viewport that the bot will use to test your application.\n\n  2. Once the test is created, you can run it by clicking the Run button. This will redirect you to the the /scrape page where you can see the LLM working in real time to run the test. You can stop this process at any time by clicking Stop.\n\n### Using the API\n\nBetaTester provides a REST API for interacting with the application. The API\nis served on http://localhost:8080. You can view the api docs at\nhttp://localhost:8080/docs when running the application locally.\n\n  1. Create a Test\n\n    \n    \n    import httpx response = httpx.post( \"http://localhost:8080/api/v1/config/upsert\", json={ \"name\": \"Test Search\", \"url\": \"https://google.com\", \"high_level_goal\": \"Find images of cats\", } ) config_id = response.json()[\"config_id\"] print(config_id)\n\n  2. Start a Test\n\n    \n    \n    import httpx response = httpx.post( f\"http://localhost:8080/api/v1/scraper/start/{config_id}\", ) run_id = response.json()[\"scrape_id\"] print(run_id)\n\n  3. Poll for Status\n\n    \n    \n    import httpx from time import sleep while True: response = httpx.get( f\"http://localhost:8080/api/v1/scraper/status/{config_id}/{run_id}\" ) status = response.json()[\"status\"] print(status) if status != \"running\": break else: sleep(5) print(response.json())\n\n## Extensions\n\n### File\n\nAutoTransform provides a file extension that allows you to store your files in\nthe storage provider of your choice. To use the file extension, you will need\nto provide the following environment variables:\n\n  * FILE_CLIENT_TYPE: The file client you are using, currently only local is supported\n  * FILE_CLIENT_CONFIG: A string that contains the configuration for your file client. The format of this object is specific to the provider you are using.\n\n    * For local the format is a json obejct with the following keys:\n\n      * save_path: The path to the directory where you want to store your files\n\nYou can add other file proviers by:\n\n  1. Adding a new class that inherits from FileClient. See local.py for an example.\n  2. Updating __init__.py to return your new class when the FILE_CLIENT_TYPE environment variable is set to the name of your new class.\n  3. Updating the FileCLientType enum to include your new client type\n\n## Debugging Prompts\n\nBetaTester will display the prompts used to run the test in the /scrape view.\nYou can also continue the chat to understand why the bot made a particular\ndecision.\n\n## About\n\nNo description, website, or topics provided.\n\n### Resources\n\nReadme\n\n### License\n\nApache-2.0 license\n\nActivity\n\n### Stars\n\n1 star\n\n### Watchers\n\n1 watching\n\n### Forks\n\n1 fork\n\nReport repository\n\n## Releases\n\nNo releases published\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 52.4%\n  * TypeScript 44.7%\n  * JavaScript 1.2%\n  * Other 1.7%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
