{"aid": "39960718", "title": "Learning Lower-Level Programming", "url": "https://jamesg.blog//2024/03/22/lower-level-programming/", "domain": "jamesg.blog", "votes": 2, "user": "signa11", "posted_at": "2024-04-07 13:42:14", "comments": 0, "source_title": "Learning lower-level programming", "source_text": "Learning lower-level programming | James' Coffee Blog\n\nSkip to main content\n\n# Learning lower-level programming\n\nPublished on March 22, 2024 under the Coding category.\n\nFor most of my programming life, I have worked with the abstractions made by\nothers. I have used tools that use well-researched and clearly defined data\nstructures to solve problems, rather than learning about them myself. Indeed,\nabstraction lets me stand on the shoulders of giants, using existing\nimplementations of algorithms and solutions to write a program. But, over the\nlast two years, I have felt an urge to peel back the layers of some\nabstractions. To understand the how behind various parts of computation.\n\nIn this post, I am going to talk about two ways I have practiced learning\nlower-level programming: building with a project in mind that I know has some\ncomplexity I don't know how to solve yet, and implementing algorithms from a\nreference.\n\n## Learning by working on a problem\n\nMy foray into lower-level programming with my interest in building a search\nengine. I didn't set out to learn about low-level data structured, but I ended\nup doing so.\n\nI wanted to build a tool that would let me search the websites operated by\nmembers of a community I am in. With a problem in mind, and sufficient\nmotivation, I got to work. But, this was not the case of me saying \"James,\nyou're going to build a search engine today!\" straight away. For I didn't\nreally know where to begin.\n\nThe first stage was research. I needed to define exactly what I would need to\ndo to solve the problem. This was a time where I could choose the level of\nabstraction at which I wanted to work. I could have chosen to use a database\nto store web pages and a pre-existing Python library to download web pages.\nThe resulting script would solve my problem, but I would miss out on one of\nthe opportunities that motivated me to work on the project: to learn more\nabout programming.\n\nIn my research, I quickly found building a search engine involved dozens of\ndifferent problems, each with their own problems. But, I didn't need to solve\neverything. I could pick and choose what I wanted to work on, and use pre-\nbuilt tools for the rest. I decided to work on a crawler, the part of a search\nengine that downloads web pages. To make the bit that searches all the web\npages, I used Elasticsearch, which was a problem of reading documentation and\nintegrating rather than writing the algorithms myself.\n\nWith a task in mind -- write a search crawler -- I could get to work. I\nstarted by writing a program that works. A program that downloads web pages.\nThen, through practice, I started to learn about edge cases: what if a web\npage doesn't load, what if a web page is not HTML, and so on. And then a\ncrucial problem came to the forefront of my mind: how do I make this fast?\nIndeed, I wanted to serve results from 1,000 websites. My Python program that\ndownloads pages one by one was too slow.\n\nHerein lay my foray into lower-level programming: figuring out ways to make a\nprogram faster.\n\nI started to look at my program and noticed a few things. First, I was\ndownloading URLs one-by-one. Since it may take 1-3 seconds to load and process\na page, and most of that time is waiting for the server to respond, there is a\nlot of time being wasted. What if I could start retrieving other web pages\nwhile I was waiting to download one? This is when concurrency clicked for me,\na technique in programming that lets your program do multiple things at the\nsame time.\n\nOn the same journey of trying to make my program faster, I learned that it\ntakes longer to search a list than a set. This was important to me because\nevery time I was about to download a URL, I checked a list to see if I had\nalready downloaded it. As the program would run longer, this process would\ntake longer. If I had downloaded 5,000 web pages, I had to do 5,000\ncomparisons. I thought: is there a more efficient way to do this? It turns out\nthere is: sets.\n\nWhen using lists, programs need to compare every item in a list to the value\nfor which you are looking. But a set uses hashing. The programming language\ncan hash your value, then do a fast lookup in a table to find if a value is or\nis not in a set.\n\nFrom an abstract problem -- build a search engine -- I was starting to learn\nmore about the fundamentals of programming. I ran into limitations -- mainly\nspeed -- that made me have to think twice about how I was building what I was\nbuilding.\n\nAs I worked on this project, I started asking more questions, such as:\n\n  * How can Elasticsearch be so fast?\n  * How could I build an efficient way of ranking search results on my own?\n\nEach of these questions resulted in a new interest. I learned about reverse\nindexes and how they are used for search. I ended up implementing TF/IDF, a\nranking algorithm, on an index I made. All one step at a time, and all for\nfun.\n\nMany more projects I worked on stemmed from my curiosity about solving a\nparticular problem, and having enough curiosity to peel back a layer of\nabstraction.\n\nI learned about tries, the data structure that helped me learn about and\nreason with trees, because I wanted to build an auto-complete for my search\nengine. I didn't want to use a Python package for this autocorrect, of which\nthere were many: I wanted to see if I could solve the problem. After research,\nI found out tries are used for auto-complete, so I knew what to build. I used\na trie package to start, so I could learn how to structure data in a trie for\nmy auto-complete problem. Eventually, I implemented a trie myself.\n\nI recommend starting with a task that feels achievable. If you decide to make\nan operating system and you have never done any reading on operating systems\nor any coding in the field, you are probably going to struggle a lot. And this\nmay lead you to think you are a worse programmer than you are. Whereas if you\nhave done a lot of web work and you decide to figure out how to make an\nautocomplete feature, many of the skills you already know apply.\n\nThere is no magic heuristic for what feels achievable; it is all down to where\nyou are in your programming journey. Three years ago, I would have said making\na programming language is impossible for me. And it probably was back then. I\ndidn't know about trees (the data structure category). I now know that\nprogramming languages are all about trees. But I did know Python and a bit\nabout the web, so building a search engine -- using existing components where\nnecessary -- felt more achievable.\n\n## Learning with a reference specification\n\nSometimes, I have a yearning to practice my programming skills but I don't\nhave a specific project in mind. When I feel this way, I sometimes look for\nalgorithms or data structures that I could implement. I often look to more\n\"obscure\" data structures -- the ones that you may not have heard of in an\nintroduction to algorithms class, but are still incredibly useful. I do this\nbecause obscure data structures feel more fun to me than learning a B-tree\n(although, likely, I will be implementing a B-tree one day).\n\nYou can usually find detailed explanations of how different data structures\nand algorithms work on Wikipedia. Here are a few examples:\n\n  * Trie (Used in auto-complete)\n  * Bloom filter (Used to quickly search if something is definitely not in a list)\n  * BitCask (A disk-based key value store)\n  * Byte-pair encoding (Used to encode text)\n  * Piece tables\n\nA step-by-step breakdown of an algorithm changes the challenge of learning\nlow-level tasks. You go from trying to reason with and solve a problem from a\ndescription at the same time to reading precise natural language instructions\nand translating them into code. I find translating a list of instructions into\ncode easier than reading a paragraph on an algorithm. Pseudocode fits into\nthis category, as do \"reference implementations\", which implement an algorithm\nin code.\n\nSome algorithms can have complex descriptions. If an algorithm or data\nstructure looks too complex and I am learning for fun, I search for another\none to implement. I know that I can always come back to something that looks\ncool later. I do not yet feel confident implementing a B-tree (used in\ndatabases), but I will get there one day! Don't worry about something being\ntoo complex. All programmers are learning every day, and to learn something\ncomplex you first need to learn the fundamentals and build confidence.\n\nSimilarly, I built confidence in web standards by implementing some web\nstandards. I implemented Webmention to start, a W3C standard for sharing\ncomments across the web. The specification states exactly what you need to do\nto build a Webmention system with which other implementations can integrate. I\nstarted by thinking a specification is really complicated and not something I\ncould implement. But I took the process step by step: following all of the\ninstructions one-by-one.\n\n## You can do low-level programming\n\nI started with high-level programming: making websites, writing data to and\nreading data from databases. Then, over time, I started to encounter lower\nlevel concepts. In pursuit of solving some problems -- building a search\nengine, and, separately, writing a language that would let me communicate with\nmy computer in a way that made sense to me -- I quickly encountered the names\nof lower-level algorithms. From here, I researched to figure out how pieces\nconnect and, step by step, implemented algorithms.\n\nThree years ago, I would have thought all I could do was make a back-end in\nFlask. That is a big feat! But, when you are curious about doing more, feeling\nlike everything else is too complex is demotivating. As with all things,\nlearning step by step is crucial. Don't take on too much at once. If you have\nnever made a programming language, making one will feel intimidating. Just as\nmaking a cake is intimidating to me because the last time I made one was in\nschool; I'm out of practice. But just as with a cake, where you need a recipe,\nhaving guidance from a specification and learning materials will be\ninvaluable.\n\nTry to solve a problem that seems interesting to you and, if you are willing,\npeel back a layer of abstraction if you see one. Wonder how search engines are\nso fast? Read up on indexes. Wonder how programming languages work? Skim the\nWikipedia page on programming languages and see what stands out. Want to check\nif something is in a list with one million items? Read up on data structures\nfor efficiently checking if something is in a list of items (i.e. using a\nset).\n\nI couldn't have done anything above without help. Reading gets you so far, but\nsometimes you don't know what you even need to search for. In these cases,\nasking people you know -- or forums -- is helpful. When I had questions about\nweb standards, I asked the web community. When I had questions about search, I\nasked friends who had done similar things (who happened to be in that same web\ncommunity!). There was once a time I thought \"I want to implement this, but I\ndon't feel confident\". A friend encouraged me to implement the specification,\nand I learned a lot in the process.\n\nProgrammers who know exactly what data structures to use, or the most\nefficient way to solve a problem, or how to optimize a program to be as fast\nas possible all started without this knowledge. It was learned. You, too, can\nlearn low-level programming.\n\nShare this post on Hacker News.\n\nShare this post on Lobste.rs.\n\nMost related Taylor Swift lyric\n\nTaught me some hard lessons I just forget what they were\n\n## Responses\n\n## Comment on this post\n\nRespond to this post by sending a Webmention.\n\nHave a comment? Email me at readers@jamesg.blog.\n\nGo Back to the Top\n\n  * Time Machine\n  * Coffee Maps\n  * Projects\n  * Talks\n  * Sitemap\n  * Archive\n  * Index\n  * Privacy\n  * Contact\n  * RSS\n\n\u2190 IndieWeb Webring \u2192\n\n", "frontpage": false}
