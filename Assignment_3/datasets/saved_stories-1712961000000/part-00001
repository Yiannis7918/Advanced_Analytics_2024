{"aid": "40014711", "title": "The One Billion Row Challenge in CUDA: from 17 minutes to 17 seconds", "url": "https://tspeterkim.github.io/posts/cuda-1brc", "domain": "tspeterkim.github.io", "votes": 2, "user": "tspeterkim", "posted_at": "2024-04-12 16:27:51", "comments": 0, "source_title": "The One Billion Row Challenge in CUDA: from 17 minutes to 17 seconds", "source_text": "The One Billion Row Challenge in CUDA: from 17 minutes to 17 seconds | Taeksang Peter Kim\n\nTaeksang Peter Kim\n\n# The One Billion Row Challenge in CUDA: from 17 minutes to 17 seconds\n\nApr 10, 2024\n\nOn my journey to learn CUDA, I decided to tackle the One Billion Row Challenge\nwith it.\n\nThe challenge is simple, but implementing it in CUDA was not. Here I will\nshare my solution that runs in 16.8 seconds on a V100. It\u2019s certainly not the\nfastest solution, but it is the first one of its kind (no cudf, hand-written\nkernels only). I challenge other CUDA enthusiasts to make it faster.\n\n## Baseline in pure C++\n\nYou can\u2019t improve what you don\u2019t measure. Since I\u2019m going to be writing C++\nanyways for CUDA, let\u2019s use a pure C++ baseline. My CUDA code should be faster\nthan this.\n\nThe approach is straight-forward: read the file line by line, parse it to get\nthe city and temperature, and accumulate them in a STL map.\n\n    \n    \n    while (getline(file, line)) { istringstream iss(line); string station; float temp; getline(iss, station, ';'); iss >> temp; auto it = stationStats.find(station); if (it == stationStats.end()) { stationStats[station] = {temp, temp, temp, 1}; } else { Stat& s = it->second; s.min = min(s.min, temp); s.max = max(s.max, temp); s.sum += temp; s.count++; } } ofstream measurements(\"measurements.out\"); for (auto& pair : stationStats) { const Stat& s = pair.second; float mean = s.sum / s.count; measurements << pair.first << \"=\" << s.min << \"/\"; measurements << fixed << setprecision(1) << mean << \"/\"; measurements << s.max << endl; }\n\nThis runs in 16.5 minutes. Let\u2019s improve this with CUDA.\n\n## Work Partitioning Approach\n\n### One Billion Threads?\n\nThe whole promise of CUDA and other parallel programming APIs is that you can\nparallelize your workload across many processes. For CUDA, it\u2019s a SIMT model -\na single instruction is executed across multiple threads in parallel.\n\nGreat, so let\u2019s just use one billion threads to process one billion lines\nconcurrently!\n\nUnfortunately, we can\u2019t just launch one billion threads. We first need to\nprepare each line buffer for each thread to process. However, preparing these\none billion line buffers requires reading the entire file, line by line\n(unless the lines were already placed in one billion files, but that would\nmake this the One Billion Files Challenge).\n\nThe effort involved in setting up these buffers would essentially replicate\nthe baseline workload, making this approach counterproductive.\n\n### Use Byte Offsets\n\nThe solution is to prepare file offsets instead of line buffers. These offsets\nare obtained iteratively, stepping through the entire file buffer by the\ndesired split size (= total file size / desired number of parts), and marking\nthe position of a new line character:\n\n    \n    \n    long long split_size = size / num_parts; long long offset = 0; std::vector<Part> parts; while (offset < size) { long long seek_offset = std::max(offset + split_size - MAX_CITY_BYTE, 0LL); if (seek_offset > size) { parts.back().length += size-offset; break; } file.seekg(seek_offset, std::ios::beg); char buf[MAX_CITY_BYTE]; file.read(buf, MAX_CITY_BYTE); // Find the new line character in the vicinity. // That will be the boundary between this and the next offset. std::streamsize n = file.gcount(); std::streamsize newline = -1; for (int i = n - 1; i >= 0; --i) { if (buf[i] == '\\n') { newline = i; break; } } int remaining = n - newline - 1; long long next_offset = seek_offset + n - remaining; parts.push_back({offset, next_offset-offset}); offset = next_offset; }\n\nThis is much faster than reading the entire file because we are working with\ninteger byte values. For example, say we want to partition the 14GB input file\nfor two threads. The while loop iterates twice (offset = 0GB -> 7GB -> 14GB).\nContrast this to a line-based approach. We would need to iterate 500M (= 1B /\n2) times to load 500M lines into our first partition.\n\nIn reality, we need more than just two threads. But one billion is too much.\nNot because our GPU can\u2019t handle one billion threads, but because finding one\nbillion offsets becomes the bottleneck in our overall runtime. We haven\u2019t even\ngotten to launching our CUDA kernels. We need to minimize our preparation time\nas much as possible.\n\nFor my solution, I create 1M partitions that takes 2.6 seconds out of the\nentire 16.8 seconds. (In comparison, creating 100M partitions alone takes over\n3 minutes.)\n\n## CUDA Kernel\n\nThe rest of the time is spent in the CUDA kernel (finally!). The idea behind\nit is simple. Each thread indexes into a different part of the file buffer,\nparses it to get the cities and temperatures, and updates the min/max/avg\nstatistics.\n\nThe implementation, however, is not trivial due to the following reasons (in\norder of annoyance):\n\n  * CUDA\u2019s AtomicMin and AtomicMax only work with int values. We\u2019ll make our own float-value-accepting variants.\n  * No std::string in CUDA. Time to make our own atof, strcmp, getline. Get ready for null terminators '\\0'.\n  * No std::map either. How can we pass in the city string to array index lookup table into our CUDA kernel?\n\nLet\u2019s go through these one by one.\n\n### AtomicMin & AtomicMax for Floats\n\nAny atomic operation in CUDA can be written with atomicCAS. Let\u2019s adapt the\nexample from the official programming guide to write atomicMin and atomicMax\nfor float values. Here\u2019s AtomicMin:\n\n    \n    \n    __device__ static float atomicMin(float* address, float val) { int* address_as_i = (int*) address; int old = *address_as_i, assumed; do { assumed = old; old = ::atomicCAS(address_as_i, assumed, // Use `fmaxf` for atomicMax. __float_as_int(::fminf(val, __int_as_float(assumed)))); } while (assumed != old); return __int_as_float(old); }\n\nNow we can atomically update min and max temperature floats.\n\n### C Strings\n\nWhile we don\u2019t have std::string, we have char*. A string is just an array of\n8-bit characters, and the raw file buffer (e.g.\n\"Hamburg;12.0\\nBulawayo;8.9\\nPalembang;38.8...\") is no different.\n\nEach thread iterates through this char array, at different offsets and for\ndifferent lengths (computed at our work partitioning step):\n\n    \n    \n    char city[MAX_CITY_BYTE]; char floatstr[5]; // longest temperature float str is -99.9 i.e. 5 bytes for (int i = 0; i < parts[bx].length; i++) { // bx is the global thread index char c = buffer[parts[bx].offset-buffer_offset + i]; if (parsing_city) { // City characters if (c == ';') { city[index] = '\\0'; index = 0; parsing_city = false; } else { city[index] = c; index++; } } else { // Float characters if (c == '\\n') { // Reached end of line floatstr[index] = '\\0'; int stat_index = get_index(cities, city, n_city); float temp = cuda_atof(floatstr); // The heart of the CUDA kernel. // Update (atomically) the temperature statistics. // Identical in spirit to the simple C++ version. atomicMin(&stats[stat_index].min, temp); atomicMax(&stats[stat_index].max, temp); atomicAdd(&stats[stat_index].sum, temp); atomicAdd(&stats[stat_index].count, 1); // reset for next line read parsing_city = true; index = 0; floatstr[0] = '\\0'; city[0] = '\\0'; } else { floatstr[index] = c; index++; } } }\n\nIt\u2019s not pretty. But it\u2019s necessary as we don\u2019t have the luxury of a getline.\nAfter parsing each line, we now have a pair of strings; a city string char\ncity[] and a temperature string char floatstr[]. (The latter requires a\nconversion from string to float and since we don\u2019t have atof in CUDA, I made\nmy own again)\n\n### City String to Index Lookup\n\n#### GPU Hash Table?\n\nHow do we store temperature statistics for each city? In C++ land, we relied\non a hash table - using the city string as key, and temperature statistic\nfloats as value. In CUDA, we don\u2019t have such a convenient std::map.\n\nOkay, let\u2019s write our own. How hard can it be? Turns out, damn near impossible\nbecause I have 100-byte city strings as keys.\n\nWhile I found some implementations online, these approaches are limited to\n32-bit keys, due to atomic operations being bounded to limited bits (even on\nthe CPU).\n\nTo be clear, you don\u2019t need atomic operations to deal with hash table\ncollisions, but you do need them when the collisions can happen across\nmultiple threads i.e. a parallel setting with concurrent inserts into the hash\ntable.\n\n#### Ask for forgiveness, not permission\n\nSo this is where I bend the rules of the original challenge a bit. I assume\nthat a list of all cities is given along with the input file. This list is the\ndata/weather_stations.csv file, which is actually used to generate the one\nbillion rows for the official challenge.\n\n#### Hacky Solution: Sorted Cities + Binary Search\n\nKnowing the list of all possible cities, I avoid using a hash table. I just\nsort the list of all cities, and pass it to my CUDA kernel. I use the sorted\nindices as my lookup table. E.g. Say sorted cities list was [\"A\",\"B\",\"C\"].\nGiven city \"B\", the lookup index is its position, 1.\n\nSorting is important because we can do binary search to find the index in\nlogarithmic time. While still slower than a hash table\u2019s constant time lookup,\nit\u2019s much faster than linearly searching 40k+ city entries.\n\n    \n    \n    // Never thought that I would be writing binary search in CUDA, but here we are. // Thanks LeetCode! __device__ int get_index(char* cities, char* city_target, int n_city) { int left = 0; int right = n_city - 1; while (left <= right) { int mid = left + (right - left) / 2; const char* city_query = cities + mid * MAX_CITY_BYTE; int cmp = cuda_strcmp(city_query, city_target); if (cmp == 0) return mid; else if (cmp < 0) left = mid + 1; else right = mid - 1; } return -1; }\n\nNow we\u2019re finally done! The heart of the kernel boils down to:\n\n    \n    \n    int stat_index = get_index(cities, city, n_city); float temp = cuda_atof(floatstr); atomicMin(&stats[stat_index].min, temp); atomicMax(&stats[stat_index].max, temp); atomicAdd(&stats[stat_index].sum, temp); atomicAdd(&stats[stat_index].count, 1);\n\nAll this just to do 4 atomic operations.\n\n## Profiling\n\nOn a V100, the CUDA solution runs in 16.8 seconds. It\u2019s a 60X improvement\ncompared to the 16.5 minutes for our C++ baseline. Here is the script to\nreproduce this.\n\nInterestingly, the kernel is ~1.5X slower on a T4, and so I used ncu to\nprofile on both devices. One thing that caught my eye was the difference in\ncontrol divergence.\n\n    \n    \n    (v100) ~ ncu --section SourceCounters fast data/measurements.txt 1000000 600000 ... Section: Source Counters ------------------------- ----------- -------------- Metric Name Metric Unit Metric Value ------------------------- ----------- -------------- Branch Instructions Ratio % 0.18 Branch Instructions inst 53,736,337,800 Branch Efficiency % 92.73 Avg. Divergent Branches 10,041,990.22 ------------------------- ----------- -------------- (t4) ~ ncu --section SourceCounters fast data/measurements.txt 1000000 600000 ... Section: Source Counters ------------------------- ----------- -------------- Metric Name Metric Unit Metric Value ------------------------- ----------- -------------- Branch Instructions Ratio % 0.17 Branch Instructions inst 53,870,435,921 Branch Efficiency % 92.73 Avg. Divergent Branches 20,156,806.42 ------------------------- ----------- --------------\n\nI expected there to be a lot of control divergence (since I\u2019m using ifs and\nloops everywhere in my kernel), but I did not expect the divergence to be\nworse on the T4. Compared to the V100, it has twice as many avg. divergent\nbranches. Could this be a reason why the kernel runs more slowly on a T4?\nAlso, why is the branch efficiency so high if there are so many divergent\nbranches?\n\nClearly, I\u2019m still learning about the ncu profiler. I welcome any guidance on\nthis area.\n\n## Possible Optimization - Privatization using Shared Memory\n\nAs I finish writing this blog, I realize that my struct Stat doesn\u2019t need to\nhold the city char array. In which case, each struct will be 16 bytes (min,\nmax, sum, count), and the entire array of statistics will be 16N bytes, where\nN is the # of unique cities.\n\nHere, N=41k (based on data/weather_stations.csv), and so the entire array will\nbe 66KB. This should be small enough to fit in shared memory (96KB per SM for\nVolta). Then, each block can update a private version of stats to reduce\ncontention of the atomic operations. This should lead to a faster solution.\n\n## Takeaway\n\nThe more and more I did this challenge, the more and more I realized that not\nall parallel workloads are meant for CUDA. Especially those involving strings\nand dynamic hash tables. I eventually had to cheat a bit and make a static\nlookup table. I am genuinely curious: is there a way to not require a list of\nall cities? (and still be faster than the baseline, of course)\n\nStill, no regrets taking on the challenge. I got to experience CUDA\u2019s\nlimitations first-hand, and that was worthwhile. Now I know I should just\nstick to Tensor matmults like I usually do.\n\n## Taeksang Peter Kim\n\n  * Taeksang Peter Kim\n  * tspeterkim3@gmail.com\n\n  * tspeterkim\n  * tspeterkim3\n  * tspeterkim\n\n", "frontpage": false}
