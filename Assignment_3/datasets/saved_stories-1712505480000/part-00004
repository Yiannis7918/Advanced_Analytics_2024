{"aid": "39958129", "title": "Do people generally agree with Shaoshan Liu and Ding Ning in their BLOG entry?", "url": "https://cacm.acm.org/blogcacm/building-computing-systems-for-embodied-artificial-intelligence/", "domain": "acm.org", "votes": 1, "user": "omnifidus", "posted_at": "2024-04-07 04:07:32", "comments": 0, "source_title": "Building Computing Systems for Embodied Artificial Intelligence \u2013 Communications of the ACM", "source_text": "Building Computing Systems for Embodied Artificial Intelligence \u2013\nCommunications of the ACM\n\nSkip to content\n\nSearch Sign In\n\nJoin ACM\n\nBLOG@CACM\n\nArchitecture and Hardware\n\n# Building Computing Systems for Embodied Artificial Intelligence\n\nThe computing challenges of embodied AI, and some research directions for\nbuilding computing systems for embodied AI.\n\nBy Shaoshan Liu and Ding Ning\n\nPosted Mar 21 2024\n\n  * Share\n\n    * Twitter\n    * Reddit\n    * Hacker News\n  * Print\n  * Join the Discussion\n\nEmbodied AI involves embedding artificial intelligence into tangible entities,\nsuch as robots, equipping them with the capacity to perceive, learn from, and\nengage dynamically with their surroundings [1]. This approach facilitates\nrobots in evolving and adapting to environmental changes. A notable instance\nof this is the Figure AI humanoid, which leverages OpenAI\u2019s cutting-edge\ntechnologies. It showcases the humanoid\u2019s advanced ability to comprehend its\nenvironment and respond aptly to various stimuli, marking a significant stride\nin the development of intelligent, interactive machines. In this article we\nreview the computing challenges of embodied AI and explore a few research\ndirections for building computing systems for embodied AI.\n\n## Computing Challenges of Embodied AI\n\nAlthough embodied AI has demonstrated its enormous potential in shaping our\nfuture economy, embodied AI is extremely demanding on computing in order to\nachieve flexibility, computing efficiency, and scalability, we summarize the\ncurrent computing challenges of embodied AI below:\n\nComplex Software Stack Challenge: Complexity breeds inflexibility. embodied AI\nsystems must integrate a diverse array of functionalities, from environmental\nperception and engaging in physical interactions to executing complex tasks.\nThis integration involves harmonizing various components such as sensor data\nanalysis, sophisticated algorithmic processing, and precise control over\nactuators. Furthermore, to cater to the broad spectrum of robotic forms and\ntheir associated tasks, a versatile embodied AI software stack is essential.\nAchieving cohesive operation across these diverse elements within a singular\nsoftware architecture introduces significant complexity, elevating the\nchallenge of creating a seamless and efficient software ecosystem.\n\nInadequate Computing Architecture: Current computational frameworks are\ninadequate for the intricate demands of embodied AI. The requisite for real-\ntime processing of vast data streams, coupled with the need for high\nconcurrency, unwavering reliability, and energy efficiency, poses a\nsignificant challenge. These limitations hinder the potential for robots to\nfunction optimally in multifaceted and dynamic environments, underscoring the\nurgent need for innovative computing architectures tailored to the nuanced\nrequirements of embodied AI.\n\nData Bottleneck Obstacle: Lack of data limits scalability. The evolution and\nrefinement of embodied AI systems heavily rely on the acquisition and\nutilization of extensive, high-quality datasets. However, procuring data from\ninteractions between robots and their operating environments proves to be a\ndaunting task. This is primarily due to the sheer variety and intricacy of\nthese environments, compounded by the logistical and technical difficulties in\ncapturing diverse, real-world data. This data bottleneck not only impedes the\ndevelopment process but also limits the potential for embodied AI robots to\nlearn, adapt, and evolve in response to their surroundings.\n\n## Building Computing Systems for Embodied AI\n\nAddressing these challenges requires a multi-faceted approach that focuses on\nachieving flexibility through layered software architecture, computational\nefficiency through innovative computer architecture, and scalability through\nautomation of data generation.\n\n### 2.1 Layered Software Stack to Achieve Flexibility\n\nWe believe that a layered software architecture is an effective way to provide\nthe abstractions necessary to manage software complexity and thereby enable\nflexibility:\n\nControl Adaptation: The control adaptation layer serves as a bridge between\ncore software and diverse hardware, simplifying the integration of different\nsensors, actuators, and control systems. It abstracts low-level complexities,\nallowing developers to concentrate on behavior logic and decision-making\nalgorithms, enhancing development efficiency. One example of the control\nadaptation layer is the stretch body library from Hello Robot [2].\n\nCore Robotic Functions: upon the control adaptation layer sits the core\nrobotic function library, containing packages for essential robot operations,\nfrom mobility to user interaction, offering developers rich, high-level\ninterfaces. It ensures compatibility and flexibility across different\nhardware, significantly boosting development efficiency. One example of the\ncore robotic function library is Meta\u2019s home robot project which provides\nbasic functions for robotic navigation and manipulation [3].\n\nRobotic Applications: the application layer offers software interfaces,\nenabling the creation of complex intelligent applications. Utilizing large\nfoundational models, developers can embed sophisticated AI applications into\nrobots, enhancing their ability to understand and interact with their\nsurroundings, examples of the robotic applications layer include RT-2 [4] and\nClip [5].\n\n2.2. Embodied AI Computer Architecture\n\nA new architecture definition is required to provide computational efficiency\nfor embodied AI applications. This architecture must integrate multiple\nmultimodal sensors, provide efficient computational support for core robotic\nfunctions, and enable real-time processing of large model-based robotic\napplications.\n\nFigure 1: Computer Architecture for Embodied AI. Credit: Shaoshan Liu\n\nSensor Integration and Synchronization: Effective sensor integration and\nsynchronization is critical, especially for robots with multiple multimodal\nsensors, because the quality of the sensor integration determines the quality\nof the sensor data. A hardware module must integrate more than ten sensors and\nprovide a common timing source for accurate data acquisition and integration.\nAn example of a sensor integration module can be found in [6].\n\nDataflow Accelerator Architecture: As discussed in our previous post, the\ncomputation of various robotic form factors follows the dataflow paradigm.\nTherefore, an effective way to improve the computational efficiency of\nembodied AI is to provide a Dataflow Accelerator Architecture [7] to\naccelerate the robotic core functions. Our goal is to develop an architecture\nthat spends only 20% of the total system computational power on robotic core\nfunctions, leaving enough computational headroom for interesting embodied AI\napplications.\n\nAI Agent Hardware Accelerator: Each embodied AI application is an independent\nAI agent. The core of AI Agent involves understanding and executing complex\ncommands through visual language models (VLMs) or visual language action\nmodels (VLAMs). The core challenge is to execute these billion-parameter VLMs\nin real-time on edge computing platforms. On the hardware acceleration side,\nself-attentive hardware acceleration is key to enhance processing of diverse,\nhigh-dimensional data. On the software optimization side, techniques like\npruning and quantization could compress model sizes by over 80% with minimal\naccuracy loss, while knowledge distillation may further reduce size by over\n90%. With these optimizations combined we aim to enable real-time processing\nof a 70B-parameter model on platforms equivalent to NVIDIA Jetson AGX Xavier,\npaving the way for more responsive and intelligent robotic applications within\nthe constraints of edge computing resources.\n\n2.3. Design Automation for Embodied AI for Scalability\n\nDesigning, optimizing, and validating embodied AI systems require extensive\ndata. Combining synthetic and real-world data addresses the scarcity of multi-\nscenario data. For instance, we can train a reinforcement learning controller\nin simulation with synthetic data, then apply small amount of real-world data\nto optimize the model and utilize transfer learning techniques to deploy the\nmodel in various real-world scenarios. We believe the development of embodied\nAI design automation pipeline through digital twin simulation is an effective\nway to address the data bottleneck to achieve scalability [8].\n\n## Conclusion\n\nDeveloping computing systems for embodied AI represents the forefront of\nautonomous machine computing research. By addressing software integration\nchallenges, optimizing computing architectures, and leveraging design\nautomation, embodied AI robots are set to offer more sophisticated and\nefficient services in an array of complex environments. This multi-\ndisciplinary endeavor opens new possibilities for rapid innovation in robotic\ntechnologies, paving the way for a future where robots seamlessly integrate\ninto our physical world.\n\n## References\n\n  1. Savva, M., Kadian, A., Maksymets, O. et al 2019. Habitat: A platform for embodied AI research. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 9339-9347).\n  2. Hello Robot Stretch Body, https://github.com/hello-robot/stretch_body/, accessed 2024/3/14.\n  3. Meta Home Robot, https://github.com/facebookresearch/home-robot, accessed 2024/3/14.\n  4. Brohan, A., Brown, N., Carbajal, J. et al, 2023. Rt-2: Vision-language-action models transfer web knowledge to robotic control. arXiv preprint arXiv:2307.15818.\n  5. OpenAI Clip, https://openai.com/research/clip, accessed 2024/3/14.\n  6. Liu, S., Yu, B., Liu, Y., et al, 2021, May. Brief industry paper: The matter of time\u2014A general and efficient system for precise sensor synchronization in robotic computing. In 2021 IEEE 27th Real-Time and Embedded Technology and Applications Symposium (RTAS) (pp. 413-416). IEEE.\n  7. Liu, S., Zhu, Y., Yu, B., Gaudiot, J.L. and Gao, G.R., 2021. Dataflow accelerator architecture for autonomous machine computing. arXiv preprint arXiv:2109.07047.\n  8. Yu, B., Tang, J. and Liu, S.S., 2023, July. Autonomous Driving Digital Twin Empowered Design Automation: An Industry Perspective. In 2023 60th ACM/IEEE Design Automation Conference (DAC) (pp. 1-4). IEEE.\n\nShaoshan Liu\u2019s background is a unique combination of technology,\nentrepreneurship, and public policy. He is currently a member of the ACM U.S.\nTechnology Policy Committee, and a member of U.S. National Academy of Public\nAdministration\u2019s Technology Leadership Panel Advisory Group. Ding Ning is the\nManaging Dean of Shenzhen Institute of Artificial Intelligence and Robotics\nfor Society (AIRS). His research focuses on embodied AI systems, their\napplications, and technology policy for AI.\n\n  * Share\n\n    * Twitter\n    * Reddit\n    * Hacker News\n  * Print\n  * Join the Discussion\n\n### Related Reading\n\n  * Research and Advances\n\nThe Challenges Ahead For Bio-Inspired \u2018Soft\u2019 Robotics\n\nArchitecture and Hardware\n\n  * Opinion\n\nCan Machines Be in Language?\n\nArtificial Intelligence and Machine Learning\n\n  * Research and Advances\n\nEvolutionary Robotics\n\nArchitecture and Hardware\n\n  * News\n\nSeeking Artificial Common Sense\n\nArtificial Intelligence and Machine Learning\n\nAdvertisement\n\nAdvertisement\n\n### Join the Discussion (0)\n\n#### Become a Member or Sign In to Post a Comment\n\nSign In Sign Up\n\n### The Latest from CACM\n\nExplore More\n\nNews Apr 4 2024\n\nSafety Fears Raised Over Risks of \u2018Penetrative AI\u2019\n\nPaul Marks\n\nArtificial Intelligence and Machine Learning\n\nNews Apr 2 2024\n\nThe Risks of Source Code Breaches\n\nDavid Geer\n\nSecurity and Privacy\n\nNews Mar 28 2024\n\nConversations with AI\n\nBennie Mols\n\nArtificial Intelligence and Machine Learning\n\n### Shape the Future of Computing\n\nACM encourages its members to take a direct hand in shaping the future of the\nassociation. There are more ways than ever to get involved.\n\nGet Involved\n\n### Communications of the ACM (CACM) is now a fully Open Access publication.\n\nBy opening CACM to the world, we hope to increase engagement among the broader\ncomputer science community and encourage non-members to discover the rich\nresources ACM has to offer.\n\nLearn More\n\nTopics\n\n  * Architecture and Hardware\n  * Artificial Intelligence and Machine Learning\n  * Computer History\n  * Computing Applications\n  * Computing Profession\n  * Data and Information\n  * Education\n  * HCI\n  * Philosophy of Computing\n  * Security and Privacy\n  * Society\n  * Software Engineering and Programming Languages\n  * Systems and Networking\n  * Theory\n\nMagazine\n\n  * Latest Issue\n  * Magazine Archive\n  * Editorial Staff and Board\n  * Submit an Article\n  * Alerts & Feeds\n  * Author Guidelines\n\nCommunications of the ACM\n\n  * About Us\n  * Frequently Asked Questions\n  * Contact Us\n  * For Advertisers\n  * Join ACM\n\n\u00a9 2024 Communications of the ACM. All Rights Reserved.\n\n  * Cookie Notice\n  * Privacy Policy\n\nBy continuing to use our website, you are agreeing to our use of cookies. To\nfind out more, please see our Privacy Policy.\n\n", "frontpage": false}
