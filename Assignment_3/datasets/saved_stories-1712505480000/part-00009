{"aid": "39958200", "title": "Chapel 2.0: Scalable and Productive Computing for All", "url": "https://chapel-lang.org/blog/posts/announcing-chapel-2.0/", "domain": "chapel-lang.org", "votes": 2, "user": "zdw", "posted_at": "2024-04-07 04:31:27", "comments": 0, "source_title": "Chapel 2.0: Scalable and Productive Computing for All", "source_text": "Chapel 2.0: Scalable and Productive Computing for All\n\n# Chapel Language Blog\n\n## Chapel 2.0: Scalable and Productive Computing for All\n\nPosted on March 21, 2024.\n\nTags: Chapel 2.0 Release Announcements\n\nBy: Daniel Fedorin\n\nTable of Contents\n\nToday, the Chapel team is excited to announce the release of Chapel version\n2.0. After years of hard work and continuous improvements, Chapel shines as an\nenjoyable and productive programming language for distributed and parallel\ncomputing. People with diverse application goals are leveraging Chapel to\nquickly develop fast and scalable software, including physical simulations,\nmassive data and graph analytics, portions of machine learning pipelines, and\nmore. The 2.0 release brings stability guarantees to Chapel\u2019s battle-tested\nfeatures, making it possible to write performant and elegant code for laptops,\nGPU workstations, and supercomputers with confidence and convenience.\n\nIn addition to numerous usability and performance improvements \u2014 including\nmany over the previous release candidate \u2014 the 2.0 release of Chapel is\nstable: the core language and library features are designed to be backwards-\ncompatible from here on. As Chapel continues to grow and evolve, additions or\nchanges to the language should not require adjusting any existing code.\n\nThose new to Chapel might be wondering how the language came about. Chapel was\npioneered by a small team at Cray Inc. who wanted to help anyone make full use\nof any parallel hardware available to them \u2014 from their multicore laptop to a\nlarge-scale supercomputer.\n\n### What Are People Doing With Chapel?\n\nAs I mentioned earlier, Chapel is being used for a diverse set of production-\ngrade applications; these applications have guided the language\u2019s development,\npushing it to grow and support real-world computing workloads.\n\n#### Arkouda: Interactive Data Analysis at Scale\n\nArkouda is one exciting application of the Chapel language. It is an open-\nsource data science library for Python written in Chapel. Arkouda enables\nusers to interactively analyze massive datasets. Using Chapel enables Arkouda\nto scale easily; as a concrete example, its argsort operation, written in\naround 100 lines of Chapel code, was able to sort 256 TiB of data in 31\nseconds, a rate of 8500 GiB/s! That throughput was achieved by scaling Arkouda\nto 8192 compute nodes on an HPE Cray EX using its Slingshot-11 network. The\nscaling was made possible through Chapel\u2019s built-in support for multi-node\nexecution.\n\nScaling results from Arkouda\u2019s argsort function\n\nArkouda allows data scientists to iterate at the speed of thought, even with\ndatasets spanning terabytes of data \u2014 scales that could never fit into the\nmemory of a single machine.\n\nAll the performance and scalability of Chapel does not come at the cost of\nconvenience or ergonomics. David Bader, the NJIT professor leading development\nof the Arachne Arkouda module for scalable graph algorithms, has this to say\nabout the language:\n\n> Chapel serves as a powerful tool for the rapid development of scalable graph\n> analysis algorithms, standing alone in its capability to enable such\n> advancements.\n\n#### CHAMPS: A Framework for Computational Fluid Dynamics\n\nAnother excellent example of Chapel\u2019s ergonomics is CHAMPS, a software\nframework focused on three-dimensional, unstructured computational fluid\ndynamics. CHAMPS is made up of over 125,000 lines of Chapel code, making it\nthe largest project written in the language. The principal investigator of\nCHAMPS, \u00c9ric Laurendeau, has remarked on the productivity gained by switching\nto Chapel:\n\n> We ask students at the master\u2019s degree to do stuff that would take 2 years\n> and they do it in 3 months. . . . So, if you want to take a summer\n> internship and you say, . . . \u201cprogram a new turbulence model,\u201d well they\n> manage. And before, it was impossible to do.\n\nAt the time of this quote, CHAMPS was 48k lines of code, a near threefold\ndecrease from the 120k lines of its C-based predecessor. In addition to this,\nCHAMPS improved upon its predecessor by extending the fluid dynamics\nsimulations to use distributed memory and be three-dimensional, unstructured,\nand multi-physics. Each of these advances represented a step up in complexity.\nDespite this, the Chapel-based CHAMPS proved to be easier to learn, program,\nand maintain.\n\n#### Coral Biodiversity Computation\n\nOne area particularly suited for parallel computing \u2014 and one at which Chapel\nexcels \u2014 is image analysis. Scott Bachman, an oceanographer and climate\nscientist, learned Chapel from the ground up to develop software for coral\nreef biodiversity analysis. Scott made use of Chapel\u2019s parallel programming\nfeatures to develop efficient algorithms for finding ideal spots for coral\npreservation. He did so by analyzing an intricate high-resolution satellite\nimage of an ocean island. Below is how Scott described his experience:\n\n> I have now written three major programs for my work using Chapel, and each\n> time I was able to significantly increase performance and achieve excellent\n> parallelism with a low barrier to entry. Chapel is my go-to language if I\n> need to stand up a highly performant software stack quickly.\n\nBy making use of parallelism, Scott was able to greatly improve on existing,\nserial implementations in Matlab. From Scott\u2019s presentation at SC23:\n\n> Previous performance (serial, MATLAB): ~ 10 days Current performance (360x\n> cores, Chapel): ~ 2 seconds Roughly 5 orders of magnitude improvement\n\nIt\u2019s also worth highlighting Chapel\u2019s portability. Scott wrote and tested his\nprograms on a laptop. With only minor modifications \u2014 including tweaks to\nenable GPU support \u2014 his code was able to be executed on Frontier, the fastest\nsystem in the TOP500, and the only one in that list to reach a computation\nspeed of one exaflop. Scott\u2019s code distributed the problem across several of\nFrontier\u2019s nodes, and across each of the eight GPUs present in each node. By\ndoing so, it was able to achieve a massive speedup: back-of-the-envelope\nestimations suggest that Scott\u2019s program would take 648 hours to run on an\n8-core CPU, whereas the 64-node version on Frontier ran in 20 minutes. In\nother words, what would\u2019ve taken an 8-core machine almost a month was sped up\nto less than the length of a lunch break.\n\nScaling the Coral Reef Biodiversity program on Frontier\n\nIn addition to being a significant performance win, this use case highlights\nan essential aspect of Chapel: the tools that Chapel provides to developers\ncan be used for programming diverse parallel hardware. Programs can be scaled\nfrom a laptop, to a GPU-enabled cloud instance, to a supercomputer, using the\nsame language concepts and features. At the same time, Chapel programs are\nvendor-neutral \u2014 they work on a variety of processors, networks, and GPUs. As\na concrete example, GPU-enabled Chapel programs work with both NVIDIA and AMD\nGPUs.\n\n### A Language Built with Scalable Parallel Computing in Mind\n\nChapel was built specifically for parallel computing at scale, guided by\nexperts and real-world high-performance use cases. Because of this, the\nlanguage has many unique features. These features interconnect to form a\nconsistent and general model for programming diverse parallel hardware, as I\nalluded to in the previous section. To get a taste of Chapel, take a look at\nthe following serial program:\n\n    \n    \n    var Space = {1..n}; var Dst, Src, Inds: [Space] int; initArrays(Src, Indices); // populate input arrays with data for i in Space do Dst[i] = Src[Inds[i]];\n\nThis program copies elements from an integer array Src to another integer\narray Dst. However, it reorders the numbers it copies \u2014 the third array, Inds,\ncontains the destination indices for each source index. In other words,\ndestinationIndex = Inds[sourceIndex].\n\nWhen trying to improve the performance of a program like this, one important\nthing to consider is that today, even the CPUs of relatively cheap consumer\nlaptops have multiple processor cores. This means that they support\nparallelism. To tweak the above program to allow it to make use of multiple\nCPU cores, it\u2019s only necessary to change the for to a forall. If you were to\nrun this on your 8-core M1 Mac, the iterations of the loop would be divided\nbetween those cores, likely resulting in a noticeable speedup over the\noriginal for-loop.\n\n    \n    \n    var Space = {1..n}; var Dst, Src, Inds: [Space] int; initArrays(Src, Indices); forall i in Space do Dst[i] = Src[Inds[i]];\n\nWith just one more tweak \u2014 the addition of an on statement \u2014 the above program\ncan be made to execute on a GPU:\n\n    \n    \n    on here.gpus[0] { var Space = {1..n}; var Dst, Src, Inds: [Space] int; initArrays(Src, Indices); forall i in Space do Dst[i] = Src[Inds[i]]; }\n\nIn this case, iterations of the loop will be executed in a massively parallel\nfashion by the multiple threads of the GPU. I covered Chapel\u2019s GPU support in\nsome detail in Introduction to GPU Programming in Chapel.\n\nTo scale the program to something like a cluster, cloud instance, or\nsupercomputer, the programmer has to make use of several compute nodes at the\nsame time. In this example, that can be achieved by asking Chapel to\ndistribute the arrays across all compute nodes available to the program. When\ndoing so, Chapel divides the iterations of the loop \u2014 as well as the array\ndata itself \u2014 across the nodes\u2019 memories and processors.\n\n    \n    \n    use BlockDist; var Space = blockDist.createDomain(1..n); var Dst, Src, Inds: [Space] int; initArrays(Src, Indices); forall i in Space do Dst[i] = Src[Inds[i]];\n\nWith additional tweaks, the multi-node and multi-GPU versions of this program\ncan be combined to distribute computations across all GPUs in an entire\ncluster. These are the exact sorts of changes that were made to Scott\nBachman\u2019s Coral Reef software above to make it run on Frontier.\n\nThe main takeaway is that the same tools \u2014 forall loops and on statements \u2014\ninterplay elegantly to fit a wide variety of use cases. Moreover, they don\u2019t\nsacrifice performance. The multi-node version of the program above (which is\nthe Bale IndexGather benchmark, by the way), outperforms standard parallel\ncomputing technologies:\n\nPerformance of Chapel\u2019s IndexGather benchmark, with the --auto-aggregation\ncompiler flag\n\nThe code presented up to this point is far from a complete picture of all of\nthe unique features that Chapel brings to the table; there\u2019s just not enough\nspace here to cover them all. Some other features to check out are:\n\n  * sync variables and coforall loops for explicit parallelism, covered in depth in one of our previous blog posts\n  * reductions, for combining a set of elements into a scalar, covered in another blog post\n  * promotion, for seamlessly applying scalar functions to multiple elements at once, covered in a third blog post\n\nAnd those are just the parallelism-specific features! Take a look at the\nAdvent of Code series for a gentle introduction to Chapel, including its\ngeneral-purpose features.\n\n### Rich Tooling Support\n\nChapel\u2019s 2.0 release also brings improvements to developer tooling. Along with\nthe latest version of the language, the Chapel team is publishing a Visual\nStudio Code extension for Chapel. This extension provides support for a number\nof features, including:\n\n  * code diagnostics (syntax and semantic errors), including quick fixes\n  * documentation on hover\n  * go-to-definition, find references\n  * linting for common issues using chplcheck\n  * and much more!\n\nThe VSCode extension is an exciting development, bringing a large number of\nmodern editor features to users of Chapel. Much like the features of Chapel\nitself, there\u2019s simply not enough room in this article to show all of them\noff. Stay tuned for another article that walks through what the new extension\ncan do in more detail. In the meantime, as a little teaser, here\u2019s a\ndemonstration of hover information and go-to-definition:\n\nHovering and going-to-definition using Chapel\u2019s VSCode extension\n\nMuch of the extension\u2019s functionality is provided by a general tool that uses\nthe Language Server Protocol. This new tool, the Chapel language server, can\nalso be used from other editors. For example, members of the Chapel team use\nit with Neovim on a daily basis.\n\n### Conclusion and Looking Forward\n\nChapel has supported developers with various computing needs in creating\nperformant and maintainable software since 2015, a track record of nearly 10\nyears. The 2.0 release represents the culmination of a concerted, multi-year\neffort to refine Chapel\u2019s core functionality based on these many years of\nexperience. Chapel is now stable, but it is not finished: the language will\ncontinue to see performance improvements, new features, and better tooling.\nWhether you are working with a personal machine or a multi-node cluster, there\nhas been no better time to get started with Chapel to get the most out of your\ncomputing hardware.\n\n", "frontpage": false}
