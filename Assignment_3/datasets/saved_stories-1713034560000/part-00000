{"aid": "40022839", "title": "Scaling Tacit Knowledge (2022)", "url": "https://nintil.com/scaling-tacit-knowledge/", "domain": "nintil.com", "votes": 3, "user": "Tomte", "posted_at": "2024-04-13 12:53:12", "comments": 0, "source_title": "Scaling tacit knowledge", "source_text": "Nintil - Scaling tacit knowledge\n\nNintil\n\nNintil\n\nTo estimate, compare, distinguish, discuss, and trace to its principal sources\neverything\n\n# Scaling tacit knowledge\n\n2021-12-10; Last updated: 2022-05-24 Wordcount: 13405 | Reading time: 71 min \u2022 Progress Studies \u2022 Science \u2022 Research \u2022 Is this article wrong?\n\n# Table of Contents\n\n  * Tacit knowledge\n\n    * Explicit knowledge\n    * Tacit knowledge\n  * Some examples\n\n    * Tacit (and private) knowledge in the life sciences: the Rejuvenome\n    * Tacit knowledge in meetings\n    * Tacit knowledge in reference checks\n    * Tacit knowledge in scientific literatures broadly\n  * Sharing tacit knowledge\n\n    * Language learning\n    * The fractal complexity of tacit knowledge: Polymerase Chain Reaction\n    * Chess, a domain where we have solved tacit knowledge transfer\n    * Software engineering\n  * Managing experts\n  * Scaling expertise\n  * Conclusion(s)\n  * References\n  * Changelog\n\n> Nobel Prize winner P.B. Medawar once wrote, in Advice to a Young Scientist,\n> that 'any scientist of any age who wants to make important discoveries must\n> study important problems.' But what makes a problem \"important\"? And how do\n> you know it when you see it? The answers don't come from reading them in a\n> book, or even by explicitly being taught them. More often, they're conveyed\n> by example, through the slow accretion of mumbled asides and grumbled\n> curses, by smiles, frowns, and exclamations over years of a close working\n> relationship between an established scientist and his or her protege.\n> (Apprentice to Genius)\n\nBen Reinhardt posted earlier in October the picture below. It shows two ways\nto \"learn a field\": one is the \"right one\" (talking to people, the outer loop)\nand another is depicted as a misconception, where one just reads key papers.\nLearning a field can take multiple meanings, it can be learning the content of\nthe field, learning the social context of the field (what are the active areas\nof research, key labs, its history), or learning to do research in the\nrelevant field.\n\nAs someone who's an example of being in that inner loop, I thought it'd be\nworthwhile to engage with this, but over time that ended up growing into a\nlonger and somewhat meandering essay on the nature of tacit knowledge. If you\nare left wondering what do I really mean, worry not: the conclusion has an\nenumeration of points I want to make. This essay makes a heavy use of examples\nand analogies, everything you need is linked from this essay, so you should\nprobably be clicking in all the links! If you want the TLDR now, here it is:\nExpertise requires acquiring a degree of private and tacit knowledge.\nExpertise cannot be taught using only explanations. Acquiring expertise can be\naccelerated by means of being exposed to a large library of examples with\ncontext. We are not leveraging this as much as we can and we should experiment\nmore to explore how far this method can get us. What I describe in this post\nis a hypothesis that is looking to be tested and I offer indirect evidence for\nwhy it may work.\n\nBen is not the only one with a person-first approach to learning: In the same\nTwitter thread, Alexey Guzey joins Ben with a 90/10 split between talking to\npeople and reading. This is not due to some limitation with the written vs\nverbal form. There are some people out there like Rob Wiblin that find it hard\nto read anything at all. Ben and Alexey's point is very different: Is there\nknowledge that can only be gained by talking to the experts? Is it faster to\ngain certain kinds of knowledge by talking to the experts?\n\nBen Reinhardt doing research\n\nTo be sure, I don't only read papers, nor does Ben exclusively talk to\nresearchers (There's a \"reading papers\" Ben at the top of the picture).\nReading papers and talking to people are clearly both useful.\n\nWhy would one talk to people instead of just reading? Reading has the\nadvantage of input speed: I don't know anyone that can speak faster than I can\nread. Reading also has the advantage of being able to incorporate figures,\nlinks, tables, or citations. And even better: One can jump and skip ahead in\ntext, have multiple documents open at once, go back and forth and traverse\nmore knowledge than a single person can possibly have in their head, zoom\ndeeply into the specifics of one given paper, find related and novel work.\nIt's hard to do this within the time box of a video call or an in person\nmeeting.\n\nHowever, the reading-first approach means that at first one will take a very\nlong time to get to answer a question that would just take seconds to ask an\nexpert. For example, if one just wants the answer to \"Does rapamycin extend\nlifespan in mice?\", getting to understand the relevant literature can take\nmonths. Sure one could do a quick Google Scholar (or plain Google) search and\nfind a bunch of papers, but that comes with some built in confidence level\n(How sure are you that the papers you found are good?). A quick call with an\nexpert can just give you the answer, the rationale for the answer, debates\naround the answer (Does it work in some mice but not others? Will it work in\nhumans?), considerations or assumptions that you had not initially considered\n(The idea of compounds analog to rapamycin (rapalogs), that the answer may\ndiffer by dosing schedule) and so forth. You can't interrogate a paper, but\nyou can ask questions to an expert (As Ben put it, in conversation).\n\nThis one-off interaction with the expert also comes with its own built in\nuncertainty: Was the expert chosen correctly? Do they have their own biases\nthat should be factored in? What if multiple experts contradict each other?\nThis interaction wouldn't lead you to learn a field, just to gain a small\npiece of knowledge about one molecule, rapamycin. For this one particular\ncase, it seems to me the heuristic \"Check on the internet for 10 minutes and\nfind an answer, otherwise call the expert\" would work, but it would work only\nif one has some prior background to quickly find and aggregate research work.\n\nHere's a more complex example: Suppose you want to learn how much salt you\nshould be taking. The Google approach yields 2.3g per day (FDA guidelines).\nBut then you are of course smarter than this and you keep digging; you deploy\nthe heuristic of inverting common knowledge (more salt is worse, period) and\ntry to find evidence that actually, too little salt can be bad. You come\nacross some work on that, showing that there's a U-shaped relation and that\nperhaps the right amount of salt to consume is more than the guidelines say.\nYou feel smug and smart. You talk to some doctors that vaguely gesture at the\nU/J-shaped relation between salt and mortality. But some time after, you learn\nof a piping hot meta-analysis fresh off the press, analyzed and endorsed by\nthis one Stephan J. Guyenet on Twitter, reasserting accepted knowledge: less\nsalt is better. This is the answer I would believe, but for this particular\none, I started with an advantage because I have done the prior work of\nsearching experts to trust in that one space (As it happens, my other go-to\nexpert for nutrition matters concurs with Guyenet). Whether here one ends up\nwith the correct answer or not would depend on how good one is at interpreting\nprimary sources and how good one is at finding good experts. But here we don't\nhave to talk to the experts, for this one very simple question that asks a\nrelation between two variables, we can rely on short analyses from the\nexperts; this both points to primary sources and explains where the\ncontradictions may be coming from. This is better in one regard than talking\nto the experts; they probably can't cite all these papers from memory, nor\nimmediately address what the trouble is with the discordant paper you found\nthat morning. Particularly illustrative was this podcast between Gary Taubes\n(Who subscribes to the \"carbs are bad\" view) and Guyenet (Who think carbs are\nfine in moderation). Guyenet came prepared with a list of arguments and\nrelevant work he could point to where he had pre-answered potential\ncounterarguments to his views. Imagine now trying to talk to either of them vs\nreading their writings, or writing a best evidence synthesis of what they are\nsaying. It seems obvious reading will yield the superior understanding, but\nnot necessarily a better answer and definately it will take longer.\n\nBut these two topics are still very simple and by no means get anywhere close\nto \"learning a field\", they are about very specific questions. If instead we\nwant to know what are open questions in the field? Or, what would be projects\nthat could accelerate the field, or something of that sort? Those links do not\nyield good answers. There is no trivial googling that will in general get you\nanswers there so one can't use the shortcut of finding expert analyses. One\ntruly has to get the field, and doing this can require acquiring forms of\nknowledge that are harder to find out there by reading papers.\n\n# Tacit knowledge\n\nWhat tacit knowledge means differs by whom you ask, but in general the\ndefinition refers to knowledge that is very hard to acquire (In the broadest\ndefinition) or knowledge that is embodied in a person (or group) and that they\ncan't make fully explicit. Of importance here is that talking to an expert\nwouldn't get you that knowledge, in this second definition. An obvious example\nis riding a bike; one could read books about cycling or talk to Tour de France\nwinners for months and not have much idea how to skillfully ride a bike on a\nfirst trial. Tacit knowledge may be hard or impossible to get from experts,\nbut this is not that bad: one doesn't need this tacit knowledge for many\npurposes. If all you need is a precise answer to a question, asking a panel of\nexperts (if they agree on the answer, at least) can yield a reasonably\ntrustworthy answer even if we are not fully aware of the chains of reasoning\nand specific pieces of evidence the experts are relying on when delivering\nthat judgement.\n\nExperts are worth talking to for reasons other than them having tacit\nknowledge: in the example earlier the expert may know the right answer to the\nrapamycin effectiveness question, but this piece of knowledge happens to be\npublicly available (a form of explicit public knowledge). Experts also possess\nprivate explicit knowledge which can be important and is what one mostly gets\nfrom one-off calls from experts. They could tell you that \"That paper that\nseems promising from 30 years ago? Yeah, a friend was there and it's quite\nsketchy, anyone you talk to from that lab will confirm\".\n\nIn an ideal world, one would learn this from reading about later attempts at,\nsay, replicating or extending that line of work, but we don't always live in\nthat world. This kind of knowledge is different from tacit knowledge in its\npurest form in that once we gain that knowledge, we could make it public and\nanyone could effortlessly learn it without having to talk to the expert again.\nSystems like Pubpeer try to scale this sort of knowledge by providing a\ncentralized repository for commentary (generally critiques) of scientific\nwork.\n\nHere's a brief typology of the knowledge relevant for the purposes of this\nessay. The lenses that are driving these categories are two: First, can we\nscale the knowledge without having access to a tutor, and second, can an\nexpert even teach you without them being present.\n\n  * Explicit knowledge\n\n    * Public\n    * Private\n  * Tacit knowledge\n\n    * Public\n\n      * Motor skills\n      * Intellectual skills\n    * Private\n\n      * Social\n      * Individual\n\n## Explicit knowledge\n\n### Public\n\nThese are facts that are easy to come by and not particularly worth saying\nmuch about. \"What's the capital of the United Kingdom\" or \"What's the market\ncapitalization of Tesla as of today\" can be quickly looked up on the internet.\n\nA problem with public explicit knowledge is that there is a lot of it, and\ninteresting chunks of it are not trivial to interpret. As in the example of\nthe salt and mortality correlation earlier, there is no general oracle that\nwill spit out facts that are guaranteed to be true. Interpreting available\npublic knowledge, and knowing where to find it in the first place, in some\nsituations requires nontrivial amounts of other kinds of knowledge, some of it\ntacit.\n\n### Private\n\nSome knowledge is not particularly hard to transmit if someone wanted to but\nthey may not have incentives to do so, and so it remains private. For example,\nwhen designing a scientific experiment it may be useful to know the cost of\nvarious reagents, supplies, and equipment. Many of these prices are available\nonline. But others are not, hidden behind a \"talk to sales\" button or an email\nto the right person. If one is in the relevant social circle, a quick message\nto a colleague can get you that information. This knowledge could be made\npublic, but generally there are incentive problems why this is not the case.\nIn the pricing example, vendors may make buyers sign NDAs to avoid leakage of\nthe pricing information.\n\n## Tacit knowledge\n\nHarry Collins and Robert Evans, in their Rethinking Expertise define tacit\nknowledge as the deep understanding one can only gain through social immersion\nin groups who possess it. This is one possible definition, but to my purposes\nhere, an overly narrow one. Tacit knowledge in the Collins-Evans sense will\ncorrespond to what I call here private individual tacit knowledge. Note that\n\"groups\" could be a single person (as in a master-apprentice relation).\n\n### Public\n\nThe first type of tacit knowledge is one I'll call public to mean that one\ncould acquire the skills with publicly available information, without need of\na coach, tutor, or apprenticeship.\n\nI divide this set of skills into two: motor and intellectual. In practice this\ndistinction is not clear cut, but broadly for \"motor\" think riding a bike and\nfor intellectual think activities that all look like sitting at a computer\ntyping away. An example of a hybrid is instrument-playing; playing an\ninstrument requires some very fine motor skills but also some sense of what\ngood music sounds like. One can hire a teacher to learn how to play, but\nanecdotally many famous guitar players are self-taught.\n\n#### Motor skills\n\nThere's a type of tacit knowledge where you need to do something (as opposed\nto reading about it or talking to an expert about it) to gain the skill. A\nbike theoretician that has spent a year reading about bike riding and\nvideocalling with bike pros can't hope to ride a bike proficiently, if at all,\non a first trial. At the same time, one can learn to ride a bike alone. If you\nwatch this video, you can see a sequence of steps that would orient you in the\nright direction. You still need to ride a bike and practice, but the video has\nenough guiding to learn the skill.\n\nBut this kind of knowledge (the one involving novel movements or fine motor\ncoordination) is not the kind of knowledge relevant to most knowledge work,\nthe focus of this essay.\n\n#### Intellectual skills\n\nOne example of this is judging the doneness of a particular item being cooked\n(could be a steak or a quiche). Someone that has cooked it a lot could tell\nwhen it is ready, but if asked to explain it, she could point to the\nappearence of some brownish patches, but not too many, or there being such and\nsuch smell. But despite not being able to verbalize this knowledge, we can\nstill teach it to some degree, in this case, in video format. Watching someone\ncooking the item repeatedly can give a sense of what \"done\" means. This is a\ntrivial example of how tacit knowledge can still be scaled, despite the expert\nnot being able to verbalize it. It also points to a key factor in enabling\nscalable tacit knowledge: Whether there are external artifacts that we can\nobserve. A video of someone meditating wouldn't teach much about how to\nmeditate.\n\nSkills that fit here would be chess (Where we have external artifacts, the\nchess board) or writing (Where the output can be read).\n\n### Private\n\nThis is the kind of knowledge that could only be acquired by means of an\napprenticeship and/or being deeply embedded in a community of practice. It\nrequires someone to transmit that knowledge. The fact that it is private need\nnot be an intrinsic feature, as with explicit private knowledge. But supposing\nwe could overcome these incentives issues and actually get to sit down with\nmultiple experts, could we make private tacit knowledge into a form that is\namenable to individual learning, and thus scaling? This is one of the core\ndriving questions of this essay, but getting there will require some\nmeandering through examples.\n\n#### Individual\n\nThis is the class of knowledge Collins and Evans have in mind in their\ndefinition earlier; for this it's not enough to apprentice, you need to be\nembedded in the relevant community. Individual private tacit knowledge is the\none that you can gain as an apprentice. An example that comes to mind is\nlearning how to design glass sculptures in the style of a particular niche\nartist that is not recorded in video.\n\n#### Social\n\nThis is the knowledge that somehow would be embodied not in the nodes but in\nthe edges of a network of knowledge workers. It's different from the other\ncategories in that the knowledge is not in anyone's head (so no apprenticeship\nwill get you there) but it's embodied in an entire organization. As an\nexample, I will claim the CEO of TSMC does not know how TSMC works. Nor does\nanyone know exactly the entire chain of processes that lead to the production\nof a humble pencil. But somehow the economy as a whole does. As with motor\nskills, this class of knowledge is outside of the scope of this essay.\n\nI want to close off this section with a brief discussion of an example that\nillustrates an example of social tacit knowledge, how hard it can be to\nreconstruct, and how we tend to see these sort of examples.\n\n##### Fogbank\n\nSuppose you hire an army of smart physics PhDs that have zero knowledge of how\nto build nuclear weapons, then ask them to design one. Could they do that? In\na recent post from Rohit Krishnan the answer from a real world experiment is\napparently yes and to the extent one distrusts that one report, I think some\ntrial and error of their own (they were not building the device, just\ndesigning it) would have set them in the right trajectory. But Rohit also\nnotes there the case of Fogbank, where trying to manufacture a material used\nin atomic weapon manufacturing that was last made decades prior, took many\nyears and millions of dollars to recreate, despite having access to the\noriginal instructions for how to make it, and despite being able to talk to\nthose that worked on the project originally. Turned out some impurity being\nadded was key, and no one in the original team was aware of this! This is\ninterestingly very similar to Collins (2001), where US-based researchers tried\nto replicate Soviet measurements of a parameter of sapphire samples,\nunsuccessfully. Turned out that the key to take the measurements in a\ncomparable way was to\n\n> The second method of greasing thread demonstrated by Checkhov, and used\n> interchangeably with the first method, was direct greasing of the fine\n> thread with human body grease. Checkhov would run the fine Chinese thread\n> briefly across the bridge of his nose or behind his ear. The ear method was\n> adopted by the Glasgow group, though it turned outthat only some people had\n> the right kind of skin. Some, it transpired, had very effective and reliable\n> grease, others\u2019 grease worked only sporadically, and some experimenters\u2019\n> skins were too dry to work at all. All this was discovered by trial and\n> error, and made for unusual laboratory notebook entries such as: \u2018Suspension\n> 3: Fred-greased Russian thread; Suspension 12: switched from George-grease\n> back to Fred-grease\u2019, and so forth. As with James Joule\u2019s famous measurement\n> of the mechanical equivalent of heat,\u201d! it seems that the experimenter\u2019s\n> body could be a crucial variable.\n\nThe Sapphire example is referenced elsewhere; Ben's notes and most discussions\nof the paper focus on the central point of the paper: the need for personal\ninteractions and trust to effectively convey tacit knowledge. But the\nconclusion of the paper is almost as important: Collins suggests a way\nforward! Instead of resigning ourselves to lenghty and costly trial and error\nwe could do better:\n\n> Reporting a Second Order Measure of Skill: This kind of science could be\n> made easier if the importance of knowing the difficulty of an experimental\n> skill or procedure was recognized and emphasized. The conventional style of\n> writing scientific journal papers (and even books) excludes details of this\n> kind. Yet someone trying to rediscover how to produce a result in the\n> absence of a laboratory visit could be helped by knowing just how hard the\n> experiment or measurement was to carry out in the first place, and just how\n> hard it continues to be. Such information could be roughly quantified \u2014 it\n> is a \u2018second order measure of skill\u2019.*\u00b0 Experimenters could record something\n> along theselines:\n>\n> It took us some 17 months to accomplish this result in the first instance,\n> during which time wetried around 165 runswith different set-ups, each run\n> taking around a day to complete. Most successful measurements on new samples\n> are now obtained in around 7 runs, butthere is a range of approximately 1 to\n> 13 runs; each run now takes about 2 hours. The distribution of numbers of\n> runs on the last 10 samples we have measured is shown in the following\n> diagram ...\n>\n> Information of this sort could be expressed briefly, without radically\n> changing the conventional style of scientific paper-writing, and yet could\n> be of significant benefit to those trying to repeat the work.It is just a\n> matter of admitting that most things that seem easy now were very hard to do\n> first time round, and that some remain hard even for the experienced\n> experimenter. We concede, of course, that within the current conventions of\n> scientific writing, setting out these difficulties would look like weakness;\n> science is conventionally described as though it were effortless, and the\n> accepted scientific demeanour reinforces this impression. What we are\n> suggesting is a slight transformation of convention and demeanour\u2014with a\n> view to improving the transmission of scientific knowledge.\n\nThis is just one way to enhance scientific writing for ease of\nreproducibility, but one could think of others.\n\nThe same is true of discussions of Fogbank: The core lesson is acknowledged\n(Tacit knowledge is real, and hard to transmit!) but such acknowledgement is\nso strong that hard is made to seem impossible, so no solutions to the problem\nof tacit knowledge transmission are proposed. We should not look at tacit\nknowledge in awe of its fractal richness, being humbled by its existence.\nRather we should look at tacit knowledge as a challenge to be overcomed!\n\n# Some examples\n\n## Tacit (and private) knowledge in the life sciences: the Rejuvenome\n\nOne can get a textbook on molecular biology and read it, yielding knowledge of\nvarious facts about molecular biology. Does then one become a molecular\nbiologist? No, because the knowledge required to do that is of a different\nsort.\n\nThis is clear with a brief example: Suppose somehow a copy of A single\ncombination gene therapy treats multiple age-related diseases (2019) lands in\nyour desk. You read it. Assuming you remember what is literally written in the\npaper you will be able to answer questions like:\n\n  * Who authored the paper?\n  * What genes were delivered? (FGF21, Klotho, sTGFbR2)\n  * How were they delivered? (AAVs, one with each gene)\n  * What was one test that showed effective treatment of a disease? (improved glucose response)\n\nThere is a second kind of questions that you could be able to answer if you\nhave read many papers of this sort that you won't be able to answer if you\nonly read this one paper:\n\n  * What other ways are there of delivering these genes?\n  * Are the tests they are using \"good\"? Do they support their claims?\n\nNow even if you understood perfectly well the context of this paper, and were\nable to discuss it passing for an actual expert in the field, if you wanted to\nrepeat the experiment they did, by yourself, without any help, would you be\nable to? In exactly the same way the authors did? Probably not, and this\nbecomes more clear the more you try to design the actual study. For example,\nyou need to feed the mice something, but the study doesn't say what the\ncontrol group gets other than it's a \"normal diet\", so you need to assume one.\nThis is also a case where you could ask the authors (The answer: Normal diet\nmeans something like NIH-31). Then, would you be able to inject the viruses in\nthe way described in the paper (retroorbital injection) without prior\ntraining? And what anesthesia would you use (the paper doesn't say; is\nisoflurane good?). For qPCR, what temperatures and timings would you use (the\npaper doesn't say).\n\nThere is something you wouldn't get in any way other than asking the authors:\nWhy is the study the way it is? Why those three genes? And why did they test\nthe things they test?^1\n\n[1]. In case you wondered, I did ask, and there is no principled answer, just\nsome background knowledge, cited in the paper, that overexpressing those genes\nled to some health benefits in the past, and the evidence for those was\nseemingly stronger than for other of the thousands of other genes, but there\nwas no model that singled out those three as optimal. However, knowing the\n-exact- way that the authors went from knowledge of the literature to those\nexact three genes is a form of tacit knowledge, they wouldn't be able to tell\nme if they tried\n\nThere is a hierarchy of knowledge at work here:\n\n  1. Learning core facts (What's on the abstract and conclusion)\n  2. Learning how facts relate to each other (e.g. what subfields are in a field, what alternatives are there to a particular choice, where does this piece of work fit in the field)\n  3. Learning how the knowledge was generated in the first place, all the way down to specific pieces of equipment (The methods section and beyond)\n  4. Learning to design novel experiments\n\nThe last one is the hardest one to make fully explicit because by then you're\ndealing with the frontiers of knowledge where the \"facts\" to rely on are not\nso much published results and more like hearsay from someone that tried this\nor that in their lab, and some .csv files you are sent from data pre-\npublication along words of caution not to further share it.\n\nHere's a concrete example of 4: When designing the Rejuvenome project (That\nultimately ended up being hosted at the Astera Institute), one of the design\nconsiderations was to have genetically heterogeneous mice. Usually lab mice\nare inbred, they are crossed sibling-to-sibling for generations until the\nresulting population is isogenic. Why do this? The textbook rationale is that\nif the genetic background is the same then that can reduce the variance of the\nexperiment, leaving only experimental conditions, which can be controlled as\nwell. However, this can also lead to a given therapy working only in one\nparticular kind of mouse, but not others, making the results less robust.\nMaybe the mouse tends to develop a particular kind of cancer very fast and\ntherapies that target that will show outsized increases in lifespan that will\nnot generalize. This kind of reasoning is why the gold standard for\nintervention effectiveness in the aging field, the Interventions Testing\nProgram uses genetically heterogeneous mice known as UM-HET3. These mice have\ndrawbacks: You have to (at the time) breed them yourself, then wait 18 months\nto age them. Based on this reasoning and the fact that they were good enough\nfor the ITP, those were the mice that went into the original Rejuvenome draft.\nAt that stage, I had no idea of how they would be housed (Answer: ~5 a cage)\nor what they would be fed (Answer: this), but I knew the ITP was running a\nsimilar program so those answers must exist somewhere. These particulars\ntherefore, were left as \"mere\" implementation details that would be elucidated\nlater, but which didn't affect the high level design of the study.\n\nAfter that initial stage however, we learned some new things that were not\nobvious from just reading papers, this time from talking to researchers in the\nfield:\n\n  * That some, believe the \"isogenic=less variable\" argument is actually false, on the grounds that isogenicity makes the mice weaker and couples them more to the environment (if an effect=genes+environment+interaction, this latter term would go up), amplifying that noise. This view is not universally shared.\n  * That there are other kinds of outbred mice, like the Diversity Outbred (DO). That naturally leads to the question of whether to use those\n\n    * Some time after that, we learned that DO male mice are very jumpy and aggressive. Given that we knew that for females you could have 5 in a cage, what happens if the males have to be single housed? Should we just do the more peaceful HET3s?\n    * Some researchers opted instead for studying only female mice. The papers using these all-female DO cohorts wouldn't explain why it was only females. In retrospective that was because of an undisclosed fact (That the authors told us, but did not write down: That they thought the male DOs would be too aggressive)\n    * We had lifespan data for the HET3s that's publicly available but not so for the DOs. We only got that by asking around and we were sent a .csv file with data from an upcoming study. Lifespan data is important to do some statistical calculations regarding sample size and power.\n  * We wanted to do all sorts of \"omics\" on the blood. But how much blood does each of these methods require? How much blood is in a mouse anyway? (1.7-2.4mL) How often can one get this blood? (Once a month) This is not so much tacit knowledge, all this information is publicly available and there are guides and even videos of how one would go about doing it. But initially these seemingly minor details were not in our mind which meant that very concrete questions like how many mice get sampled how often, or whether the same mice would be sampled throughout the study or even whether samples would be pooled were not considered. And some of these affect the study design!\n  * Altos! Altos Labs was one of the big reveals of the year in the field. But in the field people had been talking about it for months prior, in various online seminars and Q&As one could hear references to a new \"Milky Way Foundation\" launched by \"some\" billionaire. PIs here and there would mention that they had gotten a grant from them. This kind of knowledge is not so much about the domain the field studies (aging) but about the field itself and definitely impossible to acquire just by reading papers. Probably also impossible to acquire by trying to talk to researchers unless you were deep enough in the field for the other party to assume that you are already in the know.\n  * A certain promising study in a subfield of aging that showed substantial lifespan gains was not fully accepted as generalizable because it used progeroid (\"fast-aging\") mice, so there was the possibility that the intervention wouldn't work in regular mice. Many in the field when asked wished to know what would happen if it were repeated in regular mice. I had coffee with a scientist in the field who mentioned to me (While discussing unrelated matters) that the study had been done (along with the results) and that would be released eventually. This knowledge would make one be slightly less bullish on said intervention, which has implications for study design: We had planned to actually do that study ourselves as part of Rejuvenome, but now we can use that prior art to decide whether to improve upon it.\n\nMost of these pieces of knowledge are actually explicit private knowledge, not\ntacit knowledge, but in practice the borders between both are blurry. Yes, in\ntheory the answers to all the questions one wants to ask about study design\nare in someone's head and they could tell you if you asked. But you don't know\nwhat questions to ask. Knowing what the right questions to ask is a form of\ntacit knowlege. A novice in study design (i.e. me, at first), when hearing\n\"We're going to do X,Y,Z things with blood\" would probably just nod. An expert\nwould probably ask how much blood each assay requires perhaps because X,Y,Z\nsound like too much. It's not like the expert had to think about that\nobjection, it's that the relevant questions to ask become more salient with\nexpertise.\n\nGoing back to what I said earlier about the Diversity Outbred being\naggressive, you can get from here that they can be jumpy and the males can be\nvery aggressive. The jumpiness point can be learned from other public sources.\nThat males are aggressive and necessitate single housing (Usually you can have\nsay 5 mice in one cage) was something that as a matter of fact could have been\nlearned from public sources but it wasn't, it took someone to tell us that\nthis specific issue was relevant.\n\nHowever! Even after these and many other findings, the latest iteration of\nRejuvenome still looks very similar to the original vision and overall the\ntacit knowledge I've gained has played more of a finetuning role rather than\ninforming the core vision of the study.\n\n## Tacit knowledge in meetings\n\nMeetings are universally hated and rarely loved. Running effective meetings is\na form of tacit knowledge. There are for sure principles that can be distilled\nbut I don't think just stating them would be very useful. For example,\nconsider someone that suggests having an agenda for a meeting. If one just\ngets that suggestion one may be tempted to think why do that, we can just wing\nit as we go. One can add have an agenda, because otherwise you won't cover the\ntopics you want, you'll drift and reprioritizing during the meeting is harder.\nBut even then one could think I'm smarter than that, can still do it.\nSituations like this one abound in other domains on life. Does one need to\nfail to really understand why some norms and frameworks exist?\n\nConversely, when one accepts as obvious the idea that if a meeting is going in\ncircles one should do something to stop that, knowing that in the abstract\ndoesn't mean one will do it. At least in my own experience, I've been in\nmeetings where the loopiness was only seen after the fact. In later meetings\nloopiness can be picked up by a sense of distress (\"Something is off with this\nmeeting\"), a sense of impatience (\"I've heard this before\") and a sense of\ndoubt (\"Are we repeating ourselves?... or maybe they are just clarifying what\nthey said\"). Eventually when one should or should not voice that the group is\nrunning in circles (vs clarifying and weighing various options, incrementally\nadding) becomes clearer and clearer. Eventually one ends up thinking of ways\nto avoid getting there, studying why those frustrating conversations happen in\nthe first place, leading up to say what I describe here. There's nothing new I\ncan add to how to run effective meetings (Though I could write a post on that\nsummarizing what I know). But when thinking about them I've ended up thinking\nthat when giving advice it's important in many cases to explain where the\nadvice is coming from, and at the receiving end being humble enough to\noverride your rational judgement (\"I know better; I don't see why I am wrong\")\nand follow a principle instead (\"Experts tend to be right in this context\")^2\n.\n\n[2]. If this sounds strange, consider an optical illusion. You have reason to\nbelieve that two sticks are of different length because that's what your eyes\nare telling you. But you can also pattern-match this situation to situations\nwhere you have been before (being shown an optical illusion) and say and act\nas if the sticks were the same length, despite some form of belief in 'they\nare different'. Even when asked whether they are the same length and you say\nthat they are, there's a discomfort in the answer, something within says 'But\nthey are not!'. That same something must be suppressed in the case of taking\nadvice from experts in some cases. Knowing when is an art.'\n\n## Tacit knowledge in reference checks\n\nOk I cheated there is a third one, but this one is brief. Investor Graham\nDuncan (profiled here) has an article, What's going on here, with this human\non hiring, with a strong empasis on obtaining references. At the bottom of the\nessay, Graham gives us a guide to do references, questions to ask, and a guide\nto do interviews. That's the explicit knowledge that the author tries to use\nto capture what is going on in his head. Reading the essay (And Commoncog's\nprofile) changed my mind on the idea of obtaining references. Whereas before I\nwould think that \"Why get references, they are going to be biased\" now I think\nthat \"There is going to be some truth mixed with the potential bias, but if\none asks the right questions one can get to some of that truth. By asking\nmultiple people the right questions, one can triangulate how the person really\nis.\". But I still do not know how to do Duncan-level reference checks!\n\n## Tacit knowledge in scientific literatures broadly\n\nThere is more knowledge in science than is written down in the whole of\npublished papers in a given field. But at the same time, there is more\nknowledge embodied in a set of papers than is written down in the papers. If\nyou read this tweet maybe you can relate to that phenomenon, you can read a\npaper and get what it means while acknowledging (from past experience) that\nsuch understanding is very thin. Last year I wrote a post on understanding\nbiology where I try to explain the process that takes you from that to a\nricher understanding. If you read enough papers you end up noticing things\nthat the papers are not saying; this can be how often certain entities are\nmentioned, which labs tend to publish what kind of work, what methods are more\nfrequent, whether a given paper is being thorough or not (by comparison to\nothers), or even whether a given result is a priori trustworthy (e.g. is this\nan area where contradictory results abound or no matter how you measure you\nget the same thing). Reading research literatures is like an example I'll\ndiscuss below (language learning). One is constructing a model of the domain\nby using the papers as pieces of data. The task is not to memorize the\nspecific papers (after all they can be wrong) but to build a model from which\nthe papers become predictable. A trivial example is if a paper claims an\nassociation between A and B and another between B and C, nowhere in the\nliterature says that A could lead to C, but if one is aware of A->B and B->C\none could infer A->C and then try to look for evidence of that relation.\n\n# Sharing tacit knowledge\n\nTacit knowledge cannot be taught verbally, or written down. It can be\ndistilled in various ways, and hinted at, but that's it. This doesn't mean we\nare doomed to lose that knowledge once the expert dies: tacit knowledge still\ncan be acquired. The issue is that not everything that can be taught can be\nexplained. The expert can introspect and derive some rules and principles that\ntry to capture the depth of their knowledge, but that is not the knowledge\nitself. This is why one can read books by people that clearly knew what they\nwere doing and yet not be able to get anywhere near the performance of said\nexperts.\n\nBut surely there is somewhere in the middle between asking experts to write\ndown what they know (and fail at it) and apprenticing with the expert. What\nwould it take to accelerate learning of a domain, and facilitate diffusion of\nthe knowledge embedded in it? I think that the answer is being exposed to a\nlibrary of expert performances (or examples) in context. Rather than asking\nthe expert to write down how to do great job interviews, watch a few dozen\nhours of the expert doing interviews. The expert wouldn't be explaining how to\ninterview, he would be doing the actual task. This seems a close proxy for the\napprenticeship version of this, sitting next to the expert. The video probably\ncaptures most of what is relevant. Software engineering could be taught to\nproficiency similarly. The same is true, I reckon, for scientific skills\n(study design, literature evaluation, problem finding) if one added some\nrunning commentary.\n\nThis approach to learning is not new, despite it seeming unusual: This is how\nlanguage learning works!\n\n## Language learning\n\nAs various personal reports scattered through the internet show (e.g. this),\none can learn a language from a basement in complete social isolation from the\ncommunity of speakers of said language, without ever talking to other human\nbeing in the target language. We also know that being thrown into a foreign\ncountry and forced to interact with such an environment can greatly accelerate\nlanguage learning. Anecdotally, when I visited Japan some time ago I kept\nseeing \"\u51fa\u53e3\" near exits, so I started associating that to the concept of exit.\nI didn't try consciously to make that association, it effortlessly emerged\nfrom seeing it all the time.\n\nThe interesting thing of language learning is how effortless it seems to be\nfor children. The conjunction of massive input of examples with the right\ncontext leads initially to remember salient words first, then noticing overall\npatterns, inferring grammar, and ultimately speaking the language\nproficiently. Adults can learn languages in the same way in about a year by\nthe same means: exposure to a large library of examples with the right\ncontext. In one case, 18 months was enough for this one person to go from zero\nto near-native proficiency in Japanese.\n\nI am not claiming we can learn everything using the same mental structures we\nuse for language. Perhaps language is easier than other domains because we are\npre-wired for language acquisition in a way we are not for other domains. I am\nsaying that there is a domain where this (massive input of examples with\ncontext) obviously works and we should think about seeing if we can expand\nthat to other domains.\n\n## The fractal complexity of tacit knowledge: Polymerase Chain Reaction\n\nHere's something that is at first conceptually simple but then happens to be\nquite complicated: for context read this essay from David Chapman on PCR.\nThere are many videos and resources online that I perused writing this section\nand the full complexity of what doing and understanding PCR actually entails\nis not obvious at first.\n\nPolymerase Chain Reaction is a technique in biology to do amplify fragments of\na specific sequence of DNA. Could one learn how to do PCR just by reading\nabout it? Maybe. Even if not impossible, we'd agree it would be hard, for the\nreasons explained in Chapman's essay. One could then supplement text with\nvideo: Watching someone actually perform PCR seems to be a substantially\nbetter way to learn how to do it. Even better: watching someone fail at it,\nand explain what went wrong, and how to fix things along the way. Even then, I\nwouldn't suspect one would get it right on Trial 1, but you could probably get\nbetter at it. With the videos and written materials, and clear examples of\nwhat success looks like, you could get there. I don't think this is easy,\nbecause to do PCR if one has never been in a lab entails a range of accessory\nknowledge and skills that have to be gained first.\n\nThe video in Chapman's essay starts with \"the first reagent we will use is\nbuffer\" and then he continues. To someone that has never done PCR, the nature\nof this buffer is unclear. The \"real world\" explanation is that this buffer is\n\"10X PCR buffer\" and this usually comes with Taq polymerase (The enzyme that\ncopies the DNA) if one buys it from e.g. ThermoFisher. In turn, that's buffer\nfrom ThermoFisher is mixture of HCl and KCl. And this is a buffer in the sense\nthat it keeps pH constant when adding a small amount of a strong acid or base.\nIn turn this is required because the polymerase used works best at a certain\npH. Said polymerase also requires magnesium but ThermoFisher in this case\nincludes it separately from the buffer, leaving it up to you to decide how\nmuch you want: too much and the results will be noisy, too little and there\nwon't be enough amplification of the DNA. Why does Mg do this? One could\nindeed keep going deeper and deeper; moreover stabilizing pH is not the only\nreason why KCl is there; nor that is the only kind of buffer that can be used.\nFor a user of PCR, this doesn't matter: One only needs to know that there's a\ntube with buffer that comes with the polymerase one buys. It of course matters\nif one wants to improve PCR protocols. In Lorenz (2012) for example a case is\ndescribed (In Section 13) of trying to find the right concentration of\nmagnesium chloride to amplify a particular gene. The concentration suggested\nby the manufacturer did not work, but current state of the art is to just try\na number of concentrations. In practice, if one works at a particular lab, at\nfirst one doesn't know all of this, all you need to know is that there's a\nbottle with buffer and another with the polymerase. That complexity is\nabstracted away. Initially perhaps you have someone who knows how it's done\ngiving you instructions and you walk through it, mistakes are made and\ncorrections are issued until one has thoughtlessly performed the process. But\nthen one may be able to do it on ones own, then do it for different DNA\nfragments and so on until one can claim to know how to do it.\n\nSomething of interest in that same section of the Lorenz paper is that the\nauthors deliberately do PCR wrong to see what happens; if one thinks of\nlearning a task as there being a core domain and some fuzzy edges, learning\nthese borders of the task are important as well: the borders are where the\ntask starts and ends (Where do you get the materials to do the task, what do\nyou do once you are done?) but also where one can be forced out of the task:\nIf you do one step wrong or if something doesn't go according to plan, what\ndoes one do? If all one has done is the textbook case then mistakes can lead\nto paralysis or starting from scratch instead of an appropriate fix and\ncontinuation of the task.\n\nPCR involves many subskills that are left implicit in the instructional\nmaterial. The protocols involve using micropipettes to dose the right amounts\nof various reagents into a little PCR tube. Using one such pipette is a\nrelatively simpler task, but one that must be learned as well (We could\nfurther decompose the task in changing the tips of the pipette, learning to\nread the volume counter in various types of pipettes, changing the volume, and\ndoing the pipetting itself). Others include operating a thermal cycler, and if\none further expands the scope of the task then we have others: primer design,\nknowledge of how to order all the required equipment and reagents, and so\nforth.\n\nIs that enough? Not quite! One can keep going on about PCR: This other\nwalkthrough of PCR mentions that if the DNA sequence is GC-rich you want to\nincrease the time of the denaturing step but one can also achieve the same by\nincreasing the temperature. Temperature which also depends on the melting\npoint of the primers being used; and time which depends on how long the\nproduct to be obtained is, as well as the polymerase used. The primers being\nused are not fully dictated by the sequence of interest, one has to design\nthem carefully. An expert who has done this many times may eventually be able\nto guess what the right temperatures are from past experience, or have a feel\nfor what a good answer should look like.\n\nReading about PCR \"in the abstract\", watching the PCR videos linked above\nbrings to awareness the fact that all of that ends up being quite useless if\none wanted to actually do PCR from scratch to, say, see if there's COVID in a\nsample. Suppose instead you had a series of step-by-step case studies with\ndifferent primers, polymerases, and thermal cycles. Then you work through them\nlike you would a new recipe. At first you are just mechanically running\nthrough a list of instructions. Eventually a sense of understanding should\ncome in, knowing why each step is there, and how different it could be.\n\n## Chess, a domain where we have solved tacit knowledge transfer\n\nChess is an interesting domain to study tacit knowledge. The rules of chess\nare publicly available and can be easily learned. We have had centuries to\ndevelop chess-learning systems and frameworks. We have solved chess by means\nof ML. But getting good still takes many years. And good chess playing is\ndefinitely tacit knowledge: 100h of Magnus Carlsen talking to you wouldn't be\nenough to get you to play good chess.\n\nA theme running through the sections above is accelerated learning: Is there\nany amount of training that will get you to Magnus Carlsen levels of chess\nplaying in a few months? After some searching, I don't think so. The why is a\ncombination of innate skill and the limits of human brains in acquiring the\nkind of skill that chess requires (chunking and planning ahead).\n\nChess skill is to a nontrivial extent heritable, to set our expectations. From\nmy review on learning:\n\n> What about chess? Are Grandmasters good because they practice or because\n> they were born with skills that are well suited for chess? At least for the\n> case of intelligence, the correlation doesn't seem to go beyond r=0.35 in a\n> meta-analysis of amateur and skilled players with ELOs between 1311 and 2607\n> (Burgoyne et al., 2016), this implies a variance explained (R^2) of around\n> 6%. If we look only at professionals, the correlation is smaller, 0.14 This\n> does not mean the other 94% is explained by practice. Indeed, if we look at\n> heritability more broadly, for chess skill it may be around 48% (Vinkhuyzen\n> et al., 2009 ) .\n>\n> What's the impact, then, of deliberate practice? There is one paper\n> (Burgoyne & Nye, 2019) that looks at it in a sample of moderately to highly\n> skilled chess players (ELOs between 1150 to 2650) and we get that it\n> accounts for 34%. Note that this doesn't mean that deliberate practice\n> doesn't matter for novices! Indeed, for novices practice is almost all there\n> is. Higher intelligence or better memory may give players the ability to\n> better evaluate a board, but practice gives players the ability to do a such\n> evaluations to begin with! It is only when one has moved past the novice\n> stage when the effects from innate skills will begin to appear.\n\nI tried to look for examples of getting good at chess fast and I found Max\nDeutsch's creative attempt, back in 2017, to become a chess grandmaster in a\nmonth. He failed, but did so an interesting way: initially he thought he'd do\nthe obvious thing and learn from chess books, play lots of games, etc.\nHowever, that wouldn't get you to expert performance because\n\n> chess expertise is mostly a function of the expert\u2019s ability to identify,\n> often at a glance, a huge corpus of chess positions and recall or derive the\n> best move in each of these positions.\n>\n> Thus, if I choose to train in traditional way, I would essentially need to\n> find some magical way to learn and internalize as many chess positions as\n> Magnus has in his over 20 years of playing chess. And this is why this\n> month\u2019s challenge seems a bit far-fetched.\n\nBut what he did instead is quite surprising: instead of slowly absorbing a\nfeel for the game, he tried to bruteforce the process by training a neural\nnetwork that would predict which move to play next, then memorise the weights\nof said network and run it in his head. Or that was the plan, at least. That\nalso failed (There are only so many weights one can fit in memory, and only so\nmany operations one can do per second). He got to play with Magnus Carlsen\n(and lose) though.\n\nWe never got to learn how much Deutsch actually improved. There is data for\nchess grandmasters and what their Elo rating was at every given age. They all\nseem to learn at similar rates, at perhaps 40-50 points per year, but note\nalso that they were amazing players even by age 15! The learning curve for\nPraggnanandhaa, which starts before he was 10, at a more reasonable (but still\nimpressive!) 1500 Elo, improved at perhaps 200 per year. The fact that they\nall improve in similar ways should not be that surprising given that we have\nhad decades if not centuries of thinking around how to learn chess and they\nare all probably using similar methods. This reddit thread suggests that maybe\nthat 200 Elo per year increase is not that unusual when one is starting, so\nwhat distinguishes these grandmasters is not so much that they learn fast, but\nthat they are gifted.\n\nBut there are also examples of faster learning: this random online person got\nfrom 1200 to 1600 in 6 months, improving 150 points in just 2 weeks at one\npoint. Reading his notes, the pattern seems to be working through a library of\nexamples (chess puzzles) of increasing difficulty, and memorizing games played\nby grandmasters. Attempts at memorization forces the development of strategies\nto enable that memorization, so just reading chess books or watching videos\nwon't do it:\n\n> I would have considered it a waste of time before giving it a chance. The\n> trick is that to memorize a game, you sort of have to understand it. It\u2019s\n> possible to just memorize moves like you\u2019d memorize a list of random words,\n> but it will be 10x harder than just understanding what\u2019s going on.\n>\n> If you understand what\u2019s going on, you end up memorizing the game in a\n> series of chunks, instead of a series of moves. For example one miniature\n> that I\u2019ve memorized is this game between Peter De Bortoli and Botond\n> Smaraglay. I can recite move by move, but the way I remember it is roughly\n> \u201cSmith Morra gambit, knight development, bishop development, scare off\n> bishop, threaten queen trap, knight blunder, queen trap\u201d. Memorizing a\n> couple king\u2019s gambit games has definitely improved my king\u2019s gambit play by\n> giving me more ideas.\n\nVery interestingly, this one person thought that compared to these other\nactivities, actually playing chess does not improve your chess that much. Nor\ndoes coaching. This seems to match what this paper found, where the strongest\npredictor of chess skill is precisely hours of solitary practice, moreso than\nhours played at tournaments. It also makes sense to me: When playing chess you\nare not always running into novel situations, for example the openings are\nvery mechanical. Puzzles get at hard situations and memorization builds\nstrategic awareness.\n\n### Chess coaches\n\nWe don't have examples of chess masters that got to mastery without ever\nplaying the game, doing just puzzles and memorization. But we do have examples\nof chess mastery without one component that some may think is required,\ntutoring.\n\n> In addition, much of the knowledge provided by coaches is available in books\n> and computer programs, and for many beginner players, the financial\n> investment in coaching sessions and the discipline necessary to prepare for\n> regular lessons is neither affordable nor desirable. Indeed, some prominent\n> self-taught players argue that it is possible, and perhaps more practical,\n> to learn the game without the help of a coach. In a preliminary study of the\n> relative importance of various chess activities, Charness et al. (1996)\n> surveyed tournament-rated chess players from Europe, Russia, and Canada to\n> ascertain their beliefs about the relevance of different chess activities to\n> their overall chess skill, and to collect estimates of the frequency and\n> duration of time spent on these different activities. Although participants\n> in this study rated active participation in tournaments as slightly more\n> relevant to improving one\u2019s chess skill than serious analysis of positions\n> alone, subsequent regression analyses revealed that cumulative serious\n> solitary chess study was the single most powerful predictor of chess skill\n> ratings among a broad set of potential predictors, including tournament play\n> and coaching. (Charness et al., 2005)\n\nMost (80%) chess players in the sample studied by Campitelli & Gober (2008)\nemployed coaches and presence of a coach correlated with rating, albeit not as\nstrongly as say the number of chess books owned. Is coaching a marker of\nseriousness, or does it independently lead to skill? The paper doesn't quite\ntest this to my satisfaction.\n\nProof of possibility (Can you become a chess grandmaster without a coach?)\nexists, but they are rare. In practice, why do players get a coach? The most\nimmediate answer is that they believe they will get better at chess with vs\nwithout the coach. There may also be other reasons: a coach may help keep the\nplayer accountable, putting in enough hours of practice every day. Maybe\nhaving a coach makes the overall practice more enjoyable as well. And they\nreduce the psychological burden of deciding how to train and what resources to\nuse, albeit they replace that with what coach to employ. I suspect that in\nterms of raw improvement, except perhaps once one gets to the level where you\nneed to analyze specific players to beat (Grandmaster who plays other GMs),\ncoaches don't accelerate learning in chess. They might have had that effect in\nthe past, back when chess engines were weaker and chess training was less\nformalized, and the belief in coaching has continued to our days.\n\nMy takeaway from chess is, on the optimistic side, that we have managed to\nscale expert performance in this domain to the point where no teaching is\nneeded: tacit knowledge can be effectively transmitted. Moreover we have also\nfound effective ways of doing so; and these ways do not involve doing the\nactivity (chess) over and over, but rather involve especially chosen subfacets\nof the activity (chess puzzles that capture interesting situations). The\ndownside is that this is still extremely time consuming: there doesn't seem to\nbe optimizations or techniques that can lead one to mastery in a handful of\nmonths. If most domains are like chess, then accelerated expertise is a\npipedream and one has to put in the hours over a few years. But to somewhat\ncounter that, the techniques developed in chess (and language learning) can\nstill be extended to other domains. Instead of masters we may be able to train\nadvanced journeymen whereas that was previously imposible without a tutor.\nThat's still some form of success!\n\n### Is everything like chess?\n\nIf everything is like chess, as in requiring a long time to master even with\nthe best learning techniques in the world, then we shouldn't hope to be able\nto learn much faster in other domains. But we know there are domains that are\neasier to master; learning how to proficiently use a micropipette doesn't take\nyears. Other domains that don't have a long pedagogical tradition currently\nwill take years and it may seem impossible to shorten that, but that's a\nfailure of the imagination. We haven't even tried the method that I think\nwould work, other than in language learning, there we get to a period of\naround 1 year for learning with the right methods. I don't have a good handle\non how long something \"should\" take. Naively, this span of time should\ncorrelate with the number of items to be learned and their interrelations.\nPerhaps someone has somewhere a database of tasks and time it takes to learn\nthem and this can be verified experimentally, and from there we could\nextrapolate to more complex domains.\n\n## Software engineering\n\nI used to work as a software engineer. As with a nontrivial chunk of the\nsoftware engineering population, I taught myself how to code. Many people can\nlearn how to code in a day, in that they can learn about conditionals, loops\nor functions, but that wouldn't be enough to do much meaningful with that\nparticular programming language. What does a principal staff engineer know\nthat the novice doesn't? A nontrivial amount of it is not quite tacit\nknowledge: it is cached explicit knowledge; knowing what libraries to use (as\nopposed to spending a day traversing Reddit, StackOverflow, and playing with\nmultiple ones to find the one that meets the need). But there is tacit\nknowledge as well. Example: If you need to write a bunch of code to get data\nfrom some source, run some operations with it, then send messages elsewhere,\nhow abstract should that be? Should the system be able to work with any source\nof data? Should arguments be passed to functions as big \"config\" objects, or\nindividually? Should anything special be done about database connections (Like\ndesigning a singleton instance, knowing that it's useful to leave connections\nopen for reuse). How efficient should it be, given project requirements? There\nare books on these sort of questions (Section 2.6 of this for some) but just\nreading that wouldn't be enough to be good at it, one has to do the thing.\nExpert engineers can rely on their past experience built over the years to\nthink about these matters.\n\nBut what if we had a library of videos of expert programmers showing how it's\ndone? This already exists in a crude form: live coding. It has all the\nelements discussed in previous sections: It's not an expert explaining the\ndomain but actively performing the activity to be taught. They contain\nmistakes and how to fix them. The experts also add commentary, which is even\nbetter as we can't see into their thought process, just their screen. As far\nas I know watching these videos are an underused tool in teaching software\nengineering. There is no curated library of videos one should watch to get\ngood. But if we had one, would that be it? Maybe.\n\n# Managing experts\n\nI have been using \"tacit knowledge\" to refer to \"expert tacit knowledge\". One\nof the goals when writing this essay was to reason about second order\nknowledge: Not knowledge of X, but things like knowledge about X, the history\nof X, or managing experts in X.\n\nBen Reinhardt has a heuristic in his notes, that people who have done a thing\nshould be in charge of that thing because It\u2019s extremely hard to build up\nintuition for a thing without having done it. So at the end of the day \u2018having\ndone a thing\u2019 is actually a heuristic for \u2018has intuition about this thing.\u2019.\n\nIn its face, yes, this is a good heuristic. But it's unclear how weighty it\nshould be given other considerations. For example the heuristic would admonish\nus not to have Elon doing Elon things (When he started SpaceX), Ben doing\nPARPA (he's never managed a research agency before), or for that matter a\nlawyer starting a large and successful pharma company. Whereas the heuristic\nis true, so is another: That outsiders can lead to higher variance outcomes.\nThis is good when exploring the frontiers of the possible. One person's tacit\nknowledge and hard earned intuitions for a field are another's biases and\nunjustified preconceptions. Sometimes an unqualified outsider does end up\nshowing the veterans that they were wrong: such is the natural order of\nthings.\n\nThere's another issue with the heuristic: being in charge of things is also a\nskill; the same goes for teaching a skill. A great researcher can be a poor\nteacher can be a poor research manager.\n\nCollins and Evans have a quote in their book about Gary Sanders, the LIGO\nproject manager. LIGO is a large piece of equipment built to detect\ngravitational waves that is incredibly complex. Sanders had never built\nanything like LIGO and yet was put in charge of it, growing into that role,\nbeing able to manage a project in a domain, talk about the domain, without\nbeing able to work in that domain directly:\n\n> I was concerned that I just would not understand it. But I\u2019ve found that,\n> remarkably, what you call interactional expertise was not hard to achieve. I\n> couldn\u2019t design an adaptive optics system but I really do, after six to nine\n> months in the field, I really do understand the different kinds of adaptive\n> optics and the way that they work and I can draw a schematic and define the\n> algorithm, and understand the technological readiness of the different\n> techniques\u2014which ones are really ready to apply to the sky and which ones\n> need to be demonstrated and certain components have to be developed. . . .\n>\n> I can sit down with a bunch of adaptive optics experts who will come to me\n> and say \u201cGary you\u2019re wrong\u2014multi-object adaptive optics will be ready at\n> first light and it will give the following advantages . . .\u201d and I shall say\n> \u201cNo, it\u2019s multi-conjugative adaptive optics\u201d and I can give them four\n> reasons why we should go with multi-conjugative adaptive optics based on the\n> kind of science we want to do, the readiness of the technical compo- nents,\n> when we need them, and so on, and I will see as I am talking about it that\n> the room is looking back at me and saying \u201cHe does have a line, he\u2019s thought\n> it through.\u201d\n>\n> [But] if someone said to me, \u201cOK Sanders, we agree with you, now go and\n> design a multi-conjugative adaptive optics system,\u201d I couldn\u2019t do it. I\n> couldn\u2019t sit down and write out the equations. . . . But I can draw a\n> diagram of what each part does, where the technological readiness of each\n> one is\u2014what the hard parts are\u2014I know the language and I actually feel\n> qualified to make the decisions.\n>\n> Looking back to his period at LIGO, he said:\n>\n> I can\u2019t design the LIGO interferometer. I can\u2019t sit down and write down all\n> the transfer functions and work out the noise budget like [named scientist]\n> can. But if he gave a talk on it I could follow it. I can understand the\n> important parts and the hard parts, partly by listening and partly by\n> quantitatively understanding, but I couldn\u2019t come back and compose the\n> symphony. But I was in a position where I had to decide. So it\u2019s a matter of\n> who I listen to and which parts seem like they carry the argument\u2014what it is\n> that we want. . . . That\u2019s more than interactional but it\u2019s not quite\n> contributory in, I think, your usual sense of the word (Gary Sanders, LIGO\n> Project Manager)\n\nBut Collins and Evans add:\n\n> In most specialist domains in the field they have to manage, the manag- ers,\n> then, have interactional expertise but not contributory expertise.32 Does\n> this mean that their technical expertise is no greater than that of, say, a\n> sociologist who has developed interactional expertise? To say \u201cyes\u201d seems\n> wrong\u2014as Sanders says, there is something going on that is a bit more than\n> interactional expertise. The resolution seems to be that, although, as we\n> can see, contributory expertise is not required to manage even the science\n> of a scientific project, management does need kinds of expertise that are\n> referred from other projects. The managers must know, from their work and\n> experience in other sciences, what it is to have contributory expertise in a\n> science; this puts them in a position to understand what is involved in\n> making a contribution to the fields of the scientists they are leading at\n> one remove, as it were. Managers of scien- tific projects with referred\n> expertise would manage better (as well as with more authority and\n> legitimacy) than those without it.\n>\n> The experience in other fields is applied in a number of ways. For example,\n> in the other sciences they have worked in, they will have seen that what\n> enthusiasts insist are incontrovertible technical arguments turn out to be\n> controvertible; this means they know how much to discount technical\n> arguments. They will know how often and why firm technical promises turn out\n> not to be delivered. They will know the dangers of allowing the quest for\n> perfection to drive out the good enough. They will have a sense of how long\n> to allow an argument to go on and when to draw it to a close because nothing\n> new will be learned by further delay. They will have a sense of when a\n> technical decision is important and when it is not worth arguing about. They\n> will have a sense of when a problem is merely a matter of better engineering\n> and when it is fundamental.\n\nWhich also coheres with something that is maybe in a different note: Ben's\nrule of thumb for PARPA PMs is having done research in some physical domain\n(Not mathematics or CS say), it doesn't have to be the exact same domain, but\none has to be aware of the kind of activity research entails, to expect the\nunexpected, to be comfortable with failure, trial and error, debugging\nexperiments. However, Collins and Evans then point to Leslie Groves, someone\nfar from being a physicist that directed the Manhattan Project. Groves was\nexperienced in managing construction projects and picked Oppenheimer to\noversee research. The Manhattan Project example shows that the second\nheuristic: \"Managers should have experience managing\" can work as well as\n\"Being in charge of X only if you have done X\". Ideally one would choose\nsomeone that has experience both in X and overseeing X. But as with many\nthings which heuristic wins is going to depend on context: The Manhattan\nProject was very construction-heavy, and Groves never tried to micromanage the\nscientists, he left that to an actual scientist, Oppenheimer. In that\nparticular case it may have been that Oppenheimer would have been overwhelmed\nby managing the entire project (Or bored, or his talent wasted, pick one). But\nin the case of a smaller operation like a research program, then acquaintance\nwith the domain could regain primacy and become the superior heuristic.\n\nLastly there's Elon. Elon breaks the schema because when he started SpaceX he\nwas not a rocket engineer nor a manager of anything physical (He was coming\nfrom a payments background). What Elon brings to the table is being able to\nlearn fast and being a good judge of talent. Sure he read books on propulsion,\nbut he didn't bother trying to do the actual design himself from scratch,\ninstead he found a promising propulsion engineer, Tom Mueller, and hired him.\nThe same is true for Blake Scholl. A priori one wouldn't have chosen a Senior\nDirector at Groupon to lead a supersonic flight company. But what if said\nperson spends time understanding the domain, is self-aware enough to\nunderstand what he doesn't understand and, crucially, can judge other's talent\nthen it seems like a whole different case.\n\n# Scaling expertise\n\nSo how do you scale tacit knowledge (And the related and as important private\nexplicit knowledge)? Inasmuch as that is part of what makes experts experts,\nthis is tantamount to asking how do we accelerate expertise. The US DoD has\nbeen trying to do this for a while.\n\nWhat they seem to have gotten to is that you can accelerate expertise\nsomewhat, and that to do so you need very rich environments, simulations of\nthe domain to operate on. Simulations are harder to construct than just\nwatching recordings of experts, but they definitely are not trying to\nenumerate a series of principles that defines what an expert is doing and\nteach that to novices. There's no way to make a soldier \"work with civilians\"\n(What the DoD was trying to do in the link before) with principles. Rather,\nyou sit down with experts and walk them through a situation and note down what\nthey notice (for example), then do the same with novices, then show the\nnovices what the experts picked up. The experts give some reason for why they\npicked what they did (Say a firefighter may say that the smoke was thicker\nthan expected for that situation) but even without that, being able to compare\none's judgement with that given by the expert should induce some learning.\n\nFrom the various examples through the essay: I want to see a learning system\nthat consists of watching videos of expert performances of a given skill, and\nsupplemented by some written material (Like one can supplement immersion in\nlanguage learning with grammar books). This could be in VR instead of video,\nbut video is a good first point to start. The key elements:\n\n  1. The material would be a large library of examples of the activity being performed. Not instructional (i.e. staged, or classes) material.\n  2. If possible, the expert should provide some commentary when performing the activity.\n  3. The material has to require engagement at some point, as opposed to passive watching or reading. At minimum this engagement could be requiring some form of memorization, but could also be trying to guess what comes next, trying to guess what facts would an expect consider salient.\n  4. Periodically one should check progress by doing the activity that is being learned.\n  5. Design of this course should be informed by areas where we have extensive pedagogic traditions, like language learning or chess\n\n# Conclusion(s)\n\nThe essay above is somewhat meandering, so if you want to pin down exact\nassertions, out of context, here are a bunch of them that now probably make\nsense given the rest of the essay:\n\n  1. Tacit knowledge is real. There is knowledge experts have, but cannot explain or write down.\n  2. Experts have more than tacit knowledge, especially private explicit knowledge. This can be gained to some extent by talking to the experts.\n  3. Private explicit knowledge is hard to scale due to incentive issues: it's private for a reason. Sometimes it's because NDAs, sometimes because the expert gains nothing from giving away their knowledge which perhaps is a source of professional advantage.\n  4. The bulk of learning a scientific field is codified in publicly available information. This is different from the knowledge required to being able to work in the field. The closer one gets to execution (vs knowledge in the abstract) the less knowledge is publicly available.\n  5. This is not true for other domains that have less of a tradition of extensive codification, like engineering\n  6. Having just a list of the propositions that are in a bunch of papers is not enough to learn a field. But with enough such observations one can peek behind the papers and see why things are the way they are. Think of yourself as a human GPT-3; the internet doesn't teach how to think, but somehow reading a lot made GPT-3 somewhat smart. The same is true, I claim, for reading a lot of papers.\n  7. There are ways to get better at something besides doing that something. Chess puzzles and memorization beat the actual playing of chess at gaining chess skill. Field connoiseurs that don't have to do research themselves (Which frees up time) can quickly match the knowledge of those working in the field, even if they never acquire the knowledge to work in it. The time spent pipetting or setting up the Nth run of a thermal cycler can instead be spent acquiring more information.\n  8. We can accelerate learning with massive input of examples in context.\n  9. Rote memorization seems useless at first, given that one can quickly search on the internet. But the point of memorization is not just fast retrieval: it is to build internal structures, maps, frameworks, chunks, of a domain, which then can be deployed to better navigate that domain. In some domains, this can be part of the solution to scaling expertise.\n  10. How one learns a field should depend on what the goal is. There is no need to spend three years reading aging biology papers if all one wants is to know enough about companies in that space to invest in them, or to find what the open questions are, and find promising talent to lead projects to tackle them.\n  11. Talking to enough experts can get you enough knowledge to quickly validate an idea, answer a question, and get a good enough feel for a field.\n  12. To manage a project in a field, or to pinpoint the rough set of open problems in a field one does not need the deep knowledge that an expert may have. But having experts validate the derived set of problems should be part of the process.\n  13. Expert identification is an art, one needs to know what the right questions to ask are!\n  14. The understanding derived from talking to experts is shallower than that obtained from reading papers. Both are inferior to being embedded in a field, or working in a field.\n  15. The heuristic \"have done the thing\" -> being able to manage the thing makes sense. As does \"being a good manager\" -> managing the thing. This heuristic doesn't always work in the presence of smart generalists that can find good talent to support them.\n  16. Tacit knowledge cannot be taught in the usual way (by explaining it), rather it can be conveyed in indirect ways by demonstrations, apprenticeships, simulations, videos, or libraries of case studies.\n  17. Stories, case studies, or even business books are easy to dismiss as N=1 anecdotes. I used to think that. The usual tabulated neat datapoints the STEM minded are used to cannot capture the fullness of complex skills out in the wild. A collection of anecdotes is the kind of data we need to transmit tacit knowledge.\n  18. Embeddedness in a field will be very useful to get the last 10-20% of knowledge in the field. Because no one can immediately list all the relevant facts, hanging out with people in the field (in conferences, online seminars, or the local bar or cafe) will increase the probability that one will come across new facts, perhaps contained in tangential remarks. Different situations will make salient different facts to the expert, so enough interaction with experts will increasingly explore the space of their knowledge.\n\n# References\n\nSome books and articles I've read in the process of writing this essay\n\n  * Klein, Gary A. Sources of power: How people make decisions. MIT press, 2017.\n  * Hoffman, Robert R., et al. Accelerated expertise: Training for high proficiency in a complex world. Psychology Press, 2013.\n  * Collins, Harry & Evans, Roberts. Rethinking expertise. University of Chicago Press, 2008.\n  * Cedric Chin's Commonplace\n  * Salvatier, John. Reality has a surprising amount of detail\n  * Reinhardt, Ben. Working notes\n\n# Changelog\n\n  * 2022/04/08: Thanks to Max Krieger for pointing out typos and odd sentences\n  * 2022/05/24: Thanks to Barry Cotter for pointing out typos and odd sentences\n\n## Citation\n\nIn academic work, please cite this essay as:\n\nRic\u00f3n, Jos\u00e9 Luis, \u201cScaling tacit knowledge\u201d, Nintil (2021-12-10), available at\nhttps://nintil.com/scaling-tacit-knowledge/.\n\n## Backlinks\n\n  * On Reboot's Ineffective Altruism\n  * Elon's decision making: an anecdote compilation\n  * Images and Words: AI in 2026\n  * Metascience: invariants and evidence\n  * Links (54)\n  * Links (61)\n  * Links (76)\n  * Massive input and/or spaced repetition\n  * Applied positive meta-science\n  * Limits and Possibilities of Metascience\n  * New Science's NIH report: highlights\n  * Notes on 2021\n  * Evidence and the design and reform of scientific institutions\n  * Talent: a review\n\n\u2039 Links (53) Links (54) \u203a\n\n", "frontpage": false}
