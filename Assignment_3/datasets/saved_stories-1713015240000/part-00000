{"aid": "40021253", "title": "ICLR Blogposts 2024", "url": "https://iclr-blogposts.github.io/2024/about/", "domain": "iclr-blogposts.github.io", "votes": 1, "user": "qwertyforce", "posted_at": "2024-04-13 07:31:58", "comments": 0, "source_title": "about | ICLR Blogposts 2024", "source_text": "about | ICLR Blogposts 2024\n\nAnnouncements:\n\n  * The 22 blog posts 2024 are now published! Check our press release for an overview or dive directly into it on the Blog page\n  * More information regarding the poster session will be available soon.\n\n## Contents\n\n  * ICLR 2024 Blogposts Track\n  * Spotlight Posts\n  * Accepted Posts\n  * Key Dates\n  * Submissions\n  * Organizers\n\n# ICLR 2024 Blogposts Track\n\nThe Machine Learning community is currently experiencing a reproducibility\ncrisis and a reviewing crisis [Littman, 2021]. Because of the highly\ncompetitive and noisy reviewing process of ML conferences [Tran et al., 2020],\nresearchers have an incentive to oversell their results, slowing down the\nprogress and diminishing the integrity of the scientific community. Moreover\nwith the growing number of papers published and submitted at the main ML\nconferences [Lin et al., 2020], it has become more challenging to keep track\nof the latest advances in the field.\n\nBlog posts are becoming an increasingly popular and useful way to talk about\nscience [Brown and Woolston, 2018]. They offer substantial value to the\nscientific community by providing a flexible platform to foster open, human,\nand transparent discussions about new insights or limitations of a scientific\npublication. However, because they are not as recognized as standard\nscientific publications, only a minority of researchers manage to maintain an\nactive blog and get visibility for their efforts. Many are well-established\nresearchers (Francis Bach, Ben Recht, Ferenc Husz\u00e1r, Lilian Weng) or big\ncorporations that leverage entire teams of graphic designers designer and\nwriters to polish their blogs (Facebook AI, Google AI, DeepMind, OpenAI). As a\nresult, the incentives for writing scientific blog posts are largely personal;\nit is unreasonable to expect a significant portion of the machine learning\ncommunity to contribute to such an initiative when everyone is trying to\nestablish themselves through publications.\n\nSubmit your blogpost on Openreview\n\n## A Blog Post Conference Track\n\nLast year, we ran the second iteration of the Blogpost track at ICLR 2023!\n\nIt was very successful, with accepted posts presented in person at the main\nconference.\n\nOur goal is to create a formal call for blog posts at ICLR to incentivize and\nreward researchers to review past work and summarize the outcomes, develop new\nintuitions, or highlight some shortcomings. A very influential initiative of\nthis kind happened after the Second World War in France. Because of the lack\nof up-to-date textbooks, a collective of mathematicians under the pseudonym\nNicolas Bourbaki [Halmos 1957], decided to start a series of textbooks about\nthe foundations of mathematics [Bourbaki, 1939]. In the same vein, we aim to\nprovide a new way to summarize scientific knowledge in the ML community.\n\nDue to the large diversity of topics that can be discussed in a blog post, we\ndecided to restrict the range of topics for this call for blog posts. We\nidentified that the blog posts that would bring to most value to the community\nand the conference would be posts that distill and discuss previously\npublished papers.\n\n## Spotlight\n\nThe N Implementation Details of RLHF with PPO\n\n    Shengyi Costa Huang, Tianlin Liu, Leandro von Werra\nHow to compute Hessian-vector products?\n\n    Mathieu Dagr\u00e9ou, Pierre Ablin, Samuel Vaiter, Thomas Moreau\nBridging the Data Processing Inequality and Function-Space Variational\nInference\n\n    Andreas Kirsch\n\n## Accepted Posts\n\nUnderstanding in-context learning in transformers\n\n    Simone Rossi, Rui Yuan, Thomas Hannagan\nBehavioral Differences in Mode-Switching Exploration for Reinforcement\nLearning\n\n    Loren J Anderson\nFairness in AI: two philosophies or just one?\n\n    MaryBeth Defrance\nTowards Robust Foundation Models: Adversarial Contrastive Learning\n\n    Jingfeng Zhang, Xilie Xu\nA New Alchemy: Language Model Development as a Subfield?\n\n    Colin Raffel\nUnderstanding gradient inversion attacks from the prior knowledge perspective\n\n    Yanbo Wang, Jian Liang, Ran He\nBuilding Diffusion Model\u2019s theory from ground up\n\n    Ayan Das\nMasked Language Model with ALiBi and CLAP head\n\n    Jason Chuan-Chih Chou\nWhat exactly has TabPFN learned to do?\n\n    Calvin McCarter\nElaborating on the Value of Flow Matching for Density Estimation\n\n    Maternus Herold, Faried Abu Zaid\nThe Hidden Convex Optimization Landscape of Two-Layer ReLU Networks\n\n    Victor Merckl\u00e9, Franck Iutzeler, Ievgen Redko\nDeep Equilibrium Models For Algorithmic Reasoning\n\n    Sophie Xhonneux, Yu He, Andreea Deac, Jian Tang, Gauthier Gidel\nFair Model-Based Reinforcement Learning Comparisons with Explicit and\nConsistent Update Frequency\n\n    Albert Thomas, Abdelhakim Benechehab, Giuseppe Paolo, Bal\u00e1zs K\u00e9gl\nExploring Meta-learned Curiosity Algorithms\n\n    Batsirayi Mupamhi Ziki\nUnraveling The Impact of Training Samples\n\n    Daiwei Chen, Jane Zhang, Ramya Korlakai Vinayak\nRLHF without RL - Direct Preference Optimization\n\n    Michael Panchenko\nIt\u2019s Time to Move On: Primacy Bias and Why It Helps to Forget\n\n    Matthew Kielo, Vladimir Lukin\nDouble Descent Demystified\n\n    Rylan Schaeffer, Zachary Robertson, Akhilan Boopathy, Mikail Khona, Kateryna Pistunova, Jason W. Rocks, Ila R. Fiete, Andrey Gromov, Sanmi Koyejo\nOn Bayesian Model Selection: The Marginal Likelihood, Cross-Validation, and\nConditional Log Marginal Likelihood\n\n    Andreas Kirsch\n\n## Key Dates\n\nAbstract deadline: December 11th 00:00GMT, 2023 (submit to OpenReview - to be\nannounced soon).\n\nSubmission deadline: December 17th 00:00GMT, 2023 (any modifications to your\nblog post, via a pull request on GitHub).\n\nDecision Notification: January 30th, 2024 UPDATED: February 15th, 2024\n\nCamera-ready merge: March 15th, 2024\n\n## A call for blog posts discussing work previously published at ICLR\n\n#### Content\n\nWrite a post on a subject that has been published at a top-tier venue (ICLR,\nICML, NeurIPS, AAAI, UAI, CVPR, SIGGRAPH, ECCV, ICCV, etc.) relatively\nrecently.\n\n#### Conflict of interest\n\nThe authors of the blog posts will have to declare their conflicts of interest\n(positive or negative) with the paper (and the paper\u2019s authors) they write\nabout. Conflicts of interest include:\n\n  * Recent collaborators (less than 3 years)\n  * Current institution Reviewers will be asked to judge if the submission is sufficiently critical and objective of the papers addressed in the blog post.\n  * Blog Posts must not be used to highlight or advertise past publications of the **authors or their lab**.\n\nWe will only ask the authors to report if they have a conflict of interest. If\nso, reviewers will be asked to judge if the submission is sufficiently\ncritical and objective of the papers addressed in the blog post.\n\n## Publication\n\n#### Blog post\n\nThe posts will be created and published under a unified template; see the\nsubmission instructions and the sample post hosted on the blog of this\nwebsite.\n\n#### Poster\n\nAdditionally, accepted posts will have the option to present their work as a\nposter during the main poster session. For more information about the main\nposter session (time, poster format, etc.) please refer to the ICLR homepage.\n\n## Submissions\n\nOur goal is to avoid heavily engineered, professionally-made blog posts \u2014Such\nas the \u201c100+ hours\u201d mentioned as a standard by the Distill guidelines\u2014to\nentice ideas and clear writing rather than dynamic visualizations or embedded\njavascript engines. Please check our submission instructions for more details.\nWe accept submissions in both Markdown and HTML. We believe this is a good\ntrade-off between complexity and flexibility.\n\nSubmit your blogpost on Openreview\n\n## Contact\n\nFor any technical issues with the blog post repository (for example, blog\nposts not displaying correctly or issues while following the submission\ninstructions), please open an issue in our github repository.\n\nFor other inquiries, reach us via email at: blog.track.chairs@gmail.com\n\n## Organizers\n\n##### Gauthier Gidel\n\nMila, Universit\u00e9 de Montr\u00e9al\n\n##### Charlie Gauthier\n\nMila, Universit\u00e9 de Montr\u00e9al\n\n##### David Dobre\n\nMila, Universit\u00e9 de Montr\u00e9al\n\n##### Claire Vernade\n\nUniversity of Tuebingen\n\n##### Fabian Pedregosa\n\nGoogle DeepMind\n\n##### Leo Schwinn\n\nTechnical University of Munich\n\n## References\n\nMichael L Littman. Collusion rings threaten the integrity of computer science\nresearch. Communications of the ACM, 2021.\n\nDavid Tran, Alex Valtchanov, Keshav Ganapathy, Raymond Feng, Eric Slud, Micah\nGoldblum, and Tom Goldstein. An open review of OpenReview: A critical analysis\nof the machine learning conference review process. arXiv, 2020.\n\nHsuan-Tien Lin, Maria-Florina Balcan, Raia Hadsell, and Marc\u2019Aurelio Ranzato.\nWhat we learned from NeurIPS 2020 reviewing process. Medium\nhttps://medium.com/@NeurIPSConf/what-we-learned-from-neurips-2020-reviewing-\nprocess-e24549eea38f, 2020.\n\nEryn Brown and Chris Woolston. Why science blogging still matters. Nature,\n2018.\n\nPaul R Halmos. Nicolas Bourbaki. Scientific American, 1957.\n\nNicolas Bourbaki. Elements of mathematics. \u00c9ditions Hermann, 1939.\n\n", "frontpage": false}
