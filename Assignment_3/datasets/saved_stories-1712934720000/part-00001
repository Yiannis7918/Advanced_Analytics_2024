{"aid": "40010718", "title": "BobNet \u2013 modular, portable LLM built with CPU", "url": "https://github.com/dmsweetser/BobNet", "domain": "github.com/dmsweetser", "votes": 1, "user": "dmsweetser", "posted_at": "2024-04-12 09:10:34", "comments": 0, "source_title": "GitHub - dmsweetser/BobNet: A modular, portable Large Language Model built in community using consumer-grade hardware", "source_text": "GitHub - dmsweetser/BobNet: A modular, portable Large Language Model built in\ncommunity using consumer-grade hardware\n\nSkip to content\n\nSign in\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch syntax tips\n\nSign in\n\nSign up\n\nYou signed in with another tab or window. Reload to refresh your session. You\nsigned out in another tab or window. Reload to refresh your session. You\nswitched accounts on another tab or window. Reload to refresh your session.\nDismiss alert\n\ndmsweetser / BobNet Public\n\n  * Notifications\n  * Fork 1\n  * Star 2\n\nA modular, portable Large Language Model built in community using consumer-\ngrade hardware\n\n### License\n\nMIT license\n\n2 stars 1 fork Branches Tags Activity\n\nStar\n\nNotifications\n\n# dmsweetser/BobNet\n\nThis commit does not belong to any branch on this repository, and may belong\nto a fork outside of the repository.\n\n1 Branch\n\n1 Tags\n\n## Folders and files\n\nName| Name| Last commit message| Last commit date  \n---|---|---|---  \n  \n## Latest commit\n\ndmsweetserFix readme9ac356d \u00b7\n\n## History\n\n67 Commits  \n  \n### images\n\n|\n\n### images\n\n| Adds some funzies - I don't think the penalization is working yet.  \n  \n### import\n\n|\n\n### import\n\n| Adds vector store, ingest, import and share functionality - not worki...  \n  \n### ingest\n\n|\n\n### ingest\n\n| Attempting multiple hidden layers  \n  \n### lib\n\n|\n\n### lib\n\n| Fixes chunking (hopefully)  \n  \n### share\n\n|\n\n### share\n\n| Working towards a functional vector store for LLM retrieval  \n  \n### .gitignore\n\n|\n\n### .gitignore\n\n| Trying again with a mid-range hidden_dim  \n  \n### LICENSE\n\n|\n\n### LICENSE\n\n| Initial commit  \n  \n### README.md\n\n|\n\n### README.md\n\n| Fix readme  \n  \n### bob_net.py\n\n|\n\n### bob_net.py\n\n| Misc fixes to file chunking and de-duplication. Updates Readme  \n  \n### config.json\n\n|\n\n### config.json\n\n| Restores best hidden_dim config  \n  \n### install.bat\n\n|\n\n### install.bat\n\n| Initial commit - not persisting properly yet  \n  \n### install.sh\n\n|\n\n### install.sh\n\n| Adds Linux install  \n  \n### requirements.txt\n\n|\n\n### requirements.txt\n\n| Working towards a functional vector store for LLM retrieval  \n  \n### run_bob_net.bat\n\n|\n\n### run_bob_net.bat\n\n| Adjusting execution option  \n  \n### run_bob_net.sh\n\n|\n\n### run_bob_net.sh\n\n| Adds run script for Linux  \n  \n## Repository files navigation\n\n# BobNet\n\nBobNet is a modular, portable Large Language Model built in community using\nconsumer-grade hardware. The framework ingests training data and emits\nsharable \"Bob\" files that represent itty-bitty <5M Tensorflow language models\ntrained only on one brief text each (represented by a training data file). The\nsame models that are emitted are stored in a local SqliteDB as a vector store.\n\nWhen you do inference, a vector search is done with your query first, the most\nappropriate models are retrieved and then the highest-probability result from\neach round is selected as the next token. It feels like in #ai they are always\ncoming up with fancy new terms I don't understand, so I propose \"mixture of\nBob\" or M.O.B. for short as the name of this design.\n\nThe goal is to crowd-source training of individual topics into Bob files that\ncan be shared with others. Because Bob files can be emitted, shared and then\ningested elsewhere, you can build a BobNet specific to your use case, and it\nwill only be aware of what you provide. Fully modular.\n\nBobNet was created to try and address the following problems I see in the\ncurrent LLM ecosystem:\n\n  1. Capable models can only currently be built at great expense using specialized hardware.\n  2. A model built in this way is a monolith, where you have to either take it or leave it in its entirety.\n  3. A model built this way contains training data that is not controlled by the consumer.\n  4. Communities and individuals must rely on the good favor of large, for-profit corporations rather than building something themselves.\n\nBobNet is built and tested using CPU-only on consumer-grade hardware\n(currently an HP Z640). Rather than forcing users to acquire more and more\nVRAM to execute a model, BobNet has a very small resource footprint, relying\non storage space as its most limiting resource (cheep!). Every individual .bob\nfile trained on a text is shareable / portable, and a BobNet can be built\nselectively at the discretion of the user. This means you can include just the\ncontents you want, like general conversation, specialized information for your\norganization, general facts, etc... but opt-in rather than relying on prompts\nto protect your users from uninformed responses.\n\nHelp build the BobNet! Join the revolution!\n\nFUTURE WORK\n\n  1. \"Pet Store\" - interface between BobNet instances to allow truly distributed, specialized inference\n\n    1. Ability to either interface locally (for example, in a Raspberry Pi cluster on a LAN)\n    2. Ability to interface across networks\n  2. General optimization and improvement\n\n    1. It takes 5 minutes per 256 char of text currently to train on an Intel Xeon E5-2690\n    2. It takes ~50MB of storage space per 256 char of text when persisted to a .bob file\n\n## The Story of Bob\n\nThis is Bob:\n\nBob isn't very strong on his own:\n\nBut when he and his friends get together, they can do great things:\n\nAlso, Bob is portable - you can share him with your friends!\n\n## Getting Started\n\nTake the following steps to start using BobNet:\n\n  1. Clone this repo and run \"install.bat\".\n  2. Copy text training data under the \"ingest\" subfolder\n\n    1. Each individual file will become its own \"Bob\" language model\n    2. Smaller, focused files are best.\n  3. To train, run \"run_bob_net.bat\" with no arguments\n\n    1. BobNet will ingest the training data you provided.\n    2. It will store a language model per training file in a vector store.\n    3. It will also emit a *.bob file in the \"share\" subdirectory that you can share with others.\n  4. To do inference, run \"run_bob_net.bat\" with one argument, the question you are trying to answer\n\n    1. Example: \"What is 2 + 2?\"\n    2. BobNet will do a vector search to find which internal language models best fit your question.\n    3. BobNet will use each identified model to do inference, providing only the most confident result.\n    4. Models will be penalized to the degree to which they are unfamiliar with any part of the question text.\n  5. You can share *.bob files with other people\n\n    1. Each file represents the work output of training on a single text input file\n    2. You can import *.bob files shared by others by putting them in the \"import\" subdirectory\n    3. As a result, you can build your BobNet in a modular fashion, only including approved sources\n\n## About\n\nA modular, portable Large Language Model built in community using consumer-\ngrade hardware\n\n### Resources\n\nReadme\n\n### License\n\nMIT license\n\nActivity\n\n### Stars\n\n2 stars\n\n### Watchers\n\n2 watching\n\n### Forks\n\n1 fork\n\nReport repository\n\n## Releases 1\n\n1.0-InitialRelease Latest\n\nApr 12, 2024\n\n## Packages 0\n\nNo packages published\n\n## Languages\n\n  * Python 81.3%\n  * Batchfile 9.7%\n  * Shell 9.0%\n\n## Footer\n\n\u00a9 2024 GitHub, Inc.\n\nYou can\u2019t perform that action at this time.\n\n", "frontpage": false}
