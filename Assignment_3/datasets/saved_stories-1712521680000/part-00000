{"aid": "39960992", "title": "Why our AI algorithms discriminate against people with disabilities", "url": "https://news.harvard.edu/gazette/story/2024/04/why-ai-fairness-conversations-must-include-disabled-people/", "domain": "news.harvard.edu", "votes": 2, "user": "mygo", "posted_at": "2024-04-07 14:25:56", "comments": 0, "source_title": "Why AI fairness conversations must include disabled people \u2014 Harvard Gazette", "source_text": "Why AI fairness conversations must include disabled people \u2014 Harvard Gazette\n\nSkip to content\n\n  * ## Sections\n\n## Featured Topics\n\n## Featured series\n\n### Wondering\n\nA series of random questions answered by Harvard experts.\n\n## Explore the Gazette\n\n## Read the latest\n\n    * ### Getting ahead of dyslexia\n\n    * ### How did you get that frog to float?\n\n    * ### Lifting a few with my chatbot\n\nScience & Tech\n\n# Why AI fairness conversations must include disabled people\n\nNaomi Saphra, Lawrence Weru, Maitreya Shah.\n\nPhotos by Jon Chase and Kris Snibbe/Harvard Staff Photographers and courtesy\nof Maitreya Shah; photo illustration by Judy Blomquist/Harvard Staff\n\nEileen O\u2019Grady\n\nHarvard Staff Writer\n\nApril 3, 2024 7 min read\n\n## Tech offers promise to help yet too often perpetuates ableism, say\nresearchers. It doesn\u2019t have to be this way.\n\nThird in a four-part series on non-apparent disabilities.\n\nAI researcher Naomi Saphra faced \u201ca programmer\u2019s worst nightmare\u201d in 2015.\nAfter a decade of coding and just as she was about to start a Ph.D. program in\nScotland, neuropathy in her hands rendered typing too painful.\n\nSeeking a solution, Saphra turned to the very technology she was studying. She\nbegan the long process of teaching herself how to code using voice-to-text\ndictation technologies. Today, a system called Talon, which Saphra has heavily\ncustomized to complete specific tasks, allows her to code and to write papers\nfor her research on language models.\n\n\u201cI rely on it completely,\u201d said the research fellow at the Kempner Institute\nfor the Study of Natural and Artificial Intelligence. \u201cI would absolutely not\nhave a career if we didn\u2019t have AI for speech-to-text. These days it\u2019s pretty\nhard to exist in the world if you\u2019re not able to use a computer much. And as\nthings have advanced, it\u2019s been very important that the word error rate has\ngotten lower over the years.\u201d\n\nAI technology can be a powerful assistive tool for people like Saphra with\nnon-apparent disabilities \u2014 physical or mental conditions that are not\nimmediately obvious to others. But disability advocates say these tools have a\nlong way to go to become truly accessible. Experts say including disabled\npeople in conversations on AI fairness and the development process is key.\n\n\u201cIf we\u2019re creating tools that we know are fed with information that can bias\nagainst certain groups, and we integrate those into very crucial aspects of\nour lives, what\u2019s going to be the impact of that?\u201d asks Lawrence Weru, an\nassociate in biomedical informatics at Harvard Medical School.\n\nKris Snibbe/Harvard Staff Photographer\n\nLawrence Weru, an associate in biomedical informatics at Harvard Medical\nSchool, was initially excited when voice-activated AI tools such as Siri and\nAlexa were released in the early 2010s. As someone who learned to code from a\nyoung age on public library computers before personal computers were common,\nhe has long been fascinated by advances in digital technology. But Weru, who\nhas a stutter, quickly found voice-activated technology more frustrating than\nhelpful. When asking Siri for directions, the digital assistant would not\nunderstand the question if he stuttered.\n\nWhile this was hardly a new experience \u2014 before AI, Weru remembers the\nfrustration of trying to contact his bank and not being able to get past the\nautomated phone system \u2014 it was disappointing to realize that the AI likely\nhad not been trained on data from people with disabilities like his.\n\n\u201cPeople create things and people always have a vision in mind of who is going\nto be using their thing,\u201d Weru said. \u201cSometimes not everybody is included in\nthose personas.\u201d\n\nHis experience with Siri makes Weru concerned about the future of voice-\nactivated AI technology, envisioning a world in which critical tasks \u2014 making\ndoctor appointments, applying for jobs, accessing education \u2014 are powered not\nby humans, but by technologies that can\u2019t be used by everyone.\n\n\u201cIf we\u2019re creating tools that we know are fed with information that can bias\nagainst certain groups, and we integrate those into very crucial aspects of\nour lives, what\u2019s going to be the impact of that?\u201d Weru said. \u201cThat\u2019s a\nconcern that I hope people would be having enough foresight to try to address\nin advance, but historically accessibility is usually something that\u2019s treated\nas an afterthought.\u201d\n\n\u201cI would absolutely not have a career if we didn\u2019t have AI for speech-to-\ntext,\u201d said Naomi Saphra, a research fellow at the Kempner Institute.\n\nJon Chase/Harvard Staff Photographer\n\nMaitreya Shah, a fellow at the Berkman Klein Center for Internet and Society,\nrecently launched a research project analyzing different schools of thought on\n\u201cAI fairness,\u201d or movements seeking to mitigate AI bias against people in\nmarginalized groups. Shah, a blind lawyer and researcher, wants to go beyond\nconversations about accessibility and examine what he believes is the root of\nthe issue: People with disabilities are not being included in conversations\nabout AI, even in conversations about AI fairness.\n\n\u201cA lot of research so far has focused on how AI technologies discriminate\nagainst people with disabilities, how algorithms harm people with\ndisabilities,\u201d Shah said. \u201cMy aim for this project is to talk about how even\nthe conversation on AI fairness, which was purportedly commenced to fix AI\nsystems and to mitigate harms, also does not adequately account for the\nrights, challenges, and lived experiences of people with disabilities.\u201d\n\nFor his research, he\u2019s interviewing scholars who have studied the issue and\nevaluating frameworks designed to maintain AI fairness proposed by governments\nand the AI industry.\n\nShah said developers often consider disability data to be \u201coutlier data,\u201d or\ndata that differs greatly from the overall pattern and is sometimes excluded.\nBut even when it\u2019s included, there are some disabilities \u2014 like non-apparent\ndisabilities \u2014 that are overlooked more than others. If an AI is trained on a\nnarrow \u201cdefinition\u201d of disability (like if data from people who stutter is not\nused to train a voice-activated AI tool) the outcome will be that the tool is\nnot accessible.\n\n\u201cThere is a paradox,\u201d Shah said. \u201cIf you don\u2019t incorporate disability data,\nyour algorithms would be open to discriminating against people with\ndisabilities because they don\u2019t fit the normative ideas of your algorithms. If\nyou incorporate the data, a lot of people with disabilities would still be\nmissed out because inherently, the way you incorporate datasets, you divide\ndata on the axes of identity.\u201d\n\n> \u201cDo people with autism or other disabilities even want these technologies?\n> No one asks them.\u201d\n>\n> Maitreya Shah\n\nIn his own life, Shah uses some AI technologies as assistive tools including\n\u201cBe My AI,\u201d which describes images, and \u201cSeeing AI,\u201d which provides users with\nvisual information such as text, color, light, and scenery. Blind people were\nvery involved in the development and testing process for both those tools.\n\nBut Shah said too often people with disabilities are not included in the high-\nlevel decision-making and development processes for AI that is purported to\nbenefit them. He cited, as an example, technology designed to diagnose autism\nor address learning disabilities.\n\n\u201cThe question is: Do people with autism or other disabilities even want these\ntechnologies? No one asks them,\u201d Shah said.\n\nIn his research, Shah proposes adopting perspectives from disability justice\nprinciples, such as participation.\n\n\u201cLet people with disabilities participate in the development and the\ndeployment of technologies. Let them decide what is good for them, let them\ndecide how they want to define or shape their own identities.\u201d\n\nSaphra agrees, which is why she believes any developer creating assistive AI\nshould make it easily customizable, not just by AI experts or coders, but by\npeople who may not be tech experts. That way, users can set up the system to\nperform specific, essential tasks like Saphra did for writing code.\n\n\u201cIt\u2019s very important to make sure that everything you release is hackable,\neverything is open-source, and that everything has an accessible interface to\nstart with,\u201d Saphra said. \u201cThese things are going to make it more useful for\nthe greatest number of disabled people.\u201d\n\n#### Share this article\n\n  * Share on Facebook\n  * Share on LinkedIn\n  * Email article\n  * Print/PDF\n\n### Resources\n\n  * University Disability Resources serves as the central resource for disability-related information, procedures, and services for the Harvard community.\n  * Students who wish to request accommodations should contact their School\u2019s Local Disability Coordinator.\n  * The 24/7 mental health support line for students is 617-495-2042. Deaf or hard-of-hearing students can dial 711 to reach a Telecommunications Relay Service in their local area.\n  * Harvard Law School Project on Disability\n\n## Also in this series\n\n  * ### Navigating Harvard with a non-apparent disability\n\n4 students with conditions ranging from diabetes to narcolepsy describe daily\nchallenges that may not be obvious to their classmates and professors\n\n  * ### Anticipate, accommodate, empower\n\nHow to ensure students with disabilities have an equal chance to succeed?\n\n  * ### Getting ahead of dyslexia\n\nHarvard lab\u2019s research suggests at-risk kids can be identified before they\never struggle in school\n\n## You might like\n\n  * Science & Tech\n\n### Getting ahead of dyslexia\n\nHarvard lab\u2019s research suggests at-risk kids can be identified before they\never struggle in school\n\n5 min read\n\n  * Science & Tech\n\n### How did you get that frog to float?\n\nEver-creative, Nobel laureate in physics Andre Geim extols fun, fanciful side\nof very serious science\n\n4 min read\n\n  * Science & Tech\n\n### Lifting a few with my chatbot\n\nSociologist Sherry Turkle warns against growing trend of turning to AI for\ncompanionship, counsel\n\n4 min read\n\n## Trending\n\n  1. Nation & World\n\n### Forget \u2018doomers.\u2019 Warming can be stopped, top climate scientist says\n\nMichael Mann points to prehistoric catastrophes, modern environmental\nvictories\n\n6 min read\n\n  2. Campus & Community\n\n### Yes, it\u2019s exciting. Just don\u2019t look at the sun.\n\nLab, telescope specialist details Harvard eclipse-viewing party, offers safety\ntips\n\n3 min read\n\n  3. Campus & Community\n\n### Navigating Harvard with a non-apparent disability\n\n4 students with conditions ranging from diabetes to narcolepsy describe daily\nchallenges that may not be obvious to their classmates and professors\n\n6 min read\n\n## Sections\n\n## Explore the Gazette\n\n## Our recent series\n\n### Fixing the Constitution\n\nMany analysts and citizens believe that the Constitution, more than 230 years\nold, is out of touch with contemporary America. We asked five scholars to\nisolate the problem they\u2019d attack first.\n\n### Life | Work\n\nA series focused on the personal side of Harvard research and teaching.\n\n## Follow us on\n\n  * Instagram\n  * LinkedIn\n  * TikTok\n  * Facebook\n  * YouTube\n  * Email\n\n", "frontpage": false}
