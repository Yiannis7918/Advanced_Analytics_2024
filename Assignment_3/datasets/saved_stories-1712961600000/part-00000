{"aid": "40014850", "title": "\"Tear\"Able Puns, and Worse Ideas: A Minimally Thread-Safe Cell", "url": "https://shift.click/blog/tearcell/", "domain": "shift.click", "votes": 1, "user": "todsacerdoti", "posted_at": "2024-04-12 16:38:04", "comments": 0, "source_title": "\u201cTear\u201dable Puns, and Worse Ideas: A Minimally Thread-Safe Cell", "source_text": "\u201cTear\u201dable Puns, and Worse Ideas: A Minimally Thread-Safe Cell - shift.click\n\n### Thom Chiovoloni\n\n  * About\n  * Twitter\n  * GitHub\n  * Email\n\n# \u201cTear\u201dable Puns, and Worse Ideas: A Minimally Thread-Safe Cell\n\n5 minute read\n\nIf you\u2019ve ever thought \u201cUsing a Mutex<[f32; 3]> is pointless, what\u2019s the worst\nthing that could happen here?\u201d, I\u2019ve written the Cell type that empowers you\nto find out the answer to that question yourself.\n\ntearor::TearCell is a \u201cthread safe\u201d cell which downgrades data races into data\ncorruption. Among other things, it\u2019s an attempt to answer the question \u201cHow\nlittle can I care about thread safety while still calling my code thread-\nsafe?\u201d.\n\nIt does this by interpreting the data inside it\u2019s inner UnsafeCell as a\n&[AtomicU8], and performing all operations on that instead of the actual\nvalue. That is, it performs multiple tearing reads/writes, each one itself is\nthread-safe.\n\nThis is pretty dodgy, and can go wrong all kinds of ways, but is still\ntechnically thread safe, as there are not really any data races happening. (It\nonly looks like these are data races officer, the operations are perfectly\nwell-sequenced, I swear)\n\nAnyway, code implementing the core idea (stripped of optimizations and other\ncomplications) is below, I\u2019ll go over it step-by-step, because it\u2019s small, and\nI still haven\u2019t decided what level of detail to go into in a post like this.\n\n## The implementationPermalink\n\nNote that the real code is a bit more robust and complex, and will copy larger\nstructures using larger atomic operations than u8 if they\u2019re sufficiently\naligned. (However, note that this means we really do need the full breadth of\nthe restrictions imposed by Pod, as we\u2019ll get to later)\n\nSo, in an ideal world we\u2019d declare this as something like:\n\n    \n    \n    #[repr(transparent)] pub struct TearCell<T> { buffer: [AtomicU8; size_of::<T>()], _boo: PhantomData<T>, }\n\nThis would actually let us implement everything using safe code (aside from\nsome operations provided by bytemuck, which use unsafe internally but are\neasily proven sound).\n\nHowever, as it is, you\u2019re not currently allowed to use size_of in this manner,\nand so we actually implement things by converting a &core::cell::UnsafeCell<T>\nto a &[AtomicU8] on every access.\n\n    \n    \n    use bytemuck::Pod; use core::sync::atomic::{AtomicU8, Ordering}; #[repr(transparent)] pub struct TearCell<T>(core::cell::UnsafeCell<T>); impl<T: Pod> TearCell<T> { /// All (potentially) shared access to `self.0` goes through this function. #[inline] fn atom_slice(&self) -> &[AtomicU8] { // Note: the real code handles ZSTs, and avoids ever calling // (the equivalent to) this function for them. assert!(core::mem::size_of::<T>() != 0); // AtomicU8 isn't Copy, and thus bytemuck can't do this for us. // This is clearly sound though, as we never view the data // inside the UnsafeCell as anything other than `&[AtomicU8]`. unsafe { core::slice::from_raw_parts( self.0.get() as *const AtomicU8, core::mem::size_of::<T>() ) } } }\n\nI\u2019m using bytemuck because it meets the requirements of: being simple,\navailable on play.rust-lang.org, and doing what I need. I also have\ncontributed enough to it that it no longer sets off my internal NIH siren.\n\nAll operations are bounded on bytemuck::Pod. This is basically a much stronger\ncousin of Copy. Not only are all Pod types Copy, but (among other things)\nmust:\n\n  1. have no padding bytes (no (u8, u16), for example).\n  2. have no uninitialized bytes (no internal use of MaybeUninit).\n  3. have no invalid bitpatterns (no bool, char, or &T for example).\n\nFurther, they also must be repr(C) or repr(transparent), as repr(Rust) structs\ncan\u2019t actually guarantee all these things.\n\n(There are some other requirements too, feel free to read the docs if you\u2019re\ninterested. Also note that there\u2019s effort to some standardize similar marker\ntraits, but at the time of writing this, that has not gotten far enough to\nreplace bytemuck here).\n\nStrictly speaking, in the implementation provided here, I believe we almost\ncould use a more relaxed bound than Pod. I believe internal padding bytes and\nother uninitialized fields, and repr(Rust) structs would be fine for us.\n\nWhile we would be reading from an uninitialized byte sometimes, we\u2019d then be\nwriting it to one that\u2019s expected to be uninitialized. The current language of\nthe unsafe-code-guidelines seems to allow this implies that\u2019s true, but I\u2019m\nnot fully certain. That said, it\u2019s dodgy either way... and requiring Pod makes\nit easier to verify as sound.\n\n### ReadingPermalink\n\nAlright, now for load:\n\n    \n    \n    impl<T: Pod> TearCell<T> { #[inline] pub fn load(&self) -> T { // Note: Using MaybeUninit here would be better, but `Pod` gives us // access to `zeroed`, and `MaybeUninit` is still kind of a pain to // use for arrays/slices until more things stabilize. let mut dst = T::zeroed(); let dst_bytes: &mut [u8] = bytemuck::bytes_of_mut(&mut dst); let src: &[AtomicU8] = self.atom_slice(); // This can never fail, and makes `zip` produce better code... assert_eq!(dst_bytes.len(), src.len()); for (d, s) in dst_bytes.iter_mut().zip(src.iter()) { *d = s.load(Ordering::Relaxed); } dst } }\n\nThis is mostly what you\u2019d expect:\n\n  1. Create destination T we\u2019ll ultimately return,\n  2. Get it\u2019s bytes as a &mut [u8].\n  3. Get the source bytes using atom_slice as shown above.\n  4. Iterate over both source slices, initializing each destination byte using a byte read from an atomic loads from the source byte.\n\nOne point to note is that the Ordering we use doesn\u2019t matter, since\nfundamentally all access to TearCell is nonatomic, so we use the weakest we\ncan.\n\n### WritingPermalink\n\nAll that\u2019s left is store:\n\n    \n    \n    impl<T: Pod> TearCell<T> { #[inline] pub fn store(&self, value: T) { let src: &[u8] = bytemuck::bytes_of(&value); let dst: &[AtomicU8] = self.atom_slice(); assert_eq!(dst_bytes.len(), src.len()); for (d, s) in dst.iter().zip(src.iter()) { d.store(*s, Ordering::Relaxed); } } }\n\nThis is essentially the opposite of load.\n\n  1. Get a slice containing the bytes of the provided value.\n  2. Get our atom_slice.\n  3. Copy the data into the atoms, using Relaxed stores (see above for why Relaxed is used).\n\nNote that the operation bytemuck::bytes_of does here is essentially equivalent\nto what you see in the atom_slice above. (If it\u2019s easier to follow I can avoid\nleveraging libraries in the future, let me know).\n\n## Wrapping upPermalink\n\nAnd we\u2019re done!\n\nI don\u2019t really think this will be useful for anybody, and it\u2019s pretty dodgy\ncode, but it\u2019s certainly... interesting.\n\nThe real crate is more efficient than this, and slightly less dubious, but is\nessentially the same idea.\n\nIf you end up using a TearCell for anything (and you should really make sure\nyou\u2019re fully aware of why it might be a mistake...), then I\u2019d be interested in\nyour use case!\n\nAnyway, it\u2019s on crates.io, and github.\n\nTags: atomics, bad code, cells, code, crates, interesting code, mistakes, rust\n\nCategories: Blog\n\nUpdated: June 11, 2020\n\nTwitter Facebook LinkedIn\n\n## You May Also Enjoy\n\n## I wish #[non_exhaustive] worked with struct update syntax\n\n3 minute read\n\nIt\u2019s pretty annoying that in Rust, #[non_exhaustive] structs don\u2019t support\n\u201cstruct update\u201d / \u201cfunctional record update\u201d syntax (the syntax that powers\nStuff { a: b, c: d, ..blah }).\n\n## Why is there no realloc that takes the number of bytes to copy?\n\n2 minute read\n\nI\u2019d like a variant of realloc that takes the number of bytes that should be\ncopied, in the case a copy is needed.\n\n## Allocator trait 1: Let\u2019s talk about the Allocator trait\n\n5 minute read\n\nThere are... several things I find wanting about the current version of the\ncore::alloc::Allocator trait (as of 2023-08-06). I\u2019m going to do a short\nseries where I post about some of the bigger issues, and explore the different\ntradeoffs and design choices we might make. This post is an introduction to\nthat.\n\n## Miri Feature Wishlist\n\n8 minute read\n\nMiri is an evaluator for rust that detects many kinds of undefined behavior.\nHere are some things it could (possibly) do that would catch bugs I\u2019ve\nhad/seen before.\n\n  * Twitter\n  * GitHub\n  * Email\n  * Feed\n\n\u00a9 2024 shift.click. Powered by Jekyll & Minimal Mistakes.\n\n", "frontpage": false}
