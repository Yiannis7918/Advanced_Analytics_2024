{"aid": "40014863", "title": "How Change Data Capture Powers Modern Apps", "url": "https://blog.bemi.io/cdc/", "domain": "bemi.io", "votes": 2, "user": "exAspArk", "posted_at": "2024-04-12 16:38:43", "comments": 0, "source_title": "How Change Data Capture Powers Modern Apps", "source_text": "How Change Data Capture Powers Modern Apps\n\nEngineering\n\n# How Change Data Capture Powers Modern Apps\n\n#### Arjun Lall\n\nApr 11, 2024 \u2022 6 min read\n\nAt its core, Change Data Capture (CDC) is a method used to track insert,\nupdate, and delete operations made to a database.\n\nhttps://blog.bytebytego.com/p/ep92-top-5-kafka-use-cases\n\nCDC is becoming an increasingly popular software pattern, with dev tooling\nstartups centered around CDC such as Airbyte and Fivetran having cumulatively\nraised nearly a billion dollars in funding in recent years. The surge in CDC's\npopularity begs the questions: why has it become so important to today\u2019s\ndeveloper, and how does it work?\n\n## Why now?\n\nCDC isn\u2019t exactly new, but its surge in popularity can be attributed to a few\nkey reasons.\n\n### Data fragmentation and growth\n\nNot only is the amount of data that applications now generate exploding, but\nthe data is increasingly fragmented between various isolated databases, making\nit a nightmare to keep everything in sync. CDC captures changes across\nindependent data sources, allowing you to unify your data and ensure everyone\nhas the correct info.\n\nExponential growth of data volumes\n\n### Real-time demands\n\nApplication data typically flows downstream to a data warehouse periodically\non a schedule to be processed for analytics. Today's applications need to\nreact to data changes as they happen, not wait for batch updates. For example,\nto be able to make faster decisions by not having stale data on dashboards.\nSince CDC lets you react to changes as they happen, it enables real-time\nanalytics and event-driven architectures.\n\nhttps://www.scylladb.com/glossary/event-driven-architecture/\n\n### Ease of adoption\n\nThe CDC infrastructure ecosystem has matured to a point where it's now\npractical for companies at all stages. Open-source projects like Debezium and\nKafka have made it easier to build systems that continuously react to data\nchanges. These tools provide the robustness, scalability, and performance\nneeded to process and distribute large volumes of change data in real-time. As\nCDC continues to get more approachable, it's igniting a surge in demand,\ncreating a powerful feedback loop that's leading to even more tooling\ndevelopment efforts.\n\n## How does CDC work?\n\nThere are three main types of CDC implementations:\n\n  1. Log-based captures changes from the existing database transaction logs and is the newest approach.\n  2. Query-based periodically queries the database to identify changes. This approach is simpler to set up but won't capture delete operations.\n  3. Trigger-based relies on database triggers to capture changes and write them to a change table. This approach reduces database performance since it requires multiple writes on each data change.\n\nLog-based CDC is quickly becoming embraced as the de facto approach because\nit's the least invasive and most efficient. It involves a few steps:\n\n  1. Log creation: When a change is made to the database, a log entry is created that captures the details of the change.\n  2. Log consumption: The change data is processed and made available for use.\n  3. Data distribution: The data is distributed to the desired systems, such as a data warehouse, cache, or search index.\n\nLet\u2019s take a closer look at each step.\n\n### Log creation\n\nBefore a database such as PostgreSQL, MySQL, MongoDB, and SQLite stores data\nto disk, it first writes it to a transaction log.\n\nDatabase transaction logs creation\n\nThis write-ahead logging technique allows writes to be more performant since\nthe database can just do the lightweight log append operation before\nasynchronously making changes to the actual files and indexes. These\ntransaction logs primarily serve as the database's source of truth to fall\nback on in case of a failure.\n\nIn Postgres, the volume of information recorded in the Write-Ahead Logs (WAL)\ncan be adjusted. The wal_level setting offers three options, in ascending\norder of information logged: minimal, replica, and logical. CDC leverages\nthese existing logs as the source of truth of all data changes, but requires a\nlogical setting that enables changes to be read row-by-row, instead of by the\nphysical disk blocks.\n\n    \n    \n    SHOW wal_level; +-------------+ | wal_level | |-------------| | logical | +-------------+\n\nSQL command to check PostgreSQL's wal_level\n\nThe format and structure of the transaction logs depend on the implementation\nof the database type. For instance, MySQL generates a binlog, while MongoDB\nuses oplogs.\n\n### Log consumption\n\nFortunately, open-source projects like Debezium can now do most of the hard\nwork of consuming entries from the transaction log and abstracting away the\ndatabase implementation details with connectors that just produce generic\nabstract events.\n\nhttps://blog.bytebytego.com/p/reddits-architecture-the-evolutionary\n\nThe Postgres connector relies on PostgreSQL\u2019s replication protocol to access\nchanges in real-time from the server\u2019s transaction logs. It then transforms\nthis information into a specific format, such as Protobuf or JSON, and sends\nit to an output destination. Each event gets structured as a key/value pair,\nwhere the key represents the primary key of the table, and the value includes\ndetails such as the before and after states of the change, along with\nadditional metadata.\n\n    \n    \n    { \"schema\": { ... }, \"payload\": { \"before\": { \"id\": 1, \"first_name\": \"Mary\", \"last_name\": \"Samsonite\", } \"after\": { \"id\": 1, \"first_name\": \"Mary\", \"last_name\": \"Swanson\", } }, \"source\": { \"connector\": \"postgresql\", \"name\": \"server1\", \"ts_ms\": 1559033904863, \"snapshot\": true, \"db\": \"postgres\", \"sequence\": \"[\\\\\"24023119\\\\\",\\\\\"24023128\\\\\"]\", \"schema\": \"public\", \"table\": \"customers\", \"txId\": 555, \"lsn\": 24023128, \"xmin\": null, }, \"op\": \"c\", \"ts_ms\": 1559033904863 }\n\nExample Update event\n\n### Data distribution\n\nCDC systems typically incorporate a message broker component to propagate the\nDebezium events. Apache Kafka stands out for this purpose because of a few\nadvantages: scalability to handle large volumes of data, persistence of\nmessages, guaranteed ordering per partition, and compaction capability, where\nmultiple changes on the same record can optionally be easily rolled into one.\nFrom the message queue, client applications can then read events that\ncorrespond to the database tables of interest, and react to every row-level\nevent they receive.\n\nCDC distributed message queue system\n\n## Patterns\n\nThere are countless use cases where CDC systems are invaluable. You can use\nthem to build notification systems instead of relying on callbacks, to\ninvalidate caches, to update search indexes, to migrate data without downtime,\nto update vector embeddings, or to perform point-in-time data recovery, to\nname a few. I\u2019ll highlight below some common CDC system patterns I've\npersonally seen in production environments.\n\n### Microservice synchronization\n\nIn a microservice based architecture, each service often maintains its own\nstandalone database. For instance, a user service might handle user data,\nwhile a friends service manages friend-related information. You might want to\ncombine the data into a materialized view or replicate it to Elasticsearch to\npower queries such as \u201cgive me a user named Mary who has 2 friends\u201d. CDC\nfacilitates the decoupling of systems by enabling real-time data sharing\nacross different components without direct message passing, thus supporting\nthe scalability and flexibility required by these architectures.\n\nOptimized decoupled local views\n\n### Audit Trails\n\nCDC offers the most reliable and performant approach for building robust audit\ntrails. The low-level data change events can be stitched with additional\nmetadata to better record who made the change and why it was made. I'm one of\nthe contributors to Bemi, an open-source tool that provides automatic audit\ntrails, and we did this by creating libraries that inserted additional custom\napplication-specific context (userID, API endpoint, etc.) in the database\ntransaction logs using a similar technique to Google's Sqlcommenter. We stitch\nthis information together in a CDC system and then store the enriched data in\na queryable database.\n\nAudit trails CDC architecture\n\n## Conclusion\n\nAs demand for CDC grows, understanding it is becoming increasingly essential\nfor today's developers. And as developer tooling in this space continues to\nimprove, the countless use cases powered by CDC will continue to get more\naccessible.\n\nI've intentionally glossed over a lot of CDC details in this blog to keep it\nshort. But I'd recommend checking out the Bemi source code to see how CDC\nsystems that have handled billions of data changes actually work under the\nhood!\n\n## Subscribe for more like this\n\nEnter your email\n\nSubscribe\n\n## The Day Soft Deletes Caused Chaos\n\nDiscover the critical mistakes and lessons learned from using soft deletes in\nproduction systems. This blog post explores the complexities, data integrity\nissues, and alternative solutions to managing deleted data effectively.\n\nMar 12, 2024 5 min read\n\n## The Ultimate Guide to PostgreSQL Data Change Tracking\n\nExplore five methods of data change tracking in PostgreSQL available in 2024.\n\nFeb 24, 2024 8 min read\n\n## From Black Box to Open Source: Embracing Transparency\n\nBemi, a platform for real-time data tracking, announces it's open-sourcing its\ncode to build trust, expand functionality, and contribute to the developer\ncommunity. This transparency empowers users, attracts diverse perspectives,\nand fosters collaboration within the developer ecosystem.\n\nFeb 9, 2024 2 min read\n\nhi@bemi.io\n\n\u00a9 2024 Bemi Technologies\n\n", "frontpage": false}
