{"aid": "40032642", "title": "Scaling Git (2017)", "url": "https://devblogs.microsoft.com/bharry/scaling-git-and-some-back-story/", "domain": "microsoft.com", "votes": 1, "user": "redbell", "posted_at": "2024-04-14 17:18:37", "comments": 0, "source_title": "Scaling Git (and some back story)", "source_text": "Scaling Git (and some back story) - Brian Harry's Blog\n\nSkip to main content\n\nMicrosoft\n\nBrian Harry's Blog\n\nBrian Harry's Blog\n\n  * Light\n  * Dark\n\nLogin\n\n# Scaling Git (and some back story)\n\nBrian Harry\n\nFebruary 3rd, 20170 1\n\nA couple of years ago, Microsoft made the decision to begin a multi-year\ninvestment in revitalizing our engineering system across the company. We are a\nbig company with tons of teams \u2013 each with their own products, priorities,\nprocesses and tools. There are some \u201ccommon\u201d tools but also a lot of diversity\n\u2013 with VERY MANY internally developed one-off tools (by team I kind of mean\ndivision \u2013 thousands of engineers). There are a lot of downsides to this:\n\n  1. Lots of redundant investments in teams building similar tooling\n  2. Inability to fund any of the tooling to \u201ccritical mass\u201d\n  3. Difficulty for employees to move around the company due to different tools and process\n  4. Difficulty in sharing code across organizations\n  5. Friction for new hires getting started due to an overabundance of \u201cMS-only\u201d tools\n  6. And more...\n\nWe set out on an effort we call the \u201cOne Engineering System\u201d or \u201c1ES\u201d. Just\nyesterday we had a 1ES day where thousands of engineers gathered to celebrate\nthe progress we\u2019ve made, to learn about the current state and to discuss the\npath forward. It was a surprisingly good event. Aside... You might be asking\nyourself \u2013 hey, you\u2019ve been telling us for years Microsoft uses TFS, have you\nbeen lying to us? No, I haven\u2019t. Over 50K people have regularly used TFS but\nthey don\u2019t always use it for everything. Some use it for everything. Some use\nonly work item tracking. Some only version control. Some build ... We had\ninternal versions (and in many cases more than one) of virtually everything\nTFS does and someone somewhere used them all. It was a bit of chaos, quite\nhonestly. But, I think I can safely say, when aggregated and weighed \u2013 TFS had\nmore adoption than any other set of tools. I also want to point out that, when\nI say engineering system here, I am using the term VERY broadly. It includes\nbut is not limited to:\n\n  1. Source control\n  2. Work management\n  3. Builds\n  4. Release\n  5. Testing\n  6. Package management\n  7. Telemetry\n  8. Flighting\n  9. Incident management\n  10. Localization\n  11. Security scanning\n  12. Accessibility\n  13. Compliance management\n  14. Code signing\n  15. Static analysis\n  16. and much, much more\n\nSo, back to the story. When we embarked on this journey, we had some heated\ndebates about where we were going, what to prioritize, etc. You know,\ndevelopers never have opinions. There\u2019s no way to try to address everything at\nonce, without failing miserably so we agreed to start by tackling 3 problems:\n\n  * Work planning\n  * Source control\n  * Build\n\nI won\u2019t go into detailed reasons other than to say those are foundational and\nso much else integrates with them, builds on them etc. that they made sense.\nI\u2019ll also observe that we had a HUGE amount of pain around build times and\nreliability due to the size of our products \u2013 some hundreds of millions of\nlines of code. Over the intervening time those initial 3 investments have\ngrown and, to varying degrees, the 1ES effort touches almost every aspect of\nour engineering process. We put some interesting stakes in the ground. Some\nincluded: The cloud is the future \u2013 Much of our infrastructure and tools were\nhosted internally (including TFS). We agreed that the cloud is the future \u2013\nmobility, management, evolution, elasticity, all the reasons you can think of.\nA few years ago, that was very controversial. How could Microsoft put all our\nIP in the cloud? What about performance? What about security? What about\nreliability? What about compliance and control? What about... It took time but\nwe eventually got a critical mass OK with the idea and as the years have\npassed, that decision has only made more and more sense and everyone is\nexcited about moving to cloud. 1st party == 3rd party \u2013 This is an expression\nwe use internally that means, as much as possible, we want to use what we ship\nand ship what we use. It\u2019s not 100% and it\u2019s not always concurrent but it\u2019s\nthe direction \u2013 the default assumption, unless there\u2019s a good reason to do\nsomething else. Visual Studio Team Services is the foundation \u2013 We made a bet\non Team Services as the backbone. We need a fabric that ties our engineering\nsystem together \u2013 a hub from which you learn about and reach everything. That\nhub needs to be modern, rich, extensible, etc. Every team needs to be able to\ncontribute and share their distinctive contributions to the engineering\nsystem. Team Services fits the bill perfectly. Over the past year usage of\nTeam services within Microsoft has grown from a couple of thousand to over\n50,000 committed users. Like with TFS, not every team uses it for everything\nyet, but momentum in that direction is strong. Team Services work planning \u2013\nHaving chosen Team Services, it was pretty natural to choose the associated\nwork management capabilities. We\u2019ve on-boarded teams like the Windows group,\nwith many thousands of users and many millions of work items, into a single\nTeam Services account. We had to do a fair amount of performance and scale\nwork to make that viable, BTW. At this point virtually every team at Microsoft\nhas made this transition and all of our engineering work is being managed in\nTeam Services Team Services Build orchestration & CloudBuild \u2013 I\u2019m not going\nto drill on this topic too much because it\u2019s a mammoth post in and of itself.\nI\u2019ll summarize it to say we\u2019ve chosen the Team Services Build service as our\nbuild orchestration system and the Team Services Build management experience\nas our UI. We have also built a new \u201cmake engine\u201d (that we don\u2019t yet ship) for\nsome of our largest code bases that does extremely high scale and fine grained\ncaching, parallelization and incrementality. We\u2019ve seen multi-hour builds drop\nsometimes to minutes. More on this in a future post at some point. After much\nbackstory, on to the meat Git for source control Maybe the most controversial\ndecision was what to use for source control. We had an internal source control\nsystem called Source Depot that virtually everyone used in the early 2000\u2019s.\nOver time, TFS and its Team Foundation Version Control solution won over much\nof the company but never made progress with the biggest teams \u2013 like Windows\nand Office. Lots of reasons I think \u2013 some of it was just that the cost for\nsuch large teams to migrate was extremely high and the two systems (Source\nDepot and TFS) weren\u2019t different enough to justify it. But source control\nsystems generate intense loyalty \u2013 more so than just about any other developer\ntool. So the argument between TFVC, Source Depot, Git, Mercurial, and more was\nferocious and, quite honestly, we made a decision without ever getting\nconsensus \u2013 it just wasn\u2019t going to happen. We chose to standardize on Git for\nmany reasons. Over time, that decision has gotten more and more adherents.\nThere were many arguments against choosing Git but the most concrete one was\nscale. There aren\u2019t many companies with code bases the size of some of ours.\nWindows and Office, in particular (but there are others), are massive.\nThousands of engineers, millions of files, thousands of build machines\nconstantly building it, quite honestly, it\u2019s mind boggling. To be clear, when\nI refer to Window in this post, I\u2019m actually painting a very broad brush \u2013\nit\u2019s Windows for PC, Mobile, Server, HoloLens, Xbox, IOT, and more. And Git is\na distributed version control system (DVCS). It copies the entire repo and all\nits history to your local machine. Doing that with Windows is laughable (and\nwe got laughed at plenty). TFVC and Source Depot had both been carefully\noptimized for huge code bases and teams. Git had *never* been applied to a\nproblem like this (or probably even within an order of magnitude of this) and\nmany asserted it would *never* work. The first big debate was \u2013 how many repos\ndo you have \u2013 one for the whole company at one extreme or one for each small\ncomponent? A big spectrum. Git is proven to work extremely well for a very\nlarge number of modest repos so we spent a bunch of time exploring what it\nwould take to factor our large codebases into lots of tenable repos. Hmm. Ever\nworked in a huge code base for 20 years? Ever tried to go back afterwards and\ndecompose it into small repos? You can guess what we discovered. The code is\nvery hard to decompose. The cost would be very high. The risk from that level\nof churn would be enormous. And, we really do have scenarios where a single\nengineer needs to make sweeping changes across a very large swath of code.\nTrying to coordinate that across hundreds of repos would be very problematic.\nAfter much hand wringing we decided our strategy needed to be \u201cthe right\nnumber of repos based on the character of the code\u201d. Some code is separable\n(like microservices) and is ideal for isolated repos. Some code is not (like\nWindows core) and needs to be treated like a single repo. And, I want to\nemphasize, it\u2019s not just about the difficulty of decomposing the code.\nSometimes, in big highly related code bases, it really is better to treat the\ncodebase as a whole. Maybe someday I\u2019ll tell the story of Bing\u2019s effort to\ncomponentize the core Bing platform into packages and the versioning problems\nthat caused for them. They are currently backing away from that strategy. That\nmeant we had to embark upon scaling Git to work on codebases that are millions\nof files, hundreds of gigabytes and used by thousands of developers. As a\ncontextual side note, even Source Depot did not scale to the entire Windows\ncodebase. It had been split across 40+ depots so that we could scale it out\nbut a layer was built over it so that, for most use cases, you could treat it\nlike one. That abstraction wasn\u2019t perfect and definitely created some\nfriction. We started down at least 2 failed paths to scale Git. Probably the\nmost extensive one was to use Git submodules to stitch together lots of repos\ninto a single \u201csuper\u201d repo. I won\u2019t go into details but after 6 months of\nworking on that we realized it wasn\u2019t going to work \u2013 too many edge cases, too\nmuch complexity and fragility. We needed a bulletproof solution that would be\nwell supported by almost all Git tooling. Close to a year ago we reset and\nfocused on how we would actually get Git to scale to a single repo that could\nhold the entire Windows codebase (include estimates of growth and history) and\nsupport all the developers and build machines. We tried an approach of\n\u201cvirtualizing\u201d Git. Normally Git downloads *everything* when you clone. But\nwhat if it didn\u2019t? What if we virtualized the storage under it so that it only\ndownloaded the things you need. So clone of a massive 300GB repo becomes very\nfast. As I perform Git commands or read/write files in my enlistment, the\nsystem seamlessly fetches the content from the cloud (and then stores it\nlocally so future accesses to that data are all local). The one downside to\nthis is that you lose offline support. If you want that you have to \u201ctouch\u201d\neverything to manifest it locally but you don\u2019t lose anything else \u2013 you still\nget the 100% fidelity Git experience. And for our huge code bases, that was\nOK. It was a promising approach and we began to prototype it. We called the\neffort Git Virtual File System or GVFS. We set out with the goal of making as\nfew changes to git.exe as possible. For sure we didn\u2019t want to fork Git \u2013 that\nwould be a disaster. And we didn\u2019t want to change it in a way that the\ncommunity would never take our contributions back either. So we walked a fine\nline doing as much \u201cunder\u201d Git with a virtual file system driver as we could.\nThe file system driver basically virtualizes 2 things:\n\n  1. The .git folder \u2013 This is where all your pack files, history, etc. are stored. It\u2019s the \u201cwhole thing\u201d by default. We virtualized this to pull down only the files we needed when we needed them.\n  2. The \u201cworking directory\u201d \u2013 the place you go to actually edit your source, build it, etc. GVFS monitors the working directory and automatically \u201cchecks out\u201d any file that you touch making it feel like all the files are there but not paying the cost unless you actually access them.\n\nAs we progressed, as you\u2019d imagine, we learned a lot. Among them, we learned\nthe Git server has to be smart. It has to pack the Git files in an optimal\nfashion so that it doesn\u2019t have to send more to the client than absolutely\nnecessary \u2013 think of it as optimizing locality of reference. So we made lots\nof enhancements to the Team Services/TFS Git server. We also discovered that\nGit has lots of scenarios where it touches stuff it really doesn\u2019t need to.\nThis never really mattered before because it was all local and used for\nmodestly sized repos so it was fast \u2013 but when touching it means downloading\nit from the server or scanning 6,000,000 files, uh oh. So we\u2019ve been investing\nheavily in is performance optimizations to Git. Many of them also benefit\n\u201cnormal\u201d repos to some degree but they are critical for mega repos. We\u2019ve been\nsubmitting many of these improvements to the Git OSS project and have enjoyed\na good working relationship with them. So, fast forward to today. It works! We\nhave all the code from 40+ Windows Source Depot servers in a single Git repo\nhosted on VS Team Services \u2013 and it\u2019s very usable. You can enlist in a few\nminutes and do all your normal Git operations in seconds. And, for all intents\nand purposes, it\u2019s transparent. It\u2019s just Git. Your devs keep working the way\nthey work, using the tools they use. Your builds just work. Etc. It\u2019s pretty\nfrick\u2019n amazing. Magic! As a side effect, this approach also has some very\nnice characteristics for large binary files. It doesn\u2019t extend Git with a new\nmechanism like LFS does, no turds, etc. It allows you to treat large binary\nfiles like any other file but it only downloads the blobs you actually ever\ntouch. Git Merge Today, at the Git Merge conference in Brussels, Saeed\nNoursalehi shared the work we\u2019ve been doing \u2013 going into excruciating detail\non what we\u2019ve done and what we\u2019ve learned. At the same time, we open sourced\nall our work. We\u2019ve also included some additional server protocols we needed\nto introduce. You can find the GVFS project and the changes we\u2019ve made to\nGit.exe in the Microsoft GitHub organization. GVFS relies on a new Windows\nfilter driver (the moral equivalent of the FUSE driver in Linux) and we\u2019ve\nworked with the Windows team to make an early drop of that available so you\ncan try GVFS. You can read more and get more resources on Saeed\u2019s blog post. I\nencourage you to check it out. You can even install it and give it a try.\nWhile I\u2019ll celebrate that it works, I also want to emphasize that it is still\nvery much a work in progress. We aren\u2019t done with any aspect of it. We think\nwe have proven the concept but there\u2019s much work to be done to make it a\nreality. The point of announcing this now and open sourcing it is to engage\nwith the community to work together to help scale Git to the largest code\nbases. Sorry for the long post but I hope it was interesting. I\u2019m very excited\nabout the work \u2013 both on 1ES at Microsoft and on scaling Git. Brian\n\n### Brian Harry Corporate Vice President, Cloud Developer Services\n\nFollow\n\nPosted in UncategorizedTagged VS Team Services\n\n### Read next\n\nTFS 2017 Process Template Editor is available\n\nI know a bunch of people have been asking for it, now you can get it. The TFS\n2017 Process Template Editor (which, btw, is an extension to VS 2017) is now\navailable...\n\nBrian Harry February 3, 2017\n\n0 comment\n\nMore on GVFS\n\nAfter watching a couple of days of GVFS conversation, I want to add a few\nthings. What problems are we solving? GVFS (and the related Git optimizations)\nreally solves ...\n\nBrian Harry February 7, 2017\n\n0 comment\n\n## 0 comments\n\nDiscussion is closed.\n\n##### Code Block\n\nFeedback\n\nYour Privacy Choices Consumer Health Privacy\n\n", "frontpage": false}
