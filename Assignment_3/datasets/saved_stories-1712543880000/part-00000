{"aid": "39963662", "title": "The Evolution of AI Bot Blocking on News Websites", "url": "https://www.peterkrantz.com/2024/evolution-of-ai-bot-blocking-news-websites/", "domain": "peterkrantz.com", "votes": 1, "user": "pkz", "posted_at": "2024-04-07 20:35:50", "comments": 0, "source_title": "Evolution of AI Bot Blocking on News Websites", "source_text": "Evolution of AI Bot Blocking on News Websites | Peter Krantz\n\n# Evolution of AI Bot Blocking on News Websites\n\nApril 6, 2024 \u00b7 Peter Krantz\n\nThe training of Large Language Models and their subsequent use in AI chatbots\nrequire access to vast amounts of data, often scraped from various online\nsources, including news websites. This data is crucial for the bots to\nunderstand and generate human-like text.\n\nHowever, this practice of data scraping seems to have raised concerns among\nnews websites. AI systems like ChatGPT can be seen as potential competitors in\nthe news business. When chatbots are asked about current events, they can\ngenerate answers that rely on data from news websites. While it fuels the\nadvancement of AI, it also poses potential issues such as copyright\ninfringement and loss of ad revenue.\n\nHow did news websites and media companies respond?\n\n## Method#\n\nTo get an understanding of the evolution of AI bot blocking on news websites I\nhave collected the robots.txt file for the top 50 news websites from January\n2023 until April 2024. The files were collected from the excellent Internet\nArchive Wayback machine from the first day of every month. This resulted in\n800 robots.txt files that were checked for AI user agent settings.\n\nLooking at recent examples of robots.txt files I collected a list of potential\nuser agent strings for AI-related crawlers.\n\nWhile some are used directly from chat bots in a dialogue the Common Crawl\ndataset plays a pivotal role in the training of LLMs. It is a publicly\navailable web archive that contains petabytes of data from billions of web\npages. The Common Crawl user agent was also added to the list of user agents\nto check.\n\nThe following user agents were used:\n\nUser agent| Description  \n---|---  \nanthropic-ai| Anthropic, makers of Claude.  \nCCBot| Common Crawl scraper.  \nChatGPT-User| OpenAI\u2019s bot used by plugins in ChatGPT.  \ncohere-ai| Cohere.  \nFacebookBot| Facebook\u2019s crawler for public web pages to improve language\nmodels.  \nGoogle-Extended| Google\u2019s bot to improve Gemini Apps and Vertex AI generative\nAPIs.  \nGPTBot| OpenAI\u2019s web crawler.  \nPerplexityBot| Perplexity Lab\u2019s crawler.  \n  \nThe check the downloaded robots.txt files, a Python script using the\nurllib.robotparser module was used. If the user agent was blocked for the path\n\u201c/\u201d it was added to the data. Google News blocks all user agents for \u201c/\u201d and\nwas removed from the dataset.\n\n## Results#\n\nBefore September 2023 there were no website blocking the user agents apart\nfrom a few blocking the Common Crawl bot. But starting in September/October of\n2023 many news websites added the OpenAI GPTBot to their blocking strategy.\n\n#### Number of blocked AI bots by the top 50 US news sites by month\n\nData source: Internet archive robots.txt files.\n\nComparing the top 50 US websites with a similar list of Swedish news websites\nthe result looks similar. Many started blocking AI bots in late 2023. I have\nnot found an explanation to why the transition happened at that time. OpenAI\nlaunched ChatGPT Enterprise in late August 2023 but the lawsuit by the New\nYork Times were not filed until December that year.\n\n#### Number of blocked AI bots by the top 50 Swedish news sites by month\n\nData source: Internet archive robots.txt files.\n\nSwedish publishers see to prioritize blocking the Google-Extended user agent\nover smaller companies like Anthropic. Maybe that will impact the competition?\n\n## Implications#\n\nWhat happens if LLMs get limited access to quality web data and instead rely\non fringe websites or pure disinformation websites? This is a potential\nproblem for users of LLMs in the future.\n\nWhat will happen to online journalism if LLM Chat bots lets users query the\nweb for answers without having to visit the source website? How will ad\nrevenue be impacted?\n\nWill smaller less known AI startups have an advantage as they are less\nfrequently blocked compared to established AI companies?\n\n## References#\n\n  * Training Data for the Price of a Sandwich, Mozilla Foundation, 2024.\n  * Will Perplexity Beat Google or Destroy the Web?, Hard Fork Podcast, New York Times, 2024.\n  * The Times Sues OpenAI and Microsoft Over A.I. Use of Copyrighted Work, New York Times, 2023.\n\n  * Web Scraping\n\n\u00a9 2024 Peter Krantz\n\n", "frontpage": false}
