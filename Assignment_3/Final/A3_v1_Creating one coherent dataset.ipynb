{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data from github into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                File  \\\n",
      "0  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "1  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "2  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "3  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "4  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "\n",
      "                                                Text  \n",
      "0  {\"aid\": \"39958086\", \"title\": \"Large Hadron Col...  \n",
      "1  {\"aid\": \"39958094\", \"title\": \"An editor for ma...  \n",
      "2  {\"aid\": \"39958109\", \"title\": \"You shouldn't ho...  \n",
      "3  {\"aid\": \"39958127\", \"title\": \"Isaac Asimov obi...  \n",
      "4  {\"aid\": \"39958129\", \"title\": \"Do people genera...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to list all text files in a directory\n",
    "def list_text_files(directory):\n",
    "    text_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.startswith(\"part-\"):\n",
    "                text_files.append(os.path.join(root, file))\n",
    "    return text_files\n",
    "\n",
    "# Function to read text data and store in DataFrame\n",
    "def create_dataframe_from_text_files(text_files):\n",
    "    data = []\n",
    "    for file in text_files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:  # Adjust encoding if needed\n",
    "            text = f.read()\n",
    "            data.append({'File': file, 'Text': text})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Specify the parent directory containing all subdirectories with text files\n",
    "#parent_directory = 'C:/Users/bryce/Documents/@ Education/KUL/Year 2 Semester 2/Advanced analytics for business/Advanced_Analytics_2024/Assignment_3/datasets'\n",
    "parent_directory = 'C:/Users/lenne/anaconda3/envs/AA/Advanced_Analytics/Assignment_3/spark/datasets'\n",
    "\n",
    "# List all subdirectories within the parent directory\n",
    "all_subdirectories = [os.path.join(parent_directory, name) for name in os.listdir(parent_directory) if os.path.isdir(os.path.join(parent_directory, name))]\n",
    "\n",
    "# List all text files in all subdirectories\n",
    "all_text_files = []\n",
    "for subdirectory in all_subdirectories:\n",
    "    text_files = list_text_files(subdirectory)\n",
    "    all_text_files.extend(text_files)\n",
    "\n",
    "# Create DataFrame from text files\n",
    "text_df = create_dataframe_from_text_files(all_text_files)\n",
    "\n",
    "# Display DataFrame\n",
    "print(text_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   File  \\\n",
      "0     C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "1     C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "2     C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "3     C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "4     C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "...                                                 ...   \n",
      "5742  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "5743  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "5744  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "5745  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "5746  C:/Users/lenne/anaconda3/envs/AA/Advanced_Anal...   \n",
      "\n",
      "                                                   Text  \n",
      "0     {\"aid\": \"39958086\", \"title\": \"Large Hadron Col...  \n",
      "1     {\"aid\": \"39958094\", \"title\": \"An editor for ma...  \n",
      "2     {\"aid\": \"39958109\", \"title\": \"You shouldn't ho...  \n",
      "3     {\"aid\": \"39958127\", \"title\": \"Isaac Asimov obi...  \n",
      "4     {\"aid\": \"39958129\", \"title\": \"Do people genera...  \n",
      "...                                                 ...  \n",
      "5742  {\"aid\": \"40105454\", \"title\": \"The Difference B...  \n",
      "5743  {\"aid\": \"40105465\", \"title\": \"Where the Bitter...  \n",
      "5744  {\"aid\": \"40105482\", \"title\": \"Makefile-graph: ...  \n",
      "5745  {\"aid\": \"40105498\", \"title\": \"Online dating sp...  \n",
      "5746  {\"aid\": \"40105510\", \"title\": \"Everything I Kno...  \n",
      "\n",
      "[5747 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       {\"aid\": \"39958086\", \"title\": \"Large Hadron Col...\n",
      "1       {\"aid\": \"39958094\", \"title\": \"An editor for ma...\n",
      "2       {\"aid\": \"39958109\", \"title\": \"You shouldn't ho...\n",
      "3       {\"aid\": \"39958127\", \"title\": \"Isaac Asimov obi...\n",
      "4       {\"aid\": \"39958129\", \"title\": \"Do people genera...\n",
      "                              ...                        \n",
      "5742    {\"aid\": \"40105454\", \"title\": \"The Difference B...\n",
      "5743    {\"aid\": \"40105465\", \"title\": \"Where the Bitter...\n",
      "5744    {\"aid\": \"40105482\", \"title\": \"Makefile-graph: ...\n",
      "5745    {\"aid\": \"40105498\", \"title\": \"Online dating sp...\n",
      "5746    {\"aid\": \"40105510\", \"title\": \"Everything I Kno...\n",
      "Name: Text, Length: 5747, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_only_df = text_df[\"Text\"]\n",
    "print(text_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json(text):\n",
    "    # Convert JSON-like string to dictionary\n",
    "    data = json.loads(text)\n",
    "    # Convert dictionary to pandas Series\n",
    "    return pd.Series(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           aid                                              title  \\\n",
      "0     39958086  Large Hadron Collider reaches its first stable...   \n",
      "1     39958094  An editor for making wireframes with a pastebi...   \n",
      "2     39958109           You shouldn't host your own email server   \n",
      "3     39958127        Isaac Asimov obituary â€“ Brian Aldiss (1992)   \n",
      "4     39958129  Do people generally agree with Shaoshan Liu an...   \n",
      "...        ...                                                ...   \n",
      "5742  40105454  The Difference Between Startup Valuation and R...   \n",
      "5743  40105465                       Where the Bitter Lesson Ends   \n",
      "5744  40105482  Makefile-graph: Parse Make's internal database...   \n",
      "5745  40105498  Online dating spells the end of Britain's lone...   \n",
      "5746  40105510  Everything I Know About Creating Buzz, I Learn...   \n",
      "\n",
      "                                                    url  \\\n",
      "0     https://home.cern/news/news/accelerators/large...   \n",
      "1                                 https://www.webma.sh/   \n",
      "2     https://old.reddit.com/r/selfhosted/comments/t...   \n",
      "3     https://www.theguardian.com/books/1992/apr/07/...   \n",
      "4     https://cacm.acm.org/blogcacm/building-computi...   \n",
      "...                                                 ...   \n",
      "5742  https://news.crunchbase.com/venture/startup-va...   \n",
      "5743  https://geohot.github.io//blog/jekyll/update/2...   \n",
      "5744           https://github.com/dnaeon/makefile-graph   \n",
      "5745  https://www.economist.com/britain/2024/04/18/o...   \n",
      "5746  https://mbrandolph.medium.com/everything-i-kno...   \n",
      "\n",
      "                     domain  votes            user            posted_at  \\\n",
      "0                 home.cern      1        Jimmc414  2024-04-07 03:57:32   \n",
      "1                  webma.sh      1             tdk  2024-04-07 03:59:55   \n",
      "2                reddit.com      1        zgin4679  2024-04-07 04:02:29   \n",
      "3           theguardian.com      1     thunderbong  2024-04-07 04:07:15   \n",
      "4                   acm.org      1       omnifidus  2024-04-07 04:07:32   \n",
      "...                     ...    ...             ...                  ...   \n",
      "5742         crunchbase.com      1        jreacher  2024-04-21 13:04:36   \n",
      "5743       geohot.github.io      1         oli5679  2024-04-21 13:05:50   \n",
      "5744      github.com/dnaeon      1          donatj  2024-04-21 13:07:23   \n",
      "5745          economist.com      1  helsinkiandrew  2024-04-21 13:08:44   \n",
      "5746  mbrandolph.medium.com      1    priyankanath  2024-04-21 13:10:13   \n",
      "\n",
      "      comments                                       source_title  \\\n",
      "0            0  Large Hadron Collider reaches its first stable...   \n",
      "1            0                                           Web Mash   \n",
      "2            0                                            Blocked   \n",
      "3            0                              Isaac Asimov obituary   \n",
      "4            0  Building Computing Systems for Embodied Artifi...   \n",
      "...        ...                                                ...   \n",
      "5742         0  The Difference Between Startup Valuation And R...   \n",
      "5743         0                       Where the Bitter Lesson ends   \n",
      "5744         0  GitHub - dnaeon/makefile-graph: Turn your Make...   \n",
      "5745         0  Online dating spells the end of Britainâ€™s lone...   \n",
      "5746         0                                   Just a moment...   \n",
      "\n",
      "                                            source_text  frontpage  \n",
      "0     Large Hadron Collider reaches its first stable...      False  \n",
      "1     Web Mash\\n\\n<\\--- Click to share your wirefram...      False  \n",
      "2     Blocked\\n\\n# whoa there, pardner!\\n\\nYour requ...      False  \n",
      "3     Isaac Asimov obituary | Books | The Guardian\\n...      False  \n",
      "4     Building Computing Systems for Embodied Artifi...      False  \n",
      "...                                                 ...        ...  \n",
      "5742  The Difference Between Startup Valuation And R...      False  \n",
      "5743  Where the Bitter Lesson ends | the singularity...      False  \n",
      "5744  GitHub - dnaeon/makefile-graph: Turn your Make...      False  \n",
      "5745  Online dating spells the end of Britainâ€™s lone...      False  \n",
      "5746  Just a moment...\\n\\n# mbrandolph.medium.com\\n\\...      False  \n",
      "\n",
      "[5747 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the \"Text\" column and concatenate the result\n",
    "result_df = text_only_df.apply(parse_json)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aid', 'title', 'url', 'domain', 'votes', 'user', 'posted_at',\n",
      "       'comments', 'source_title', 'source_text', 'frontpage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result_df to a CSV file\n",
    "#result_df.to_csv('parsed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into CSV file\n",
    "#result_df.to_csv('data_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into JSON file\n",
    "result_df.to_json('data_full.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5747, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_full.csv')\n",
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
