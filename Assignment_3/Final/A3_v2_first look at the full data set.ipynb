{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data from github into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryce\\AppData\\Local\\Temp\\ipykernel_31948\\3755196054.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                File  \\\n",
      "0  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "1  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "2  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "3  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "4  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "\n",
      "                                                Text  \n",
      "0  {\"aid\": \"39958086\", \"title\": \"Large Hadron Col...  \n",
      "1  {\"aid\": \"39958094\", \"title\": \"An editor for ma...  \n",
      "2  {\"aid\": \"39958109\", \"title\": \"You shouldn't ho...  \n",
      "3  {\"aid\": \"39958127\", \"title\": \"Isaac Asimov obi...  \n",
      "4  {\"aid\": \"39958129\", \"title\": \"Do people genera...  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to list all text files in a directory\n",
    "def list_text_files(directory):\n",
    "    text_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.startswith(\"part-\"):\n",
    "                text_files.append(os.path.join(root, file))\n",
    "    return text_files\n",
    "\n",
    "# Function to read text data and store in DataFrame\n",
    "def create_dataframe_from_text_files(text_files):\n",
    "    data = []\n",
    "    for file in text_files:\n",
    "        with open(file, 'r', encoding='utf-8') as f:  # Adjust encoding if needed\n",
    "            text = f.read()\n",
    "            data.append({'File': file, 'Text': text})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Specify the parent directory containing all subdirectories with text files\n",
    "parent_directory = 'C:/Users/bryce/Documents/@ Education/KUL/Year 2 Semester 2/Advanced analytics for business/Advanced_Analytics_2024/Assignment_3/datasets'\n",
    "\n",
    "# List all subdirectories within the parent directory\n",
    "all_subdirectories = [os.path.join(parent_directory, name) for name in os.listdir(parent_directory) if os.path.isdir(os.path.join(parent_directory, name))]\n",
    "\n",
    "# List all text files in all subdirectories\n",
    "all_text_files = []\n",
    "for subdirectory in all_subdirectories:\n",
    "    text_files = list_text_files(subdirectory)\n",
    "    all_text_files.extend(text_files)\n",
    "\n",
    "# Create DataFrame from text files\n",
    "text_df = create_dataframe_from_text_files(all_text_files)\n",
    "\n",
    "# Display DataFrame\n",
    "print(text_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   File  \\\n",
      "0     C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "1     C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "2     C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "3     C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "4     C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "...                                                 ...   \n",
      "5742  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "5743  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "5744  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "5745  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "5746  C:/Users/bryce/Documents/@ Education/KUL/Year ...   \n",
      "\n",
      "                                                   Text  \n",
      "0     {\"aid\": \"39958086\", \"title\": \"Large Hadron Col...  \n",
      "1     {\"aid\": \"39958094\", \"title\": \"An editor for ma...  \n",
      "2     {\"aid\": \"39958109\", \"title\": \"You shouldn't ho...  \n",
      "3     {\"aid\": \"39958127\", \"title\": \"Isaac Asimov obi...  \n",
      "4     {\"aid\": \"39958129\", \"title\": \"Do people genera...  \n",
      "...                                                 ...  \n",
      "5742  {\"aid\": \"40105454\", \"title\": \"The Difference B...  \n",
      "5743  {\"aid\": \"40105465\", \"title\": \"Where the Bitter...  \n",
      "5744  {\"aid\": \"40105482\", \"title\": \"Makefile-graph: ...  \n",
      "5745  {\"aid\": \"40105498\", \"title\": \"Online dating sp...  \n",
      "5746  {\"aid\": \"40105510\", \"title\": \"Everything I Kno...  \n",
      "\n",
      "[5747 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       {\"aid\": \"39958086\", \"title\": \"Large Hadron Col...\n",
      "1       {\"aid\": \"39958094\", \"title\": \"An editor for ma...\n",
      "2       {\"aid\": \"39958109\", \"title\": \"You shouldn't ho...\n",
      "3       {\"aid\": \"39958127\", \"title\": \"Isaac Asimov obi...\n",
      "4       {\"aid\": \"39958129\", \"title\": \"Do people genera...\n",
      "                              ...                        \n",
      "5742    {\"aid\": \"40105454\", \"title\": \"The Difference B...\n",
      "5743    {\"aid\": \"40105465\", \"title\": \"Where the Bitter...\n",
      "5744    {\"aid\": \"40105482\", \"title\": \"Makefile-graph: ...\n",
      "5745    {\"aid\": \"40105498\", \"title\": \"Online dating sp...\n",
      "5746    {\"aid\": \"40105510\", \"title\": \"Everything I Kno...\n",
      "Name: Text, Length: 5747, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_only_df = text_df[\"Text\"]\n",
    "print(text_only_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def parse_json(text):\n",
    "    # Convert JSON-like string to dictionary\n",
    "    data = json.loads(text)\n",
    "    # Convert dictionary to pandas Series\n",
    "    return pd.Series(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           aid                                              title  \\\n",
      "0     39958086  Large Hadron Collider reaches its first stable...   \n",
      "1     39958094  An editor for making wireframes with a pastebi...   \n",
      "2     39958109           You shouldn't host your own email server   \n",
      "3     39958127        Isaac Asimov obituary â€“ Brian Aldiss (1992)   \n",
      "4     39958129  Do people generally agree with Shaoshan Liu an...   \n",
      "...        ...                                                ...   \n",
      "5742  40105454  The Difference Between Startup Valuation and R...   \n",
      "5743  40105465                       Where the Bitter Lesson Ends   \n",
      "5744  40105482  Makefile-graph: Parse Make's internal database...   \n",
      "5745  40105498  Online dating spells the end of Britain's lone...   \n",
      "5746  40105510  Everything I Know About Creating Buzz, I Learn...   \n",
      "\n",
      "                                                    url  \\\n",
      "0     https://home.cern/news/news/accelerators/large...   \n",
      "1                                 https://www.webma.sh/   \n",
      "2     https://old.reddit.com/r/selfhosted/comments/t...   \n",
      "3     https://www.theguardian.com/books/1992/apr/07/...   \n",
      "4     https://cacm.acm.org/blogcacm/building-computi...   \n",
      "...                                                 ...   \n",
      "5742  https://news.crunchbase.com/venture/startup-va...   \n",
      "5743  https://geohot.github.io//blog/jekyll/update/2...   \n",
      "5744           https://github.com/dnaeon/makefile-graph   \n",
      "5745  https://www.economist.com/britain/2024/04/18/o...   \n",
      "5746  https://mbrandolph.medium.com/everything-i-kno...   \n",
      "\n",
      "                     domain  votes            user            posted_at  \\\n",
      "0                 home.cern      1        Jimmc414  2024-04-07 03:57:32   \n",
      "1                  webma.sh      1             tdk  2024-04-07 03:59:55   \n",
      "2                reddit.com      1        zgin4679  2024-04-07 04:02:29   \n",
      "3           theguardian.com      1     thunderbong  2024-04-07 04:07:15   \n",
      "4                   acm.org      1       omnifidus  2024-04-07 04:07:32   \n",
      "...                     ...    ...             ...                  ...   \n",
      "5742         crunchbase.com      1        jreacher  2024-04-21 13:04:36   \n",
      "5743       geohot.github.io      1         oli5679  2024-04-21 13:05:50   \n",
      "5744      github.com/dnaeon      1          donatj  2024-04-21 13:07:23   \n",
      "5745          economist.com      1  helsinkiandrew  2024-04-21 13:08:44   \n",
      "5746  mbrandolph.medium.com      1    priyankanath  2024-04-21 13:10:13   \n",
      "\n",
      "      comments                                       source_title  \\\n",
      "0            0  Large Hadron Collider reaches its first stable...   \n",
      "1            0                                           Web Mash   \n",
      "2            0                                            Blocked   \n",
      "3            0                              Isaac Asimov obituary   \n",
      "4            0  Building Computing Systems for Embodied Artifi...   \n",
      "...        ...                                                ...   \n",
      "5742         0  The Difference Between Startup Valuation And R...   \n",
      "5743         0                       Where the Bitter Lesson ends   \n",
      "5744         0  GitHub - dnaeon/makefile-graph: Turn your Make...   \n",
      "5745         0  Online dating spells the end of Britainâ€™s lone...   \n",
      "5746         0                                   Just a moment...   \n",
      "\n",
      "                                            source_text  frontpage  \n",
      "0     Large Hadron Collider reaches its first stable...      False  \n",
      "1     Web Mash\\n\\n<\\--- Click to share your wirefram...      False  \n",
      "2     Blocked\\n\\n# whoa there, pardner!\\n\\nYour requ...      False  \n",
      "3     Isaac Asimov obituary | Books | The Guardian\\n...      False  \n",
      "4     Building Computing Systems for Embodied Artifi...      False  \n",
      "...                                                 ...        ...  \n",
      "5742  The Difference Between Startup Valuation And R...      False  \n",
      "5743  Where the Bitter Lesson ends | the singularity...      False  \n",
      "5744  GitHub - dnaeon/makefile-graph: Turn your Make...      False  \n",
      "5745  Online dating spells the end of Britainâ€™s lone...      False  \n",
      "5746  Just a moment...\\n\\n# mbrandolph.medium.com\\n\\...      False  \n",
      "\n",
      "[5747 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the \"Text\" column and concatenate the result\n",
    "result_df = text_only_df.apply(parse_json)\n",
    "\n",
    "# Display the result\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aid', 'title', 'url', 'domain', 'votes', 'user', 'posted_at',\n",
      "       'comments', 'source_title', 'source_text', 'frontpage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export result_df to a CSV file\n",
    "result_df.to_csv('parsed_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into CSV file\n",
    "result_df.to_csv('data_full.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Into JSON file\n",
    "result_df.to_json('data_full.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5747, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_full.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           aid                                              title  \\\n",
      "0     39958086  Large Hadron Collider reaches its first stable...   \n",
      "1     39958094  An editor for making wireframes with a pastebi...   \n",
      "2     39958109           You shouldn't host your own email server   \n",
      "3     39958127        Isaac Asimov obituary â€“ Brian Aldiss (1992)   \n",
      "4     39958129  Do people generally agree with Shaoshan Liu an...   \n",
      "...        ...                                                ...   \n",
      "5742  40105454  The Difference Between Startup Valuation and R...   \n",
      "5743  40105465                       Where the Bitter Lesson Ends   \n",
      "5744  40105482  Makefile-graph: Parse Make's internal database...   \n",
      "5745  40105498  Online dating spells the end of Britain's lone...   \n",
      "5746  40105510  Everything I Know About Creating Buzz, I Learn...   \n",
      "\n",
      "                                                    url  \\\n",
      "0     https://home.cern/news/news/accelerators/large...   \n",
      "1                                 https://www.webma.sh/   \n",
      "2     https://old.reddit.com/r/selfhosted/comments/t...   \n",
      "3     https://www.theguardian.com/books/1992/apr/07/...   \n",
      "4     https://cacm.acm.org/blogcacm/building-computi...   \n",
      "...                                                 ...   \n",
      "5742  https://news.crunchbase.com/venture/startup-va...   \n",
      "5743  https://geohot.github.io//blog/jekyll/update/2...   \n",
      "5744           https://github.com/dnaeon/makefile-graph   \n",
      "5745  https://www.economist.com/britain/2024/04/18/o...   \n",
      "5746  https://mbrandolph.medium.com/everything-i-kno...   \n",
      "\n",
      "                     domain  votes            user            posted_at  \\\n",
      "0                 home.cern      1        Jimmc414  2024-04-07 03:57:32   \n",
      "1                  webma.sh      1             tdk  2024-04-07 03:59:55   \n",
      "2                reddit.com      1        zgin4679  2024-04-07 04:02:29   \n",
      "3           theguardian.com      1     thunderbong  2024-04-07 04:07:15   \n",
      "4                   acm.org      1       omnifidus  2024-04-07 04:07:32   \n",
      "...                     ...    ...             ...                  ...   \n",
      "5742         crunchbase.com      1        jreacher  2024-04-21 13:04:36   \n",
      "5743       geohot.github.io      1         oli5679  2024-04-21 13:05:50   \n",
      "5744      github.com/dnaeon      1          donatj  2024-04-21 13:07:23   \n",
      "5745          economist.com      1  helsinkiandrew  2024-04-21 13:08:44   \n",
      "5746  mbrandolph.medium.com      1    priyankanath  2024-04-21 13:10:13   \n",
      "\n",
      "      comments                                       source_title  \\\n",
      "0            0  Large Hadron Collider reaches its first stable...   \n",
      "1            0                                           Web Mash   \n",
      "2            0                                            Blocked   \n",
      "3            0                              Isaac Asimov obituary   \n",
      "4            0  Building Computing Systems for Embodied Artifi...   \n",
      "...        ...                                                ...   \n",
      "5742         0  The Difference Between Startup Valuation And R...   \n",
      "5743         0                       Where the Bitter Lesson ends   \n",
      "5744         0  GitHub - dnaeon/makefile-graph: Turn your Make...   \n",
      "5745         0  Online dating spells the end of Britainâ€™s lone...   \n",
      "5746         0                                   Just a moment...   \n",
      "\n",
      "                                            source_text  frontpage  \n",
      "0     Large Hadron Collider reaches its first stable...      False  \n",
      "1     Web Mash\\n\\n<\\--- Click to share your wirefram...      False  \n",
      "2     Blocked\\n\\n# whoa there, pardner!\\n\\nYour requ...      False  \n",
      "3     Isaac Asimov obituary | Books | The Guardian\\n...      False  \n",
      "4     Building Computing Systems for Embodied Artifi...      False  \n",
      "...                                                 ...        ...  \n",
      "5742  The Difference Between Startup Valuation And R...      False  \n",
      "5743  Where the Bitter Lesson ends | the singularity...      False  \n",
      "5744  GitHub - dnaeon/makefile-graph: Turn your Make...      False  \n",
      "5745  Online dating spells the end of Britainâ€™s lone...      False  \n",
      "5746  Just a moment...\\n\\n# mbrandolph.medium.com\\n\\...      False  \n",
      "\n",
      "[5747 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frontpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: frontpage, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the \"frontpage\" variable\n",
    "print(data['frontpage'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Binarize the 'frontpage' variable\n",
    "data['frontpage'] = data['frontpage'].astype(int)  # Convert True/False to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: frontpage, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Check if correct\n",
    "print(data['frontpage'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of False and True in 'frontpage' variable:\n",
      "frontpage\n",
      "0    4764\n",
      "1     983\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of occurrences of each class in the 'frontpage' variable\n",
    "frontpage_counts = data['frontpage'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts of False and True in 'frontpage' variable:\")\n",
    "print(frontpage_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "5742    0\n",
      "5743    0\n",
      "5744    0\n",
      "5745    0\n",
      "5746    0\n",
      "Name: comments, Length: 5747, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the \"comments\" variable\n",
    "print(data['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of comments:\n",
      "comments\n",
      "0      5219\n",
      "2       203\n",
      "3        67\n",
      "4        42\n",
      "5        26\n",
      "6        23\n",
      "8        19\n",
      "7        17\n",
      "9        17\n",
      "11       13\n",
      "12       11\n",
      "13        8\n",
      "16        7\n",
      "14        6\n",
      "17        6\n",
      "15        5\n",
      "19        5\n",
      "18        5\n",
      "10        4\n",
      "28        3\n",
      "35        3\n",
      "22        3\n",
      "20        3\n",
      "21        2\n",
      "88        2\n",
      "26        2\n",
      "24        2\n",
      "23        1\n",
      "76        1\n",
      "105       1\n",
      "33        1\n",
      "57        1\n",
      "83        1\n",
      "63        1\n",
      "142       1\n",
      "67        1\n",
      "46        1\n",
      "40        1\n",
      "38        1\n",
      "82        1\n",
      "45        1\n",
      "36        1\n",
      "25        1\n",
      "51        1\n",
      "89        1\n",
      "49        1\n",
      "34        1\n",
      "44        1\n",
      "29        1\n",
      "92        1\n",
      "48        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of occurrences of each class in the 'frontpage' variable\n",
    "comments_counts = data['comments'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Counts of comments:\")\n",
    "print(comments_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of 'comments': [  0  11   2   3   4   7  17   9   8   6  10  14  19   5  15  12  33  40\n",
      "  16  38  18  89  92  23  82  20  29  44  34  49  22  51  26  25  36  45\n",
      "  24  35  21  13  46  67 142  63  83  57  28  88 105  76  48]\n"
     ]
    }
   ],
   "source": [
    "unique_comments = data['comments'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique values of 'comments':\", unique_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posted_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2024-04-07 03:57:32\n",
      "1       2024-04-07 03:59:55\n",
      "2       2024-04-07 04:02:29\n",
      "3       2024-04-07 04:07:15\n",
      "4       2024-04-07 04:07:32\n",
      "               ...         \n",
      "5742    2024-04-21 13:04:36\n",
      "5743    2024-04-21 13:05:50\n",
      "5744    2024-04-21 13:07:23\n",
      "5745    2024-04-21 13:08:44\n",
      "5746    2024-04-21 13:10:13\n",
      "Name: posted_at, Length: 5747, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the \"posted_at\" variable\n",
    "print(data['posted_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I woud like to convert \"posted_at\" into two separate variables. Day: A numeric variable counting the days from the earliest time measure. Time: time difference with first post at every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            posted_at         Day      Time\n",
      "0 2024-04-07 03:57:32  2024-04-07  03:57:32\n",
      "1 2024-04-07 03:59:55  2024-04-07  03:59:55\n",
      "2 2024-04-07 04:02:29  2024-04-07  04:02:29\n",
      "3 2024-04-07 04:07:15  2024-04-07  04:07:15\n",
      "4 2024-04-07 04:07:32  2024-04-07  04:07:32\n"
     ]
    }
   ],
   "source": [
    "# Convert 'posted_at' to datetime format\n",
    "data['posted_at'] = pd.to_datetime(data['posted_at'])\n",
    "\n",
    "# Extract 'Day' and 'Time' components\n",
    "data['Day'] = data['posted_at'].dt.date\n",
    "data['Time'] = data['posted_at'].dt.time\n",
    "\n",
    "# Print the DataFrame to check the changes\n",
    "print(data[['posted_at', 'Day', 'Time']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aid', 'title', 'url', 'domain', 'votes', 'user', 'posted_at',\n",
      "       'comments', 'source_title', 'source_text', 'frontpage', 'Day', 'Time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print(data.head())\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Jimmc414\n",
      "1                  tdk\n",
      "2             zgin4679\n",
      "3          thunderbong\n",
      "4            omnifidus\n",
      "             ...      \n",
      "5742          jreacher\n",
      "5743           oli5679\n",
      "5744            donatj\n",
      "5745    helsinkiandrew\n",
      "5746      priyankanath\n",
      "Name: user, Length: 5747, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the \"user\" variable\n",
    "print(data['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of 'user': ['Jimmc414' 'tdk' 'zgin4679' ... 'jreacher' 'oli5679' 'donatj']\n",
      "Number of unique users: 2630\n"
     ]
    }
   ],
   "source": [
    "unique_users = data['user'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique values of 'user':\", unique_users)\n",
    "\n",
    "# Calculate the number of unique users\n",
    "num_unique_users = len(unique_users)\n",
    "print(\"Number of unique users:\", num_unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "5742    1\n",
      "5743    1\n",
      "5744    1\n",
      "5745    1\n",
      "5746    1\n",
      "Name: votes, Length: 5747, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the \"votes\" variable\n",
    "print(data['votes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values of 'votes': [  1   7   2  11   8  33  15   6   3   4   5  12  17  13  10  41   9  14\n",
      "  31  53  27  18  25  22  24  20  38  58  28  30  16  45  39  54  88  70\n",
      "  40  84  35  29  23  21  56  19 130 103  42  34  69  43  63  44  26  82\n",
      " 137  47  59  50  85 437  92  36  49  57  32  73  76  48  37 106  65  90]\n"
     ]
    }
   ],
   "source": [
    "unique_votes = data['votes'].unique()\n",
    "\n",
    "# Print the unique values\n",
    "print(\"Unique values of 'votes':\", unique_votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   home.cern\n",
      "1                    webma.sh\n",
      "2                  reddit.com\n",
      "3             theguardian.com\n",
      "4                     acm.org\n",
      "                ...          \n",
      "5742           crunchbase.com\n",
      "5743         geohot.github.io\n",
      "5744        github.com/dnaeon\n",
      "5745            economist.com\n",
      "5746    mbrandolph.medium.com\n",
      "Name: domain, Length: 5747, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the \"domain\" variable\n",
    "print(data['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique domains: 2936\n"
     ]
    }
   ],
   "source": [
    "unique_domain = data['domain'].unique()\n",
    "\n",
    "# Calculate the number of unique users\n",
    "num_unique_domain = len(unique_domain)\n",
    "print(\"Number of unique domains:\", num_unique_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Missing Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>source_title</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>source_text</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column Name  Missing Count\n",
       "8  source_title            116\n",
       "9   source_text              5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_count = data.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
