{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import WOEEncoder \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler, RobustScaler \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesSearchCV uses Bayesian optimization techniques to search for the best hyperparameters.\n",
    "It employs a probabilistic model to approximate the objective function (model performance) and decides the next set of hyperparameters to evaluate based on this approximation.\n",
    "Unlike GridSearchCV, it does not search through all possible combinations of hyperparameters. Instead, it iteratively selects the most promising set of hyperparameters based on the model's performance observed so far.\n",
    "Bayesian optimization tends to be more efficient in finding good hyperparameters compared to grid search, especially for high-dimensional or continuous hyperparameter spaces.\n",
    "\n",
    "In summary, while GridSearchCV performs an exhaustive search over a predefined grid of hyperparameters, BayesSearchCV uses Bayesian optimization to efficiently explore the hyperparameter space and find promising configurations. BayesSearchCV is often preferred when dealing with complex or high-dimensional hyperparameter spaces where an exhaustive search becomes impractical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../datasets/train.csv')\n",
    "data_test = pd.read_csv('../datasets/test.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **missing for now: outlier detection**\n",
    "### **also look into this encoder for categorical variables: from category_encoders.cat_boost import CatBoostEncoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests, being an ensemble of decision trees, are generally not sensitive to the scale of numeric features. The reason is that decision trees make splits based on feature values but do not rely on the absolute scale of those values. Therefore, in many cases, scaling is not a strict requirement when using Random Forests. --> no standardization for now so we keep interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- we get (1) a labeled dataset (train.csv) and (2) an unlabeled dataset (test.csv)\n",
    "- split train.csv into a train and test set\n",
    "- that train set, u should split into train and validation sets (stratified CV split because imbalance)\n",
    "- that test set has labels, so u can compare the predictions on X_test, y_test with the labels to evaluate performance of the different models **NOTE: to fit a model on the test set that is coming from train.csv, u need to pass the tuned values of the hyperparameters (tuned on the validation set)**\n",
    "- choose the best performing model \n",
    "- then make predictions on test.csv (unlabeled) and export to a csv file which you upload to the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " note: after finding the optimal parameters, put the values in the pipeline (paramters of RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas \n",
    "- change objective function? to account for top 20 evaluation metric?\n",
    "- use proftree? proflogit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Missing Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dropped_calls_ratio</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Usage_Band</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>call_cost_per_min</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name  Missing Count\n",
       "22  Dropped_calls_ratio              4\n",
       "23           Usage_Band              4\n",
       "25    call_cost_per_min              4"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training data\n",
    "missing_count = data_train.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with Missing Values in training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>F</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26/07/98</td>\n",
       "      <td>26.966667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>K244380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22/03/97</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>K244320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>03/01/96</td>\n",
       "      <td>58.133333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>CAS30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>K213590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>08/08/98</td>\n",
       "      <td>26.533333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>CAS30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>K212820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "1736      F  48.0     26/07/98  26.966667            2.0  Play 100   BS110   \n",
       "3237      F  34.0     22/03/97  43.333333            2.0  Play 100   BS110   \n",
       "3836      M  21.0     03/01/96  58.133333            2.0  Play 100   CAS30   \n",
       "4301      F  22.0     08/08/98  26.533333            5.0  Play 100   CAS30   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "1736             0.0            0.0                0.0               0.0   \n",
       "3237             0.0            0.0                0.0               0.0   \n",
       "3836             0.0            0.0                0.0               0.0   \n",
       "4301             0.0            0.0                0.0               0.0   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "1736                0.0               0.0                     0.0   \n",
       "3237                0.0               0.0                     0.0   \n",
       "3836                0.0               0.0                     0.0   \n",
       "4301                0.0               0.0                     0.0   \n",
       "\n",
       "      Nat_call_cost_Sum  AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "1736                0.0      0.0         0.0         0.0             0.0   \n",
       "3237                0.0      0.0         0.0         0.0             0.0   \n",
       "3836                0.0      0.0         0.0         0.0             0.0   \n",
       "4301                0.0      0.0         0.0         0.0             0.0   \n",
       "\n",
       "      National mins  AveNational  All_calls_mins  Dropped_calls_ratio  \\\n",
       "1736            0.0          0.0             0.0                  NaN   \n",
       "3237            0.0          0.0             0.0                  NaN   \n",
       "3836            0.0          0.0             0.0                  NaN   \n",
       "4301            0.0          0.0             0.0                  NaN   \n",
       "\n",
       "     Usage_Band  Mins_charge  call_cost_per_min  actual call cost  \\\n",
       "1736        NaN       -600.0                NaN               0.0   \n",
       "3237        NaN       -600.0                NaN               0.0   \n",
       "3836        NaN       -600.0                NaN               0.0   \n",
       "4301        NaN       -600.0                NaN               0.0   \n",
       "\n",
       "      Total_call_cost  Total_Cost Tariff_OK  average cost min  Peak ratio  \\\n",
       "1736              0.0       59.94        OK               0.5         0.0   \n",
       "3237              0.0       59.94        OK               0.5         0.0   \n",
       "3836              0.0       59.94        OK               0.5         0.0   \n",
       "4301              0.0       59.94        OK               0.5         0.0   \n",
       "\n",
       "      OffPeak ratio  Weekend ratio  Nat-InterNat Ratio high Dropped calls  \\\n",
       "1736            0.0            0.0                 0.0                  F   \n",
       "3237            0.0            0.0                 0.0                  F   \n",
       "3836            0.0            0.0                 0.0                  F   \n",
       "4301            0.0            0.0                 0.0                  F   \n",
       "\n",
       "     No Usage  target       id  \n",
       "1736        T       0  K244380  \n",
       "3237        T       0  K244320  \n",
       "3836        T       1  K213590  \n",
       "4301        T       1  K212820  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values_train = data_train[data_train.isnull().any(axis=1)]\n",
    "print(\"Rows with Missing Values in training data:\")\n",
    "rows_with_missing_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Missing Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dropped_calls_ratio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Usage_Band</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>call_cost_per_min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name  Missing Count\n",
       "22  Dropped_calls_ratio              1\n",
       "23           Usage_Band              1\n",
       "25    call_cost_per_min              1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data\n",
    "missing_count = data_test.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with Missing Values in test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>07/09/98</td>\n",
       "      <td>24.858347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.092169</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.29251</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.12627</td>\n",
       "      <td>-3.215572</td>\n",
       "      <td>-5.011147</td>\n",
       "      <td>3.519628</td>\n",
       "      <td>2.912569</td>\n",
       "      <td>0.27729</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.090036</td>\n",
       "      <td>-0.10749</td>\n",
       "      <td>-20.274408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-599.241325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.291928</td>\n",
       "      <td>-2.74686</td>\n",
       "      <td>66.563274</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.510543</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>-0.003596</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>K689673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "1389      F  34.0     07/09/98  24.858347            2.0  Play 100   BS110   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "1389             7.0       0.092169                2.0          12.29251   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "1389                2.0          -3.12627               -3.215572   \n",
       "\n",
       "      Nat_call_cost_Sum   AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "1389          -5.011147  3.519628    2.912569     0.27729           -22.0   \n",
       "\n",
       "      National mins  AveNational  All_calls_mins  Dropped_calls_ratio  \\\n",
       "1389      -2.090036     -0.10749      -20.274408                  NaN   \n",
       "\n",
       "     Usage_Band  Mins_charge  call_cost_per_min  actual call cost  \\\n",
       "1389        NaN  -599.241325                NaN         -3.291928   \n",
       "\n",
       "      Total_call_cost  Total_Cost Tariff_OK  average cost min  Peak ratio  \\\n",
       "1389         -2.74686   66.563274        OK          0.510543    0.001085   \n",
       "\n",
       "      OffPeak ratio  Weekend ratio  Nat-InterNat Ratio high Dropped calls  \\\n",
       "1389      -0.017429      -0.003596           -0.004193                  F   \n",
       "\n",
       "     No Usage       id  \n",
       "1389        T  K689673  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values_test = data_test[data_test.isnull().any(axis=1)]\n",
    "print(\"\\nRows with Missing Values in test data:\")\n",
    "rows_with_missing_values_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we will impute this since it's so little rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'target'\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = data_train.drop(target_column, axis=1)\n",
    "y_train = data_train[target_column]\n",
    "\n",
    "X_test = data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target variable is binary and imbalanced (with the minority class having a frequency of 15%), so using a stratified splitting approach is recommended to ensure that both the training and validation sets have a similar distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_splitter = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, valid_index in stratified_splitter.split(X_train, y_train):\n",
    "    X_train_split, X_valid_split = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_split, y_valid_split = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    # Now you can use X_train_split, y_train_split for training and X_valid_split, y_valid_split for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Distribution: 75.00% (3783 rows)\n",
      "Validation Set Distribution: 25.00% (1261 rows)\n"
     ]
    }
   ],
   "source": [
    "total_train_samples = X_train_split.shape[0] + X_valid_split.shape[0]\n",
    "train_distribution_percentage = (X_train_split.shape[0]/ total_train_samples) * 100\n",
    "validation_distribution_percentage = (X_valid_split.shape[0] / total_train_samples) * 100\n",
    "\n",
    "print(f\"Training Set Distribution: {train_distribution_percentage:.2f}% ({X_train_split.shape[0]} rows)\")\n",
    "print(f\"Validation Set Distribution: {validation_distribution_percentage:.2f}% ({X_valid_split.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenne\\AppData\\Local\\Temp\\ipykernel_18572\\328505691.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_split['Tariff_OK'] = np.where(X_train_split['Tariff_OK'] == 'OK', 1, 0)\n",
      "C:\\Users\\lenne\\AppData\\Local\\Temp\\ipykernel_18572\\328505691.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_valid_split['Tariff_OK'] = np.where(X_valid_split['Tariff_OK'] == 'OK', 1, 0)\n"
     ]
    }
   ],
   "source": [
    "X_train_split['Tariff_OK'] = np.where(X_train_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_valid_split['Tariff_OK'] = np.where(X_valid_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_test['Tariff_OK'] = np.where(X_test['Tariff_OK'] == 'OK', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to remove prefix from column names\n",
    "class RemovePrefixTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, prefixes):\n",
    "        self.prefixes = prefixes\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for prefix in self.prefixes:\n",
    "            X.columns = [col.split(f'{prefix}__')[1] if f'{prefix}__' in col else col for col in X.columns]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can handle them explicitly before preprocessing, for example, by replacing them with the most frequent category using fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Med' 'MedLow' 'MedHigh' 'Low' 'High']\n"
     ]
    }
   ],
   "source": [
    "X_train_split = X_train_split.copy()\n",
    "X_train_split['Usage_Band'] = X_train_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_train_split['Usage_Band'].unique())\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_train_split['Dropped_calls_ratio'] = X_train_split['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_train_split['call_cost_per_min'] = X_train_split['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_split = X_valid_split.copy()\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_valid_split['Dropped_calls_ratio'] = X_valid_split['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_valid_split['call_cost_per_min'] = X_valid_split['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())\n",
    "\n",
    "# Handle missing values in 'Usage_Band' for X_validation_split\n",
    "X_valid_split['Usage_Band'] = X_valid_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedHigh' 'Med' 'High' 'MedLow' 'Low']\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.copy()\n",
    "X_test['Usage_Band'] = X_test['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_test['Usage_Band'].unique())\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_test['Dropped_calls_ratio'] = X_test['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_test['call_cost_per_min'] = X_test['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop\n",
    "columns_to_drop = ['id', 'Connect_Date']  # Drop because it's not numerical, later on add it back to know which prediction corresponds to which individual\n",
    "\n",
    "# Define columns for different encoding methods\n",
    "one_hot_encode_columns = ['Gender', 'high Dropped calls', 'No Usage']\n",
    "woe_encode_columns = ['tariff', 'Handset', 'Usage_Band'] #ipv ordinal endoding\n",
    "PCA_columns = [\n",
    "    'Dropped_Calls',\n",
    "    'Peak_calls_Sum',\n",
    "    'Peak_mins_Sum',\n",
    "    'OffPeak_calls_Sum',\n",
    "    'OffPeak_mins_Sum',\n",
    "    'Weekend_calls_Sum',\n",
    "    'Weekend_mins_Sum',\n",
    "    'International_mins_Sum',\n",
    "    'Nat_call_cost_Sum',\n",
    "    #'AvePeak',\n",
    "    #'AveOffPeak',\n",
    "    #'AveWeekend',\n",
    "    'National_calls',\n",
    "    'National mins',\n",
    "    'National mins',\n",
    "    #'AveNational',\n",
    "    'All_calls_mins',\n",
    "    'Dropped_calls_ratio',\n",
    "    'Mins_charge',\n",
    "    'call_cost_per_min',\n",
    "    'actual call cost',\n",
    "    'Total_call_cost',\n",
    "    'Total_Cost',\n",
    "    'Peak ratio',\n",
    "    'OffPeak ratio',\n",
    "    'Weekend ratio',\n",
    "    'Nat-InterNat Ratio',\n",
    "    #'average cost min' #\n",
    "]\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# Define the PCA pipeline\n",
    "pca_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize the data\n",
    "    ('pca', PCA(n_components=0.80))  # Apply PCA to retain 80% of the variance\n",
    "])\n",
    "\n",
    "# Modify the preprocessing pipeline to apply PCA only on PCA columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('one_hot_encode', OneHotEncoder(drop='first', sparse_output=False), one_hot_encode_columns),\n",
    "        ('WOE_encode', WOEEncoder(), woe_encode_columns),\n",
    "        ('pca', pca_pipeline, PCA_columns), # Apply PCA only on PCA columns\n",
    "        ('standardize', RobustScaler(), ['Age', 'L_O_S', 'AvePeak', 'AveOffPeak', 'AveWeekend', 'AveNational', 'average cost min'])\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the remaining columns as they are\n",
    ")\n",
    "\n",
    "# Build the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('remove_prefix', RemovePrefixTransformer(prefixes=['one_hot_encode', 'WOE_encode', 'pca', 'standardize', 'remainder']))   # Add this step to remove the prefix\n",
    "])\n",
    "\n",
    "rf_classifier=RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Define the final pipeline with PCA\n",
    "lgb_pipeline_with_pca = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', rf_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate profit metric on test set\n",
    "def calculate_profit_metric(y_probabilities, dataset):\n",
    "    # Extract probabilities for positive class\n",
    "    churn_probabilities = y_probabilities[:, 1]\n",
    "\n",
    "    # Create DataFrame with churn probabilities and corresponding profitability\n",
    "    profit_df = pd.DataFrame({\"churn_prob\": churn_probabilities, \"profit\": dataset[\"average cost min\"]})\n",
    "\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    profit_df = profit_df.sort_values(by='churn_prob', ascending=False)\n",
    "\n",
    "    # Calculate profit @ top-20\n",
    "    top_20_profit = profit_df[\"profit\"][:20].sum()\n",
    "\n",
    "    return top_20_profit\n",
    "\n",
    "\n",
    "\n",
    "def calculate_profit_metric_2(y_true, y_test_proba, dataset=X_train_split, top_k=20):\n",
    "    # Reset indices of the dataset DataFrame\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Convert y_probabilities to a DataFrame and then reset indices\n",
    "    #proba_df = pd.DataFrame(proba, columns=['Prob_0', 'Prob_1'])\n",
    "    proba_df = pd.DataFrame(y_test_proba, columns=['Prob_1'])\n",
    "    proba_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    y_true.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Now concatenate the DataFrames\n",
    "    profit_df = pd.concat([dataset[['average cost min']], proba_df, y_true], axis=1)\n",
    "\n",
    "    # Sort concatenated_df by PROB_1 column in descending order\n",
    "    profit_df_sorted = profit_df.sort_values(by='Prob_1', ascending=False)\n",
    "\n",
    "    # Filter the top 20 rows\n",
    "    top_k_rows = profit_df_sorted.head(top_k)\n",
    "\n",
    "    # Filter the top 20 rows where target == 1 (actual churner) and sum the 'average cost min' values\n",
    "    profit_at_top_k = top_k_rows[(top_k_rows[y_true.name] == 1) & (top_k_rows['Prob_1'] > 0.5)]['average cost min'].sum() \n",
    "    \n",
    "    return profit_at_top_k\n",
    "\n",
    "#response_method='predict_proba', \n",
    "profit_scorer = make_scorer(calculate_profit_metric_2, needs_proba=True, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def precision_at_k(y_true, y_test_proba):\n",
    "    threshold = np.sort(y_test_proba)[::-1][int(0.0066*len(y_test_proba))] #0.00529\n",
    "    y_pred = np.asarray([1 if i >= threshold else 0 for i in y_test_proba])\n",
    "    return precision_score(y_true, y_pred)\n",
    "\n",
    "precision_at_k_scorer = make_scorer(precision_at_k, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Precision measures the proportion of true positive predictions among all positive predictions made by the model. It focuses on minimizing false positives, which is useful when the cost of incorrectly predicting a positive (churn) is high. Optimizing for precision ensures that when the model predicts churn, it's highly confident that the customer will churn. This can be important in scenarios where resources for intervention (such as retention offers) are limited, and you want to ensure that they are allocated effectively. --> try to maximize precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>high Dropped calls_T</th>\n",
       "      <th>No Usage_T</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>Age</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Tariff_OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421050</td>\n",
       "      <td>-0.951537</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>-2.568681</td>\n",
       "      <td>2.103107</td>\n",
       "      <td>-0.970825</td>\n",
       "      <td>0.336637</td>\n",
       "      <td>0.443232</td>\n",
       "      <td>1.235294</td>\n",
       "      <td>-0.177387</td>\n",
       "      <td>-0.108087</td>\n",
       "      <td>-0.148181</td>\n",
       "      <td>1.265743</td>\n",
       "      <td>-0.219327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.090559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173919</td>\n",
       "      <td>2.982628</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>0.727921</td>\n",
       "      <td>-1.376481</td>\n",
       "      <td>-0.489993</td>\n",
       "      <td>1.714494</td>\n",
       "      <td>0.402646</td>\n",
       "      <td>-0.235294</td>\n",
       "      <td>0.526743</td>\n",
       "      <td>0.507529</td>\n",
       "      <td>-0.330827</td>\n",
       "      <td>1.851660</td>\n",
       "      <td>0.337205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.764287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.016968</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.756511</td>\n",
       "      <td>-2.222597</td>\n",
       "      <td>-1.437766</td>\n",
       "      <td>-2.204695</td>\n",
       "      <td>-0.437399</td>\n",
       "      <td>0.605702</td>\n",
       "      <td>1.764706</td>\n",
       "      <td>-0.250508</td>\n",
       "      <td>0.220543</td>\n",
       "      <td>-0.024856</td>\n",
       "      <td>-0.806401</td>\n",
       "      <td>0.195994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.485256</td>\n",
       "      <td>-2.908287</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>-2.209708</td>\n",
       "      <td>3.358562</td>\n",
       "      <td>-1.820766</td>\n",
       "      <td>-0.961110</td>\n",
       "      <td>-0.250943</td>\n",
       "      <td>-0.235294</td>\n",
       "      <td>-0.492891</td>\n",
       "      <td>4.817387</td>\n",
       "      <td>-0.257835</td>\n",
       "      <td>-0.120450</td>\n",
       "      <td>-0.081423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.046880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173919</td>\n",
       "      <td>-0.135439</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>-1.667525</td>\n",
       "      <td>-0.510305</td>\n",
       "      <td>-0.414703</td>\n",
       "      <td>-1.002194</td>\n",
       "      <td>1.142253</td>\n",
       "      <td>-0.117647</td>\n",
       "      <td>0.216655</td>\n",
       "      <td>-0.115337</td>\n",
       "      <td>44.515591</td>\n",
       "      <td>-0.283772</td>\n",
       "      <td>0.520425</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.185542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173919</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>-0.614652</td>\n",
       "      <td>-2.741799</td>\n",
       "      <td>0.595936</td>\n",
       "      <td>0.094180</td>\n",
       "      <td>0.686978</td>\n",
       "      <td>-0.411765</td>\n",
       "      <td>-0.719025</td>\n",
       "      <td>6.227392</td>\n",
       "      <td>0.653429</td>\n",
       "      <td>-0.224919</td>\n",
       "      <td>4.237628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033322</td>\n",
       "      <td>2.982628</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>3.607626</td>\n",
       "      <td>1.771087</td>\n",
       "      <td>0.888979</td>\n",
       "      <td>-0.774427</td>\n",
       "      <td>1.172062</td>\n",
       "      <td>-0.764706</td>\n",
       "      <td>0.157075</td>\n",
       "      <td>1.214787</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>-0.206194</td>\n",
       "      <td>0.878667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.537311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173919</td>\n",
       "      <td>2.975147</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>-1.105980</td>\n",
       "      <td>0.270728</td>\n",
       "      <td>-0.796901</td>\n",
       "      <td>0.881906</td>\n",
       "      <td>-0.049475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633717</td>\n",
       "      <td>0.026466</td>\n",
       "      <td>-0.132774</td>\n",
       "      <td>-0.208792</td>\n",
       "      <td>-0.115895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.767044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.421050</td>\n",
       "      <td>-0.135439</td>\n",
       "      <td>0.756511</td>\n",
       "      <td>-3.786768</td>\n",
       "      <td>0.269913</td>\n",
       "      <td>-1.791040</td>\n",
       "      <td>0.547872</td>\n",
       "      <td>0.460650</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.069059</td>\n",
       "      <td>-0.336080</td>\n",
       "      <td>1.193783</td>\n",
       "      <td>-0.206194</td>\n",
       "      <td>0.154632</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.141485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.173919</td>\n",
       "      <td>-0.135439</td>\n",
       "      <td>-0.271153</td>\n",
       "      <td>-1.070018</td>\n",
       "      <td>0.479234</td>\n",
       "      <td>-0.173069</td>\n",
       "      <td>0.350096</td>\n",
       "      <td>-0.253132</td>\n",
       "      <td>1.882353</td>\n",
       "      <td>-0.415708</td>\n",
       "      <td>-0.043761</td>\n",
       "      <td>-0.364188</td>\n",
       "      <td>-0.354297</td>\n",
       "      <td>-0.412918</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.728833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3783 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_M  high Dropped calls_T  No Usage_T    tariff   Handset  \\\n",
       "0          0.0                   0.0         0.0  0.421050 -0.951537   \n",
       "1          1.0                   0.0         0.0 -0.173919  2.982628   \n",
       "3          0.0                   0.0         0.0 -0.016968  0.007327   \n",
       "4          0.0                   0.0         0.0 -0.485256 -2.908287   \n",
       "5          1.0                   0.0         0.0 -0.173919 -0.135439   \n",
       "...        ...                   ...         ...       ...       ...   \n",
       "5038       0.0                   0.0         0.0 -0.173919  0.007327   \n",
       "5039       0.0                   0.0         0.0  0.033322  2.982628   \n",
       "5040       0.0                   0.0         0.0 -0.173919  2.975147   \n",
       "5042       1.0                   0.0         0.0  0.421050 -0.135439   \n",
       "5043       1.0                   0.0         0.0 -0.173919 -0.135439   \n",
       "\n",
       "      Usage_Band      pca0      pca1      pca2      pca3      pca4       Age  \\\n",
       "0      -0.271153 -2.568681  2.103107 -0.970825  0.336637  0.443232  1.235294   \n",
       "1      -0.271153  0.727921 -1.376481 -0.489993  1.714494  0.402646 -0.235294   \n",
       "3       0.756511 -2.222597 -1.437766 -2.204695 -0.437399  0.605702  1.764706   \n",
       "4      -0.271153 -2.209708  3.358562 -1.820766 -0.961110 -0.250943 -0.235294   \n",
       "5      -0.271153 -1.667525 -0.510305 -0.414703 -1.002194  1.142253 -0.117647   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "5038   -0.271153 -0.614652 -2.741799  0.595936  0.094180  0.686978 -0.411765   \n",
       "5039    0.008762  3.607626  1.771087  0.888979 -0.774427  1.172062 -0.764706   \n",
       "5040   -0.271153 -1.105980  0.270728 -0.796901  0.881906 -0.049475  0.000000   \n",
       "5042    0.756511 -3.786768  0.269913 -1.791040  0.547872  0.460650  1.000000   \n",
       "5043   -0.271153 -1.070018  0.479234 -0.173069  0.350096 -0.253132  1.882353   \n",
       "\n",
       "         L_O_S   AvePeak  AveOffPeak  AveWeekend  AveNational  Dropped_Calls  \\\n",
       "0    -0.177387 -0.108087   -0.148181    1.265743    -0.219327            1.0   \n",
       "1     0.526743  0.507529   -0.330827    1.851660     0.337205            0.0   \n",
       "3    -0.250508  0.220543   -0.024856   -0.806401     0.195994            0.0   \n",
       "4    -0.492891  4.817387   -0.257835   -0.120450    -0.081423            0.0   \n",
       "5     0.216655 -0.115337   44.515591   -0.283772     0.520425            7.0   \n",
       "...        ...       ...         ...         ...          ...            ...   \n",
       "5038 -0.719025  6.227392    0.653429   -0.224919     4.237628            0.0   \n",
       "5039  0.157075  1.214787    0.090600   -0.206194     0.878667            1.0   \n",
       "5040  0.633717  0.026466   -0.132774   -0.208792    -0.115895            0.0   \n",
       "5042 -0.069059 -0.336080    1.193783   -0.206194     0.154632            1.0   \n",
       "5043 -0.415708 -0.043761   -0.364188   -0.354297    -0.412918           -1.0   \n",
       "\n",
       "      average cost min  Tariff_OK  \n",
       "0            -0.090559          1  \n",
       "1             0.764287          1  \n",
       "3             1.486252          1  \n",
       "4            -1.046880          1  \n",
       "5             0.185542          1  \n",
       "...                ...        ...  \n",
       "5038          0.515393          1  \n",
       "5039         -0.537311          1  \n",
       "5040          0.767044          1  \n",
       "5042          1.141485          1  \n",
       "5043          0.728833          1  \n",
       "\n",
       "[3783 rows x 20 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017103077340&gt;},\n",
       "                   refit=&#x27;profit&#x27;,\n",
       "                   scoring={&#x27;profit&#x27;: make_scorer(calculate_profit_metric_2, needs_proba=True)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                    random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4, 6, 8, 10],\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017103077340&gt;},\n",
       "                   refit=&#x27;profit&#x27;,\n",
       "                   scoring={&#x27;profit&#x27;: make_scorer(calculate_profit_metric_2, needs_proba=True)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                                    random_state=42),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [1, 2, 3, 4, 5],\n",
       "                                        'min_samples_split': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000017103077340>},\n",
       "                   refit='profit',\n",
       "                   scoring={'profit': make_scorer(calculate_profit_metric_2, needs_proba=True)})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_param_dist = {\n",
    "    'n_estimators': randint(130, 150),  # Adjust bounds based on your preference\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],  # Adjust bounds based on your preference\n",
    "} \n",
    "\n",
    "lgb_grid_search = RandomizedSearchCV(rf_classifier, lgb_param_dist, scoring={'profit': profit_scorer}, refit='profit', verbose=0, cv=5, n_jobs=-1, n_iter=100)\n",
    "\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_preprocessed, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=3, n_estimators=141,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=3, n_estimators=141,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=3, n_estimators=141,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_grid_search.best_estimator_ #has the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 2.7927497999999993\n",
      "Best Parameters: {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 141}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", lgb_grid_search.best_score_)\n",
    "print(\"Best Parameters:\", lgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=3, n_estimators=141,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=3, n_estimators=141,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=3, n_estimators=141,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_preprocessed, y_train_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the validation set IPV FIT_TRANSFORM GWN TRANSFORM BC INFO VAN TRAINING SET\n",
    "X_valid_preprocessed = preprocessing_pipeline.transform(X_valid_split)\n",
    "\n",
    "pred = best_lgb_model.predict(X_valid_preprocessed)\n",
    "\n",
    "# Evaluate on the validation set for LightGBM\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for LightGBM on Validation Set: 0.9234706579432179\n",
      "Profit @ Top-20 for LightGBM on Validation Set: 3.2882420000000008\n",
      "Profit @ Top-20 for LightGBM on Validation Set (THIS ONE IS MORE CORRECT): 2.581869\n",
      "because models that differ in the 1st profit metric but not in the 2nd get the same score on the leaderboard!\n",
      "0.7193877551020408\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "# Calculate profit metric\n",
    "profit_metric = calculate_profit_metric(y_valid_probabilities_lgb, X_valid_split)\n",
    "\n",
    "profit_metric2 = calculate_profit_metric_2(y_valid_split, y_valid_probabilities_lgb[:, 1], X_valid_split, top_k=20)\n",
    "\n",
    "print(f'AUC for LightGBM on Validation Set: {auc_score_lgb}')\n",
    "print(f'Profit @ Top-20 for LightGBM on Validation Set: {profit_metric}')\n",
    "print(f'Profit @ Top-20 for LightGBM on Validation Set (THIS ONE IS MORE CORRECT): {profit_metric2}')\n",
    "print(f'because models that differ in the 1st profit metric but not in the 2nd get the same score on the leaderboard!')\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "pred = best_lgb_model.predict(X_valid_preprocessed)\n",
    "print(precision_score(y_true=y_valid_split, y_pred=pred))\n",
    "\n",
    "print(precision_at_k(y_true=y_valid_split, y_test_proba=y_valid_probabilities_lgb[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LightGBM: {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 141}\n"
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters for LightGBM\n",
    "best_hyperparameters_LGB = lgb_grid_search.best_params_\n",
    "print(f'Best Hyperparameters for LightGBM: {best_hyperparameters_LGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.675466</td>\n",
       "      <td>0.324534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.684141</td>\n",
       "      <td>0.315859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.675188</td>\n",
       "      <td>0.324812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.682071</td>\n",
       "      <td>0.317929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.691140</td>\n",
       "      <td>0.308860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.650647</td>\n",
       "      <td>0.349353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.634717</td>\n",
       "      <td>0.365283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.623972</td>\n",
       "      <td>0.376028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.617688</td>\n",
       "      <td>0.382312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.707412</td>\n",
       "      <td>0.292588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_0    PROB_1\n",
       "0     K751808  0.675466  0.324534\n",
       "1     K837351  0.684141  0.315859\n",
       "2     K548114  0.675188  0.324812\n",
       "3     K736156  0.682071  0.317929\n",
       "4     K508080  0.691140  0.308860\n",
       "...       ...       ...       ...\n",
       "1677  K588314  0.650647  0.349353\n",
       "1678  K826807  0.634717  0.365283\n",
       "1679  K982731  0.623972  0.376028\n",
       "1680  K623037  0.617688  0.382312\n",
       "1681  K883413  0.707412  0.292588\n",
       "\n",
       "[1682 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing pipeline to the validation set\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "# Evaluate on the test set for LightGBM\n",
    "y_test_probabilities_lgb = best_lgb_model.predict_proba(X_test_preprocessed)\n",
    "y_test_probabilities_lgb = pd.DataFrame(y_test_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "y_test_probabilities_lgb_with_id = pd.concat([data_test['id'], y_test_probabilities_lgb], axis=1)\n",
    "y_test_probabilities_lgb_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LGB = y_test_probabilities_lgb_with_id.iloc[:, [0, 2]]\n",
    "result_LGB.to_csv('result_LGB_22.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.324534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.315859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.324812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.317929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.308860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.349353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.365283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.376028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.382312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.292588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_1\n",
       "0     K751808  0.324534\n",
       "1     K837351  0.315859\n",
       "2     K548114  0.324812\n",
       "3     K736156  0.317929\n",
       "4     K508080  0.308860\n",
       "...       ...       ...\n",
       "1677  K588314  0.349353\n",
       "1678  K826807  0.365283\n",
       "1679  K982731  0.376028\n",
       "1680  K623037  0.382312\n",
       "1681  K883413  0.292588\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      " 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = best_lgb_model.predict(X_valid_preprocessed)\n",
    "# Set the printing options to display all elements of the array\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Print the entire array of predictions\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of the first 20 'average cost min' values where target=1: 2.581869\n"
     ]
    }
   ],
   "source": [
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_preprocessed)\n",
    "y_valid_probabilities_lgb = pd.DataFrame(y_valid_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "\n",
    "X_valid_split.reset_index(drop=True, inplace=True)\n",
    "y_valid_probabilities_lgb.reset_index(drop=True, inplace=True)\n",
    "y_valid_split.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now concatenate the DataFrames\n",
    "concatenated_df = pd.concat([X_valid_split[['id', 'average cost min']], y_valid_probabilities_lgb, y_valid_split], axis=1)\n",
    "\n",
    "# Sort concatenated_df by PROB_1 column in descending order\n",
    "concatenated_df_sorted = concatenated_df.sort_values(by='PROB_1', ascending=False)\n",
    "\n",
    "# Filter the top 20 rows\n",
    "top_20 = concatenated_df_sorted.head(20)\n",
    "\n",
    "# Filter the top 20 rows where target == 0 and sum the 'average cost min' values\n",
    "sum_average_cost_min = top_20[(top_20['target'] == 1) & (top_20['PROB_1'] > 0.5)]['average cost min'].sum()\n",
    "\n",
    "print(\"Sum of the first 20 'average cost min' values where target=1:\", sum_average_cost_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>K417370</td>\n",
       "      <td>0.157983</td>\n",
       "      <td>0.088301</td>\n",
       "      <td>0.911699</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>K400920</td>\n",
       "      <td>0.183781</td>\n",
       "      <td>0.090224</td>\n",
       "      <td>0.909776</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>K399070</td>\n",
       "      <td>0.164935</td>\n",
       "      <td>0.091344</td>\n",
       "      <td>0.908656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>K405040</td>\n",
       "      <td>0.148111</td>\n",
       "      <td>0.091881</td>\n",
       "      <td>0.908119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>K397300</td>\n",
       "      <td>0.201234</td>\n",
       "      <td>0.092365</td>\n",
       "      <td>0.907635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>K399570</td>\n",
       "      <td>0.170917</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.907191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>K400530</td>\n",
       "      <td>0.174552</td>\n",
       "      <td>0.093117</td>\n",
       "      <td>0.906883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>K416360</td>\n",
       "      <td>0.148202</td>\n",
       "      <td>0.093203</td>\n",
       "      <td>0.906797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>K402730</td>\n",
       "      <td>0.131272</td>\n",
       "      <td>0.095281</td>\n",
       "      <td>0.904719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>K404950</td>\n",
       "      <td>0.167631</td>\n",
       "      <td>0.095692</td>\n",
       "      <td>0.904308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>K408010</td>\n",
       "      <td>0.119861</td>\n",
       "      <td>0.099242</td>\n",
       "      <td>0.900758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>K412090</td>\n",
       "      <td>0.200419</td>\n",
       "      <td>0.101122</td>\n",
       "      <td>0.898878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>K405250</td>\n",
       "      <td>0.113072</td>\n",
       "      <td>0.106340</td>\n",
       "      <td>0.893660</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>K412280</td>\n",
       "      <td>0.151791</td>\n",
       "      <td>0.110371</td>\n",
       "      <td>0.889629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>K401590</td>\n",
       "      <td>0.137077</td>\n",
       "      <td>0.113403</td>\n",
       "      <td>0.886597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>K404670</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.128344</td>\n",
       "      <td>0.871656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>K412150</td>\n",
       "      <td>0.141509</td>\n",
       "      <td>0.135398</td>\n",
       "      <td>0.864602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>K411530</td>\n",
       "      <td>0.274677</td>\n",
       "      <td>0.173591</td>\n",
       "      <td>0.826409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>K406720</td>\n",
       "      <td>0.159279</td>\n",
       "      <td>0.179162</td>\n",
       "      <td>0.820838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>K399270</td>\n",
       "      <td>0.195039</td>\n",
       "      <td>0.184305</td>\n",
       "      <td>0.815695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  average cost min    PROB_0    PROB_1  target\n",
       "427   K417370          0.157983  0.088301  0.911699       1\n",
       "339   K400920          0.183781  0.090224  0.909776       1\n",
       "868   K399070          0.164935  0.091344  0.908656       0\n",
       "363   K405040          0.148111  0.091881  0.908119       1\n",
       "840   K397300          0.201234  0.092365  0.907635       1\n",
       "1249  K399570          0.170917  0.092809  0.907191       1\n",
       "1009  K400530          0.174552  0.093117  0.906883       1\n",
       "291   K416360          0.148202  0.093203  0.906797       1\n",
       "23    K402730          0.131272  0.095281  0.904719       1\n",
       "554   K404950          0.167631  0.095692  0.904308       1\n",
       "450   K408010          0.119861  0.099242  0.900758       0\n",
       "1164  K412090          0.200419  0.101122  0.898878       1\n",
       "101   K405250          0.113072  0.106340  0.893660       1\n",
       "102   K412280          0.151791  0.110371  0.889629       1\n",
       "155   K401590          0.137077  0.113403  0.886597       1\n",
       "56    K404670          0.146900  0.128344  0.871656       0\n",
       "885   K412150          0.141509  0.135398  0.864602       1\n",
       "217   K411530          0.274677  0.173591  0.826409       0\n",
       "958   K406720          0.159279  0.179162  0.820838       1\n",
       "57    K399270          0.195039  0.184305  0.815695       1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df_sorted.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nu de profit werkt en als we tunen op validation top20 = 4.8 & scorebord: 3.4\n",
    "\n",
    "toen we het deden op \"beste model\": 6.05 op scorebord & 3.20 op validation\n",
    "\n",
    "DUS IS DE BEREKENING VAN PROFIT WEL JUIST?\n",
    "\n",
    "5.79 op scorebord ipv 6.05 voor profit als we average cost min uit PCA halen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the explainer using the best model\n",
    "explainer = shap.TreeExplainer(best_lgb_model)\n",
    "\n",
    "# Calculate SHAP values using the best model\n",
    "shap_values = explainer.shap_values(X_train_preprocessed)\n",
    "\n",
    "# Visualize SHAP values\n",
    "shap.summary_plot(shap_values, X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
