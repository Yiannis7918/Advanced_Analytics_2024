{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\AA\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import WOEEncoder \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesSearchCV uses Bayesian optimization techniques to search for the best hyperparameters.\n",
    "It employs a probabilistic model to approximate the objective function (model performance) and decides the next set of hyperparameters to evaluate based on this approximation.\n",
    "Unlike GridSearchCV, it does not search through all possible combinations of hyperparameters. Instead, it iteratively selects the most promising set of hyperparameters based on the model's performance observed so far.\n",
    "Bayesian optimization tends to be more efficient in finding good hyperparameters compared to grid search, especially for high-dimensional or continuous hyperparameter spaces.\n",
    "\n",
    "In summary, while GridSearchCV performs an exhaustive search over a predefined grid of hyperparameters, BayesSearchCV uses Bayesian optimization to efficiently explore the hyperparameter space and find promising configurations. BayesSearchCV is often preferred when dealing with complex or high-dimensional hyperparameter spaces where an exhaustive search becomes impractical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../datasets/train.csv')\n",
    "data_test = pd.read_csv('../datasets/test.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **missing for now: outlier detection**\n",
    "### **also look into this encoder for categorical variables: from category_encoders.cat_boost import CatBoostEncoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests, being an ensemble of decision trees, are generally not sensitive to the scale of numeric features. The reason is that decision trees make splits based on feature values but do not rely on the absolute scale of those values. Therefore, in many cases, scaling is not a strict requirement when using Random Forests. --> no standardization for now so we keep interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- we get (1) a labeled dataset (train.csv) and (2) an unlabeled dataset (test.csv)\n",
    "- split train.csv into a train and test set\n",
    "- that train set, u should split into train and validation sets (stratified CV split because imbalance)\n",
    "- that test set has labels, so u can compare the predictions on X_test, y_test with the labels to evaluate performance of the different models **NOTE: to fit a model on the test set that is coming from train.csv, u need to pass the tuned values of the hyperparameters (tuned on the validation set)**\n",
    "- choose the best performing model \n",
    "- then make predictions on test.csv (unlabeled) and export to a csv file which you upload to the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " note: after finding the optimal parameters, put the values in the pipeline (paramters of RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas \n",
    "- change objective function? to account for top 20 evaluation metric?\n",
    "- use proftree? proflogit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Missing Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dropped_calls_ratio</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Usage_Band</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>call_cost_per_min</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name  Missing Count\n",
       "22  Dropped_calls_ratio              4\n",
       "23           Usage_Band              4\n",
       "25    call_cost_per_min              4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training data\n",
    "missing_count = data_train.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with Missing Values in training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>F</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26/07/98</td>\n",
       "      <td>26.966667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>K244380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22/03/97</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>K244320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>03/01/96</td>\n",
       "      <td>58.133333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>CAS30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>K213590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>08/08/98</td>\n",
       "      <td>26.533333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>CAS30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>K212820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "1736      F  48.0     26/07/98  26.966667            2.0  Play 100   BS110   \n",
       "3237      F  34.0     22/03/97  43.333333            2.0  Play 100   BS110   \n",
       "3836      M  21.0     03/01/96  58.133333            2.0  Play 100   CAS30   \n",
       "4301      F  22.0     08/08/98  26.533333            5.0  Play 100   CAS30   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "1736             0.0            0.0                0.0               0.0   \n",
       "3237             0.0            0.0                0.0               0.0   \n",
       "3836             0.0            0.0                0.0               0.0   \n",
       "4301             0.0            0.0                0.0               0.0   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "1736                0.0               0.0                     0.0   \n",
       "3237                0.0               0.0                     0.0   \n",
       "3836                0.0               0.0                     0.0   \n",
       "4301                0.0               0.0                     0.0   \n",
       "\n",
       "      Nat_call_cost_Sum  AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "1736                0.0      0.0         0.0         0.0             0.0   \n",
       "3237                0.0      0.0         0.0         0.0             0.0   \n",
       "3836                0.0      0.0         0.0         0.0             0.0   \n",
       "4301                0.0      0.0         0.0         0.0             0.0   \n",
       "\n",
       "      National mins  AveNational  All_calls_mins  Dropped_calls_ratio  \\\n",
       "1736            0.0          0.0             0.0                  NaN   \n",
       "3237            0.0          0.0             0.0                  NaN   \n",
       "3836            0.0          0.0             0.0                  NaN   \n",
       "4301            0.0          0.0             0.0                  NaN   \n",
       "\n",
       "     Usage_Band  Mins_charge  call_cost_per_min  actual call cost  \\\n",
       "1736        NaN       -600.0                NaN               0.0   \n",
       "3237        NaN       -600.0                NaN               0.0   \n",
       "3836        NaN       -600.0                NaN               0.0   \n",
       "4301        NaN       -600.0                NaN               0.0   \n",
       "\n",
       "      Total_call_cost  Total_Cost Tariff_OK  average cost min  Peak ratio  \\\n",
       "1736              0.0       59.94        OK               0.5         0.0   \n",
       "3237              0.0       59.94        OK               0.5         0.0   \n",
       "3836              0.0       59.94        OK               0.5         0.0   \n",
       "4301              0.0       59.94        OK               0.5         0.0   \n",
       "\n",
       "      OffPeak ratio  Weekend ratio  Nat-InterNat Ratio high Dropped calls  \\\n",
       "1736            0.0            0.0                 0.0                  F   \n",
       "3237            0.0            0.0                 0.0                  F   \n",
       "3836            0.0            0.0                 0.0                  F   \n",
       "4301            0.0            0.0                 0.0                  F   \n",
       "\n",
       "     No Usage  target       id  \n",
       "1736        T       0  K244380  \n",
       "3237        T       0  K244320  \n",
       "3836        T       1  K213590  \n",
       "4301        T       1  K212820  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values_train = data_train[data_train.isnull().any(axis=1)]\n",
    "print(\"Rows with Missing Values in training data:\")\n",
    "rows_with_missing_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Missing Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dropped_calls_ratio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Usage_Band</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>call_cost_per_min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name  Missing Count\n",
       "22  Dropped_calls_ratio              1\n",
       "23           Usage_Band              1\n",
       "25    call_cost_per_min              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data\n",
    "missing_count = data_test.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with Missing Values in test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>07/09/98</td>\n",
       "      <td>24.858347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.092169</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.29251</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.12627</td>\n",
       "      <td>-3.215572</td>\n",
       "      <td>-5.011147</td>\n",
       "      <td>3.519628</td>\n",
       "      <td>2.912569</td>\n",
       "      <td>0.27729</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.090036</td>\n",
       "      <td>-0.10749</td>\n",
       "      <td>-20.274408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-599.241325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.291928</td>\n",
       "      <td>-2.74686</td>\n",
       "      <td>66.563274</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.510543</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>-0.003596</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>K689673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "1389      F  34.0     07/09/98  24.858347            2.0  Play 100   BS110   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "1389             7.0       0.092169                2.0          12.29251   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "1389                2.0          -3.12627               -3.215572   \n",
       "\n",
       "      Nat_call_cost_Sum   AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "1389          -5.011147  3.519628    2.912569     0.27729           -22.0   \n",
       "\n",
       "      National mins  AveNational  All_calls_mins  Dropped_calls_ratio  \\\n",
       "1389      -2.090036     -0.10749      -20.274408                  NaN   \n",
       "\n",
       "     Usage_Band  Mins_charge  call_cost_per_min  actual call cost  \\\n",
       "1389        NaN  -599.241325                NaN         -3.291928   \n",
       "\n",
       "      Total_call_cost  Total_Cost Tariff_OK  average cost min  Peak ratio  \\\n",
       "1389         -2.74686   66.563274        OK          0.510543    0.001085   \n",
       "\n",
       "      OffPeak ratio  Weekend ratio  Nat-InterNat Ratio high Dropped calls  \\\n",
       "1389      -0.017429      -0.003596           -0.004193                  F   \n",
       "\n",
       "     No Usage       id  \n",
       "1389        T  K689673  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values_test = data_test[data_test.isnull().any(axis=1)]\n",
    "print(\"\\nRows with Missing Values in test data:\")\n",
    "rows_with_missing_values_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we will impute this since it's so little rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'target'\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = data_train.drop(target_column, axis=1)\n",
    "y_train = data_train[target_column]\n",
    "\n",
    "X_test = data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target variable is binary and imbalanced (with the minority class having a frequency of 15%), so using a stratified splitting approach is recommended to ensure that both the training and validation sets have a similar distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)\n",
    "    # Now you can use X_train_split, y_train_split for training and X_valid_split, y_valid_split for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Distribution: 75.00% (3783 rows)\n",
      "Validation Set Distribution: 25.00% (1261 rows)\n"
     ]
    }
   ],
   "source": [
    "total_train_samples = X_train_split.shape[0] + X_valid_split.shape[0]\n",
    "train_distribution_percentage = (X_train_split.shape[0]/ total_train_samples) * 100\n",
    "validation_distribution_percentage = (X_valid_split.shape[0] / total_train_samples) * 100\n",
    "\n",
    "print(f\"Training Set Distribution: {train_distribution_percentage:.2f}% ({X_train_split.shape[0]} rows)\")\n",
    "print(f\"Validation Set Distribution: {validation_distribution_percentage:.2f}% ({X_valid_split.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split['Tariff_OK'] = np.where(X_train_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_valid_split['Tariff_OK'] = np.where(X_valid_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_test['Tariff_OK'] = np.where(X_test['Tariff_OK'] == 'OK', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to remove prefix from column names\n",
    "class RemovePrefixTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, prefixes):\n",
    "        self.prefixes = prefixes\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for prefix in self.prefixes:\n",
    "            X.columns = [col.split(f'{prefix}__')[1] if f'{prefix}__' in col else col for col in X.columns]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can handle them explicitly before preprocessing, for example, by replacing them with the most frequent category using fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedHigh' 'High' 'Med' 'Low' 'MedLow']\n"
     ]
    }
   ],
   "source": [
    "X_train_split = X_train_split.copy()\n",
    "X_train_split['Usage_Band'] = X_train_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_train_split['Usage_Band'].unique())\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_train_split['Dropped_calls_ratio'] = X_train_split['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_train_split['call_cost_per_min'] = X_train_split['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_split = X_valid_split.copy()\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_valid_split['Dropped_calls_ratio'] = X_valid_split['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_valid_split['call_cost_per_min'] = X_valid_split['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())\n",
    "\n",
    "# Handle missing values in 'Usage_Band' for X_validation_split\n",
    "X_valid_split['Usage_Band'] = X_valid_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedHigh' 'Med' 'High' 'MedLow' 'Low']\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.copy()\n",
    "X_test['Usage_Band'] = X_test['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_test['Usage_Band'].unique())\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_test['Dropped_calls_ratio'] = X_test['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_test['call_cost_per_min'] = X_test['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop\n",
    "columns_to_drop = ['id', 'Connect_Date']  # Drop because it's not numerical, later on add it back to know which prediction corresponds to which individual\n",
    "\n",
    "# Define columns for different encoding methods\n",
    "one_hot_encode_columns = ['Gender', 'high Dropped calls', 'No Usage']\n",
    "woe_encode_columns = ['tariff', 'Handset', 'Usage_Band'] #ipv ordinal endoding\n",
    "PCA_columns = [\n",
    "    'Age',\n",
    "    'L_O_S',\n",
    "    'Dropped_Calls',\n",
    "    'Peak_calls_Sum',\n",
    "    'Peak_mins_Sum',\n",
    "    'OffPeak_calls_Sum',\n",
    "    'OffPeak_mins_Sum',\n",
    "    'Weekend_calls_Sum',\n",
    "    'Weekend_mins_Sum',\n",
    "    'International_mins_Sum',\n",
    "    'Nat_call_cost_Sum',\n",
    "    'AvePeak',\n",
    "    'AveOffPeak',\n",
    "    'AveWeekend',\n",
    "    'National_calls',\n",
    "    'National mins',\n",
    "    'AveNational',\n",
    "    'All_calls_mins',\n",
    "    'Dropped_calls_ratio',\n",
    "    'Mins_charge',\n",
    "    'call_cost_per_min',\n",
    "    'actual call cost',\n",
    "    'Total_call_cost',\n",
    "    'Total_Cost',\n",
    "    'average cost min',\n",
    "    'Peak ratio',\n",
    "    'OffPeak ratio',\n",
    "    'Weekend ratio',\n",
    "    'Nat-InterNat Ratio'\n",
    "]\n",
    "\n",
    "# Define the PCA pipeline\n",
    "pca_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Standardize the data\n",
    "    ('pca', PCA(n_components=0.80))  # Apply PCA to retain 90% of the variance\n",
    "])\n",
    "\n",
    "# Modify the preprocessing pipeline to apply PCA only on PCA columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('one_hot_encode', OneHotEncoder(drop='first', sparse_output=False), one_hot_encode_columns),\n",
    "        ('WOE_encode', WOEEncoder(), woe_encode_columns),\n",
    "        ('pca', pca_pipeline, PCA_columns)  # Apply PCA only on PCA columns\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the remaining columns as they are\n",
    ")\n",
    "\n",
    "# Build the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('remove_prefix', RemovePrefixTransformer(prefixes=['one_hot_encode', 'WOE_encode', 'pca', 'remainder']))   # Add this step to remove the prefix\n",
    "])\n",
    "\n",
    "positive_fraction = y_train_split.sum() / len(y_train_split)\n",
    "lgb_classifier = lgb.LGBMClassifier(scale_pos_weight=(1/positive_fraction)*1.2)\n",
    "######################################################################################\n",
    "#lgb_classifier = lgb.LGBMClassifier(scale_pos_weight=(1 - y_train_split.sum() / len(y_train_split)))\n",
    "\n",
    "# Define the final pipeline with PCA\n",
    "lgb_pipeline_with_pca = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', lgb_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate profit metric on test set\n",
    "def calculate_profit_metric(y_probabilities, dataset):\n",
    "    # Extract probabilities for positive class\n",
    "    churn_probabilities = y_probabilities[:, 1]\n",
    "\n",
    "    # Create DataFrame with churn probabilities and corresponding profitability\n",
    "    profit_df = pd.DataFrame({\"churn_prob\": churn_probabilities, \"profit\": dataset[\"average cost min\"]})\n",
    "\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    profit_df = profit_df.sort_values(by='churn_prob', ascending=False)\n",
    "\n",
    "    # Calculate profit @ top-20\n",
    "    top_20_profit = profit_df[\"profit\"][:20].sum()\n",
    "\n",
    "    return top_20_profit\n",
    "\n",
    "\n",
    "\n",
    "def calculate_profit_metric_2(y_true, y_probabilities, dataset, top_k=20):\n",
    "    # Reset indices of the dataset DataFrame\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Convert y_probabilities to a DataFrame and then reset indices\n",
    "    y_probabilities = pd.DataFrame(y_probabilities, columns=['Prob_0', 'Prob_1'])\n",
    "    y_probabilities.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Now concatenate the DataFrames\n",
    "    profit_df = pd.concat([dataset[['average cost min']], y_probabilities, y_true], axis=1)\n",
    "\n",
    "    # Sort concatenated_df by PROB_1 column in descending order\n",
    "    profit_df_sorted = profit_df.sort_values(by='Prob_1', ascending=False)\n",
    "\n",
    "    # Filter the top 20 rows\n",
    "    top_k_rows = profit_df_sorted.head(top_k)\n",
    "\n",
    "    # Filter the top 20 rows where target == 1 (actual churner) and sum the 'average cost min' values\n",
    "    profit_at_top_k = top_k_rows[(top_k_rows[y_true.name] == 1) & (top_k_rows['Prob_1'] > 0.5)]['average cost min'].sum()  \n",
    "    \n",
    "    return profit_at_top_k\n",
    "\n",
    "'''\n",
    "# Define evaluation metrics\n",
    "def profit_at_top_20(y_true, y_pred, top_k=20):\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    sorted_indices = sorted(range(len(y_pred)), key=lambda k: y_pred[k, 1], reverse=True)\n",
    "\n",
    "    # Identify the top-20 customers\n",
    "    top_20_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Calculate profit at top-20\n",
    "    profit = sum(y_true[i] * y_pred[i, 1] for i in top_20_indices)\n",
    "\n",
    "    return profit\n",
    "\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True)\n",
    "'''\n",
    "\n",
    "\n",
    "def profit_at_top_20(y_true, y_pred, dataset, top_k=20):\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    sorted_indices = sorted(range(len(y_pred)), key=lambda k: y_pred[k, 1], reverse=True)\n",
    "\n",
    "    # Identify the top-k churners\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Calculate profit at top-k churners\n",
    "    profit = sum(dataset.iloc[i][\"average cost min\"] for i in top_k_indices if y_true[i] == 1)\n",
    "\n",
    "    return profit\n",
    "\n",
    "def profit_at_top_20(y_true, y_pred_proba, dataset, top_k=20):\n",
    "    sorted_indices = sorted(range(len(y_pred_proba)), key=lambda k: y_pred_proba[k, 1], reverse=True)\n",
    "    top_k_indices = sorted_indices[:top_k]\n",
    "    profit = sum(dataset.iloc[i][\"average_cost_min\"] for i in top_k_indices if y_true[i] == 1)\n",
    "    return profit\n",
    "\n",
    "######## NEW ############\n",
    "def profit_at_top_20(y_true, y_pred_proba):\n",
    "    # Sort instances by predicted probabilities of churn in descending order\n",
    "    sorted_indices = np.argsort(y_pred_proba[:, 1])[::-1]\n",
    "    \n",
    "    # Select top 20 instances\n",
    "    top_20_indices = sorted_indices[:20]\n",
    "    \n",
    "    # Filter top 20 indices where y_true is equal to 1\n",
    "    top_20_indices_churners = [i for i in top_20_indices if y_true[i] == 1]\n",
    "    \n",
    "    # Calculate the sum of profitability for top 20 churners\n",
    "    profit_top_20 = np.sum(X_train.loc[top_20_indices_churners, 'average cost min'])\n",
    "    \n",
    "    return profit_top_20\n",
    "\n",
    "\n",
    "# Define custom scorer\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Precision measures the proportion of true positive predictions among all positive predictions made by the model. It focuses on minimizing false positives, which is useful when the cost of incorrectly predicting a positive (churn) is high. Optimizing for precision ensures that when the model predicts churn, it's highly confident that the customer will churn. This can be important in scenarios where resources for intervention (such as retention offers) are limited, and you want to ensure that they are allocated effectively. --> try to maximize precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>high Dropped calls_T</th>\n",
       "      <th>No Usage_T</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>pca0</th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>Tariff_OK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025258</td>\n",
       "      <td>-1.872393</td>\n",
       "      <td>-0.048636</td>\n",
       "      <td>1.386993</td>\n",
       "      <td>0.876328</td>\n",
       "      <td>-1.297747</td>\n",
       "      <td>2.075615</td>\n",
       "      <td>-1.250224</td>\n",
       "      <td>-0.646143</td>\n",
       "      <td>0.387267</td>\n",
       "      <td>0.365983</td>\n",
       "      <td>1.192806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025258</td>\n",
       "      <td>-1.872393</td>\n",
       "      <td>0.127154</td>\n",
       "      <td>8.137217</td>\n",
       "      <td>2.937139</td>\n",
       "      <td>2.873771</td>\n",
       "      <td>-0.607021</td>\n",
       "      <td>-0.935561</td>\n",
       "      <td>0.368291</td>\n",
       "      <td>-0.014974</td>\n",
       "      <td>1.135921</td>\n",
       "      <td>0.032158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412173</td>\n",
       "      <td>-1.872393</td>\n",
       "      <td>-0.267809</td>\n",
       "      <td>-2.186995</td>\n",
       "      <td>0.291708</td>\n",
       "      <td>-1.382133</td>\n",
       "      <td>-0.808999</td>\n",
       "      <td>0.238299</td>\n",
       "      <td>-0.400260</td>\n",
       "      <td>-0.124212</td>\n",
       "      <td>0.177303</td>\n",
       "      <td>-0.681670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.575781</td>\n",
       "      <td>-1.872393</td>\n",
       "      <td>-0.267809</td>\n",
       "      <td>-0.873312</td>\n",
       "      <td>2.247522</td>\n",
       "      <td>-1.248357</td>\n",
       "      <td>0.700398</td>\n",
       "      <td>-0.720249</td>\n",
       "      <td>0.595635</td>\n",
       "      <td>-0.444188</td>\n",
       "      <td>-0.630592</td>\n",
       "      <td>0.383382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054640</td>\n",
       "      <td>-2.495128</td>\n",
       "      <td>-0.267809</td>\n",
       "      <td>-1.306921</td>\n",
       "      <td>-1.808283</td>\n",
       "      <td>1.613189</td>\n",
       "      <td>0.445472</td>\n",
       "      <td>-1.442473</td>\n",
       "      <td>0.589917</td>\n",
       "      <td>-0.776438</td>\n",
       "      <td>-2.002249</td>\n",
       "      <td>1.871834</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054640</td>\n",
       "      <td>-0.076099</td>\n",
       "      <td>-0.267809</td>\n",
       "      <td>-0.885071</td>\n",
       "      <td>-0.716197</td>\n",
       "      <td>-0.445664</td>\n",
       "      <td>-0.749103</td>\n",
       "      <td>-0.713300</td>\n",
       "      <td>-0.360288</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>1.832095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054640</td>\n",
       "      <td>-0.076099</td>\n",
       "      <td>-0.267809</td>\n",
       "      <td>-1.699194</td>\n",
       "      <td>-1.342866</td>\n",
       "      <td>0.528860</td>\n",
       "      <td>0.369493</td>\n",
       "      <td>-1.777610</td>\n",
       "      <td>-0.998509</td>\n",
       "      <td>-0.134087</td>\n",
       "      <td>-0.347059</td>\n",
       "      <td>0.882527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.575781</td>\n",
       "      <td>-1.872393</td>\n",
       "      <td>-0.267809</td>\n",
       "      <td>-1.738098</td>\n",
       "      <td>1.112853</td>\n",
       "      <td>-1.367370</td>\n",
       "      <td>-0.989003</td>\n",
       "      <td>0.134119</td>\n",
       "      <td>-0.281156</td>\n",
       "      <td>0.725913</td>\n",
       "      <td>0.090856</td>\n",
       "      <td>0.325016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.412173</td>\n",
       "      <td>-0.076099</td>\n",
       "      <td>0.827872</td>\n",
       "      <td>-3.519844</td>\n",
       "      <td>2.483799</td>\n",
       "      <td>-2.002371</td>\n",
       "      <td>0.466759</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>1.516680</td>\n",
       "      <td>-0.112715</td>\n",
       "      <td>1.041565</td>\n",
       "      <td>-1.554432</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054640</td>\n",
       "      <td>-2.495128</td>\n",
       "      <td>-0.267809</td>\n",
       "      <td>-1.218425</td>\n",
       "      <td>-0.010849</td>\n",
       "      <td>0.616934</td>\n",
       "      <td>-0.120925</td>\n",
       "      <td>-1.290686</td>\n",
       "      <td>-0.660748</td>\n",
       "      <td>-0.476292</td>\n",
       "      <td>-0.263910</td>\n",
       "      <td>-0.376731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3783 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_M  high Dropped calls_T  No Usage_T    tariff   Handset  \\\n",
       "3898       0.0                   0.0         0.0 -0.025258 -1.872393   \n",
       "454        1.0                   0.0         0.0 -0.025258 -1.872393   \n",
       "2872       1.0                   0.0         0.0  0.412173 -1.872393   \n",
       "77         0.0                   0.0         0.0 -0.575781 -1.872393   \n",
       "3529       1.0                   0.0         0.0 -0.054640 -2.495128   \n",
       "...        ...                   ...         ...       ...       ...   \n",
       "1017       1.0                   0.0         0.0 -0.054640 -0.076099   \n",
       "1729       0.0                   0.0         0.0 -0.054640 -0.076099   \n",
       "4060       1.0                   0.0         0.0 -0.575781 -1.872393   \n",
       "2626       0.0                   0.0         0.0  0.412173 -0.076099   \n",
       "825        0.0                   0.0         0.0 -0.054640 -2.495128   \n",
       "\n",
       "      Usage_Band      pca0      pca1      pca2      pca3      pca4      pca5  \\\n",
       "3898   -0.048636  1.386993  0.876328 -1.297747  2.075615 -1.250224 -0.646143   \n",
       "454     0.127154  8.137217  2.937139  2.873771 -0.607021 -0.935561  0.368291   \n",
       "2872   -0.267809 -2.186995  0.291708 -1.382133 -0.808999  0.238299 -0.400260   \n",
       "77     -0.267809 -0.873312  2.247522 -1.248357  0.700398 -0.720249  0.595635   \n",
       "3529   -0.267809 -1.306921 -1.808283  1.613189  0.445472 -1.442473  0.589917   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1017   -0.267809 -0.885071 -0.716197 -0.445664 -0.749103 -0.713300 -0.360288   \n",
       "1729   -0.267809 -1.699194 -1.342866  0.528860  0.369493 -1.777610 -0.998509   \n",
       "4060   -0.267809 -1.738098  1.112853 -1.367370 -0.989003  0.134119 -0.281156   \n",
       "2626    0.827872 -3.519844  2.483799 -2.002371  0.466759  0.010876  1.516680   \n",
       "825    -0.267809 -1.218425 -0.010849  0.616934 -0.120925 -1.290686 -0.660748   \n",
       "\n",
       "          pca6      pca7      pca8  Tariff_OK  \n",
       "3898  0.387267  0.365983  1.192806          1  \n",
       "454  -0.014974  1.135921  0.032158          1  \n",
       "2872 -0.124212  0.177303 -0.681670          1  \n",
       "77   -0.444188 -0.630592  0.383382          1  \n",
       "3529 -0.776438 -2.002249  1.871834          1  \n",
       "...        ...       ...       ...        ...  \n",
       "1017 -0.192000  0.016089  1.832095          1  \n",
       "1729 -0.134087 -0.347059  0.882527          1  \n",
       "4060  0.725913  0.090856  0.325016          1  \n",
       "2626 -0.112715  1.041565 -1.554432          1  \n",
       "825  -0.476292 -0.263910 -0.376731          1  \n",
       "\n",
       "[3783 rows x 16 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 559, number of negative: 3224\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2325\n",
      "[LightGBM] [Info] Number of data points in the train set: 3783, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147766 -> initscore=-1.752229\n",
      "[LightGBM] [Info] Start training from score -1.752229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(scale_pos_weight=8.12093023255814),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.015, 0.016],\n",
       "                         &#x27;max_depth&#x27;: [1, 2],\n",
       "                         &#x27;n_estimators&#x27;: [140, 145, 150, 155]},\n",
       "             refit=&#x27;precision&#x27;, scoring={&#x27;precision&#x27;: &#x27;precision&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(scale_pos_weight=8.12093023255814),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.015, 0.016],\n",
       "                         &#x27;max_depth&#x27;: [1, 2],\n",
       "                         &#x27;n_estimators&#x27;: [140, 145, 150, 155]},\n",
       "             refit=&#x27;precision&#x27;, scoring={&#x27;precision&#x27;: &#x27;precision&#x27;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(scale_pos_weight=8.12093023255814)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(scale_pos_weight=8.12093023255814)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(scale_pos_weight=8.12093023255814),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.015, 0.016],\n",
       "                         'max_depth': [1, 2],\n",
       "                         'n_estimators': [140, 145, 150, 155]},\n",
       "             refit='precision', scoring={'precision': 'precision'})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [140, 145, 150, 155],\n",
    "    'max_depth': [1, 2],\n",
    "    'learning_rate': [0.01, 0.015, 0.016],\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_profit_metric_2(y_true, y_probabilities, dataset, top_k=20):\n",
    "    # Reset indices of the dataset DataFrame\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Convert y_probabilities to a DataFrame and then reset indices\n",
    "    y_probabilities = pd.DataFrame(y_probabilities, columns=['Prob_0', 'Prob_1'])\n",
    "    y_probabilities.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Now concatenate the DataFrames\n",
    "    profit_df = pd.concat([dataset[['average cost min']], y_probabilities, y_true], axis=1)\n",
    "\n",
    "    # Sort concatenated_df by PROB_1 column in descending order\n",
    "    profit_df_sorted = profit_df.sort_values(by='Prob_1', ascending=False)\n",
    "\n",
    "    # Filter the top 20 rows\n",
    "    top_k_rows = profit_df_sorted.head(top_k)\n",
    "\n",
    "    # Filter the top 20 rows where target == 1 (actual churner) and sum the 'average cost min' values\n",
    "    profit_at_top_k = top_k_rows[(top_k_rows[y_true.name] == 1) & (top_k_rows['Prob_1'] > 0.5)]['average cost min'].sum()  \n",
    "    \n",
    "    return profit_at_top_k\n",
    "\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM\n",
    "#lgb_grid_search = GridSearchCV(lgb_classifier, lgb_param_grid, scoring={'profit_at_top_20': profit_at_top_20_scorer}, refit='profit_at_top_20', verbose=0, cv=5, n_jobs=-1)\n",
    "lgb_grid_search = GridSearchCV(lgb_classifier, lgb_param_grid, scoring={'precision': 'precision'}, refit='precision', verbose=0, cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_preprocessed, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=1, n_estimators=140,\n",
       "               scale_pos_weight=8.12093023255814)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=1, n_estimators=140,\n",
       "               scale_pos_weight=8.12093023255814)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, max_depth=1, n_estimators=140,\n",
       "               scale_pos_weight=8.12093023255814)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_grid_search.best_estimator_ #has the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.7613562876227606\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", lgb_grid_search.best_score_)\n",
    "print(\"Best Parameters:\", lgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 559, number of negative: 3224\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2325\n",
      "[LightGBM] [Info] Number of data points in the train set: 3783, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147766 -> initscore=-1.752229\n",
      "[LightGBM] [Info] Start training from score -1.752229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=1, n_estimators=140,\n",
       "               scale_pos_weight=8.12093023255814)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=1, n_estimators=140,\n",
       "               scale_pos_weight=8.12093023255814)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, max_depth=1, n_estimators=140,\n",
       "               scale_pos_weight=8.12093023255814)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_preprocessed, y_train_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the validation set IPV FIT_TRANSFORM GWN TRANSFORM BC INFO VAN TRAINING SET\n",
    "X_valid_preprocessed = preprocessing_pipeline.transform(X_valid_split)\n",
    "\n",
    "pred = best_lgb_model.predict(X_valid_preprocessed)\n",
    "\n",
    "# Evaluate on the validation set for LightGBM\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for LightGBM on Validation Set: 0.8401325331332834\n",
      "Profit @ Top-20 for LightGBM on Validation Set: 3.0505089999999995\n",
      "Profit @ Top-20 for LightGBM on Validation Set (THIS ONE IS MORE CORRECT: 2.573963\n",
      "because models that differ in the 1st profit metric but not in the 2nd get the same score on the leaderboard!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8264462809917356"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "# Calculate profit metric\n",
    "profit_metric = calculate_profit_metric(y_valid_probabilities_lgb, X_valid_split)\n",
    "\n",
    "profit_metric2 = calculate_profit_metric_2(y_valid_split, y_valid_probabilities_lgb, X_valid_split, top_k=20)\n",
    "\n",
    "print(f'AUC for LightGBM on Validation Set: {auc_score_lgb}')\n",
    "print(f'Profit @ Top-20 for LightGBM on Validation Set: {profit_metric}')\n",
    "print(f'Profit @ Top-20 for LightGBM on Validation Set (THIS ONE IS MORE CORRECT: {profit_metric2}')\n",
    "print(f'because models that differ in the 1st profit metric but not in the 2nd get the same score on the leaderboard!')\n",
    "\n",
    "pred = best_lgb_model.predict(X_valid_preprocessed)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_true=y_valid_split, y_pred=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LightGBM: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters for LightGBM\n",
    "best_hyperparameters_LGB = lgb_grid_search.best_params_\n",
    "print(f'Best Hyperparameters for LightGBM: {best_hyperparameters_LGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.545752</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.545752</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.545752</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.545752</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.545752</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_0    PROB_1\n",
       "0     K751808  0.815824  0.184176\n",
       "1     K837351  0.545752  0.454248\n",
       "2     K548114  0.815824  0.184176\n",
       "3     K736156  0.815824  0.184176\n",
       "4     K508080  0.815824  0.184176\n",
       "...       ...       ...       ...\n",
       "1677  K588314  0.545752  0.454248\n",
       "1678  K826807  0.545752  0.454248\n",
       "1679  K982731  0.545752  0.454248\n",
       "1680  K623037  0.545752  0.454248\n",
       "1681  K883413  0.815824  0.184176\n",
       "\n",
       "[1682 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing pipeline to the validation set\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "# Evaluate on the test set for LightGBM\n",
    "y_test_probabilities_lgb = best_lgb_model.predict_proba(X_test_preprocessed)\n",
    "y_test_probabilities_lgb = pd.DataFrame(y_test_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "y_test_probabilities_lgb_with_id = pd.concat([data_test['id'], y_test_probabilities_lgb], axis=1)\n",
    "y_test_probabilities_lgb_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LGB = y_test_probabilities_lgb_with_id.iloc[:, [0, 2]]\n",
    "result_LGB.to_csv('result_LGB_12.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.454248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.184176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_1\n",
       "0     K751808  0.184176\n",
       "1     K837351  0.454248\n",
       "2     K548114  0.184176\n",
       "3     K736156  0.184176\n",
       "4     K508080  0.184176\n",
       "...       ...       ...\n",
       "1677  K588314  0.454248\n",
       "1678  K826807  0.454248\n",
       "1679  K982731  0.454248\n",
       "1680  K623037  0.454248\n",
       "1681  K883413  0.184176\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred = best_lgb_model.predict(X_valid_preprocessed)\n",
    "# Set the printing options to display all elements of the array\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Print the entire array of predictions\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_lgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_valid_probabilities_lgb \u001b[38;5;241m=\u001b[39m \u001b[43mbest_lgb_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid_preprocessed)\n\u001b[0;32m      2\u001b[0m y_valid_probabilities_lgb \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(y_valid_probabilities_lgb, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROB_0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROB_1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m X_valid_split\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_lgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_preprocessed)\n",
    "y_valid_probabilities_lgb = pd.DataFrame(y_valid_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "\n",
    "X_valid_split.reset_index(drop=True, inplace=True)\n",
    "y_valid_probabilities_lgb.reset_index(drop=True, inplace=True)\n",
    "y_valid_split.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Now concatenate the DataFrames\n",
    "concatenated_df = pd.concat([X_valid_split[['id', 'average cost min']], y_valid_probabilities_lgb, y_valid_split], axis=1)\n",
    "\n",
    "# Sort concatenated_df by PROB_1 column in descending order\n",
    "concatenated_df_sorted = concatenated_df.sort_values(by='PROB_1', ascending=False)\n",
    "\n",
    "# Filter the top 20 rows\n",
    "top_20 = concatenated_df_sorted.head(30)\n",
    "\n",
    "# Filter the top 20 rows where target == 0 and sum the 'average cost min' values\n",
    "sum_average_cost_min = top_20[(top_20['target'] == 1) & (top_20['PROB_1'] > 0.5)]['average cost min'].sum()\n",
    "\n",
    "print(\"Sum of the first 20 'average cost min' values where target=1:\", sum_average_cost_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>K290350</td>\n",
       "      <td>0.173851</td>\n",
       "      <td>0.271606</td>\n",
       "      <td>0.728394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>K347180</td>\n",
       "      <td>0.169780</td>\n",
       "      <td>0.271606</td>\n",
       "      <td>0.728394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>K349750</td>\n",
       "      <td>0.175370</td>\n",
       "      <td>0.271606</td>\n",
       "      <td>0.728394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>K381140</td>\n",
       "      <td>0.130899</td>\n",
       "      <td>0.271606</td>\n",
       "      <td>0.728394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>K298460</td>\n",
       "      <td>0.185948</td>\n",
       "      <td>0.271606</td>\n",
       "      <td>0.728394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>K146560</td>\n",
       "      <td>0.161412</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>K164590</td>\n",
       "      <td>0.101634</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>K278840</td>\n",
       "      <td>0.147004</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>K319530</td>\n",
       "      <td>0.125350</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>K139920</td>\n",
       "      <td>0.134705</td>\n",
       "      <td>0.815824</td>\n",
       "      <td>0.184176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1261 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  average cost min    PROB_0    PROB_1  target\n",
       "1260  K290350          0.173851  0.271606  0.728394       1\n",
       "380   K347180          0.169780  0.271606  0.728394       1\n",
       "284   K349750          0.175370  0.271606  0.728394       1\n",
       "288   K381140          0.130899  0.271606  0.728394       0\n",
       "299   K298460          0.185948  0.271606  0.728394       0\n",
       "...       ...               ...       ...       ...     ...\n",
       "594   K146560          0.161412  0.815824  0.184176       0\n",
       "597   K164590          0.101634  0.815824  0.184176       0\n",
       "598   K278840          0.147004  0.815824  0.184176       0\n",
       "601   K319530          0.125350  0.815824  0.184176       0\n",
       "630   K139920          0.134705  0.815824  0.184176       0\n",
       "\n",
       "[1261 rows x 5 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
