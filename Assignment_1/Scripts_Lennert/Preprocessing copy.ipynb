{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import WOEEncoder \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BayesSearchCV uses Bayesian optimization techniques to search for the best hyperparameters.\n",
    "It employs a probabilistic model to approximate the objective function (model performance) and decides the next set of hyperparameters to evaluate based on this approximation.\n",
    "Unlike GridSearchCV, it does not search through all possible combinations of hyperparameters. Instead, it iteratively selects the most promising set of hyperparameters based on the model's performance observed so far.\n",
    "Bayesian optimization tends to be more efficient in finding good hyperparameters compared to grid search, especially for high-dimensional or continuous hyperparameter spaces.\n",
    "\n",
    "In summary, while GridSearchCV performs an exhaustive search over a predefined grid of hyperparameters, BayesSearchCV uses Bayesian optimization to efficiently explore the hyperparameter space and find promising configurations. BayesSearchCV is often preferred when dealing with complex or high-dimensional hyperparameter spaces where an exhaustive search becomes impractical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../datasets/train.csv')\n",
    "data_test = pd.read_csv('../datasets/test.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **missing for now: outlier detection**\n",
    "### **also look into this encoder for categorical variables: from category_encoders.cat_boost import CatBoostEncoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests, being an ensemble of decision trees, are generally not sensitive to the scale of numeric features. The reason is that decision trees make splits based on feature values but do not rely on the absolute scale of those values. Therefore, in many cases, scaling is not a strict requirement when using Random Forests. --> no standardization for now so we keep interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- we get (1) a labeled dataset (train.csv) and (2) an unlabeled dataset (test.csv)\n",
    "- split train.csv into a train and test set\n",
    "- that train set, u should split into train and validation sets (stratified CV split because imbalance)\n",
    "- that test set has labels, so u can compare the predictions on X_test, y_test with the labels to evaluate performance of the different models **NOTE: to fit a model on the test set that is coming from train.csv, u need to pass the tuned values of the hyperparameters (tuned on the validation set)**\n",
    "- choose the best performing model \n",
    "- then make predictions on test.csv (unlabeled) and export to a csv file which you upload to the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " note: after finding the optimal parameters, put the values in the pipeline (paramters of RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas \n",
    "- change objective function? to account for top 20 evaluation metric?\n",
    "- use proftree? proflogit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Missing Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dropped_calls_ratio</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Usage_Band</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>call_cost_per_min</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name  Missing Count\n",
       "22  Dropped_calls_ratio              4\n",
       "23           Usage_Band              4\n",
       "25    call_cost_per_min              4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training data\n",
    "missing_count = data_train.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with Missing Values in training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>F</td>\n",
       "      <td>48.0</td>\n",
       "      <td>26/07/98</td>\n",
       "      <td>26.966667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>K244380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22/03/97</td>\n",
       "      <td>43.333333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>K244320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>03/01/96</td>\n",
       "      <td>58.133333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>CAS30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>K213590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>08/08/98</td>\n",
       "      <td>26.533333</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>CAS30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.94</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>K212820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "1736      F  48.0     26/07/98  26.966667            2.0  Play 100   BS110   \n",
       "3237      F  34.0     22/03/97  43.333333            2.0  Play 100   BS110   \n",
       "3836      M  21.0     03/01/96  58.133333            2.0  Play 100   CAS30   \n",
       "4301      F  22.0     08/08/98  26.533333            5.0  Play 100   CAS30   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "1736             0.0            0.0                0.0               0.0   \n",
       "3237             0.0            0.0                0.0               0.0   \n",
       "3836             0.0            0.0                0.0               0.0   \n",
       "4301             0.0            0.0                0.0               0.0   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "1736                0.0               0.0                     0.0   \n",
       "3237                0.0               0.0                     0.0   \n",
       "3836                0.0               0.0                     0.0   \n",
       "4301                0.0               0.0                     0.0   \n",
       "\n",
       "      Nat_call_cost_Sum  AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "1736                0.0      0.0         0.0         0.0             0.0   \n",
       "3237                0.0      0.0         0.0         0.0             0.0   \n",
       "3836                0.0      0.0         0.0         0.0             0.0   \n",
       "4301                0.0      0.0         0.0         0.0             0.0   \n",
       "\n",
       "      National mins  AveNational  All_calls_mins  Dropped_calls_ratio  \\\n",
       "1736            0.0          0.0             0.0                  NaN   \n",
       "3237            0.0          0.0             0.0                  NaN   \n",
       "3836            0.0          0.0             0.0                  NaN   \n",
       "4301            0.0          0.0             0.0                  NaN   \n",
       "\n",
       "     Usage_Band  Mins_charge  call_cost_per_min  actual call cost  \\\n",
       "1736        NaN       -600.0                NaN               0.0   \n",
       "3237        NaN       -600.0                NaN               0.0   \n",
       "3836        NaN       -600.0                NaN               0.0   \n",
       "4301        NaN       -600.0                NaN               0.0   \n",
       "\n",
       "      Total_call_cost  Total_Cost Tariff_OK  average cost min  Peak ratio  \\\n",
       "1736              0.0       59.94        OK               0.5         0.0   \n",
       "3237              0.0       59.94        OK               0.5         0.0   \n",
       "3836              0.0       59.94        OK               0.5         0.0   \n",
       "4301              0.0       59.94        OK               0.5         0.0   \n",
       "\n",
       "      OffPeak ratio  Weekend ratio  Nat-InterNat Ratio high Dropped calls  \\\n",
       "1736            0.0            0.0                 0.0                  F   \n",
       "3237            0.0            0.0                 0.0                  F   \n",
       "3836            0.0            0.0                 0.0                  F   \n",
       "4301            0.0            0.0                 0.0                  F   \n",
       "\n",
       "     No Usage  target       id  \n",
       "1736        T       0  K244380  \n",
       "3237        T       0  K244320  \n",
       "3836        T       1  K213590  \n",
       "4301        T       1  K212820  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values_train = data_train[data_train.isnull().any(axis=1)]\n",
    "print(\"Rows with Missing Values in training data:\")\n",
    "rows_with_missing_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Missing Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dropped_calls_ratio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Usage_Band</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>call_cost_per_min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name  Missing Count\n",
       "22  Dropped_calls_ratio              1\n",
       "23           Usage_Band              1\n",
       "25    call_cost_per_min              1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data\n",
    "missing_count = data_test.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows with Missing Values in test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>F</td>\n",
       "      <td>34.0</td>\n",
       "      <td>07/09/98</td>\n",
       "      <td>24.858347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS110</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.092169</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.29251</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.12627</td>\n",
       "      <td>-3.215572</td>\n",
       "      <td>-5.011147</td>\n",
       "      <td>3.519628</td>\n",
       "      <td>2.912569</td>\n",
       "      <td>0.27729</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-2.090036</td>\n",
       "      <td>-0.10749</td>\n",
       "      <td>-20.274408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-599.241325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.291928</td>\n",
       "      <td>-2.74686</td>\n",
       "      <td>66.563274</td>\n",
       "      <td>OK</td>\n",
       "      <td>0.510543</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>-0.017429</td>\n",
       "      <td>-0.003596</td>\n",
       "      <td>-0.004193</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>K689673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender   Age Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "1389      F  34.0     07/09/98  24.858347            2.0  Play 100   BS110   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "1389             7.0       0.092169                2.0          12.29251   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "1389                2.0          -3.12627               -3.215572   \n",
       "\n",
       "      Nat_call_cost_Sum   AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "1389          -5.011147  3.519628    2.912569     0.27729           -22.0   \n",
       "\n",
       "      National mins  AveNational  All_calls_mins  Dropped_calls_ratio  \\\n",
       "1389      -2.090036     -0.10749      -20.274408                  NaN   \n",
       "\n",
       "     Usage_Band  Mins_charge  call_cost_per_min  actual call cost  \\\n",
       "1389        NaN  -599.241325                NaN         -3.291928   \n",
       "\n",
       "      Total_call_cost  Total_Cost Tariff_OK  average cost min  Peak ratio  \\\n",
       "1389         -2.74686   66.563274        OK          0.510543    0.001085   \n",
       "\n",
       "      OffPeak ratio  Weekend ratio  Nat-InterNat Ratio high Dropped calls  \\\n",
       "1389      -0.017429      -0.003596           -0.004193                  F   \n",
       "\n",
       "     No Usage       id  \n",
       "1389        T  K689673  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_missing_values_test = data_test[data_test.isnull().any(axis=1)]\n",
    "print(\"\\nRows with Missing Values in test data:\")\n",
    "rows_with_missing_values_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we will impute this since it's so little rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'target'\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = data_train.drop(target_column, axis=1)\n",
    "y_train = data_train[target_column]\n",
    "\n",
    "X_test = data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't know if this should be done after splitting or not -- still need to change this so that test uses the same day 1 as train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date_column(data, date_column):\n",
    "    # Convert the date column to datetime format\n",
    "    data[date_column] = pd.to_datetime(data[date_column], format='%d/%m/%y')\n",
    "\n",
    "    # Find the earliest date\n",
    "    earliest_date = data[date_column].min()\n",
    "\n",
    "    # Convert the date column to days since the earliest date\n",
    "    data[date_column] = (data[date_column] - earliest_date).dt.days\n",
    "\n",
    "    return data\n",
    "\n",
    "X_train = process_date_column(X_train, 'Connect_Date')\n",
    "X_test = process_date_column(X_test, 'Connect_Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target variable is binary and imbalanced (with the minority class having a frequency of 15%), so using a stratified splitting approach is recommended to ensure that both the training and validation sets have a similar distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, valid_index in stratified_splitter.split(X_train, y_train):\n",
    "    X_train_split, X_valid_split = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_split, y_valid_split = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    # Now you can use X_train_split, y_train_split for training and X_valid_split, y_valid_split for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Distribution: 80.02% (4036 rows)\n",
      "Validation Set Distribution: 19.98% (1008 rows)\n"
     ]
    }
   ],
   "source": [
    "total_train_samples = X_train_split.shape[0] + X_valid_split.shape[0]\n",
    "train_distribution_percentage = (X_train_split.shape[0]/ total_train_samples) * 100\n",
    "validation_distribution_percentage = (X_valid_split.shape[0] / total_train_samples) * 100\n",
    "\n",
    "print(f\"Training Set Distribution: {train_distribution_percentage:.2f}% ({X_train_split.shape[0]} rows)\")\n",
    "print(f\"Validation Set Distribution: {validation_distribution_percentage:.2f}% ({X_valid_split.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenne\\AppData\\Local\\Temp\\ipykernel_10512\\328505691.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_split['Tariff_OK'] = np.where(X_train_split['Tariff_OK'] == 'OK', 1, 0)\n",
      "C:\\Users\\lenne\\AppData\\Local\\Temp\\ipykernel_10512\\328505691.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_valid_split['Tariff_OK'] = np.where(X_valid_split['Tariff_OK'] == 'OK', 1, 0)\n"
     ]
    }
   ],
   "source": [
    "X_train_split['Tariff_OK'] = np.where(X_train_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_valid_split['Tariff_OK'] = np.where(X_valid_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_test['Tariff_OK'] = np.where(X_test['Tariff_OK'] == 'OK', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>870</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS210</td>\n",
       "      <td>62.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>185.0</td>\n",
       "      <td>438.600001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>126.002615</td>\n",
       "      <td>2.045727</td>\n",
       "      <td>2.467742</td>\n",
       "      <td>2.370811</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>251.0</td>\n",
       "      <td>620.600001</td>\n",
       "      <td>2.472510</td>\n",
       "      <td>746.602616</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>Med</td>\n",
       "      <td>20.600001</td>\n",
       "      <td>9.930712</td>\n",
       "      <td>2.045727</td>\n",
       "      <td>52.446773</td>\n",
       "      <td>112.386773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150531</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.706735</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.203034</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K262360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25.0</td>\n",
       "      <td>350</td>\n",
       "      <td>46.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 100</td>\n",
       "      <td>ASAD90</td>\n",
       "      <td>146.0</td>\n",
       "      <td>718.800000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>164.700000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>251.580636</td>\n",
       "      <td>41.072379</td>\n",
       "      <td>4.923288</td>\n",
       "      <td>1.680612</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>248.0</td>\n",
       "      <td>920.700000</td>\n",
       "      <td>3.712500</td>\n",
       "      <td>1172.280636</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>Med</td>\n",
       "      <td>320.700000</td>\n",
       "      <td>12.807103</td>\n",
       "      <td>41.072380</td>\n",
       "      <td>116.546571</td>\n",
       "      <td>221.546571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188988</td>\n",
       "      <td>0.780710</td>\n",
       "      <td>0.178886</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.273249</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K170160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>59.0</td>\n",
       "      <td>924</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 50</td>\n",
       "      <td>BS110</td>\n",
       "      <td>84.0</td>\n",
       "      <td>317.400001</td>\n",
       "      <td>57.0</td>\n",
       "      <td>161.699999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.998036</td>\n",
       "      <td>20.950771</td>\n",
       "      <td>3.778571</td>\n",
       "      <td>2.836842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>479.100000</td>\n",
       "      <td>3.397872</td>\n",
       "      <td>503.098036</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>MedLow</td>\n",
       "      <td>179.100000</td>\n",
       "      <td>11.624922</td>\n",
       "      <td>20.820235</td>\n",
       "      <td>28.019646</td>\n",
       "      <td>111.419646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221467</td>\n",
       "      <td>0.662492</td>\n",
       "      <td>0.337508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050090</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K332460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>21.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Play 300</td>\n",
       "      <td>WC95</td>\n",
       "      <td>14.0</td>\n",
       "      <td>309.600000</td>\n",
       "      <td>326.0</td>\n",
       "      <td>637.800000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>87.051515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.114286</td>\n",
       "      <td>1.956442</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>346.0</td>\n",
       "      <td>961.800000</td>\n",
       "      <td>2.779769</td>\n",
       "      <td>1048.851515</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>Med</td>\n",
       "      <td>-838.200000</td>\n",
       "      <td>9.403618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.820606</td>\n",
       "      <td>112.760606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107509</td>\n",
       "      <td>0.321896</td>\n",
       "      <td>0.663132</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K394220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>27.0</td>\n",
       "      <td>579</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CAT 100</td>\n",
       "      <td>S50</td>\n",
       "      <td>170.0</td>\n",
       "      <td>414.600001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342.300000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.399999</td>\n",
       "      <td>33.928464</td>\n",
       "      <td>19.946237</td>\n",
       "      <td>2.438824</td>\n",
       "      <td>171.150000</td>\n",
       "      <td>1.828571</td>\n",
       "      <td>193.0</td>\n",
       "      <td>795.300000</td>\n",
       "      <td>4.120725</td>\n",
       "      <td>829.228464</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>Med</td>\n",
       "      <td>195.300000</td>\n",
       "      <td>10.213127</td>\n",
       "      <td>19.946237</td>\n",
       "      <td>30.124776</td>\n",
       "      <td>135.124776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162952</td>\n",
       "      <td>0.521313</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.048284</td>\n",
       "      <td>0.042661</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K286620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender   Age  Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "0      F  50.0           870  29.200000            2.0  Play 100   BS210   \n",
       "1      M  25.0           350  46.533333            1.0   CAT 100  ASAD90   \n",
       "3      F  59.0           924  27.400000            1.0    CAT 50   BS110   \n",
       "4      F  25.0          1103  21.433333            1.0  Play 300    WC95   \n",
       "5      M  27.0           579  38.900000            8.0   CAT 100     S50   \n",
       "\n",
       "   Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "0            62.0     153.000000              185.0        438.600001   \n",
       "1           146.0     718.800000               98.0        164.700000   \n",
       "3            84.0     317.400001               57.0        161.699999   \n",
       "4            14.0     309.600000              326.0        637.800000   \n",
       "5           170.0     414.600001                2.0        342.300000   \n",
       "\n",
       "   Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "0                4.0         29.000000              126.002615   \n",
       "1                4.0         37.200000              251.580636   \n",
       "3                0.0          0.000000               23.998036   \n",
       "4                6.0         14.400000               87.051515   \n",
       "5               21.0         38.399999               33.928464   \n",
       "\n",
       "   Nat_call_cost_Sum    AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "0           2.045727   2.467742    2.370811    7.250000           251.0   \n",
       "1          41.072379   4.923288    1.680612    9.300000           248.0   \n",
       "3          20.950771   3.778571    2.836842    0.000000           141.0   \n",
       "4           0.000000  22.114286    1.956442    2.400000           346.0   \n",
       "5          19.946237   2.438824  171.150000    1.828571           193.0   \n",
       "\n",
       "   National mins  AveNational  All_calls_mins  Dropped_calls_ratio Usage_Band  \\\n",
       "0     620.600001     2.472510      746.602616             0.003984        Med   \n",
       "1     920.700000     3.712500     1172.280636             0.002016        Med   \n",
       "3     479.100000     3.397872      503.098036             0.003546     MedLow   \n",
       "4     961.800000     2.779769     1048.851515             0.001445        Med   \n",
       "5     795.300000     4.120725      829.228464             0.020725        Med   \n",
       "\n",
       "   Mins_charge  call_cost_per_min  actual call cost  Total_call_cost  \\\n",
       "0    20.600001           9.930712          2.045727        52.446773   \n",
       "1   320.700000          12.807103         41.072380       116.546571   \n",
       "3   179.100000          11.624922         20.820235        28.019646   \n",
       "4  -838.200000           9.403618          0.000000        34.820606   \n",
       "5   195.300000          10.213127         19.946237        30.124776   \n",
       "\n",
       "   Total_Cost  Tariff_OK  average cost min  Peak ratio  OffPeak ratio  \\\n",
       "0  112.386773          1          0.150531    0.246536       0.706735   \n",
       "1  221.546571          1          0.188988    0.780710       0.178886   \n",
       "3  111.419646          1          0.221467    0.662492       0.337508   \n",
       "4  112.760606          1          0.107509    0.321896       0.663132   \n",
       "5  135.124776          1          0.162952    0.521313       0.430404   \n",
       "\n",
       "   Weekend ratio  Nat-InterNat Ratio high Dropped calls No Usage       id  \n",
       "0       0.046729            0.203034                  F        F  K262360  \n",
       "1       0.040404            0.273249                  F        F  K170160  \n",
       "3       0.000000            0.050090                  F        F  K332460  \n",
       "4       0.014972            0.090509                  F        F  K394220  \n",
       "5       0.048284            0.042661                  F        F  K286620  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to remove prefix from column names\n",
    "class RemovePrefixTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, prefixes):\n",
    "        self.prefixes = prefixes\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for prefix in self.prefixes:\n",
    "            X.columns = [col.split(f'{prefix}__')[1] if f'{prefix}__' in col else col for col in X.columns]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Med' 'MedLow' 'MedHigh' 'Low' 'High' nan]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_split['Usage_Band'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can handle them explicitly before preprocessing, for example, by replacing them with the most frequent category using fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Med' 'MedLow' 'MedHigh' 'Low' 'High']\n"
     ]
    }
   ],
   "source": [
    "X_train_split = X_train_split.copy()\n",
    "X_train_split['Usage_Band'] = X_train_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_train_split['Usage_Band'].unique())\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_train_split['Dropped_calls_ratio'] = X_train_split['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_train_split['call_cost_per_min'] = X_train_split['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_split = y_train_split.fillna(y_train_split.mode()[0])\n",
    "y_valid_split = y_valid_split.fillna(y_train_split.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_split = X_valid_split.copy()\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_valid_split['Dropped_calls_ratio'] = X_valid_split['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_valid_split['call_cost_per_min'] = X_valid_split['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())\n",
    "\n",
    "# Handle missing values in 'Usage_Band' for X_validation_split\n",
    "X_valid_split['Usage_Band'] = X_valid_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedHigh' 'Med' 'High' 'MedLow' 'Low']\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.copy()\n",
    "X_test['Usage_Band'] = X_test['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_test['Usage_Band'].unique())\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_test['Dropped_calls_ratio'] = X_test['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_test['call_cost_per_min'] = X_test['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "      <th>high Dropped calls</th>\n",
       "      <th>No Usage</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>870</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Play 100</td>\n",
       "      <td>BS210</td>\n",
       "      <td>62.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>185.0</td>\n",
       "      <td>438.600001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>126.002615</td>\n",
       "      <td>2.045727</td>\n",
       "      <td>2.467742</td>\n",
       "      <td>2.370811</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>251.0</td>\n",
       "      <td>620.600001</td>\n",
       "      <td>2.472510</td>\n",
       "      <td>746.602616</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>Med</td>\n",
       "      <td>20.600001</td>\n",
       "      <td>9.930712</td>\n",
       "      <td>2.045727</td>\n",
       "      <td>52.446773</td>\n",
       "      <td>112.386773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150531</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.706735</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.203034</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K262360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>25.0</td>\n",
       "      <td>350</td>\n",
       "      <td>46.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 100</td>\n",
       "      <td>ASAD90</td>\n",
       "      <td>146.0</td>\n",
       "      <td>718.800000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>164.700000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>251.580636</td>\n",
       "      <td>41.072379</td>\n",
       "      <td>4.923288</td>\n",
       "      <td>1.680612</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>248.0</td>\n",
       "      <td>920.700000</td>\n",
       "      <td>3.712500</td>\n",
       "      <td>1172.280636</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>Med</td>\n",
       "      <td>320.700000</td>\n",
       "      <td>12.807103</td>\n",
       "      <td>41.072380</td>\n",
       "      <td>116.546571</td>\n",
       "      <td>221.546571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188988</td>\n",
       "      <td>0.780710</td>\n",
       "      <td>0.178886</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.273249</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K170160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>59.0</td>\n",
       "      <td>924</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CAT 50</td>\n",
       "      <td>BS110</td>\n",
       "      <td>84.0</td>\n",
       "      <td>317.400001</td>\n",
       "      <td>57.0</td>\n",
       "      <td>161.699999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.998036</td>\n",
       "      <td>20.950771</td>\n",
       "      <td>3.778571</td>\n",
       "      <td>2.836842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>479.100000</td>\n",
       "      <td>3.397872</td>\n",
       "      <td>503.098036</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>MedLow</td>\n",
       "      <td>179.100000</td>\n",
       "      <td>11.624922</td>\n",
       "      <td>20.820235</td>\n",
       "      <td>28.019646</td>\n",
       "      <td>111.419646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221467</td>\n",
       "      <td>0.662492</td>\n",
       "      <td>0.337508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050090</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K332460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>21.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Play 300</td>\n",
       "      <td>WC95</td>\n",
       "      <td>14.0</td>\n",
       "      <td>309.600000</td>\n",
       "      <td>326.0</td>\n",
       "      <td>637.800000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>87.051515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.114286</td>\n",
       "      <td>1.956442</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>346.0</td>\n",
       "      <td>961.800000</td>\n",
       "      <td>2.779769</td>\n",
       "      <td>1048.851515</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>Med</td>\n",
       "      <td>-838.200000</td>\n",
       "      <td>9.403618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.820606</td>\n",
       "      <td>112.760606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107509</td>\n",
       "      <td>0.321896</td>\n",
       "      <td>0.663132</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.090509</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K394220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>27.0</td>\n",
       "      <td>579</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>CAT 100</td>\n",
       "      <td>S50</td>\n",
       "      <td>170.0</td>\n",
       "      <td>414.600001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342.300000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.399999</td>\n",
       "      <td>33.928464</td>\n",
       "      <td>19.946237</td>\n",
       "      <td>2.438824</td>\n",
       "      <td>171.150000</td>\n",
       "      <td>1.828571</td>\n",
       "      <td>193.0</td>\n",
       "      <td>795.300000</td>\n",
       "      <td>4.120725</td>\n",
       "      <td>829.228464</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>Med</td>\n",
       "      <td>195.300000</td>\n",
       "      <td>10.213127</td>\n",
       "      <td>19.946237</td>\n",
       "      <td>30.124776</td>\n",
       "      <td>135.124776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162952</td>\n",
       "      <td>0.521313</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.048284</td>\n",
       "      <td>0.042661</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>K286620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender   Age  Connect_Date      L_O_S  Dropped_Calls    tariff Handset  \\\n",
       "0      F  50.0           870  29.200000            2.0  Play 100   BS210   \n",
       "1      M  25.0           350  46.533333            1.0   CAT 100  ASAD90   \n",
       "3      F  59.0           924  27.400000            1.0    CAT 50   BS110   \n",
       "4      F  25.0          1103  21.433333            1.0  Play 300    WC95   \n",
       "5      M  27.0           579  38.900000            8.0   CAT 100     S50   \n",
       "\n",
       "   Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "0            62.0     153.000000              185.0        438.600001   \n",
       "1           146.0     718.800000               98.0        164.700000   \n",
       "3            84.0     317.400001               57.0        161.699999   \n",
       "4            14.0     309.600000              326.0        637.800000   \n",
       "5           170.0     414.600001                2.0        342.300000   \n",
       "\n",
       "   Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "0                4.0         29.000000              126.002615   \n",
       "1                4.0         37.200000              251.580636   \n",
       "3                0.0          0.000000               23.998036   \n",
       "4                6.0         14.400000               87.051515   \n",
       "5               21.0         38.399999               33.928464   \n",
       "\n",
       "   Nat_call_cost_Sum    AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "0           2.045727   2.467742    2.370811    7.250000           251.0   \n",
       "1          41.072379   4.923288    1.680612    9.300000           248.0   \n",
       "3          20.950771   3.778571    2.836842    0.000000           141.0   \n",
       "4           0.000000  22.114286    1.956442    2.400000           346.0   \n",
       "5          19.946237   2.438824  171.150000    1.828571           193.0   \n",
       "\n",
       "   National mins  AveNational  All_calls_mins  Dropped_calls_ratio Usage_Band  \\\n",
       "0     620.600001     2.472510      746.602616             0.003984        Med   \n",
       "1     920.700000     3.712500     1172.280636             0.002016        Med   \n",
       "3     479.100000     3.397872      503.098036             0.003546     MedLow   \n",
       "4     961.800000     2.779769     1048.851515             0.001445        Med   \n",
       "5     795.300000     4.120725      829.228464             0.020725        Med   \n",
       "\n",
       "   Mins_charge  call_cost_per_min  actual call cost  Total_call_cost  \\\n",
       "0    20.600001           9.930712          2.045727        52.446773   \n",
       "1   320.700000          12.807103         41.072380       116.546571   \n",
       "3   179.100000          11.624922         20.820235        28.019646   \n",
       "4  -838.200000           9.403618          0.000000        34.820606   \n",
       "5   195.300000          10.213127         19.946237        30.124776   \n",
       "\n",
       "   Total_Cost  Tariff_OK  average cost min  Peak ratio  OffPeak ratio  \\\n",
       "0  112.386773          1          0.150531    0.246536       0.706735   \n",
       "1  221.546571          1          0.188988    0.780710       0.178886   \n",
       "3  111.419646          1          0.221467    0.662492       0.337508   \n",
       "4  112.760606          1          0.107509    0.321896       0.663132   \n",
       "5  135.124776          1          0.162952    0.521313       0.430404   \n",
       "\n",
       "   Weekend ratio  Nat-InterNat Ratio high Dropped calls No Usage       id  \n",
       "0       0.046729            0.203034                  F        F  K262360  \n",
       "1       0.040404            0.273249                  F        F  K170160  \n",
       "3       0.000000            0.050090                  F        F  K332460  \n",
       "4       0.014972            0.090509                  F        F  K394220  \n",
       "5       0.048284            0.042661                  F        F  K286620  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop\n",
    "columns_to_drop = ['id']  # Drop because it's not numerical, later on add it back to know which prediction corresponds to which individual\n",
    "\n",
    "# Define columns for different encoding methods\n",
    "one_hot_encode_columns = ['Gender', 'high Dropped calls', 'No Usage']\n",
    "woe_encode_columns = ['tariff', 'Handset', 'Usage_Band'] #ipv ordinal endoding\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('one_hot_encode', OneHotEncoder(drop='first', sparse_output=False), one_hot_encode_columns),\n",
    "        ('WOE_encode', WOEEncoder(), woe_encode_columns),\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the remaining columns as they are\n",
    ")\n",
    "\n",
    "# Build the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('remove_prefix', RemovePrefixTransformer(prefixes=['one_hot_encode', 'WOE_encode', 'remainder']))   # Add this step to remove the prefix\n",
    "])\n",
    "\n",
    "lgb_classifier = lgb.LGBMClassifier(is_unbalance=True)\n",
    "#lgb_classifier = lgb.LGBMClassifier(scale_pos_weight=(1 - y_train_split.sum() / len(y_train_split)))\n",
    "\n",
    "lgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', lgb_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "def profit_at_top_20(y_true, y_probabilities, top_k=20):\n",
    "    # Extract probabilities for positive class\n",
    "    churn_probabilities = y_probabilities[:, 1]\n",
    "\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    sorted_indices = sorted(range(len(churn_probabilities)), key=lambda k: churn_probabilities[k], reverse=True)\n",
    "\n",
    "    # Identify the top-20 customers\n",
    "    top_20_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Calculate profit at top-20\n",
    "    profit = sum(y_true[i] * churn_probabilities[i] for i in top_20_indices)\n",
    "\n",
    "    return profit\n",
    "\n",
    "# Define custom scorer for use in GridSearchCV or RandomizedSearchCV\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True)\n",
    "\n",
    "\n",
    "profit = pd.DataFrameFrame(X_train_split[\"average cost min\"])\n",
    "profit.loc[:,]\n",
    "\n",
    "def profit_metric(prob_array, dataset):\n",
    "    X_test_profit = pd.DataFrame(dataset[\"average cost min\"])\n",
    "    X_test_profit.loc[:,\"churn_prob\"] = prob_array\n",
    "    X_test_profit = X_test_profit.sort_values(by='churn_prob', ascending=False)\n",
    "    return X_test_profit[\"average cost min\"][:20].sum()\n",
    "\n",
    "# Define evaluation metrics\n",
    "def profit_at_top_20(y_true, y_pred, top_k=20):\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    sorted_indices = sorted(range(len(y_pred)), key=lambda k: y_pred[k, 1], reverse=True)\n",
    "\n",
    "    # Identify the top-20 customers\n",
    "    top_20_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Calculate profit at top-20\n",
    "    profit = sum(y_true[i] * y_pred[i, 1] for i in top_20_indices)\n",
    "\n",
    "    return profit\n",
    "\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>high Dropped calls_T</th>\n",
       "      <th>No Usage_T</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420413</td>\n",
       "      <td>-1.012710</td>\n",
       "      <td>-0.242724</td>\n",
       "      <td>50.0</td>\n",
       "      <td>870</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>185.0</td>\n",
       "      <td>438.600001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>126.002615</td>\n",
       "      <td>2.045727</td>\n",
       "      <td>2.467742</td>\n",
       "      <td>2.370811</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>251.0</td>\n",
       "      <td>620.600001</td>\n",
       "      <td>2.472510</td>\n",
       "      <td>746.602616</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>20.600001</td>\n",
       "      <td>9.930712</td>\n",
       "      <td>2.045727</td>\n",
       "      <td>52.446773</td>\n",
       "      <td>112.386773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150531</td>\n",
       "      <td>0.246536</td>\n",
       "      <td>0.706735</td>\n",
       "      <td>0.046729</td>\n",
       "      <td>0.203034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137133</td>\n",
       "      <td>2.964342</td>\n",
       "      <td>-0.242724</td>\n",
       "      <td>25.0</td>\n",
       "      <td>350</td>\n",
       "      <td>46.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>718.800000</td>\n",
       "      <td>98.0</td>\n",
       "      <td>164.700000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>251.580636</td>\n",
       "      <td>41.072379</td>\n",
       "      <td>4.923288</td>\n",
       "      <td>1.680612</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>248.0</td>\n",
       "      <td>920.700000</td>\n",
       "      <td>3.712500</td>\n",
       "      <td>1172.280636</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>320.700000</td>\n",
       "      <td>12.807103</td>\n",
       "      <td>41.072380</td>\n",
       "      <td>116.546571</td>\n",
       "      <td>221.546571</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188988</td>\n",
       "      <td>0.780710</td>\n",
       "      <td>0.178886</td>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.273249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.041542</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>0.760057</td>\n",
       "      <td>59.0</td>\n",
       "      <td>924</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>317.400001</td>\n",
       "      <td>57.0</td>\n",
       "      <td>161.699999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.998036</td>\n",
       "      <td>20.950771</td>\n",
       "      <td>3.778571</td>\n",
       "      <td>2.836842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.0</td>\n",
       "      <td>479.100000</td>\n",
       "      <td>3.397872</td>\n",
       "      <td>503.098036</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>179.100000</td>\n",
       "      <td>11.624922</td>\n",
       "      <td>20.820235</td>\n",
       "      <td>28.019646</td>\n",
       "      <td>111.419646</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221467</td>\n",
       "      <td>0.662492</td>\n",
       "      <td>0.337508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.504292</td>\n",
       "      <td>-2.631809</td>\n",
       "      <td>-0.242724</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1103</td>\n",
       "      <td>21.433333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>309.600000</td>\n",
       "      <td>326.0</td>\n",
       "      <td>637.800000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>87.051515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.114286</td>\n",
       "      <td>1.956442</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>346.0</td>\n",
       "      <td>961.800000</td>\n",
       "      <td>2.779769</td>\n",
       "      <td>1048.851515</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>-838.200000</td>\n",
       "      <td>9.403618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.820606</td>\n",
       "      <td>112.760606</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107509</td>\n",
       "      <td>0.321896</td>\n",
       "      <td>0.663132</td>\n",
       "      <td>0.014972</td>\n",
       "      <td>0.090509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137133</td>\n",
       "      <td>-0.111923</td>\n",
       "      <td>-0.242724</td>\n",
       "      <td>27.0</td>\n",
       "      <td>579</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>414.600001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>342.300000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.399999</td>\n",
       "      <td>33.928464</td>\n",
       "      <td>19.946237</td>\n",
       "      <td>2.438824</td>\n",
       "      <td>171.150000</td>\n",
       "      <td>1.828571</td>\n",
       "      <td>193.0</td>\n",
       "      <td>795.300000</td>\n",
       "      <td>4.120725</td>\n",
       "      <td>829.228464</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>195.300000</td>\n",
       "      <td>10.213127</td>\n",
       "      <td>19.946237</td>\n",
       "      <td>30.124776</td>\n",
       "      <td>135.124776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.162952</td>\n",
       "      <td>0.521313</td>\n",
       "      <td>0.430404</td>\n",
       "      <td>0.048284</td>\n",
       "      <td>0.042661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137133</td>\n",
       "      <td>0.026744</td>\n",
       "      <td>-0.242724</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1270</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>721.200000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>75.600001</td>\n",
       "      <td>29.0</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>104.796650</td>\n",
       "      <td>34.346783</td>\n",
       "      <td>27.738462</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>2.034483</td>\n",
       "      <td>69.0</td>\n",
       "      <td>855.800001</td>\n",
       "      <td>12.402899</td>\n",
       "      <td>960.596651</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>255.800001</td>\n",
       "      <td>13.427203</td>\n",
       "      <td>34.346784</td>\n",
       "      <td>65.785779</td>\n",
       "      <td>170.785779</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177791</td>\n",
       "      <td>0.842720</td>\n",
       "      <td>0.088338</td>\n",
       "      <td>0.068941</td>\n",
       "      <td>0.122455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024608</td>\n",
       "      <td>2.964342</td>\n",
       "      <td>-0.021064</td>\n",
       "      <td>16.0</td>\n",
       "      <td>623</td>\n",
       "      <td>37.433333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1169.400001</td>\n",
       "      <td>201.0</td>\n",
       "      <td>657.900000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>71.400001</td>\n",
       "      <td>242.983418</td>\n",
       "      <td>56.451295</td>\n",
       "      <td>7.744371</td>\n",
       "      <td>3.273134</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>386.0</td>\n",
       "      <td>1898.700002</td>\n",
       "      <td>4.918912</td>\n",
       "      <td>2141.683420</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>698.700002</td>\n",
       "      <td>8.079475</td>\n",
       "      <td>56.451295</td>\n",
       "      <td>129.346320</td>\n",
       "      <td>279.346320</td>\n",
       "      <td>1</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>0.615895</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>0.127974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5040</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137133</td>\n",
       "      <td>2.984962</td>\n",
       "      <td>-0.242724</td>\n",
       "      <td>29.0</td>\n",
       "      <td>271</td>\n",
       "      <td>49.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>405.600000</td>\n",
       "      <td>124.0</td>\n",
       "      <td>301.200001</td>\n",
       "      <td>11.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>174.140881</td>\n",
       "      <td>13.703878</td>\n",
       "      <td>3.004444</td>\n",
       "      <td>2.429032</td>\n",
       "      <td>2.090909</td>\n",
       "      <td>270.0</td>\n",
       "      <td>729.800001</td>\n",
       "      <td>2.702963</td>\n",
       "      <td>903.940882</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>129.800001</td>\n",
       "      <td>10.557687</td>\n",
       "      <td>13.703878</td>\n",
       "      <td>65.946142</td>\n",
       "      <td>170.946142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.189112</td>\n",
       "      <td>0.555769</td>\n",
       "      <td>0.412716</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.238615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.420413</td>\n",
       "      <td>-0.111923</td>\n",
       "      <td>0.760057</td>\n",
       "      <td>46.0</td>\n",
       "      <td>790</td>\n",
       "      <td>31.866667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>112.200000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>230.700000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>59.510484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.558333</td>\n",
       "      <td>7.441935</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>105.0</td>\n",
       "      <td>347.100000</td>\n",
       "      <td>3.305714</td>\n",
       "      <td>406.610484</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>-252.900000</td>\n",
       "      <td>11.464996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.804194</td>\n",
       "      <td>83.744194</td>\n",
       "      <td>1</td>\n",
       "      <td>0.205957</td>\n",
       "      <td>0.323250</td>\n",
       "      <td>0.664650</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.171451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5043</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.137133</td>\n",
       "      <td>-0.111923</td>\n",
       "      <td>-0.242724</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1046</td>\n",
       "      <td>23.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>403.200000</td>\n",
       "      <td>187.0</td>\n",
       "      <td>290.700000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.800000</td>\n",
       "      <td>159.824747</td>\n",
       "      <td>13.556153</td>\n",
       "      <td>2.724324</td>\n",
       "      <td>1.554545</td>\n",
       "      <td>1.581818</td>\n",
       "      <td>357.0</td>\n",
       "      <td>728.700000</td>\n",
       "      <td>2.041176</td>\n",
       "      <td>888.524747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.700000</td>\n",
       "      <td>10.533141</td>\n",
       "      <td>13.556153</td>\n",
       "      <td>61.503577</td>\n",
       "      <td>166.503577</td>\n",
       "      <td>1</td>\n",
       "      <td>0.187393</td>\n",
       "      <td>0.553314</td>\n",
       "      <td>0.398930</td>\n",
       "      <td>0.047756</td>\n",
       "      <td>0.219329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4036 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender_M  high Dropped calls_T  No Usage_T    tariff   Handset  \\\n",
       "0          0.0                   0.0         0.0  0.420413 -1.012710   \n",
       "1          1.0                   0.0         0.0 -0.137133  2.964342   \n",
       "3          0.0                   0.0         0.0 -0.041542  0.026744   \n",
       "4          0.0                   0.0         0.0 -0.504292 -2.631809   \n",
       "5          1.0                   0.0         0.0 -0.137133 -0.111923   \n",
       "...        ...                   ...         ...       ...       ...   \n",
       "5038       0.0                   0.0         0.0 -0.137133  0.026744   \n",
       "5039       0.0                   0.0         0.0  0.024608  2.964342   \n",
       "5040       0.0                   0.0         0.0 -0.137133  2.984962   \n",
       "5042       1.0                   0.0         0.0  0.420413 -0.111923   \n",
       "5043       1.0                   0.0         0.0 -0.137133 -0.111923   \n",
       "\n",
       "      Usage_Band   Age  Connect_Date      L_O_S  Dropped_Calls  \\\n",
       "0      -0.242724  50.0           870  29.200000            2.0   \n",
       "1      -0.242724  25.0           350  46.533333            1.0   \n",
       "3       0.760057  59.0           924  27.400000            1.0   \n",
       "4      -0.242724  25.0          1103  21.433333            1.0   \n",
       "5      -0.242724  27.0           579  38.900000            8.0   \n",
       "...          ...   ...           ...        ...            ...   \n",
       "5038   -0.242724  22.0          1270  15.866667            1.0   \n",
       "5039   -0.021064  16.0           623  37.433333            2.0   \n",
       "5040   -0.242724  29.0           271  49.166667            1.0   \n",
       "5042    0.760057  46.0           790  31.866667            2.0   \n",
       "5043   -0.242724  61.0          1046  23.333333            0.0   \n",
       "\n",
       "      Peak_calls_Sum  Peak_mins_Sum  OffPeak_calls_Sum  OffPeak_mins_Sum  \\\n",
       "0               62.0     153.000000              185.0        438.600001   \n",
       "1              146.0     718.800000               98.0        164.700000   \n",
       "3               84.0     317.400001               57.0        161.699999   \n",
       "4               14.0     309.600000              326.0        637.800000   \n",
       "5              170.0     414.600001                2.0        342.300000   \n",
       "...              ...            ...                ...               ...   \n",
       "5038            26.0     721.200000               14.0         75.600001   \n",
       "5039           151.0    1169.400001              201.0        657.900000   \n",
       "5040           135.0     405.600000              124.0        301.200001   \n",
       "5042            72.0     112.200000               31.0        230.700000   \n",
       "5043           148.0     403.200000              187.0        290.700000   \n",
       "\n",
       "      Weekend_calls_Sum  Weekend_mins_Sum  International_mins_Sum  \\\n",
       "0                   4.0         29.000000              126.002615   \n",
       "1                   4.0         37.200000              251.580636   \n",
       "3                   0.0          0.000000               23.998036   \n",
       "4                   6.0         14.400000               87.051515   \n",
       "5                  21.0         38.399999               33.928464   \n",
       "...                 ...               ...                     ...   \n",
       "5038               29.0         59.000000              104.796650   \n",
       "5039               34.0         71.400001              242.983418   \n",
       "5040               11.0         23.000000              174.140881   \n",
       "5042                2.0          4.200000               59.510484   \n",
       "5043               22.0         34.800000              159.824747   \n",
       "\n",
       "      Nat_call_cost_Sum    AvePeak  AveOffPeak  AveWeekend  National_calls  \\\n",
       "0              2.045727   2.467742    2.370811    7.250000           251.0   \n",
       "1             41.072379   4.923288    1.680612    9.300000           248.0   \n",
       "3             20.950771   3.778571    2.836842    0.000000           141.0   \n",
       "4              0.000000  22.114286    1.956442    2.400000           346.0   \n",
       "5             19.946237   2.438824  171.150000    1.828571           193.0   \n",
       "...                 ...        ...         ...         ...             ...   \n",
       "5038          34.346783  27.738462    5.400000    2.034483            69.0   \n",
       "5039          56.451295   7.744371    3.273134    2.100000           386.0   \n",
       "5040          13.703878   3.004444    2.429032    2.090909           270.0   \n",
       "5042           0.000000   1.558333    7.441935    2.100000           105.0   \n",
       "5043          13.556153   2.724324    1.554545    1.581818           357.0   \n",
       "\n",
       "      National mins  AveNational  All_calls_mins  Dropped_calls_ratio  \\\n",
       "0        620.600001     2.472510      746.602616             0.003984   \n",
       "1        920.700000     3.712500     1172.280636             0.002016   \n",
       "3        479.100000     3.397872      503.098036             0.003546   \n",
       "4        961.800000     2.779769     1048.851515             0.001445   \n",
       "5        795.300000     4.120725      829.228464             0.020725   \n",
       "...             ...          ...             ...                  ...   \n",
       "5038     855.800001    12.402899      960.596651             0.007246   \n",
       "5039    1898.700002     4.918912     2141.683420             0.002591   \n",
       "5040     729.800001     2.702963      903.940882             0.001852   \n",
       "5042     347.100000     3.305714      406.610484             0.009524   \n",
       "5043     728.700000     2.041176      888.524747             0.000000   \n",
       "\n",
       "      Mins_charge  call_cost_per_min  actual call cost  Total_call_cost  \\\n",
       "0       20.600001           9.930712          2.045727        52.446773   \n",
       "1      320.700000          12.807103         41.072380       116.546571   \n",
       "3      179.100000          11.624922         20.820235        28.019646   \n",
       "4     -838.200000           9.403618          0.000000        34.820606   \n",
       "5      195.300000          10.213127         19.946237        30.124776   \n",
       "...           ...                ...               ...              ...   \n",
       "5038   255.800001          13.427203         34.346784        65.785779   \n",
       "5039   698.700002           8.079475         56.451295       129.346320   \n",
       "5040   129.800001          10.557687         13.703878        65.946142   \n",
       "5042  -252.900000          11.464996          0.000000        23.804194   \n",
       "5043   128.700000          10.533141         13.556153        61.503577   \n",
       "\n",
       "      Total_Cost  Tariff_OK  average cost min  Peak ratio  OffPeak ratio  \\\n",
       "0     112.386773          1          0.150531    0.246536       0.706735   \n",
       "1     221.546571          1          0.188988    0.780710       0.178886   \n",
       "3     111.419646          1          0.221467    0.662492       0.337508   \n",
       "4     112.760606          1          0.107509    0.321896       0.663132   \n",
       "5     135.124776          1          0.162952    0.521313       0.430404   \n",
       "...          ...        ...               ...         ...            ...   \n",
       "5038  170.785779          1          0.177791    0.842720       0.088338   \n",
       "5039  279.346320          1          0.130433    0.615895       0.346500   \n",
       "5040  170.946142          1          0.189112    0.555769       0.412716   \n",
       "5042   83.744194          1          0.205957    0.323250       0.664650   \n",
       "5043  166.503577          1          0.187393    0.553314       0.398930   \n",
       "\n",
       "      Weekend ratio  Nat-InterNat Ratio  \n",
       "0          0.046729            0.203034  \n",
       "1          0.040404            0.273249  \n",
       "3          0.000000            0.050090  \n",
       "4          0.014972            0.090509  \n",
       "5          0.048284            0.042661  \n",
       "...             ...                 ...  \n",
       "5038       0.068941            0.122455  \n",
       "5039       0.037605            0.127974  \n",
       "5040       0.031515            0.238615  \n",
       "5042       0.012100            0.171451  \n",
       "5043       0.047756            0.219329  \n",
       "\n",
       "[4036 rows x 37 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming X_train_split is your training data\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique data types:\n",
      "[dtype('float64') dtype('int64') dtype('int32')]\n"
     ]
    }
   ],
   "source": [
    "unique_dtypes = X_train_preprocessed.dtypes.unique()\n",
    "print(\"Unique data types:\")\n",
    "print(unique_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>high Dropped calls_T</th>\n",
       "      <th>No Usage_T</th>\n",
       "      <th>tariff</th>\n",
       "      <th>Handset</th>\n",
       "      <th>Usage_Band</th>\n",
       "      <th>Age</th>\n",
       "      <th>Connect_Date</th>\n",
       "      <th>L_O_S</th>\n",
       "      <th>Dropped_Calls</th>\n",
       "      <th>Peak_calls_Sum</th>\n",
       "      <th>Peak_mins_Sum</th>\n",
       "      <th>OffPeak_calls_Sum</th>\n",
       "      <th>OffPeak_mins_Sum</th>\n",
       "      <th>Weekend_calls_Sum</th>\n",
       "      <th>Weekend_mins_Sum</th>\n",
       "      <th>International_mins_Sum</th>\n",
       "      <th>Nat_call_cost_Sum</th>\n",
       "      <th>AvePeak</th>\n",
       "      <th>AveOffPeak</th>\n",
       "      <th>AveWeekend</th>\n",
       "      <th>National_calls</th>\n",
       "      <th>National mins</th>\n",
       "      <th>AveNational</th>\n",
       "      <th>All_calls_mins</th>\n",
       "      <th>Dropped_calls_ratio</th>\n",
       "      <th>Mins_charge</th>\n",
       "      <th>call_cost_per_min</th>\n",
       "      <th>actual call cost</th>\n",
       "      <th>Total_call_cost</th>\n",
       "      <th>Total_Cost</th>\n",
       "      <th>Tariff_OK</th>\n",
       "      <th>average cost min</th>\n",
       "      <th>Peak ratio</th>\n",
       "      <th>OffPeak ratio</th>\n",
       "      <th>Weekend ratio</th>\n",
       "      <th>Nat-InterNat Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Gender_M, high Dropped calls_T, No Usage_T, tariff, Handset, Usage_Band, Age, Connect_Date, L_O_S, Dropped_Calls, Peak_calls_Sum, Peak_mins_Sum, OffPeak_calls_Sum, OffPeak_mins_Sum, Weekend_calls_Sum, Weekend_mins_Sum, International_mins_Sum, Nat_call_cost_Sum, AvePeak, AveOffPeak, AveWeekend, National_calls, National mins, AveNational, All_calls_mins, Dropped_calls_ratio, Mins_charge, call_cost_per_min, actual call cost, Total_call_cost, Total_Cost, Tariff_OK, average cost min, Peak ratio, OffPeak ratio, Weekend ratio, Nat-InterNat Ratio]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows with missing values in the 'Usage_Band' column\n",
    "missing_values = X_train_preprocessed[X_train_preprocessed.isnull().any(axis=1)]\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;, scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;, scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [150, 160, 170, 180, 190, 200]},\n",
       "             refit='auc', scoring={'auc': 'roc_auc'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "\n",
    "lgb_classifier = lgb.LGBMClassifier(is_unbalance=True)\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM\n",
    "lgb_grid_search = GridSearchCV(lgb_classifier, lgb_param_grid, scoring={'auc': 'roc_auc'}, refit='auc', verbose=0, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_preprocessed, y_train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31)\n",
    "\n",
    "is_unbalance=True, learning_rate=0.05, max_depth=4,\n",
    "               n_estimators=160) (verw missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "met nog ordinal zowel als WOE maar using the lgb_pipeline in de grid search ipv enkel het model (dus grid_search.fit op xtrain en ytrain ipv xtrain preprocessed): (is_unbalance=True, learning_rate=0.01, max_depth=1,  n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(is_unbalance=True, learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=170)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=170)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=170)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_grid_search.best_estimator_ #has the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9396228258745358\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 170}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", lgb_grid_search.best_score_)\n",
    "print(\"Best Parameters:\", lgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hieronder overal X_train_split vervangen door X_train_preprocessed als ik approach 1 gebruik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(is_unbalance=True, learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=170)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=170)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, learning_rate=0.05, max_depth=5,\n",
       "               n_estimators=170)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_preprocessed, y_train_split) #X_train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the validation set IPV FIT_TRANSFORM GWN TRANSFORM BC INFO VAN TRAINING SET\n",
    "X_valid_preprocessed = preprocessing_pipeline.transform(X_valid_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1\n",
      " 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = best_lgb_model.predict(X_valid_preprocessed)\n",
    "# Set the printing options to display all elements of the array\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Print the entire array of predictions\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.97818119, 0.02181881],\n",
       "       [0.89001448, 0.10998552],\n",
       "       [0.04952627, 0.95047373],\n",
       "       [0.33700798, 0.66299202],\n",
       "       [0.91310105, 0.08689895],\n",
       "       [0.06294326, 0.93705674],\n",
       "       [0.95516213, 0.04483787],\n",
       "       [0.71387396, 0.28612604],\n",
       "       [0.97816474, 0.02183526],\n",
       "       [0.96121393, 0.03878607],\n",
       "       [0.58278515, 0.41721485],\n",
       "       [0.88065122, 0.11934878],\n",
       "       [0.94239571, 0.05760429],\n",
       "       [0.04938117, 0.95061883],\n",
       "       [0.85672228, 0.14327772],\n",
       "       [0.94807433, 0.05192567],\n",
       "       [0.96327171, 0.03672829],\n",
       "       [0.07634028, 0.92365972],\n",
       "       [0.88851144, 0.11148856],\n",
       "       [0.02878254, 0.97121746],\n",
       "       [0.76060929, 0.23939071],\n",
       "       [0.98094102, 0.01905898],\n",
       "       [0.98017122, 0.01982878],\n",
       "       [0.96347242, 0.03652758],\n",
       "       [0.95182042, 0.04817958],\n",
       "       [0.89640071, 0.10359929],\n",
       "       [0.07166317, 0.92833683],\n",
       "       [0.79551072, 0.20448928],\n",
       "       [0.023897  , 0.976103  ],\n",
       "       [0.97829469, 0.02170531],\n",
       "       [0.86849981, 0.13150019],\n",
       "       [0.97002052, 0.02997948],\n",
       "       [0.97887069, 0.02112931],\n",
       "       [0.09728097, 0.90271903],\n",
       "       [0.98258944, 0.01741056],\n",
       "       [0.90987941, 0.09012059],\n",
       "       [0.96857248, 0.03142752],\n",
       "       [0.86244114, 0.13755886],\n",
       "       [0.73788548, 0.26211452],\n",
       "       [0.95068413, 0.04931587],\n",
       "       [0.16426547, 0.83573453],\n",
       "       [0.80488175, 0.19511825],\n",
       "       [0.87403514, 0.12596486],\n",
       "       [0.28614694, 0.71385306],\n",
       "       [0.8929127 , 0.1070873 ],\n",
       "       [0.96208088, 0.03791912],\n",
       "       [0.97738457, 0.02261543],\n",
       "       [0.07907151, 0.92092849],\n",
       "       [0.04846395, 0.95153605],\n",
       "       [0.84446167, 0.15553833],\n",
       "       [0.98006078, 0.01993922],\n",
       "       [0.98943945, 0.01056055],\n",
       "       [0.96281409, 0.03718591],\n",
       "       [0.95690976, 0.04309024],\n",
       "       [0.88429754, 0.11570246],\n",
       "       [0.95028628, 0.04971372],\n",
       "       [0.22297993, 0.77702007],\n",
       "       [0.59445382, 0.40554618],\n",
       "       [0.93801067, 0.06198933],\n",
       "       [0.94121274, 0.05878726],\n",
       "       [0.93677528, 0.06322472],\n",
       "       [0.96775987, 0.03224013],\n",
       "       [0.03161108, 0.96838892],\n",
       "       [0.99598986, 0.00401014],\n",
       "       [0.02401173, 0.97598827],\n",
       "       [0.89292507, 0.10707493],\n",
       "       [0.9651684 , 0.0348316 ],\n",
       "       [0.13924109, 0.86075891],\n",
       "       [0.95786524, 0.04213476],\n",
       "       [0.02951873, 0.97048127],\n",
       "       [0.90249498, 0.09750502],\n",
       "       [0.04235296, 0.95764704],\n",
       "       [0.56987916, 0.43012084],\n",
       "       [0.94983898, 0.05016102],\n",
       "       [0.99694536, 0.00305464],\n",
       "       [0.94214792, 0.05785208],\n",
       "       [0.96406744, 0.03593256],\n",
       "       [0.97510986, 0.02489014],\n",
       "       [0.9910715 , 0.0089285 ],\n",
       "       [0.9342019 , 0.0657981 ],\n",
       "       [0.91073363, 0.08926637],\n",
       "       [0.10508687, 0.89491313],\n",
       "       [0.97857784, 0.02142216],\n",
       "       [0.94559374, 0.05440626],\n",
       "       [0.9699667 , 0.0300333 ],\n",
       "       [0.06027988, 0.93972012],\n",
       "       [0.88238563, 0.11761437],\n",
       "       [0.90557382, 0.09442618],\n",
       "       [0.91781614, 0.08218386],\n",
       "       [0.34373022, 0.65626978],\n",
       "       [0.97816824, 0.02183176],\n",
       "       [0.13644724, 0.86355276],\n",
       "       [0.93262173, 0.06737827],\n",
       "       [0.83723132, 0.16276868],\n",
       "       [0.85716751, 0.14283249],\n",
       "       [0.98732195, 0.01267805],\n",
       "       [0.99708623, 0.00291377],\n",
       "       [0.93016348, 0.06983652],\n",
       "       [0.6341101 , 0.3658899 ],\n",
       "       [0.98253349, 0.01746651],\n",
       "       [0.99020556, 0.00979444],\n",
       "       [0.07474348, 0.92525652],\n",
       "       [0.6117836 , 0.3882164 ],\n",
       "       [0.91031753, 0.08968247],\n",
       "       [0.95769337, 0.04230663],\n",
       "       [0.95865589, 0.04134411],\n",
       "       [0.07719504, 0.92280496],\n",
       "       [0.92606076, 0.07393924],\n",
       "       [0.83021062, 0.16978938],\n",
       "       [0.52295831, 0.47704169],\n",
       "       [0.91685361, 0.08314639],\n",
       "       [0.90980059, 0.09019941],\n",
       "       [0.96632864, 0.03367136],\n",
       "       [0.7653219 , 0.2346781 ],\n",
       "       [0.98396052, 0.01603948],\n",
       "       [0.97475002, 0.02524998],\n",
       "       [0.91017824, 0.08982176],\n",
       "       [0.97261603, 0.02738397],\n",
       "       [0.95148466, 0.04851534],\n",
       "       [0.88652824, 0.11347176],\n",
       "       [0.91133604, 0.08866396],\n",
       "       [0.16715469, 0.83284531],\n",
       "       [0.95449488, 0.04550512],\n",
       "       [0.46321899, 0.53678101],\n",
       "       [0.89300927, 0.10699073],\n",
       "       [0.14348115, 0.85651885],\n",
       "       [0.79632608, 0.20367392],\n",
       "       [0.97002352, 0.02997648],\n",
       "       [0.08663967, 0.91336033],\n",
       "       [0.80408482, 0.19591518],\n",
       "       [0.8768116 , 0.1231884 ],\n",
       "       [0.17902372, 0.82097628],\n",
       "       [0.03690866, 0.96309134],\n",
       "       [0.96862641, 0.03137359],\n",
       "       [0.88188805, 0.11811195],\n",
       "       [0.96272121, 0.03727879],\n",
       "       [0.98413814, 0.01586186],\n",
       "       [0.94623146, 0.05376854],\n",
       "       [0.98612463, 0.01387537],\n",
       "       [0.0848237 , 0.9151763 ],\n",
       "       [0.99307551, 0.00692449],\n",
       "       [0.08323439, 0.91676561],\n",
       "       [0.95374636, 0.04625364],\n",
       "       [0.0987984 , 0.9012016 ],\n",
       "       [0.99853429, 0.00146571],\n",
       "       [0.44465861, 0.55534139],\n",
       "       [0.89609819, 0.10390181],\n",
       "       [0.9738429 , 0.0261571 ],\n",
       "       [0.96019235, 0.03980765],\n",
       "       [0.97600582, 0.02399418],\n",
       "       [0.87236998, 0.12763002],\n",
       "       [0.74506256, 0.25493744],\n",
       "       [0.13149294, 0.86850706],\n",
       "       [0.96531192, 0.03468808],\n",
       "       [0.77688092, 0.22311908],\n",
       "       [0.09093861, 0.90906139],\n",
       "       [0.94406274, 0.05593726],\n",
       "       [0.95944769, 0.04055231],\n",
       "       [0.93779805, 0.06220195],\n",
       "       [0.04588375, 0.95411625],\n",
       "       [0.96008414, 0.03991586],\n",
       "       [0.90351594, 0.09648406],\n",
       "       [0.65173723, 0.34826277],\n",
       "       [0.8702518 , 0.1297482 ],\n",
       "       [0.02859292, 0.97140708],\n",
       "       [0.07572532, 0.92427468],\n",
       "       [0.88972661, 0.11027339],\n",
       "       [0.97262419, 0.02737581],\n",
       "       [0.94960481, 0.05039519],\n",
       "       [0.97477128, 0.02522872],\n",
       "       [0.96568209, 0.03431791],\n",
       "       [0.80655133, 0.19344867],\n",
       "       [0.05583778, 0.94416222],\n",
       "       [0.92485269, 0.07514731],\n",
       "       [0.96128772, 0.03871228],\n",
       "       [0.80512188, 0.19487812],\n",
       "       [0.80061622, 0.19938378],\n",
       "       [0.9819398 , 0.0180602 ],\n",
       "       [0.61275448, 0.38724552],\n",
       "       [0.82908419, 0.17091581],\n",
       "       [0.86534633, 0.13465367],\n",
       "       [0.86994128, 0.13005872],\n",
       "       [0.95540503, 0.04459497],\n",
       "       [0.95189373, 0.04810627],\n",
       "       [0.98995456, 0.01004544],\n",
       "       [0.96449935, 0.03550065],\n",
       "       [0.78824142, 0.21175858],\n",
       "       [0.96746804, 0.03253196],\n",
       "       [0.97322341, 0.02677659],\n",
       "       [0.9095778 , 0.0904222 ],\n",
       "       [0.98685648, 0.01314352],\n",
       "       [0.40093738, 0.59906262],\n",
       "       [0.95160285, 0.04839715],\n",
       "       [0.99165134, 0.00834866],\n",
       "       [0.98041891, 0.01958109],\n",
       "       [0.92118534, 0.07881466],\n",
       "       [0.9427397 , 0.0572603 ],\n",
       "       [0.91084646, 0.08915354],\n",
       "       [0.98510408, 0.01489592],\n",
       "       [0.64345284, 0.35654716],\n",
       "       [0.12154891, 0.87845109],\n",
       "       [0.99608678, 0.00391322],\n",
       "       [0.83338331, 0.16661669],\n",
       "       [0.05701714, 0.94298286],\n",
       "       [0.3153881 , 0.6846119 ],\n",
       "       [0.53787149, 0.46212851],\n",
       "       [0.98418249, 0.01581751],\n",
       "       [0.11916902, 0.88083098],\n",
       "       [0.98539479, 0.01460521],\n",
       "       [0.82489906, 0.17510094],\n",
       "       [0.12125483, 0.87874517],\n",
       "       [0.49567627, 0.50432373],\n",
       "       [0.98097842, 0.01902158],\n",
       "       [0.98351504, 0.01648496],\n",
       "       [0.97698757, 0.02301243],\n",
       "       [0.82546381, 0.17453619],\n",
       "       [0.99606243, 0.00393757],\n",
       "       [0.98267085, 0.01732915],\n",
       "       [0.22656285, 0.77343715],\n",
       "       [0.78337535, 0.21662465],\n",
       "       [0.92201321, 0.07798679],\n",
       "       [0.95852302, 0.04147698],\n",
       "       [0.96577931, 0.03422069],\n",
       "       [0.08063948, 0.91936052],\n",
       "       [0.25133744, 0.74866256],\n",
       "       [0.93411518, 0.06588482],\n",
       "       [0.92128337, 0.07871663],\n",
       "       [0.9837988 , 0.0162012 ],\n",
       "       [0.98450847, 0.01549153],\n",
       "       [0.9691744 , 0.0308256 ],\n",
       "       [0.05518708, 0.94481292],\n",
       "       [0.97765704, 0.02234296],\n",
       "       [0.96200005, 0.03799995],\n",
       "       [0.8154944 , 0.1845056 ],\n",
       "       [0.92910275, 0.07089725],\n",
       "       [0.94652819, 0.05347181],\n",
       "       [0.78532654, 0.21467346],\n",
       "       [0.99437972, 0.00562028],\n",
       "       [0.94153043, 0.05846957],\n",
       "       [0.87048806, 0.12951194],\n",
       "       [0.94697992, 0.05302008],\n",
       "       [0.90057081, 0.09942919],\n",
       "       [0.95625353, 0.04374647],\n",
       "       [0.96079588, 0.03920412],\n",
       "       [0.98819258, 0.01180742],\n",
       "       [0.99799283, 0.00200717],\n",
       "       [0.94684237, 0.05315763],\n",
       "       [0.92247106, 0.07752894],\n",
       "       [0.9432829 , 0.0567171 ],\n",
       "       [0.97273728, 0.02726272],\n",
       "       [0.79731325, 0.20268675],\n",
       "       [0.85227939, 0.14772061],\n",
       "       [0.95224509, 0.04775491],\n",
       "       [0.98193071, 0.01806929],\n",
       "       [0.9859086 , 0.0140914 ],\n",
       "       [0.97893465, 0.02106535],\n",
       "       [0.58513755, 0.41486245],\n",
       "       [0.93805004, 0.06194996],\n",
       "       [0.84531421, 0.15468579],\n",
       "       [0.11245123, 0.88754877],\n",
       "       [0.96104307, 0.03895693],\n",
       "       [0.83998765, 0.16001235],\n",
       "       [0.95931476, 0.04068524],\n",
       "       [0.0351315 , 0.9648685 ],\n",
       "       [0.89642315, 0.10357685],\n",
       "       [0.91347317, 0.08652683],\n",
       "       [0.98251592, 0.01748408],\n",
       "       [0.99195576, 0.00804424],\n",
       "       [0.03969399, 0.96030601],\n",
       "       [0.9679551 , 0.0320449 ],\n",
       "       [0.97035166, 0.02964834],\n",
       "       [0.98508818, 0.01491182],\n",
       "       [0.99275606, 0.00724394],\n",
       "       [0.8665857 , 0.1334143 ],\n",
       "       [0.3472182 , 0.6527818 ],\n",
       "       [0.09868496, 0.90131504],\n",
       "       [0.81673611, 0.18326389],\n",
       "       [0.94372752, 0.05627248],\n",
       "       [0.97772326, 0.02227674],\n",
       "       [0.75211133, 0.24788867],\n",
       "       [0.97552654, 0.02447346],\n",
       "       [0.54607719, 0.45392281],\n",
       "       [0.66001624, 0.33998376],\n",
       "       [0.89228497, 0.10771503],\n",
       "       [0.9488272 , 0.0511728 ],\n",
       "       [0.9188087 , 0.0811913 ],\n",
       "       [0.99396661, 0.00603339],\n",
       "       [0.03597899, 0.96402101],\n",
       "       [0.063948  , 0.936052  ],\n",
       "       [0.96842076, 0.03157924],\n",
       "       [0.98674891, 0.01325109],\n",
       "       [0.94489554, 0.05510446],\n",
       "       [0.9604914 , 0.0395086 ],\n",
       "       [0.73488463, 0.26511537],\n",
       "       [0.78984826, 0.21015174],\n",
       "       [0.98257821, 0.01742179],\n",
       "       [0.12271947, 0.87728053],\n",
       "       [0.94907076, 0.05092924],\n",
       "       [0.80061897, 0.19938103],\n",
       "       [0.92861756, 0.07138244],\n",
       "       [0.07545557, 0.92454443],\n",
       "       [0.96887386, 0.03112614],\n",
       "       [0.86651131, 0.13348869],\n",
       "       [0.5246107 , 0.4753893 ],\n",
       "       [0.82182211, 0.17817789],\n",
       "       [0.96023304, 0.03976696],\n",
       "       [0.98106427, 0.01893573],\n",
       "       [0.84289387, 0.15710613],\n",
       "       [0.98120442, 0.01879558],\n",
       "       [0.93155693, 0.06844307],\n",
       "       [0.80081794, 0.19918206],\n",
       "       [0.71200532, 0.28799468],\n",
       "       [0.59750575, 0.40249425],\n",
       "       [0.96357855, 0.03642145],\n",
       "       [0.68171791, 0.31828209],\n",
       "       [0.98705075, 0.01294925],\n",
       "       [0.78010627, 0.21989373],\n",
       "       [0.0256058 , 0.9743942 ],\n",
       "       [0.78304495, 0.21695505],\n",
       "       [0.96935211, 0.03064789],\n",
       "       [0.74579027, 0.25420973],\n",
       "       [0.69288868, 0.30711132],\n",
       "       [0.91750902, 0.08249098],\n",
       "       [0.88136746, 0.11863254],\n",
       "       [0.72873661, 0.27126339],\n",
       "       [0.83854895, 0.16145105],\n",
       "       [0.07278544, 0.92721456],\n",
       "       [0.95902753, 0.04097247],\n",
       "       [0.89713549, 0.10286451],\n",
       "       [0.87182435, 0.12817565],\n",
       "       [0.94429087, 0.05570913],\n",
       "       [0.65861985, 0.34138015],\n",
       "       [0.05867767, 0.94132233],\n",
       "       [0.94641836, 0.05358164],\n",
       "       [0.91034093, 0.08965907],\n",
       "       [0.84403812, 0.15596188],\n",
       "       [0.98943446, 0.01056554],\n",
       "       [0.85203366, 0.14796634],\n",
       "       [0.29702179, 0.70297821],\n",
       "       [0.99121968, 0.00878032],\n",
       "       [0.02809002, 0.97190998],\n",
       "       [0.76016853, 0.23983147],\n",
       "       [0.97749152, 0.02250848],\n",
       "       [0.85843435, 0.14156565],\n",
       "       [0.66181401, 0.33818599],\n",
       "       [0.95579205, 0.04420795],\n",
       "       [0.96174401, 0.03825599],\n",
       "       [0.86749205, 0.13250795],\n",
       "       [0.96474621, 0.03525379],\n",
       "       [0.82617394, 0.17382606],\n",
       "       [0.26456046, 0.73543954],\n",
       "       [0.9444497 , 0.0555503 ],\n",
       "       [0.9321353 , 0.0678647 ],\n",
       "       [0.64058192, 0.35941808],\n",
       "       [0.09209404, 0.90790596],\n",
       "       [0.04263632, 0.95736368],\n",
       "       [0.97031949, 0.02968051],\n",
       "       [0.96842562, 0.03157438],\n",
       "       [0.1334131 , 0.8665869 ],\n",
       "       [0.07626255, 0.92373745],\n",
       "       [0.98468996, 0.01531004],\n",
       "       [0.64776337, 0.35223663],\n",
       "       [0.94713821, 0.05286179],\n",
       "       [0.95854191, 0.04145809],\n",
       "       [0.86720892, 0.13279108],\n",
       "       [0.96007978, 0.03992022],\n",
       "       [0.95867463, 0.04132537],\n",
       "       [0.98847936, 0.01152064],\n",
       "       [0.3430255 , 0.6569745 ],\n",
       "       [0.94541451, 0.05458549],\n",
       "       [0.85827625, 0.14172375],\n",
       "       [0.97917083, 0.02082917],\n",
       "       [0.95864957, 0.04135043],\n",
       "       [0.90465329, 0.09534671],\n",
       "       [0.15345429, 0.84654571],\n",
       "       [0.05765227, 0.94234773],\n",
       "       [0.95692925, 0.04307075],\n",
       "       [0.95243194, 0.04756806],\n",
       "       [0.96995066, 0.03004934],\n",
       "       [0.77327174, 0.22672826],\n",
       "       [0.94864102, 0.05135898],\n",
       "       [0.93797501, 0.06202499],\n",
       "       [0.79247765, 0.20752235],\n",
       "       [0.86685907, 0.13314093],\n",
       "       [0.96168354, 0.03831646],\n",
       "       [0.71916233, 0.28083767],\n",
       "       [0.82835443, 0.17164557],\n",
       "       [0.92054143, 0.07945857],\n",
       "       [0.97646164, 0.02353836],\n",
       "       [0.83827729, 0.16172271],\n",
       "       [0.85962241, 0.14037759],\n",
       "       [0.02971845, 0.97028155],\n",
       "       [0.8042493 , 0.1957507 ],\n",
       "       [0.89712999, 0.10287001],\n",
       "       [0.99275626, 0.00724374],\n",
       "       [0.85074076, 0.14925924],\n",
       "       [0.8883435 , 0.1116565 ],\n",
       "       [0.95995243, 0.04004757],\n",
       "       [0.98149606, 0.01850394],\n",
       "       [0.95939238, 0.04060762],\n",
       "       [0.98414944, 0.01585056],\n",
       "       [0.97573727, 0.02426273],\n",
       "       [0.97899595, 0.02100405],\n",
       "       [0.35940854, 0.64059146],\n",
       "       [0.9112176 , 0.0887824 ],\n",
       "       [0.06010293, 0.93989707],\n",
       "       [0.83382704, 0.16617296],\n",
       "       [0.92302771, 0.07697229],\n",
       "       [0.13023051, 0.86976949],\n",
       "       [0.96585393, 0.03414607],\n",
       "       [0.86520619, 0.13479381],\n",
       "       [0.7816299 , 0.2183701 ],\n",
       "       [0.03099836, 0.96900164],\n",
       "       [0.08965955, 0.91034045],\n",
       "       [0.37909885, 0.62090115],\n",
       "       [0.88712111, 0.11287889],\n",
       "       [0.98425298, 0.01574702],\n",
       "       [0.03588014, 0.96411986],\n",
       "       [0.96844786, 0.03155214],\n",
       "       [0.83077757, 0.16922243],\n",
       "       [0.97131064, 0.02868936],\n",
       "       [0.8645432 , 0.1354568 ],\n",
       "       [0.99455997, 0.00544003],\n",
       "       [0.95605672, 0.04394328],\n",
       "       [0.97499732, 0.02500268],\n",
       "       [0.95411792, 0.04588208],\n",
       "       [0.01408248, 0.98591752],\n",
       "       [0.92493739, 0.07506261],\n",
       "       [0.92709397, 0.07290603],\n",
       "       [0.92029182, 0.07970818],\n",
       "       [0.82854983, 0.17145017],\n",
       "       [0.08688594, 0.91311406],\n",
       "       [0.69834282, 0.30165718],\n",
       "       [0.96239504, 0.03760496],\n",
       "       [0.45002579, 0.54997421],\n",
       "       [0.95173243, 0.04826757],\n",
       "       [0.15633816, 0.84366184],\n",
       "       [0.99363803, 0.00636197],\n",
       "       [0.96417643, 0.03582357],\n",
       "       [0.84838045, 0.15161955],\n",
       "       [0.8712599 , 0.1287401 ],\n",
       "       [0.80870229, 0.19129771],\n",
       "       [0.96903379, 0.03096621],\n",
       "       [0.70942207, 0.29057793],\n",
       "       [0.89021286, 0.10978714],\n",
       "       [0.04861007, 0.95138993],\n",
       "       [0.06571087, 0.93428913],\n",
       "       [0.90707564, 0.09292436],\n",
       "       [0.94042862, 0.05957138],\n",
       "       [0.84972674, 0.15027326],\n",
       "       [0.77747525, 0.22252475],\n",
       "       [0.95396934, 0.04603066],\n",
       "       [0.94711498, 0.05288502],\n",
       "       [0.96022798, 0.03977202],\n",
       "       [0.87455125, 0.12544875],\n",
       "       [0.9257202 , 0.0742798 ],\n",
       "       [0.0224166 , 0.9775834 ],\n",
       "       [0.93634997, 0.06365003],\n",
       "       [0.91850141, 0.08149859],\n",
       "       [0.80411105, 0.19588895],\n",
       "       [0.82095847, 0.17904153],\n",
       "       [0.96711334, 0.03288666],\n",
       "       [0.90862419, 0.09137581],\n",
       "       [0.90843668, 0.09156332],\n",
       "       [0.09750081, 0.90249919],\n",
       "       [0.66180535, 0.33819465],\n",
       "       [0.90525415, 0.09474585],\n",
       "       [0.95926046, 0.04073954],\n",
       "       [0.9604826 , 0.0395174 ],\n",
       "       [0.98468128, 0.01531872],\n",
       "       [0.95807   , 0.04193   ],\n",
       "       [0.90282185, 0.09717815],\n",
       "       [0.04481485, 0.95518515],\n",
       "       [0.85262596, 0.14737404],\n",
       "       [0.40936402, 0.59063598],\n",
       "       [0.0755639 , 0.9244361 ],\n",
       "       [0.97362233, 0.02637767],\n",
       "       [0.97184603, 0.02815397],\n",
       "       [0.99333059, 0.00666941],\n",
       "       [0.93923309, 0.06076691],\n",
       "       [0.16231408, 0.83768592],\n",
       "       [0.85915645, 0.14084355],\n",
       "       [0.78426452, 0.21573548],\n",
       "       [0.97839179, 0.02160821],\n",
       "       [0.94572556, 0.05427444],\n",
       "       [0.05673314, 0.94326686],\n",
       "       [0.90268795, 0.09731205],\n",
       "       [0.94221571, 0.05778429],\n",
       "       [0.74569898, 0.25430102],\n",
       "       [0.67734891, 0.32265109],\n",
       "       [0.0521277 , 0.9478723 ],\n",
       "       [0.99489364, 0.00510636],\n",
       "       [0.94864919, 0.05135081],\n",
       "       [0.94551731, 0.05448269],\n",
       "       [0.94525775, 0.05474225],\n",
       "       [0.9710416 , 0.0289584 ],\n",
       "       [0.63102955, 0.36897045],\n",
       "       [0.92463956, 0.07536044],\n",
       "       [0.93680934, 0.06319066],\n",
       "       [0.96568706, 0.03431294],\n",
       "       [0.98951579, 0.01048421],\n",
       "       [0.05670911, 0.94329089],\n",
       "       [0.59605757, 0.40394243],\n",
       "       [0.10971945, 0.89028055],\n",
       "       [0.9589123 , 0.0410877 ],\n",
       "       [0.99487396, 0.00512604],\n",
       "       [0.83279882, 0.16720118],\n",
       "       [0.78053338, 0.21946662],\n",
       "       [0.06706441, 0.93293559],\n",
       "       [0.1796192 , 0.8203808 ],\n",
       "       [0.97108783, 0.02891217],\n",
       "       [0.09155483, 0.90844517],\n",
       "       [0.96422315, 0.03577685],\n",
       "       [0.75723688, 0.24276312],\n",
       "       [0.99343171, 0.00656829],\n",
       "       [0.94390283, 0.05609717],\n",
       "       [0.74223681, 0.25776319],\n",
       "       [0.94731413, 0.05268587],\n",
       "       [0.89985708, 0.10014292],\n",
       "       [0.97234753, 0.02765247],\n",
       "       [0.76965135, 0.23034865],\n",
       "       [0.95322133, 0.04677867],\n",
       "       [0.13488454, 0.86511546],\n",
       "       [0.86045856, 0.13954144],\n",
       "       [0.98842347, 0.01157653],\n",
       "       [0.99577826, 0.00422174],\n",
       "       [0.90291663, 0.09708337],\n",
       "       [0.97191376, 0.02808624],\n",
       "       [0.72206548, 0.27793452],\n",
       "       [0.10202311, 0.89797689],\n",
       "       [0.09946789, 0.90053211],\n",
       "       [0.49308948, 0.50691052],\n",
       "       [0.84901287, 0.15098713],\n",
       "       [0.96567327, 0.03432673],\n",
       "       [0.88464422, 0.11535578],\n",
       "       [0.79584955, 0.20415045],\n",
       "       [0.15158865, 0.84841135],\n",
       "       [0.99690323, 0.00309677],\n",
       "       [0.82968277, 0.17031723],\n",
       "       [0.13768839, 0.86231161],\n",
       "       [0.78861754, 0.21138246],\n",
       "       [0.82193965, 0.17806035],\n",
       "       [0.93950322, 0.06049678],\n",
       "       [0.81261219, 0.18738781],\n",
       "       [0.0192453 , 0.9807547 ],\n",
       "       [0.8953429 , 0.1046571 ],\n",
       "       [0.85382969, 0.14617031],\n",
       "       [0.97339813, 0.02660187],\n",
       "       [0.96335175, 0.03664825],\n",
       "       [0.96324921, 0.03675079],\n",
       "       [0.13314632, 0.86685368],\n",
       "       [0.89473185, 0.10526815],\n",
       "       [0.91944934, 0.08055066],\n",
       "       [0.99107462, 0.00892538],\n",
       "       [0.42762413, 0.57237587],\n",
       "       [0.11470744, 0.88529256],\n",
       "       [0.87749418, 0.12250582],\n",
       "       [0.95028883, 0.04971117],\n",
       "       [0.90080805, 0.09919195],\n",
       "       [0.03665095, 0.96334905],\n",
       "       [0.91018904, 0.08981096],\n",
       "       [0.09466577, 0.90533423],\n",
       "       [0.85519363, 0.14480637],\n",
       "       [0.86174003, 0.13825997],\n",
       "       [0.98333772, 0.01666228],\n",
       "       [0.98708913, 0.01291087],\n",
       "       [0.94256876, 0.05743124],\n",
       "       [0.9735959 , 0.0264041 ],\n",
       "       [0.02919462, 0.97080538],\n",
       "       [0.97080727, 0.02919273],\n",
       "       [0.89723959, 0.10276041],\n",
       "       [0.92753954, 0.07246046],\n",
       "       [0.06633772, 0.93366228],\n",
       "       [0.93602107, 0.06397893],\n",
       "       [0.86493069, 0.13506931],\n",
       "       [0.97714496, 0.02285504],\n",
       "       [0.06259048, 0.93740952],\n",
       "       [0.98509238, 0.01490762],\n",
       "       [0.62184582, 0.37815418],\n",
       "       [0.9480354 , 0.0519646 ],\n",
       "       [0.02883295, 0.97116705],\n",
       "       [0.03928149, 0.96071851],\n",
       "       [0.04405864, 0.95594136],\n",
       "       [0.83469591, 0.16530409],\n",
       "       [0.95104392, 0.04895608],\n",
       "       [0.89833449, 0.10166551],\n",
       "       [0.5838544 , 0.4161456 ],\n",
       "       [0.89674144, 0.10325856],\n",
       "       [0.9669618 , 0.0330382 ],\n",
       "       [0.97965046, 0.02034954],\n",
       "       [0.90220996, 0.09779004],\n",
       "       [0.93113947, 0.06886053],\n",
       "       [0.94131478, 0.05868522],\n",
       "       [0.95246339, 0.04753661],\n",
       "       [0.86384041, 0.13615959],\n",
       "       [0.99289632, 0.00710368],\n",
       "       [0.71590213, 0.28409787],\n",
       "       [0.90403214, 0.09596786],\n",
       "       [0.81368177, 0.18631823],\n",
       "       [0.88324451, 0.11675549],\n",
       "       [0.98213225, 0.01786775],\n",
       "       [0.9127106 , 0.0872894 ],\n",
       "       [0.89022621, 0.10977379],\n",
       "       [0.15895389, 0.84104611],\n",
       "       [0.19707214, 0.80292786],\n",
       "       [0.12411088, 0.87588912],\n",
       "       [0.88409859, 0.11590141],\n",
       "       [0.96380155, 0.03619845],\n",
       "       [0.95039064, 0.04960936],\n",
       "       [0.77575544, 0.22424456],\n",
       "       [0.15902853, 0.84097147],\n",
       "       [0.91647593, 0.08352407],\n",
       "       [0.89505803, 0.10494197],\n",
       "       [0.87993712, 0.12006288],\n",
       "       [0.94464357, 0.05535643],\n",
       "       [0.89074378, 0.10925622],\n",
       "       [0.97325804, 0.02674196],\n",
       "       [0.96289099, 0.03710901],\n",
       "       [0.97487499, 0.02512501],\n",
       "       [0.97222389, 0.02777611],\n",
       "       [0.94330877, 0.05669123],\n",
       "       [0.97026744, 0.02973256],\n",
       "       [0.75411257, 0.24588743],\n",
       "       [0.79618395, 0.20381605],\n",
       "       [0.88230554, 0.11769446],\n",
       "       [0.98779691, 0.01220309],\n",
       "       [0.97470598, 0.02529402],\n",
       "       [0.96813246, 0.03186754],\n",
       "       [0.96699938, 0.03300062],\n",
       "       [0.03287083, 0.96712917],\n",
       "       [0.97115183, 0.02884817],\n",
       "       [0.96807922, 0.03192078],\n",
       "       [0.9693931 , 0.0306069 ],\n",
       "       [0.85905055, 0.14094945],\n",
       "       [0.95934175, 0.04065825],\n",
       "       [0.95911921, 0.04088079],\n",
       "       [0.95779386, 0.04220614],\n",
       "       [0.96589699, 0.03410301],\n",
       "       [0.48535836, 0.51464164],\n",
       "       [0.95307455, 0.04692545],\n",
       "       [0.8686983 , 0.1313017 ],\n",
       "       [0.97970599, 0.02029401],\n",
       "       [0.98446135, 0.01553865],\n",
       "       [0.92768636, 0.07231364],\n",
       "       [0.97819695, 0.02180305],\n",
       "       [0.18801042, 0.81198958],\n",
       "       [0.81629189, 0.18370811],\n",
       "       [0.92691015, 0.07308985],\n",
       "       [0.97977481, 0.02022519],\n",
       "       [0.97656979, 0.02343021],\n",
       "       [0.9706541 , 0.0293459 ],\n",
       "       [0.05494748, 0.94505252],\n",
       "       [0.93626676, 0.06373324],\n",
       "       [0.95872097, 0.04127903],\n",
       "       [0.09744716, 0.90255284],\n",
       "       [0.96298785, 0.03701215],\n",
       "       [0.01015848, 0.98984152],\n",
       "       [0.76128358, 0.23871642],\n",
       "       [0.97828928, 0.02171072],\n",
       "       [0.96478033, 0.03521967],\n",
       "       [0.84098138, 0.15901862],\n",
       "       [0.93332719, 0.06667281],\n",
       "       [0.97705878, 0.02294122],\n",
       "       [0.9411415 , 0.0588585 ],\n",
       "       [0.66239208, 0.33760792],\n",
       "       [0.89250934, 0.10749066],\n",
       "       [0.03898461, 0.96101539],\n",
       "       [0.9745365 , 0.0254635 ],\n",
       "       [0.94540245, 0.05459755],\n",
       "       [0.8525584 , 0.1474416 ],\n",
       "       [0.82286509, 0.17713491],\n",
       "       [0.90658861, 0.09341139],\n",
       "       [0.98267741, 0.01732259],\n",
       "       [0.08207636, 0.91792364],\n",
       "       [0.98712339, 0.01287661],\n",
       "       [0.99647216, 0.00352784],\n",
       "       [0.94954253, 0.05045747],\n",
       "       [0.83232424, 0.16767576],\n",
       "       [0.94347345, 0.05652655],\n",
       "       [0.94731742, 0.05268258],\n",
       "       [0.4850992 , 0.5149008 ],\n",
       "       [0.88456732, 0.11543268],\n",
       "       [0.77733824, 0.22266176],\n",
       "       [0.98230602, 0.01769398],\n",
       "       [0.90427251, 0.09572749],\n",
       "       [0.91416696, 0.08583304],\n",
       "       [0.98252851, 0.01747149],\n",
       "       [0.98479132, 0.01520868],\n",
       "       [0.1069563 , 0.8930437 ],\n",
       "       [0.9733187 , 0.0266813 ],\n",
       "       [0.77008895, 0.22991105],\n",
       "       [0.10060592, 0.89939408],\n",
       "       [0.96611067, 0.03388933],\n",
       "       [0.96957336, 0.03042664],\n",
       "       [0.98109937, 0.01890063],\n",
       "       [0.95333149, 0.04666851],\n",
       "       [0.93853562, 0.06146438],\n",
       "       [0.97754599, 0.02245401],\n",
       "       [0.97818357, 0.02181643],\n",
       "       [0.07501475, 0.92498525],\n",
       "       [0.97168937, 0.02831063],\n",
       "       [0.90409282, 0.09590718],\n",
       "       [0.96136518, 0.03863482],\n",
       "       [0.07221727, 0.92778273],\n",
       "       [0.86938694, 0.13061306],\n",
       "       [0.78672886, 0.21327114],\n",
       "       [0.92178948, 0.07821052],\n",
       "       [0.97070048, 0.02929952],\n",
       "       [0.94298865, 0.05701135],\n",
       "       [0.98500646, 0.01499354],\n",
       "       [0.74016213, 0.25983787],\n",
       "       [0.96236483, 0.03763517],\n",
       "       [0.86429136, 0.13570864],\n",
       "       [0.93190512, 0.06809488],\n",
       "       [0.06789549, 0.93210451],\n",
       "       [0.05157847, 0.94842153],\n",
       "       [0.62150994, 0.37849006],\n",
       "       [0.81484918, 0.18515082],\n",
       "       [0.80709953, 0.19290047],\n",
       "       [0.52980575, 0.47019425],\n",
       "       [0.70009827, 0.29990173],\n",
       "       [0.87982635, 0.12017365],\n",
       "       [0.77861986, 0.22138014],\n",
       "       [0.97057065, 0.02942935],\n",
       "       [0.83334139, 0.16665861],\n",
       "       [0.99335177, 0.00664823],\n",
       "       [0.95923035, 0.04076965],\n",
       "       [0.85983391, 0.14016609],\n",
       "       [0.94563584, 0.05436416],\n",
       "       [0.08055442, 0.91944558],\n",
       "       [0.09284268, 0.90715732],\n",
       "       [0.93164443, 0.06835557],\n",
       "       [0.98504123, 0.01495877],\n",
       "       [0.92799693, 0.07200307],\n",
       "       [0.89643337, 0.10356663],\n",
       "       [0.05856671, 0.94143329],\n",
       "       [0.05006204, 0.94993796],\n",
       "       [0.96541253, 0.03458747],\n",
       "       [0.85757291, 0.14242709],\n",
       "       [0.97296245, 0.02703755],\n",
       "       [0.97801638, 0.02198362],\n",
       "       [0.01819866, 0.98180134],\n",
       "       [0.99295543, 0.00704457],\n",
       "       [0.89116952, 0.10883048],\n",
       "       [0.97937635, 0.02062365],\n",
       "       [0.907104  , 0.092896  ],\n",
       "       [0.9728895 , 0.0271105 ],\n",
       "       [0.8407048 , 0.1592952 ],\n",
       "       [0.80318466, 0.19681534],\n",
       "       [0.93378971, 0.06621029],\n",
       "       [0.96248785, 0.03751215],\n",
       "       [0.85096501, 0.14903499],\n",
       "       [0.95790668, 0.04209332],\n",
       "       [0.97731493, 0.02268507],\n",
       "       [0.08592689, 0.91407311],\n",
       "       [0.91076071, 0.08923929],\n",
       "       [0.9648252 , 0.0351748 ],\n",
       "       [0.8836842 , 0.1163158 ],\n",
       "       [0.9366557 , 0.0633443 ],\n",
       "       [0.96503435, 0.03496565],\n",
       "       [0.80675241, 0.19324759],\n",
       "       [0.84789855, 0.15210145],\n",
       "       [0.94263822, 0.05736178],\n",
       "       [0.95299081, 0.04700919],\n",
       "       [0.8255166 , 0.1744834 ],\n",
       "       [0.85921337, 0.14078663],\n",
       "       [0.53769958, 0.46230042],\n",
       "       [0.95097637, 0.04902363],\n",
       "       [0.97150494, 0.02849506],\n",
       "       [0.96604075, 0.03395925],\n",
       "       [0.99054872, 0.00945128],\n",
       "       [0.90627371, 0.09372629],\n",
       "       [0.91503604, 0.08496396],\n",
       "       [0.99556904, 0.00443096],\n",
       "       [0.03123433, 0.96876567],\n",
       "       [0.67784535, 0.32215465],\n",
       "       [0.84138055, 0.15861945],\n",
       "       [0.94124556, 0.05875444],\n",
       "       [0.02171917, 0.97828083],\n",
       "       [0.88744571, 0.11255429],\n",
       "       [0.5365834 , 0.4634166 ],\n",
       "       [0.85312125, 0.14687875],\n",
       "       [0.59364115, 0.40635885],\n",
       "       [0.84135866, 0.15864134],\n",
       "       [0.97208132, 0.02791868],\n",
       "       [0.8086652 , 0.1913348 ],\n",
       "       [0.88162358, 0.11837642],\n",
       "       [0.6435493 , 0.3564507 ],\n",
       "       [0.77346166, 0.22653834],\n",
       "       [0.99032417, 0.00967583],\n",
       "       [0.82991995, 0.17008005],\n",
       "       [0.85691549, 0.14308451],\n",
       "       [0.96862421, 0.03137579],\n",
       "       [0.02616983, 0.97383017],\n",
       "       [0.8717595 , 0.1282405 ],\n",
       "       [0.07502053, 0.92497947],\n",
       "       [0.98679493, 0.01320507],\n",
       "       [0.65235081, 0.34764919],\n",
       "       [0.95844322, 0.04155678],\n",
       "       [0.91849294, 0.08150706],\n",
       "       [0.05931579, 0.94068421],\n",
       "       [0.99307583, 0.00692417],\n",
       "       [0.04876611, 0.95123389],\n",
       "       [0.08327911, 0.91672089],\n",
       "       [0.70553345, 0.29446655],\n",
       "       [0.56122601, 0.43877399],\n",
       "       [0.07034095, 0.92965905],\n",
       "       [0.97260162, 0.02739838],\n",
       "       [0.71312434, 0.28687566],\n",
       "       [0.9760527 , 0.0239473 ],\n",
       "       [0.89858988, 0.10141012],\n",
       "       [0.90916338, 0.09083662],\n",
       "       [0.91002251, 0.08997749],\n",
       "       [0.98341305, 0.01658695],\n",
       "       [0.91730093, 0.08269907],\n",
       "       [0.95977131, 0.04022869],\n",
       "       [0.97724492, 0.02275508],\n",
       "       [0.9113477 , 0.0886523 ],\n",
       "       [0.93850877, 0.06149123],\n",
       "       [0.88559508, 0.11440492],\n",
       "       [0.57835574, 0.42164426],\n",
       "       [0.88223001, 0.11776999],\n",
       "       [0.87312865, 0.12687135],\n",
       "       [0.98410281, 0.01589719],\n",
       "       [0.95392463, 0.04607537],\n",
       "       [0.89152149, 0.10847851],\n",
       "       [0.38550243, 0.61449757],\n",
       "       [0.97635483, 0.02364517],\n",
       "       [0.94359284, 0.05640716],\n",
       "       [0.04281868, 0.95718132],\n",
       "       [0.16751618, 0.83248382],\n",
       "       [0.02853441, 0.97146559],\n",
       "       [0.90013717, 0.09986283],\n",
       "       [0.89662596, 0.10337404],\n",
       "       [0.96568926, 0.03431074],\n",
       "       [0.84060139, 0.15939861],\n",
       "       [0.66026849, 0.33973151],\n",
       "       [0.57480582, 0.42519418],\n",
       "       [0.77650899, 0.22349101],\n",
       "       [0.85833491, 0.14166509],\n",
       "       [0.98120527, 0.01879473],\n",
       "       [0.92732015, 0.07267985],\n",
       "       [0.886093  , 0.113907  ],\n",
       "       [0.97594256, 0.02405744],\n",
       "       [0.97688561, 0.02311439],\n",
       "       [0.72922193, 0.27077807],\n",
       "       [0.91324254, 0.08675746],\n",
       "       [0.18634845, 0.81365155],\n",
       "       [0.92451626, 0.07548374],\n",
       "       [0.23678959, 0.76321041],\n",
       "       [0.46053611, 0.53946389],\n",
       "       [0.92583302, 0.07416698],\n",
       "       [0.96804113, 0.03195887],\n",
       "       [0.83729103, 0.16270897],\n",
       "       [0.05117467, 0.94882533],\n",
       "       [0.94074136, 0.05925864],\n",
       "       [0.8532964 , 0.1467036 ],\n",
       "       [0.02379029, 0.97620971],\n",
       "       [0.91208734, 0.08791266],\n",
       "       [0.84326738, 0.15673262],\n",
       "       [0.96090812, 0.03909188],\n",
       "       [0.03642069, 0.96357931],\n",
       "       [0.9260567 , 0.0739433 ],\n",
       "       [0.9579386 , 0.0420614 ],\n",
       "       [0.26141466, 0.73858534],\n",
       "       [0.97503553, 0.02496447],\n",
       "       [0.99234806, 0.00765194],\n",
       "       [0.97218786, 0.02781214],\n",
       "       [0.97699623, 0.02300377],\n",
       "       [0.93742232, 0.06257768],\n",
       "       [0.07287656, 0.92712344],\n",
       "       [0.90174044, 0.09825956],\n",
       "       [0.98241545, 0.01758455],\n",
       "       [0.82293412, 0.17706588],\n",
       "       [0.97189066, 0.02810934],\n",
       "       [0.0996889 , 0.9003111 ],\n",
       "       [0.94077817, 0.05922183],\n",
       "       [0.93788762, 0.06211238],\n",
       "       [0.99479448, 0.00520552],\n",
       "       [0.87273067, 0.12726933],\n",
       "       [0.68376368, 0.31623632],\n",
       "       [0.10694659, 0.89305341],\n",
       "       [0.95630006, 0.04369994],\n",
       "       [0.99120812, 0.00879188],\n",
       "       [0.98457482, 0.01542518],\n",
       "       [0.45231283, 0.54768717],\n",
       "       [0.99035496, 0.00964504],\n",
       "       [0.975969  , 0.024031  ],\n",
       "       [0.95703207, 0.04296793],\n",
       "       [0.87828842, 0.12171158],\n",
       "       [0.96162569, 0.03837431],\n",
       "       [0.97064817, 0.02935183],\n",
       "       [0.95596996, 0.04403004],\n",
       "       [0.97975589, 0.02024411],\n",
       "       [0.97622347, 0.02377653],\n",
       "       [0.9207618 , 0.0792382 ],\n",
       "       [0.79050671, 0.20949329],\n",
       "       [0.98174188, 0.01825812],\n",
       "       [0.98136395, 0.01863605],\n",
       "       [0.77737873, 0.22262127],\n",
       "       [0.94403596, 0.05596404],\n",
       "       [0.95538324, 0.04461676],\n",
       "       [0.97971983, 0.02028017],\n",
       "       [0.99104957, 0.00895043],\n",
       "       [0.98012041, 0.01987959],\n",
       "       [0.99094368, 0.00905632],\n",
       "       [0.8018438 , 0.1981562 ],\n",
       "       [0.89023668, 0.10976332],\n",
       "       [0.94338083, 0.05661917],\n",
       "       [0.86875683, 0.13124317],\n",
       "       [0.92886192, 0.07113808],\n",
       "       [0.09053512, 0.90946488],\n",
       "       [0.18887598, 0.81112402],\n",
       "       [0.95722564, 0.04277436],\n",
       "       [0.96692093, 0.03307907],\n",
       "       [0.97244507, 0.02755493],\n",
       "       [0.88597111, 0.11402889],\n",
       "       [0.96764871, 0.03235129],\n",
       "       [0.07551388, 0.92448612],\n",
       "       [0.95479786, 0.04520214],\n",
       "       [0.05635022, 0.94364978],\n",
       "       [0.97479326, 0.02520674],\n",
       "       [0.03714481, 0.96285519],\n",
       "       [0.0740085 , 0.9259915 ],\n",
       "       [0.86567257, 0.13432743],\n",
       "       [0.9592606 , 0.0407394 ],\n",
       "       [0.84136428, 0.15863572],\n",
       "       [0.88339238, 0.11660762],\n",
       "       [0.98252332, 0.01747668],\n",
       "       [0.72948086, 0.27051914],\n",
       "       [0.03299916, 0.96700084],\n",
       "       [0.88229409, 0.11770591],\n",
       "       [0.96510643, 0.03489357],\n",
       "       [0.8934185 , 0.1065815 ],\n",
       "       [0.09179258, 0.90820742],\n",
       "       [0.96145788, 0.03854212],\n",
       "       [0.04445004, 0.95554996],\n",
       "       [0.979222  , 0.020778  ],\n",
       "       [0.97560499, 0.02439501],\n",
       "       [0.95246119, 0.04753881],\n",
       "       [0.97217311, 0.02782689],\n",
       "       [0.93406218, 0.06593782],\n",
       "       [0.12074266, 0.87925734],\n",
       "       [0.85456981, 0.14543019],\n",
       "       [0.97306694, 0.02693306],\n",
       "       [0.86814264, 0.13185736],\n",
       "       [0.99680584, 0.00319416],\n",
       "       [0.20640747, 0.79359253],\n",
       "       [0.78256562, 0.21743438],\n",
       "       [0.91554444, 0.08445556],\n",
       "       [0.98162079, 0.01837921],\n",
       "       [0.52002673, 0.47997327],\n",
       "       [0.96277904, 0.03722096],\n",
       "       [0.8926638 , 0.1073362 ],\n",
       "       [0.97532624, 0.02467376],\n",
       "       [0.9129424 , 0.0870576 ],\n",
       "       [0.48956167, 0.51043833],\n",
       "       [0.87062381, 0.12937619],\n",
       "       [0.79970609, 0.20029391],\n",
       "       [0.81805013, 0.18194987],\n",
       "       [0.03597021, 0.96402979],\n",
       "       [0.02020047, 0.97979953],\n",
       "       [0.68219023, 0.31780977],\n",
       "       [0.94290949, 0.05709051],\n",
       "       [0.84970808, 0.15029192],\n",
       "       [0.88031332, 0.11968668],\n",
       "       [0.90949961, 0.09050039],\n",
       "       [0.85593067, 0.14406933],\n",
       "       [0.98152975, 0.01847025],\n",
       "       [0.95382645, 0.04617355],\n",
       "       [0.87268822, 0.12731178],\n",
       "       [0.97463208, 0.02536792],\n",
       "       [0.94857671, 0.05142329],\n",
       "       [0.69547582, 0.30452418],\n",
       "       [0.67420338, 0.32579662],\n",
       "       [0.96127367, 0.03872633],\n",
       "       [0.96409161, 0.03590839],\n",
       "       [0.86936326, 0.13063674],\n",
       "       [0.85533861, 0.14466139],\n",
       "       [0.9381287 , 0.0618713 ],\n",
       "       [0.89642594, 0.10357406],\n",
       "       [0.07339741, 0.92660259],\n",
       "       [0.67791241, 0.32208759],\n",
       "       [0.9599459 , 0.0400541 ],\n",
       "       [0.96023133, 0.03976867],\n",
       "       [0.89354066, 0.10645934],\n",
       "       [0.81989648, 0.18010352],\n",
       "       [0.93846564, 0.06153436],\n",
       "       [0.9639924 , 0.0360076 ],\n",
       "       [0.96546386, 0.03453614],\n",
       "       [0.68254495, 0.31745505],\n",
       "       [0.83366886, 0.16633114],\n",
       "       [0.75981705, 0.24018295],\n",
       "       [0.96673486, 0.03326514],\n",
       "       [0.92831508, 0.07168492],\n",
       "       [0.98243807, 0.01756193],\n",
       "       [0.80268766, 0.19731234],\n",
       "       [0.06072268, 0.93927732],\n",
       "       [0.06314493, 0.93685507],\n",
       "       [0.98498353, 0.01501647],\n",
       "       [0.96793848, 0.03206152],\n",
       "       [0.98445016, 0.01554984],\n",
       "       [0.98651642, 0.01348358],\n",
       "       [0.98227297, 0.01772703],\n",
       "       [0.90665465, 0.09334535],\n",
       "       [0.96786943, 0.03213057],\n",
       "       [0.9649323 , 0.0350677 ],\n",
       "       [0.86795948, 0.13204052]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_preprocessed)\n",
    "y_valid_probabilities_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "AUC for LightGBM on Validation Set: 0.9547858833824253\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "print(f'AUC for LightGBM on Validation Set: {auc_score_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LightGBM: {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 170}\n"
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters for LightGBM\n",
    "best_hyperparameters_LGB = lgb_grid_search.best_params_\n",
    "print(f'Best Hyperparameters for LightGBM: {best_hyperparameters_LGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the validation set\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nauc_score_test_lgb = roc_auc_score(y_test, y_test_probabilities_lgb[:, 1])\\nprint(f'AUC for LightGBM on Test Set: {auc_score_test_lgb}')\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the test set for LightGBM\n",
    "y_test_probabilities_lgb = best_lgb_model.predict_proba(X_test_preprocessed)\n",
    "'''\n",
    "auc_score_test_lgb = roc_auc_score(y_test, y_test_probabilities_lgb[:, 1])\n",
    "print(f'AUC for LightGBM on Test Set: {auc_score_test_lgb}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.993307</td>\n",
       "      <td>0.006693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.904630</td>\n",
       "      <td>0.095370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.885515</td>\n",
       "      <td>0.114485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.982821</td>\n",
       "      <td>0.017179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.952967</td>\n",
       "      <td>0.047033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.885859</td>\n",
       "      <td>0.114141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.730128</td>\n",
       "      <td>0.269872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.923763</td>\n",
       "      <td>0.076237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.772554</td>\n",
       "      <td>0.227446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.991537</td>\n",
       "      <td>0.008463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_0    PROB_1\n",
       "0     K751808  0.993307  0.006693\n",
       "1     K837351  0.904630  0.095370\n",
       "2     K548114  0.885515  0.114485\n",
       "3     K736156  0.982821  0.017179\n",
       "4     K508080  0.952967  0.047033\n",
       "...       ...       ...       ...\n",
       "1677  K588314  0.885859  0.114141\n",
       "1678  K826807  0.730128  0.269872\n",
       "1679  K982731  0.923763  0.076237\n",
       "1680  K623037  0.772554  0.227446\n",
       "1681  K883413  0.991537  0.008463\n",
       "\n",
       "[1682 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_probabilities_lgb = pd.DataFrame(y_test_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "y_test_probabilities_lgb_with_id = pd.concat([data_test['id'], y_test_probabilities_lgb], axis=1)\n",
    "y_test_probabilities_lgb_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LGB = y_test_probabilities_lgb_with_id.iloc[:, [0, 2]]\n",
    "result_LGB.to_csv('result_LGB_4.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.006693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.095370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.114485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.017179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.047033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.114141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.269872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.076237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.227446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.008463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_1\n",
       "0     K751808  0.006693\n",
       "1     K837351  0.095370\n",
       "2     K548114  0.114485\n",
       "3     K736156  0.017179\n",
       "4     K508080  0.047033\n",
       "...       ...       ...\n",
       "1677  K588314  0.114141\n",
       "1678  K826807  0.269872\n",
       "1679  K982731  0.076237\n",
       "1680  K623037  0.227446\n",
       "1681  K883413  0.008463\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2\n",
    "\n",
    "In Option 1, you're directly tuning the hyperparameters of the LightGBM classifier (lgb_classifier) without considering the preprocessing steps. This means the hyperparameters are optimized based solely on the transformed features. LightGBM is giving you a warning about the parameters because it's detecting potential issues with the parameter values, but it still proceeds with the training.\n",
    "\n",
    "In Option 2, you're using the entire pipeline (lgb_pipeline) within the GridSearchCV. This includes the preprocessing steps and the LightGBM model. **The warnings you see are related to the features being preprocessed, and they do not affect the model optimization process. However, the optimization process may be affected by the preprocessing steps if they are not handled properly.**\n",
    "\n",
    "The difference in results, particularly the warning about non-finite test scores and the change in the best parameters and score, may indicate that the preprocessing steps in Option 2 are affecting the optimization process. It's possible that the preprocessing steps are causing issues such as feature scaling problems or missing values, leading to non-finite test scores and affecting the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\AA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                                         ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                           transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                                          &#x27;drop&#x27;,\n",
       "                                                                                          [&#x27;id&#x27;]),\n",
       "                                                                                         (&#x27;one_hot_encode&#x27;,\n",
       "                                                                                          OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                                        sparse_output=False),\n",
       "                                                                                          [&#x27;Gender&#x27;,\n",
       "                                                                                           &#x27;high &#x27;\n",
       "                                                                                           &#x27;Dropped &#x27;\n",
       "                                                                                           &#x27;calls&#x27;,\n",
       "                                                                                           &#x27;No &#x27;\n",
       "                                                                                           &#x27;Usage&#x27;]),\n",
       "                                                                                         (&#x27;WOE_encode&#x27;,\n",
       "                                                                                          WOEEncoder(),\n",
       "                                                                                          [&#x27;tariff&#x27;,\n",
       "                                                                                           &#x27;Handset&#x27;,\n",
       "                                                                                           &#x27;Usage_Band&#x27;])])),\n",
       "                                                        (&#x27;remove_prefix&#x27;,\n",
       "                                                         RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                                           &#x27;WOE_encode&#x27;,\n",
       "                                                                                           &#x27;remainder&#x27;]))])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        LGBMClassifier(is_unbalance=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;model__max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;model__n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;, scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                                         ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                           transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                                          &#x27;drop&#x27;,\n",
       "                                                                                          [&#x27;id&#x27;]),\n",
       "                                                                                         (&#x27;one_hot_encode&#x27;,\n",
       "                                                                                          OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                                        sparse_output=False),\n",
       "                                                                                          [&#x27;Gender&#x27;,\n",
       "                                                                                           &#x27;high &#x27;\n",
       "                                                                                           &#x27;Dropped &#x27;\n",
       "                                                                                           &#x27;calls&#x27;,\n",
       "                                                                                           &#x27;No &#x27;\n",
       "                                                                                           &#x27;Usage&#x27;]),\n",
       "                                                                                         (&#x27;WOE_encode&#x27;,\n",
       "                                                                                          WOEEncoder(),\n",
       "                                                                                          [&#x27;tariff&#x27;,\n",
       "                                                                                           &#x27;Handset&#x27;,\n",
       "                                                                                           &#x27;Usage_Band&#x27;])])),\n",
       "                                                        (&#x27;remove_prefix&#x27;,\n",
       "                                                         RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                                           &#x27;WOE_encode&#x27;,\n",
       "                                                                                           &#x27;remainder&#x27;]))])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        LGBMClassifier(is_unbalance=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;model__max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;model__n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;, scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;, LGBMClassifier(is_unbalance=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;id&#x27;]),\n",
       "                                                 (&#x27;one_hot_encode&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;Gender&#x27;,\n",
       "                                                   &#x27;high Dropped calls&#x27;,\n",
       "                                                   &#x27;No Usage&#x27;]),\n",
       "                                                 (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                                  [&#x27;tariff&#x27;, &#x27;Handset&#x27;,\n",
       "                                                   &#x27;Usage_Band&#x27;])])),\n",
       "                (&#x27;remove_prefix&#x27;,\n",
       "                 RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                   &#x27;WOE_encode&#x27;,\n",
       "                                                   &#x27;remainder&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;, [&#x27;id&#x27;]),\n",
       "                                (&#x27;one_hot_encode&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]),\n",
       "                                (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                 [&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop_columns</label><div class=\"sk-toggleable__content\"><pre>[&#x27;id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOE_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOEEncoder</label><div class=\"sk-toggleable__content\"><pre>WOEEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;Connect_Date&#x27;, &#x27;L_O_S&#x27;, &#x27;Dropped_Calls&#x27;, &#x27;Peak_calls_Sum&#x27;, &#x27;Peak_mins_Sum&#x27;, &#x27;OffPeak_calls_Sum&#x27;, &#x27;OffPeak_mins_Sum&#x27;, &#x27;Weekend_calls_Sum&#x27;, &#x27;Weekend_mins_Sum&#x27;, &#x27;International_mins_Sum&#x27;, &#x27;Nat_call_cost_Sum&#x27;, &#x27;AvePeak&#x27;, &#x27;AveOffPeak&#x27;, &#x27;AveWeekend&#x27;, &#x27;National_calls&#x27;, &#x27;National mins&#x27;, &#x27;AveNational&#x27;, &#x27;All_calls_mins&#x27;, &#x27;Dropped_calls_ratio&#x27;, &#x27;Mins_charge&#x27;, &#x27;call_cost_per_min&#x27;, &#x27;actual call cost&#x27;, &#x27;Total_call_cost&#x27;, &#x27;Total_Cost&#x27;, &#x27;Tariff_OK&#x27;, &#x27;average cost min&#x27;, &#x27;Peak ratio&#x27;, &#x27;OffPeak ratio&#x27;, &#x27;Weekend ratio&#x27;, &#x27;Nat-InterNat Ratio&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePrefixTransformer</label><div class=\"sk-toggleable__content\"><pre>RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;, &#x27;WOE_encode&#x27;, &#x27;remainder&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        Pipeline(steps=[('preprocessor',\n",
       "                                                         ColumnTransformer(remainder='passthrough',\n",
       "                                                                           transformers=[('drop_columns',\n",
       "                                                                                          'drop',\n",
       "                                                                                          ['id']),\n",
       "                                                                                         ('one_hot_encode',\n",
       "                                                                                          OneHotEncoder(drop='first',\n",
       "                                                                                                        sparse_output=False),\n",
       "                                                                                          ['Gender',\n",
       "                                                                                           'high '\n",
       "                                                                                           'Dropped '\n",
       "                                                                                           'calls',\n",
       "                                                                                           'No '\n",
       "                                                                                           'Usage']),\n",
       "                                                                                         ('WOE_encode',\n",
       "                                                                                          WOEEncoder(),\n",
       "                                                                                          ['tariff',\n",
       "                                                                                           'Handset',\n",
       "                                                                                           'Usage_Band'])])),\n",
       "                                                        ('remove_prefix',\n",
       "                                                         RemovePrefixTransformer(prefixes=['one_hot_encode',\n",
       "                                                                                           'WOE_encode',\n",
       "                                                                                           'remainder']))])),\n",
       "                                       ('model',\n",
       "                                        LGBMClassifier(is_unbalance=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       "                         'model__max_depth': [1, 2, 3, 4, 5],\n",
       "                         'model__n_estimators': [150, 160, 170, 180, 190, 200]},\n",
       "             refit='auc', scoring={'auc': 'roc_auc'})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "lgb_param_grid = {\n",
    "    'model__n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'model__max_depth': [1, 2, 3, 4, 5],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM\n",
    "lgb_grid_search = GridSearchCV(lgb_pipeline, lgb_param_grid, scoring={'auc': 'roc_auc'}, refit='auc', verbose=0, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;id&#x27;]),\n",
       "                                                 (&#x27;one_hot_encode&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;Gender&#x27;,\n",
       "                                                   &#x27;high Dropped calls&#x27;,\n",
       "                                                   &#x27;No Usage&#x27;]),\n",
       "                                                 (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                                  [&#x27;tariff&#x27;, &#x27;Handset&#x27;,\n",
       "                                                   &#x27;Usage_Band&#x27;])])),\n",
       "                (&#x27;remove_prefix&#x27;,\n",
       "                 RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                   &#x27;WOE_encode&#x27;,\n",
       "                                                   &#x27;remainder&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;, [&#x27;id&#x27;]),\n",
       "                                (&#x27;one_hot_encode&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]),\n",
       "                                (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                 [&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop_columns</label><div class=\"sk-toggleable__content\"><pre>[&#x27;id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOE_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOEEncoder</label><div class=\"sk-toggleable__content\"><pre>WOEEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;Connect_Date&#x27;, &#x27;L_O_S&#x27;, &#x27;Dropped_Calls&#x27;, &#x27;Peak_calls_Sum&#x27;, &#x27;Peak_mins_Sum&#x27;, &#x27;OffPeak_calls_Sum&#x27;, &#x27;OffPeak_mins_Sum&#x27;, &#x27;Weekend_calls_Sum&#x27;, &#x27;Weekend_mins_Sum&#x27;, &#x27;International_mins_Sum&#x27;, &#x27;Nat_call_cost_Sum&#x27;, &#x27;AvePeak&#x27;, &#x27;AveOffPeak&#x27;, &#x27;AveWeekend&#x27;, &#x27;National_calls&#x27;, &#x27;National mins&#x27;, &#x27;AveNational&#x27;, &#x27;All_calls_mins&#x27;, &#x27;Dropped_calls_ratio&#x27;, &#x27;Mins_charge&#x27;, &#x27;call_cost_per_min&#x27;, &#x27;actual call cost&#x27;, &#x27;Total_call_cost&#x27;, &#x27;Total_Cost&#x27;, &#x27;Tariff_OK&#x27;, &#x27;average cost min&#x27;, &#x27;Peak ratio&#x27;, &#x27;OffPeak ratio&#x27;, &#x27;Weekend ratio&#x27;, &#x27;Nat-InterNat Ratio&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePrefixTransformer</label><div class=\"sk-toggleable__content\"><pre>RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;, &#x27;WOE_encode&#x27;, &#x27;remainder&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, learning_rate=0.01, max_depth=1,\n",
       "               n_estimators=150)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('preprocessor',\n",
       "                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                    transformers=[('drop_columns',\n",
       "                                                                   'drop',\n",
       "                                                                   ['id']),\n",
       "                                                                  ('one_hot_encode',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   ['Gender',\n",
       "                                                                    'high '\n",
       "                                                                    'Dropped '\n",
       "                                                                    'calls',\n",
       "                                                                    'No '\n",
       "                                                                    'Usage']),\n",
       "                                                                  ('WOE_encode',\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   ['tariff',\n",
       "                                                                    'Handset',\n",
       "                                                                    'Usage_Band'])])),\n",
       "                                 ('remove_prefix',\n",
       "                                  RemovePrefixTransformer(prefixes=['one_hot_encode',\n",
       "                                                                    'WOE_encode',\n",
       "                                                                    'remainder']))])),\n",
       "                ('model',\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_grid_search.best_estimator_ #has the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: nan\n",
      "Best Parameters: {'model__learning_rate': 0.01, 'model__max_depth': 1, 'model__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", lgb_grid_search.best_score_)\n",
    "print(\"Best Parameters:\", lgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;id&#x27;]),\n",
       "                                                 (&#x27;one_hot_encode&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;Gender&#x27;,\n",
       "                                                   &#x27;high Dropped calls&#x27;,\n",
       "                                                   &#x27;No Usage&#x27;]),\n",
       "                                                 (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                                  [&#x27;tariff&#x27;, &#x27;Handset&#x27;,\n",
       "                                                   &#x27;Usage_Band&#x27;])])),\n",
       "                (&#x27;remove_prefix&#x27;,\n",
       "                 RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                   &#x27;WOE_encode&#x27;,\n",
       "                                                   &#x27;remainder&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;, [&#x27;id&#x27;]),\n",
       "                                (&#x27;one_hot_encode&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]),\n",
       "                                (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                 [&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop_columns</label><div class=\"sk-toggleable__content\"><pre>[&#x27;id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOE_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOEEncoder</label><div class=\"sk-toggleable__content\"><pre>WOEEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;Connect_Date&#x27;, &#x27;L_O_S&#x27;, &#x27;Dropped_Calls&#x27;, &#x27;Peak_calls_Sum&#x27;, &#x27;Peak_mins_Sum&#x27;, &#x27;OffPeak_calls_Sum&#x27;, &#x27;OffPeak_mins_Sum&#x27;, &#x27;Weekend_calls_Sum&#x27;, &#x27;Weekend_mins_Sum&#x27;, &#x27;International_mins_Sum&#x27;, &#x27;Nat_call_cost_Sum&#x27;, &#x27;AvePeak&#x27;, &#x27;AveOffPeak&#x27;, &#x27;AveWeekend&#x27;, &#x27;National_calls&#x27;, &#x27;National mins&#x27;, &#x27;AveNational&#x27;, &#x27;All_calls_mins&#x27;, &#x27;Dropped_calls_ratio&#x27;, &#x27;Mins_charge&#x27;, &#x27;call_cost_per_min&#x27;, &#x27;actual call cost&#x27;, &#x27;Total_call_cost&#x27;, &#x27;Total_Cost&#x27;, &#x27;Tariff_OK&#x27;, &#x27;average cost min&#x27;, &#x27;Peak ratio&#x27;, &#x27;OffPeak ratio&#x27;, &#x27;Weekend ratio&#x27;, &#x27;Nat-InterNat Ratio&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePrefixTransformer</label><div class=\"sk-toggleable__content\"><pre>RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;, &#x27;WOE_encode&#x27;, &#x27;remainder&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, learning_rate=0.01, max_depth=1,\n",
       "               n_estimators=150)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('preprocessor',\n",
       "                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                    transformers=[('drop_columns',\n",
       "                                                                   'drop',\n",
       "                                                                   ['id']),\n",
       "                                                                  ('one_hot_encode',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   ['Gender',\n",
       "                                                                    'high '\n",
       "                                                                    'Dropped '\n",
       "                                                                    'calls',\n",
       "                                                                    'No '\n",
       "                                                                    'Usage']),\n",
       "                                                                  ('WOE_encode',\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   ['tariff',\n",
       "                                                                    'Handset',\n",
       "                                                                    'Usage_Band'])])),\n",
       "                                 ('remove_prefix',\n",
       "                                  RemovePrefixTransformer(prefixes=['one_hot_encode',\n",
       "                                                                    'WOE_encode',\n",
       "                                                                    'remainder']))])),\n",
       "                ('model',\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_split, y_train_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = best_lgb_model.predict(X_valid_split)\n",
    "# Set the printing options to display all elements of the array\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Print the entire array of predictions\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.7160099 , 0.2839901 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.76520071, 0.23479929],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7160099 , 0.2839901 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.76520071, 0.23479929],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.76520071, 0.23479929],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.76520071, 0.23479929],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7160099 , 0.2839901 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.76520071, 0.23479929],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.76520071, 0.23479929],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.27218332, 0.72781668],\n",
       "       [0.60401895, 0.39598105],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.7787287 , 0.2212713 ],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.81979004, 0.18020996],\n",
       "       [0.60401895, 0.39598105]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_split)\n",
    "y_valid_probabilities_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for LightGBM on Validation Set: 0.8868162605183176\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_split)\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "print(f'AUC for LightGBM on Validation Set: {auc_score_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LightGBM: {'model__learning_rate': 0.01, 'model__max_depth': 1, 'model__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters for LightGBM\n",
    "best_hyperparameters_LGB = lgb_grid_search.best_params_\n",
    "print(f'Best Hyperparameters for LightGBM: {best_hyperparameters_LGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nauc_score_test_lgb = roc_auc_score(y_test, y_test_probabilities_lgb[:, 1])\\nprint(f'AUC for LightGBM on Test Set: {auc_score_test_lgb}')\\n\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the test set for LightGBM\n",
    "y_test_probabilities_lgb = best_lgb_model.predict_proba(X_test)\n",
    "'''\n",
    "auc_score_test_lgb = roc_auc_score(y_test, y_test_probabilities_lgb[:, 1])\n",
    "print(f'AUC for LightGBM on Test Set: {auc_score_test_lgb}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.819790</td>\n",
       "      <td>0.180210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.604019</td>\n",
       "      <td>0.395981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.819790</td>\n",
       "      <td>0.180210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.819790</td>\n",
       "      <td>0.180210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.819790</td>\n",
       "      <td>0.180210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.604019</td>\n",
       "      <td>0.395981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.604019</td>\n",
       "      <td>0.395981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.604019</td>\n",
       "      <td>0.395981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.604019</td>\n",
       "      <td>0.395981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.819790</td>\n",
       "      <td>0.180210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_0    PROB_1\n",
       "0     K751808  0.819790  0.180210\n",
       "1     K837351  0.604019  0.395981\n",
       "2     K548114  0.819790  0.180210\n",
       "3     K736156  0.819790  0.180210\n",
       "4     K508080  0.819790  0.180210\n",
       "...       ...       ...       ...\n",
       "1677  K588314  0.604019  0.395981\n",
       "1678  K826807  0.604019  0.395981\n",
       "1679  K982731  0.604019  0.395981\n",
       "1680  K623037  0.604019  0.395981\n",
       "1681  K883413  0.819790  0.180210\n",
       "\n",
       "[1682 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_probabilities_lgb\n",
    "y_test_probabilities_lgb = pd.DataFrame(y_test_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "y_test_probabilities_lgb_with_id = pd.concat([data_test['id'], y_test_probabilities_lgb], axis=1)\n",
    "y_test_probabilities_lgb_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LGB = y_test_probabilities_lgb_with_id.iloc[:, [0, 2]]\n",
    "result_LGB.to_csv('result_LGB_5.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the LGBM model from the pipeline\n",
    "best_lgb_model = lgb_grid_search.best_estimator_.named_steps['model']\n",
    "\n",
    "# Get feature importances from the LGBM model\n",
    "feature_importances = best_lgb_model.feature_importances_\n",
    "\n",
    "# Map feature names to their importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort features based on their importance\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print or visualize the feature importance\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sofia taak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=10)\n",
    "search=BayesSearchCV(model,search_spaces=random_grid,n_jobs=-1,cv=cv,n_iter=50, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Find optimal parameters\n",
    "search.fit(X_train,y_train)\n",
    "search.best_score_\n",
    "search.best_estimator_\n",
    "search.best_params_\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_val)\n",
    "MSE = mean_squared_error(y_val, pred)\n",
    "RMSE=np.sqrt(MSE)\n",
    "RMSE\n",
    "MAE=mean_absolute_error(y_val, pred)\n",
    "MAE\n",
    "\n",
    "\n",
    "pred_f = model.predict(df_test)\n",
    "pred_df = df_test[['property_id']]\n",
    "pred_df['pred_price'] = pred_f\n",
    "pred_df.to_csv('pred_rf_pipe2.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHATGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "\n",
    "# Define evaluation metrics\n",
    "def profit_at_top_20(y_true, y_probabilities, top_k=20):\n",
    "    # Extract probabilities for positive class\n",
    "    churn_probabilities = y_probabilities[:, 1]\n",
    "\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    sorted_indices = sorted(range(len(churn_probabilities)), key=lambda k: churn_probabilities[k], reverse=True)\n",
    "\n",
    "    return profit\n",
    "\n",
    "# Define custom scorer for use in GridSearchCV or RandomizedSearchCV\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True)\n",
    "\n",
    "# Function to calculate profit metric on test set\n",
    "def calculate_profit_metric(y_probabilities, dataset):\n",
    "    # Extract probabilities for positive class\n",
    "    churn_probabilities = y_probabilities[:, 1]\n",
    "\n",
    "    # Create DataFrame with churn probabilities and corresponding profitability\n",
    "    profit_df = pd.DataFrame({\"churn_prob\": churn_probabilities, \"profit\": dataset[\"average cost min\"]})\n",
    "\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    profit_df = profit_df.sort_values(by='churn_prob', ascending=False)\n",
    "\n",
    "    # Calculate profit @ top-20\n",
    "    top_20_profit = profit_df[\"profit\"][:20].sum()\n",
    "\n",
    "    return top_20_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "\n",
    "lgb_classifier = lgb.LGBMClassifier(is_unbalance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\AA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;,\n",
       "             scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;profit_at_top_20&#x27;: make_scorer(profit_at_top_20)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;,\n",
       "             scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;profit_at_top_20&#x27;: make_scorer(profit_at_top_20)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       "                         'max_depth': [1, 2, 3, 4, 5],\n",
       "                         'n_estimators': [150, 160, 170, 180, 190, 200]},\n",
       "             refit='auc',\n",
       "             scoring={'auc': 'roc_auc',\n",
       "                      'profit_at_top_20': make_scorer(profit_at_top_20)})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define evaluation metrics to include in GridSearchCV scoring\n",
    "scoring = {'auc': 'roc_auc', 'profit_at_top_20': profit_at_top_20_scorer}\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM\n",
    "lgb_grid_search = GridSearchCV(lgb_classifier, lgb_param_grid, scoring=scoring, refit='auc', verbose=0, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_preprocessed, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "AUC Score: 0.9547858833824253\n",
      "Profit @ Top-20: 3.459009\n"
     ]
    }
   ],
   "source": [
    "# Access the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Apply preprocessing pipeline to the validation set\n",
    "X_valid_preprocessed = preprocessing_pipeline.transform(X_valid_split)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_preprocessed)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "# Calculate profit metric\n",
    "profit_metric = calculate_profit_metric(y_valid_probabilities_lgb, X_valid_split)\n",
    "\n",
    "print(f'AUC Score: {auc_score_lgb}')\n",
    "print(f'Profit @ Top-20: {profit_metric}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2 CHATGPT: don 't use y_proba but y_pred because \"based on the top-k would-be churners as predicted by your model, sum some proxy of \"retained profitability\" in case the customer was indeed a churner, or zero otherwise\" SO DO * y_true want als dat = 1, dan mag je alleen de profit tellen\n",
    "\n",
    "\n",
    "In this version:\n",
    "\n",
    "The profit_at_top_20 function now accepts y_true and y_pred, where y_pred is the predicted labels.\n",
    "The profit_at_top_20_scorer created using make_scorer ensures that profit_at_top_20 function is used for calculating the profit at top-20 during the GridSearchCV process.\n",
    "During the GridSearchCV process, y_pred (the predicted labels) will be passed to the profit_at_top_20 function along with y_true for each fold during cross-validation. This allows GridSearchCV to evaluate the model based on both AUC and profit at top-20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509692 -> initscore=0.038773\n",
      "[LightGBM] [Info] Start training from score 0.038773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\AA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-25 {color: black;}#sk-container-id-25 pre{padding: 0;}#sk-container-id-25 div.sk-toggleable {background-color: white;}#sk-container-id-25 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-25 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-25 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-25 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-25 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-25 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-25 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-25 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-25 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-25 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-25 div.sk-item {position: relative;z-index: 1;}#sk-container-id-25 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-25 div.sk-item::before, #sk-container-id-25 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-25 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-25 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-25 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-25 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-25 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-25 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-25 div.sk-label-container {text-align: center;}#sk-container-id-25 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-25 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(class_weight={0: 1, 1: 6}),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [1, 3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [140, 160, 180, 200]},\n",
       "             refit=&#x27;profit_at_top_20&#x27;,\n",
       "             scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;profit_at_top_20&#x27;: make_scorer(profit_at_top_20)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-88\" type=\"checkbox\" ><label for=\"sk-estimator-id-88\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(class_weight={0: 1, 1: 6}),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                         &#x27;max_depth&#x27;: [1, 3, 5, 7],\n",
       "                         &#x27;n_estimators&#x27;: [140, 160, 180, 200]},\n",
       "             refit=&#x27;profit_at_top_20&#x27;,\n",
       "             scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;profit_at_top_20&#x27;: make_scorer(profit_at_top_20)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-89\" type=\"checkbox\" ><label for=\"sk-estimator-id-89\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight={0: 1, 1: 6})</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight={0: 1, 1: 6})</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(class_weight={0: 1, 1: 6}),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'max_depth': [1, 3, 5, 7],\n",
       "                         'n_estimators': [140, 160, 180, 200]},\n",
       "             refit='profit_at_top_20',\n",
       "             scoring={'auc': 'roc_auc',\n",
       "                      'profit_at_top_20': make_scorer(profit_at_top_20)})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define evaluation metrics\n",
    "def profit_at_top_20(y_true, y_pred, top_k=20):\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    sorted_indices = sorted(range(len(y_pred)), key=lambda k: y_pred[k, 1], reverse=True)\n",
    "\n",
    "    # Identify the top-20 customers\n",
    "    top_20_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Calculate profit at top-20\n",
    "    profit = sum(y_true[i] * y_pred[i, 1] for i in top_20_indices)\n",
    "\n",
    "    return profit\n",
    "\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True)\n",
    "\n",
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "########## NEW GRID ##########\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [140, 160, 180, 200],        # Number of boosting rounds\n",
    "    'max_depth': [1, 3, 5, 7],                     # Maximum depth of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1],         # Learning rate\n",
    "    #'num_leaves': [20, 30, 40],                 # Maximum number of leaves per tree\n",
    "    #'min_data_in_leaf': [20, 30, 40],           # Minimum number of samples required to be at a leaf node\n",
    "    #'bagging_fraction': [0.6, 0.7, 0.8],        # Fraction of data to be randomly sampled for training each tree\n",
    "    #'lambda_l1': [0.1, 0.3, 0.5],               # L1 regularization parameter\n",
    "    #'lambda_l2': [0.1, 0.3, 0.5],               # L2 regularization parameter\n",
    "    #'max_bin': [100, 150, 200]                  # Maximum number of bins\n",
    "}\n",
    "\n",
    "\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "\n",
    "\n",
    "\n",
    "# Define cost matrix\n",
    "cost_matrix = np.array([[0, 1],  # Cost of false positive\n",
    "                        [6, 0]])  # Cost of false negative\n",
    "\n",
    "###### ADD COST SENSITIVITY BECAUSE NOW I GET THE RESULTS FROM USING THE FULL PIPELINE IN 1 GO, nl. AUC Score: 0.8868162605183176 and Profit @ Top-20: 4.134671\n",
    "\n",
    "# Convert cost matrix to a dictionary\n",
    "class_weights = {0: cost_matrix[0, 1],  # Class 0 (non-churner) weight\n",
    "                 1: cost_matrix[1, 0]}  # Class 1 (churner) weight\n",
    "\n",
    "# Pass class weights dictionary to LightGBM model\n",
    "lgb_classifier = lgb.LGBMClassifier(class_weight=class_weights) #ipv is_unbalanced = True\n",
    "\n",
    "\n",
    "\n",
    "# Define custom scorer for use in GridSearchCV or RandomizedSearchCV\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True)\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM with custom scoring\n",
    "lgb_grid_search = GridSearchCV(lgb_classifier, lgb_param_grid, scoring={'profit_at_top_20': profit_at_top_20_scorer, 'auc': 'roc_auc'}, refit='profit_at_top_20', verbose=0, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_preprocessed, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509692 -> initscore=0.038773\n",
      "[LightGBM] [Info] Start training from score 0.038773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight={0: 1, 1: 6}, learning_rate=0.01, max_depth=1,\n",
       "               n_estimators=140)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" checked><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight={0: 1, 1: 6}, learning_rate=0.01, max_depth=1,\n",
       "               n_estimators=140)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight={0: 1, 1: 6}, learning_rate=0.01, max_depth=1,\n",
       "               n_estimators=140)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_preprocessed, y_train_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8781203365861662\n",
      "Profit @ Top-20: 4.100587\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing pipeline to the validation set\n",
    "X_valid_preprocessed = preprocessing_pipeline.transform(X_valid_split)\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_preprocessed)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "# Calculate profit metric\n",
    "profit_metric = calculate_profit_metric(y_valid_probabilities_lgb, X_valid_split)\n",
    "\n",
    "print(f'AUC Score: {auc_score_lgb}')\n",
    "print(f'Profit @ Top-20: {profit_metric}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LightGBM: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 140}\n"
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters for LightGBM\n",
    "best_hyperparameters_LGB = lgb_grid_search.best_params_\n",
    "print(f'Best Hyperparameters for LightGBM: {best_hyperparameters_LGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.643029</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.391280</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.643029</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.643029</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.643029</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.391280</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.391280</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.391280</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.391280</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.643029</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_0    PROB_1\n",
       "0     K751808  0.643029  0.356971\n",
       "1     K837351  0.391280  0.608720\n",
       "2     K548114  0.643029  0.356971\n",
       "3     K736156  0.643029  0.356971\n",
       "4     K508080  0.643029  0.356971\n",
       "...       ...       ...       ...\n",
       "1677  K588314  0.391280  0.608720\n",
       "1678  K826807  0.391280  0.608720\n",
       "1679  K982731  0.391280  0.608720\n",
       "1680  K623037  0.391280  0.608720\n",
       "1681  K883413  0.643029  0.356971\n",
       "\n",
       "[1682 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply preprocessing pipeline to the validation set\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "# Evaluate on the test set for LightGBM\n",
    "y_test_probabilities_lgb = best_lgb_model.predict_proba(X_test_preprocessed)\n",
    "y_test_probabilities_lgb = pd.DataFrame(y_test_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "y_test_probabilities_lgb_with_id = pd.concat([data_test['id'], y_test_probabilities_lgb], axis=1)\n",
    "y_test_probabilities_lgb_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.608720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.356971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_1\n",
       "0     K751808  0.356971\n",
       "1     K837351  0.608720\n",
       "2     K548114  0.356971\n",
       "3     K736156  0.356971\n",
       "4     K508080  0.356971\n",
       "...       ...       ...\n",
       "1677  K588314  0.608720\n",
       "1678  K826807  0.608720\n",
       "1679  K982731  0.608720\n",
       "1680  K623037  0.608720\n",
       "1681  K883413  0.356971\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LGB = y_test_probabilities_lgb_with_id.iloc[:, [0, 2]]\n",
    "result_LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LGB.to_csv('result_LGB_5.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\AA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                                         ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                           transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                                          &#x27;drop&#x27;,\n",
       "                                                                                          [&#x27;id&#x27;]),\n",
       "                                                                                         (&#x27;one_hot_encode&#x27;,\n",
       "                                                                                          OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                                        sparse_output=False),\n",
       "                                                                                          [&#x27;Gender&#x27;,\n",
       "                                                                                           &#x27;high &#x27;\n",
       "                                                                                           &#x27;Dropped &#x27;\n",
       "                                                                                           &#x27;calls&#x27;,\n",
       "                                                                                           &#x27;No &#x27;\n",
       "                                                                                           &#x27;Usage&#x27;]),\n",
       "                                                                                         (&#x27;WOE_encode&#x27;,\n",
       "                                                                                          WOEEncoder(),\n",
       "                                                                                          [&#x27;tariff&#x27;,\n",
       "                                                                                           &#x27;Handset&#x27;,\n",
       "                                                                                           &#x27;Usage_Ban...\n",
       "                                                         RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                                           &#x27;WOE_encode&#x27;,\n",
       "                                                                                           &#x27;remainder&#x27;]))])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        LGBMClassifier(is_unbalance=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;model__max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;model__n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;profit_at_top_20&#x27;,\n",
       "             scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;profit_at_top_20&#x27;: make_scorer(profit_at_top_20)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                                        Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                                         ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                                           transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                                          &#x27;drop&#x27;,\n",
       "                                                                                          [&#x27;id&#x27;]),\n",
       "                                                                                         (&#x27;one_hot_encode&#x27;,\n",
       "                                                                                          OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                                        sparse_output=False),\n",
       "                                                                                          [&#x27;Gender&#x27;,\n",
       "                                                                                           &#x27;high &#x27;\n",
       "                                                                                           &#x27;Dropped &#x27;\n",
       "                                                                                           &#x27;calls&#x27;,\n",
       "                                                                                           &#x27;No &#x27;\n",
       "                                                                                           &#x27;Usage&#x27;]),\n",
       "                                                                                         (&#x27;WOE_encode&#x27;,\n",
       "                                                                                          WOEEncoder(),\n",
       "                                                                                          [&#x27;tariff&#x27;,\n",
       "                                                                                           &#x27;Handset&#x27;,\n",
       "                                                                                           &#x27;Usage_Ban...\n",
       "                                                         RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                                           &#x27;WOE_encode&#x27;,\n",
       "                                                                                           &#x27;remainder&#x27;]))])),\n",
       "                                       (&#x27;model&#x27;,\n",
       "                                        LGBMClassifier(is_unbalance=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;model__learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;model__max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;model__n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;profit_at_top_20&#x27;,\n",
       "             scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;profit_at_top_20&#x27;: make_scorer(profit_at_top_20)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;, LGBMClassifier(is_unbalance=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;id&#x27;]),\n",
       "                                                 (&#x27;one_hot_encode&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;Gender&#x27;,\n",
       "                                                   &#x27;high Dropped calls&#x27;,\n",
       "                                                   &#x27;No Usage&#x27;]),\n",
       "                                                 (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                                  [&#x27;tariff&#x27;, &#x27;Handset&#x27;,\n",
       "                                                   &#x27;Usage_Band&#x27;])])),\n",
       "                (&#x27;remove_prefix&#x27;,\n",
       "                 RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                   &#x27;WOE_encode&#x27;,\n",
       "                                                   &#x27;remainder&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-96\" type=\"checkbox\" ><label for=\"sk-estimator-id-96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;, [&#x27;id&#x27;]),\n",
       "                                (&#x27;one_hot_encode&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]),\n",
       "                                (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                 [&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-97\" type=\"checkbox\" ><label for=\"sk-estimator-id-97\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop_columns</label><div class=\"sk-toggleable__content\"><pre>[&#x27;id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-98\" type=\"checkbox\" ><label for=\"sk-estimator-id-98\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-99\" type=\"checkbox\" ><label for=\"sk-estimator-id-99\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-100\" type=\"checkbox\" ><label for=\"sk-estimator-id-100\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-101\" type=\"checkbox\" ><label for=\"sk-estimator-id-101\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOE_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-102\" type=\"checkbox\" ><label for=\"sk-estimator-id-102\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOEEncoder</label><div class=\"sk-toggleable__content\"><pre>WOEEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-103\" type=\"checkbox\" ><label for=\"sk-estimator-id-103\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-104\" type=\"checkbox\" ><label for=\"sk-estimator-id-104\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-105\" type=\"checkbox\" ><label for=\"sk-estimator-id-105\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePrefixTransformer</label><div class=\"sk-toggleable__content\"><pre>RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;, &#x27;WOE_encode&#x27;, &#x27;remainder&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-106\" type=\"checkbox\" ><label for=\"sk-estimator-id-106\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessing',\n",
       "                                        Pipeline(steps=[('preprocessor',\n",
       "                                                         ColumnTransformer(remainder='passthrough',\n",
       "                                                                           transformers=[('drop_columns',\n",
       "                                                                                          'drop',\n",
       "                                                                                          ['id']),\n",
       "                                                                                         ('one_hot_encode',\n",
       "                                                                                          OneHotEncoder(drop='first',\n",
       "                                                                                                        sparse_output=False),\n",
       "                                                                                          ['Gender',\n",
       "                                                                                           'high '\n",
       "                                                                                           'Dropped '\n",
       "                                                                                           'calls',\n",
       "                                                                                           'No '\n",
       "                                                                                           'Usage']),\n",
       "                                                                                         ('WOE_encode',\n",
       "                                                                                          WOEEncoder(),\n",
       "                                                                                          ['tariff',\n",
       "                                                                                           'Handset',\n",
       "                                                                                           'Usage_Ban...\n",
       "                                                         RemovePrefixTransformer(prefixes=['one_hot_encode',\n",
       "                                                                                           'WOE_encode',\n",
       "                                                                                           'remainder']))])),\n",
       "                                       ('model',\n",
       "                                        LGBMClassifier(is_unbalance=True))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       "                         'model__max_depth': [1, 2, 3, 4, 5],\n",
       "                         'model__n_estimators': [150, 160, 170, 180, 190, 200]},\n",
       "             refit='profit_at_top_20',\n",
       "             scoring={'auc': 'roc_auc',\n",
       "                      'profit_at_top_20': make_scorer(profit_at_top_20)})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "lgb_param_grid = {\n",
    "    'model__n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'model__max_depth': [1, 2, 3, 4, 5],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM\n",
    "lgb_grid_search = GridSearchCV(lgb_pipeline, lgb_param_grid, scoring={'profit_at_top_20': profit_at_top_20_scorer, 'auc': 'roc_auc'}, refit='profit_at_top_20', verbose=0, cv=5, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-107\" type=\"checkbox\" ><label for=\"sk-estimator-id-107\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                  ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                    transformers=[(&#x27;drop_columns&#x27;,\n",
       "                                                                   &#x27;drop&#x27;,\n",
       "                                                                   [&#x27;id&#x27;]),\n",
       "                                                                  (&#x27;one_hot_encode&#x27;,\n",
       "                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   [&#x27;Gender&#x27;,\n",
       "                                                                    &#x27;high &#x27;\n",
       "                                                                    &#x27;Dropped &#x27;\n",
       "                                                                    &#x27;calls&#x27;,\n",
       "                                                                    &#x27;No &#x27;\n",
       "                                                                    &#x27;Usage&#x27;]),\n",
       "                                                                  (&#x27;WOE_encode&#x27;,\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   [&#x27;tariff&#x27;,\n",
       "                                                                    &#x27;Handset&#x27;,\n",
       "                                                                    &#x27;Usage_Band&#x27;])])),\n",
       "                                 (&#x27;remove_prefix&#x27;,\n",
       "                                  RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                                    &#x27;WOE_encode&#x27;,\n",
       "                                                                    &#x27;remainder&#x27;]))])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-108\" type=\"checkbox\" ><label for=\"sk-estimator-id-108\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;id&#x27;]),\n",
       "                                                 (&#x27;one_hot_encode&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                                                sparse_output=False),\n",
       "                                                  [&#x27;Gender&#x27;,\n",
       "                                                   &#x27;high Dropped calls&#x27;,\n",
       "                                                   &#x27;No Usage&#x27;]),\n",
       "                                                 (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                                  [&#x27;tariff&#x27;, &#x27;Handset&#x27;,\n",
       "                                                   &#x27;Usage_Band&#x27;])])),\n",
       "                (&#x27;remove_prefix&#x27;,\n",
       "                 RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;,\n",
       "                                                   &#x27;WOE_encode&#x27;,\n",
       "                                                   &#x27;remainder&#x27;]))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-109\" type=\"checkbox\" ><label for=\"sk-estimator-id-109\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;drop_columns&#x27;, &#x27;drop&#x27;, [&#x27;id&#x27;]),\n",
       "                                (&#x27;one_hot_encode&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;first&#x27;,\n",
       "                                               sparse_output=False),\n",
       "                                 [&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]),\n",
       "                                (&#x27;WOE_encode&#x27;, WOEEncoder(),\n",
       "                                 [&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-110\" type=\"checkbox\" ><label for=\"sk-estimator-id-110\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop_columns</label><div class=\"sk-toggleable__content\"><pre>[&#x27;id&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-111\" type=\"checkbox\" ><label for=\"sk-estimator-id-111\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-112\" type=\"checkbox\" ><label for=\"sk-estimator-id-112\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">one_hot_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gender&#x27;, &#x27;high Dropped calls&#x27;, &#x27;No Usage&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-113\" type=\"checkbox\" ><label for=\"sk-estimator-id-113\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse_output=False)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-114\" type=\"checkbox\" ><label for=\"sk-estimator-id-114\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOE_encode</label><div class=\"sk-toggleable__content\"><pre>[&#x27;tariff&#x27;, &#x27;Handset&#x27;, &#x27;Usage_Band&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-115\" type=\"checkbox\" ><label for=\"sk-estimator-id-115\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">WOEEncoder</label><div class=\"sk-toggleable__content\"><pre>WOEEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-116\" type=\"checkbox\" ><label for=\"sk-estimator-id-116\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Age&#x27;, &#x27;Connect_Date&#x27;, &#x27;L_O_S&#x27;, &#x27;Dropped_Calls&#x27;, &#x27;Peak_calls_Sum&#x27;, &#x27;Peak_mins_Sum&#x27;, &#x27;OffPeak_calls_Sum&#x27;, &#x27;OffPeak_mins_Sum&#x27;, &#x27;Weekend_calls_Sum&#x27;, &#x27;Weekend_mins_Sum&#x27;, &#x27;International_mins_Sum&#x27;, &#x27;Nat_call_cost_Sum&#x27;, &#x27;AvePeak&#x27;, &#x27;AveOffPeak&#x27;, &#x27;AveWeekend&#x27;, &#x27;National_calls&#x27;, &#x27;National mins&#x27;, &#x27;AveNational&#x27;, &#x27;All_calls_mins&#x27;, &#x27;Dropped_calls_ratio&#x27;, &#x27;Mins_charge&#x27;, &#x27;call_cost_per_min&#x27;, &#x27;actual call cost&#x27;, &#x27;Total_call_cost&#x27;, &#x27;Total_Cost&#x27;, &#x27;Tariff_OK&#x27;, &#x27;average cost min&#x27;, &#x27;Peak ratio&#x27;, &#x27;OffPeak ratio&#x27;, &#x27;Weekend ratio&#x27;, &#x27;Nat-InterNat Ratio&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-117\" type=\"checkbox\" ><label for=\"sk-estimator-id-117\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-118\" type=\"checkbox\" ><label for=\"sk-estimator-id-118\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RemovePrefixTransformer</label><div class=\"sk-toggleable__content\"><pre>RemovePrefixTransformer(prefixes=[&#x27;one_hot_encode&#x27;, &#x27;WOE_encode&#x27;, &#x27;remainder&#x27;])</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-119\" type=\"checkbox\" ><label for=\"sk-estimator-id-119\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, learning_rate=0.01, max_depth=1,\n",
       "               n_estimators=150)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 Pipeline(steps=[('preprocessor',\n",
       "                                  ColumnTransformer(remainder='passthrough',\n",
       "                                                    transformers=[('drop_columns',\n",
       "                                                                   'drop',\n",
       "                                                                   ['id']),\n",
       "                                                                  ('one_hot_encode',\n",
       "                                                                   OneHotEncoder(drop='first',\n",
       "                                                                                 sparse_output=False),\n",
       "                                                                   ['Gender',\n",
       "                                                                    'high '\n",
       "                                                                    'Dropped '\n",
       "                                                                    'calls',\n",
       "                                                                    'No '\n",
       "                                                                    'Usage']),\n",
       "                                                                  ('WOE_encode',\n",
       "                                                                   WOEEncoder(),\n",
       "                                                                   ['tariff',\n",
       "                                                                    'Handset',\n",
       "                                                                    'Usage_Band'])])),\n",
       "                                 ('remove_prefix',\n",
       "                                  RemovePrefixTransformer(prefixes=['one_hot_encode',\n",
       "                                                                    'WOE_encode',\n",
       "                                                                    'remainder']))])),\n",
       "                ('model',\n",
       "                 LGBMClassifier(is_unbalance=True, learning_rate=0.01,\n",
       "                                max_depth=1, n_estimators=150))])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_split, y_train_split) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8868162605183176\n",
      "Profit @ Top-20: 4.134671\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_split)\n",
    "\n",
    "# Calculate AUC\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "# Calculate profit metric\n",
    "profit_metric = calculate_profit_metric(y_valid_probabilities_lgb, X_valid_split)\n",
    "\n",
    "#profit_metric2 = profit_at_top_20(y_valid_split, y_valid_probabilities_lgb)\n",
    "\n",
    "print(f'AUC Score: {auc_score_lgb}')\n",
    "print(f'Profit @ Top-20: {profit_metric}')\n",
    "#print(f'Profit @ Top-20: {profit_metric2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
