{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing (pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "set_config(transform_output = \"pandas\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import WOEEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../datasets/train.csv')\n",
    "data_test = pd.read_csv('../datasets/test.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = data_train.shape[0] + data_test.shape[0]\n",
    "train_distribution_percentage = (data_train.shape[0] / total_samples) * 100\n",
    "test_distribution_percentage = (data_test.shape[0] / total_samples) * 100\n",
    "\n",
    "print(f\"Training Set Distribution: {train_distribution_percentage:.2f}% ({data_train.shape[0]} rows)\")\n",
    "print(f\"Testing Set Distribution: {test_distribution_percentage:.2f}% ({data_test.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing ideas\n",
    "- missing values: drop or impute? Maybe just do median imputation because there’s so little\n",
    "- imbalance in target (15% vs 85%): use stratified CV! Evaluate with proper metrics! Use ensemble of models! Data augmentation (e.g. undersampling or SMOTE) or using class weights? \n",
    "- gender: one-hot encoding (binary indicator 1/0)\n",
    "- tariff: weights of evidence or one-hot encoding (ordinality or not?)\n",
    "- handset: WOE\n",
    "- Usage_Band: ordinal so take this into account but also WOE maybe --> woe instead\n",
    "- tariff_OK, high dropped calls and No Usage might be very uninformative because extremely imbalanced – if we use: one-hot encoding for all (change tariff_OK values to OK vs High, so regrouping the High CAT 100, High CAT 50 and High Play 100)\n",
    "- for numerical ones i'm not sure, maybe some form of outlier detection and potentially some WOE\n",
    "\n",
    "\n",
    "### **missing for now: outlier detection**\n",
    "### **also look into this encoder for categorical variables: from category_encoders.cat_boost import CatBoostEncoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests, being an ensemble of decision trees, are generally not sensitive to the scale of numeric features. The reason is that decision trees make splits based on feature values but do not rely on the absolute scale of those values. Therefore, in many cases, scaling is not a strict requirement when using Random Forests. --> no standardization for now so we keep interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- we get (1) a labeled dataset (train.csv) and (2) an unlabeled dataset (test.csv)\n",
    "- split train.csv into a train and test set\n",
    "- that train set, u should split into train and validation sets (stratified CV split because imbalance)\n",
    "- that test set has labels, so u can compare the predictions on X_test, y_test with the labels to evaluate performance of the different models **NOTE: to fit a model on the test set that is coming from train.csv, u need to pass the tuned values of the hyperparameters (tuned on the validation set)**\n",
    "- choose the best performing model \n",
    "- then make predictions on test.csv (unlabeled) and export to a csv file which you upload to the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " note: after finding the optimal parameters, put the values in the pipeline (paramters of RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other ideas \n",
    "- change objective function? to account for top 20 evaluation metric?\n",
    "- use proftree? proflogit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training data\n",
    "missing_count = data_train.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_missing_values_train = data_train[data_train.isnull().any(axis=1)]\n",
    "print(\"Rows with Missing Values in training data:\")\n",
    "rows_with_missing_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data\n",
    "missing_count = data_test.isnull().sum() \n",
    "missing_data = pd.DataFrame({'Column Name': missing_count.index, 'Missing Count': missing_count.values})\n",
    "missing_data = missing_data.sort_values(by='Missing Count', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_missing_values_test = data_test[data_test.isnull().any(axis=1)]\n",
    "print(\"\\nRows with Missing Values in test data:\")\n",
    "rows_with_missing_values_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**we will impute this since it's so little rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = data_train.dropna()\n",
    "#data_test = data_test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR NOW I AM DROPPING BC ELSE GOT ERRORS FOR MY PIPELINE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'target'\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = data_train.drop(target_column, axis=1)\n",
    "y_train = data_train[target_column]\n",
    "\n",
    "X_test = data_test#.drop(target_column, axis=1)\n",
    "#y_test = data_test[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "don't know if this should be done after splitting or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_date_column(data, date_column):\n",
    "    # Convert the date column to datetime format\n",
    "    data[date_column] = pd.to_datetime(data[date_column], format='%d/%m/%y')\n",
    "\n",
    "    # Find the earliest date\n",
    "    earliest_date = data[date_column].min()\n",
    "\n",
    "    # Convert the date column to days since the earliest date\n",
    "    data[date_column] = (data[date_column] - earliest_date).dt.days\n",
    "\n",
    "    return data\n",
    "\n",
    "X_train = process_date_column(X_train, 'Connect_Date')\n",
    "X_test = process_date_column(X_test, 'Connect_Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into train and validation set -- should i use train test split instead? im confused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target variable is binary and imbalanced (with the minority class having a frequency of 15%), so using a stratified splitting approach is recommended to ensure that both the training and validation sets have a similar distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, valid_index in stratified_splitter.split(X_train, y_train):\n",
    "    X_train_split, X_valid_split = X_train.iloc[train_index], X_train.iloc[valid_index]\n",
    "    y_train_split, y_valid_split = y_train.iloc[train_index], y_train.iloc[valid_index]\n",
    "    # Now you can use X_train_split, y_train_split for training and X_valid_split, y_valid_split for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_samples = X_train_split.shape[0] + X_valid_split.shape[0]\n",
    "train_distribution_percentage = (X_train_split.shape[0]/ total_train_samples) * 100\n",
    "validation_distribution_percentage = (X_valid_split.shape[0] / total_train_samples) * 100\n",
    "\n",
    "print(f\"Training Set Distribution: {train_distribution_percentage:.2f}% ({X_train_split.shape[0]} rows)\")\n",
    "print(f\"Validation Set Distribution: {validation_distribution_percentage:.2f}% ({X_valid_split.shape[0]} rows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split['Tariff_OK'] = np.where(X_train_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_valid_split['Tariff_OK'] = np.where(X_valid_split['Tariff_OK'] == 'OK', 1, 0)\n",
    "X_test['Tariff_OK'] = np.where(X_test['Tariff_OK'] == 'OK', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'id' is the name of the column\n",
    "# Convert 'id' column to sets to get unique values\n",
    "X_train_ids = set(X_train_split['id'])\n",
    "y_train_ids = set(y_train_split.index)\n",
    "\n",
    "# Check for overlapping values\n",
    "overlapping_ids = X_train_ids.intersection(y_train_ids)\n",
    "\n",
    "if overlapping_ids:\n",
    "    print(\"There are overlapping values for the 'id' column between X_train_split and y_train_split.\")\n",
    "    print(\"Overlapping IDs:\", overlapping_ids)\n",
    "else:\n",
    "    print(\"There are no overlapping values for the 'id' column between X_train_split and y_train_split. This is how it should be.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom transformer to remove prefix from column names\n",
    "class RemovePrefixTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, prefixes):\n",
    "        self.prefixes = prefixes\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for prefix in self.prefixes:\n",
    "            X.columns = [col.split(f'{prefix}__')[1] if f'{prefix}__' in col else col for col in X.columns]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to apply both mode imputation and ordinal encoding to the 'Usage_Band' column, you can achieve this by creating a custom transformer using scikit-learn's FunctionTransformer. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Define a function for mode imputation\n",
    "def mode_imputation(data):\n",
    "    mode_value = data.mode().iloc[0]  # Calculate the mode\n",
    "    return data.fillna(mode_value)    # Fill missing values with the mode\n",
    "\n",
    "# Define a custom transformer for mode imputation\n",
    "mode_imputer = FunctionTransformer(mode_imputation)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_split['Usage_Band'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can handle them explicitly before preprocessing, for example, by replacing them with the most frequent category using fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split = X_train_split.copy()\n",
    "X_train_split['Usage_Band'] = X_train_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_train_split['Usage_Band'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_split = y_train_split.fillna(y_train_split.mode()[0])\n",
    "y_valid_split = y_valid_split.fillna(y_train_split.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_split = X_valid_split.copy()\n",
    "\n",
    "# Handle missing values in 'Usage_Band' for X_validation_split\n",
    "X_valid_split['Usage_Band'] = X_valid_split['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_train_split['Dropped_calls_ratio'] = X_train_split['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_train_split['call_cost_per_min'] = X_train_split['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.copy()\n",
    "X_test['Usage_Band'] = X_test['Usage_Band'].fillna(X_train_split['Usage_Band'].mode()[0])\n",
    "print(X_test['Usage_Band'].unique())\n",
    "\n",
    "# Handle missing values in 'Dropped_calls_ratio' by filling with the median\n",
    "X_test['Dropped_calls_ratio'] = X_test['Dropped_calls_ratio'].fillna(X_train_split['Dropped_calls_ratio'].median())\n",
    "\n",
    "# Handle missing values in 'call_cost_per_min' by filling with the median\n",
    "X_test['call_cost_per_min'] = X_test['call_cost_per_min'].fillna(X_train_split['call_cost_per_min'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop\n",
    "columns_to_drop = ['id']  # Drop because it's not numerical, later on add it back to know which prediction corresponds to which individual\n",
    "\n",
    "# Define columns for different encoding methods\n",
    "one_hot_encode_columns = ['Gender', 'high Dropped calls', 'No Usage']\n",
    "woe_encode_columns = ['tariff', 'Handset', 'Usage_Band'] #ipv ordinal endoding\n",
    "ordinal_encode_columns = ['Usage_Band']\n",
    "impute_num = ['Dropped_calls_ratio', 'call_cost_per_min']\n",
    "impute_cat = ['Usage_Band']\n",
    "#numeric_columns = X_train_split.select_dtypes(include=['int64', 'float64']).columns\n",
    "#categorical_columns = X_train_split.select_dtypes(include=['object']).columns\n",
    "#categorical_columns = [col for col in categorical_columns if col != 'id']\n",
    "\n",
    "# Define the preprocessing steps for each column\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('drop_columns', 'drop', columns_to_drop),\n",
    "        ('impute_median', SimpleImputer(strategy='median'), impute_num),\n",
    "        #('impute_mode', SimpleImputer(strategy='most_frequent'), impute_cat),\n",
    "        ('one_hot_encode', OneHotEncoder(drop='first', sparse_output=False), one_hot_encode_columns),\n",
    "        ('WOE_encode', WOEEncoder(), woe_encode_columns),\n",
    "        #('ordinal_encode', OrdinalEncoder(categories=[['Low', 'MedLow', 'Med', 'MedHigh', 'High']]), ['Usage_Band']) #ordinal_encode_columns\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the remaining columns as they are\n",
    ")\n",
    "\n",
    "# Build the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('remove_prefix', RemovePrefixTransformer(prefixes=['impute_median', 'one_hot_encode', 'WOE_encode', 'remainder']))  #'ordinal_encode' # Add this step to remove the prefix\n",
    "])\n",
    "\n",
    "# Define the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42) #class_weight='balanced' - but gives same AUC on validation set\n",
    "\n",
    "lgb_classifier = lgb.LGBMClassifier(is_unbalance=True)\n",
    "#lgb_classifier = lgb.LGBMClassifier(scale_pos_weight=(1 - y_train_split.sum() / len(y_train_split)))\n",
    "\n",
    "xgb_classifier= xgb.XGBClassifier(scale_pos_weight=(1 - y_train_split.sum() / len(y_train_split)))\n",
    "\n",
    "# Build the full pipeline with preprocessing and model\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', rf_classifier)\n",
    "])\n",
    "\n",
    "lgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', lgb_classifier)\n",
    "])\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('model', xgb_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat last 2 code lines for the other 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "def profit_at_top_20(y_true, y_probabilities, top_k=20):\n",
    "    # Extract probabilities for positive class\n",
    "    churn_probabilities = y_probabilities[:, 1]\n",
    "\n",
    "    # Sort customers by predicted probabilities in descending order\n",
    "    sorted_indices = sorted(range(len(churn_probabilities)), key=lambda k: churn_probabilities[k], reverse=True)\n",
    "\n",
    "    # Identify the top-20 customers\n",
    "    top_20_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Calculate profit at top-20\n",
    "    profit = sum(y_true[i] * churn_probabilities[i] for i in top_20_indices)\n",
    "\n",
    "    return profit\n",
    "\n",
    "# Define custom scorer for use in GridSearchCV or RandomizedSearchCV\n",
    "profit_at_top_20_scorer = make_scorer(profit_at_top_20, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train_split is your training data\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dtypes = X_train_preprocessed.dtypes.unique()\n",
    "\n",
    "print(\"Unique data types:\")\n",
    "print(unique_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only numerical so that's good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with missing values in the 'Usage_Band' column\n",
    "missing_values = X_train_preprocessed[X_train_preprocessed.isnull().any(axis=1)]\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used a separate custom classifier to keep the names as original variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(full_pipeline, param_grid, scoring={'profit_at_top_20': profit_at_top_20_scorer, 'auc': 'roc_auc'},\n",
    "                           refit='profit_at_top_20', cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on training data\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build parameter grid for hyperparameter tuning\n",
    "rf_param_grid = {\n",
    "    'model__n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'model__max_depth': [1, 2, 3, 4, 5], # maximum number of levels allowed in each decision tree\n",
    "    'model__min_samples_split': [2, 4, 6, 8, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 3, 4]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance\n",
    "rf_grid_search = GridSearchCV(rf_pipeline, rf_param_grid, scoring={'auc': 'roc_auc'}, refit='auc', cv=5, verbose=2, n_jobs=1)\n",
    "\n",
    "# Fit the GridSearchCV on training data\n",
    "rf_grid_search.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from the grid search\n",
    "best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the validation set\n",
    "y_valid_probabilities = best_model.predict_proba(X_valid_split)\n",
    "#profit_at_top_20_score = profit_at_top_20(y_valid_split, y_valid_probabilities)\n",
    "auc_score = roc_auc_score(y_valid_split, y_valid_probabilities[:, 1])\n",
    "\n",
    "#print(f'Profit at Top-20: {profit_at_top_20_score}')\n",
    "print(f'AUC on Validation Set: {auc_score}')\n",
    "\n",
    "# Access the best hyperparameters\n",
    "best_hyperparameters_RF = rf_grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_hyperparameters_RF}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_probabilities = best_model.predict_proba(X_test)\n",
    "'''\n",
    "auc_score_test = roc_auc_score(y_test, y_test_probabilities[:, 1])\n",
    "print(f'AUC on Test Set: {auc_score_test}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the LGBM model from the pipeline\n",
    "best_rf_model = rf_grid_search.best_estimator_.named_steps['model']\n",
    "\n",
    "# Get feature importances from the LGBM model\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "\n",
    "# Map feature names to their importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort features based on their importance\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print or visualize the feature importance\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {float('{:.2f}'.format(importance))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={&#x27;model__learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;model__max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;model__n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;, scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-306\" type=\"checkbox\" ><label for=\"sk-estimator-id-306\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={&#x27;model__learning_rate&#x27;: [0.01, 0.05, 0.1, 0.2],\n",
       "                         &#x27;model__max_depth&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;model__n_estimators&#x27;: [150, 160, 170, 180, 190, 200]},\n",
       "             refit=&#x27;auc&#x27;, scoring={&#x27;auc&#x27;: &#x27;roc_auc&#x27;})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-307\" type=\"checkbox\" ><label for=\"sk-estimator-id-307\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-308\" type=\"checkbox\" ><label for=\"sk-estimator-id-308\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMClassifier(is_unbalance=True), n_jobs=-1,\n",
       "             param_grid={'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
       "                         'model__max_depth': [1, 2, 3, 4, 5],\n",
       "                         'model__n_estimators': [150, 160, 170, 180, 190, 200]},\n",
       "             refit='auc', scoring={'auc': 'roc_auc'})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "lgb_param_grid = {\n",
    "    'model__n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'model__max_depth': [1, 2, 3, 4, 5],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train_split, y_train_split)\n",
    "\n",
    "lgb_classifier = lgb.LGBMClassifier(is_unbalance=True)\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM\n",
    "lgb_grid_search = GridSearchCV(lgb_classifier, lgb_param_grid, scoring={'auc': 'roc_auc'}, refit='auc', verbose=0, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_preprocessed, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid for LightGBM hyperparameter tuning\n",
    "lgb_param_grid = {\n",
    "    'model__n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'model__max_depth': [1, 2, 3, 4, 5],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance for LightGBM\n",
    "lgb_grid_search = GridSearchCV(lgb_pipeline, lgb_param_grid, scoring={'auc': 'roc_auc'}, refit='auc', verbose=0, cv=5, n_jobs=1)\n",
    "\n",
    "# Fit the GridSearchCV on training data for LightGBM\n",
    "lgb_grid_search.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31)\n",
    "\n",
    "is_unbalance=True, learning_rate=0.05, max_depth=4,\n",
    "               n_estimators=160) (verw missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "met nog ordinal : (is_unbalance=True, learning_rate=0.01, max_depth=1,\n",
    "               n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(is_unbalance=True, model__learning_rate=0.01, model__max_depth=1,\n",
       "               model__n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-309\" type=\"checkbox\" checked><label for=\"sk-estimator-id-309\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, model__learning_rate=0.01, model__max_depth=1,\n",
       "               model__n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, model__learning_rate=0.01, model__max_depth=1,\n",
       "               model__n_estimators=150)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_grid_search.best_estimator_ #has the optimal hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9374601613901374\n",
      "Best Parameters: {'model__learning_rate': 0.01, 'model__max_depth': 1, 'model__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\", lgb_grid_search.best_score_)\n",
    "print(\"Best Parameters:\", lgb_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hieronder overal X_train_split vervangen door X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n",
      "[LightGBM] [Info] Number of positive: 596, number of negative: 3440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7077\n",
      "[LightGBM] [Info] Number of data points in the train set: 4036, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.147671 -> initscore=-1.752986\n",
      "[LightGBM] [Info] Start training from score -1.752986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(is_unbalance=True, model__learning_rate=0.01, model__max_depth=1,\n",
       "               model__n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-310\" type=\"checkbox\" checked><label for=\"sk-estimator-id-310\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(is_unbalance=True, model__learning_rate=0.01, model__max_depth=1,\n",
       "               model__n_estimators=150)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(is_unbalance=True, model__learning_rate=0.01, model__max_depth=1,\n",
       "               model__n_estimators=150)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best LightGBM model from the grid search\n",
    "best_lgb_model = lgb_grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_preprocessed, y_train_split) #X_train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the validation set IPV FIT_TRANSFORM GWN TRANSFORM BC INFO VAN TRAINING SET\n",
    "X_valid_preprocessed = preprocessing_pipeline.transform(X_valid_split)\n",
    "X_valid_split = X_valid_preprocessed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n",
      "[0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = best_lgb_model.predict(X_valid_split)\n",
    "# Set the printing options to display all elements of the array\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# Print the entire array of predictions\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.95346907e-01, 4.65309338e-03],\n",
       "       [9.79702249e-01, 2.02977507e-02],\n",
       "       [7.78354031e-03, 9.92216460e-01],\n",
       "       [5.68036832e-02, 9.43196317e-01],\n",
       "       [9.85857462e-01, 1.41425375e-02],\n",
       "       [8.27880349e-02, 9.17211965e-01],\n",
       "       [9.89694557e-01, 1.03054430e-02],\n",
       "       [9.42332366e-01, 5.76676335e-02],\n",
       "       [9.96149423e-01, 3.85057741e-03],\n",
       "       [9.96017706e-01, 3.98229398e-03],\n",
       "       [8.14044576e-01, 1.85955424e-01],\n",
       "       [9.77326258e-01, 2.26737417e-02],\n",
       "       [9.96285152e-01, 3.71484811e-03],\n",
       "       [2.14965343e-02, 9.78503466e-01],\n",
       "       [9.74910896e-01, 2.50891045e-02],\n",
       "       [9.91965416e-01, 8.03458384e-03],\n",
       "       [9.96558043e-01, 3.44195707e-03],\n",
       "       [2.09047838e-01, 7.90952162e-01],\n",
       "       [9.95825760e-01, 4.17423995e-03],\n",
       "       [7.02144870e-02, 9.29785513e-01],\n",
       "       [9.70185069e-01, 2.98149306e-02],\n",
       "       [9.99165222e-01, 8.34778396e-04],\n",
       "       [9.96848039e-01, 3.15196071e-03],\n",
       "       [9.92139009e-01, 7.86099090e-03],\n",
       "       [9.98355751e-01, 1.64424911e-03],\n",
       "       [9.84797900e-01, 1.52021001e-02],\n",
       "       [4.59116346e-02, 9.54088365e-01],\n",
       "       [9.73137754e-01, 2.68622463e-02],\n",
       "       [1.50224540e-02, 9.84977546e-01],\n",
       "       [9.97900351e-01, 2.09964932e-03],\n",
       "       [9.90442311e-01, 9.55768880e-03],\n",
       "       [9.91353546e-01, 8.64645438e-03],\n",
       "       [9.93805475e-01, 6.19452544e-03],\n",
       "       [1.13992884e-01, 8.86007116e-01],\n",
       "       [9.96998815e-01, 3.00118473e-03],\n",
       "       [9.88485475e-01, 1.15145251e-02],\n",
       "       [9.92112375e-01, 7.88762483e-03],\n",
       "       [9.75341006e-01, 2.46589940e-02],\n",
       "       [9.41059930e-01, 5.89400700e-02],\n",
       "       [9.95497820e-01, 4.50217996e-03],\n",
       "       [2.68131701e-01, 7.31868299e-01],\n",
       "       [9.77334099e-01, 2.26659008e-02],\n",
       "       [9.98303473e-01, 1.69652719e-03],\n",
       "       [9.55008727e-02, 9.04499127e-01],\n",
       "       [9.69731329e-01, 3.02686711e-02],\n",
       "       [9.94319933e-01, 5.68006663e-03],\n",
       "       [9.94348571e-01, 5.65142913e-03],\n",
       "       [3.12902885e-02, 9.68709712e-01],\n",
       "       [9.89138046e-03, 9.90108620e-01],\n",
       "       [9.75767164e-01, 2.42328355e-02],\n",
       "       [9.97645120e-01, 2.35487957e-03],\n",
       "       [9.97991807e-01, 2.00819339e-03],\n",
       "       [9.98418128e-01, 1.58187150e-03],\n",
       "       [9.96663887e-01, 3.33611283e-03],\n",
       "       [9.96821080e-01, 3.17892012e-03],\n",
       "       [9.88126056e-01, 1.18739442e-02],\n",
       "       [5.94252840e-01, 4.05747160e-01],\n",
       "       [9.13975388e-01, 8.60246117e-02],\n",
       "       [9.80210508e-01, 1.97894918e-02],\n",
       "       [9.49470790e-01, 5.05292104e-02],\n",
       "       [9.85052857e-01, 1.49471427e-02],\n",
       "       [9.98300970e-01, 1.69903000e-03],\n",
       "       [3.45168483e-02, 9.65483152e-01],\n",
       "       [9.99594433e-01, 4.05566800e-04],\n",
       "       [1.06832664e-02, 9.89316734e-01],\n",
       "       [9.66840726e-01, 3.31592744e-02],\n",
       "       [9.95122401e-01, 4.87759935e-03],\n",
       "       [2.73052464e-02, 9.72694754e-01],\n",
       "       [9.97705957e-01, 2.29404345e-03],\n",
       "       [1.27879276e-02, 9.87212072e-01],\n",
       "       [9.69939012e-01, 3.00609880e-02],\n",
       "       [1.37124554e-02, 9.86287545e-01],\n",
       "       [8.91002567e-01, 1.08997433e-01],\n",
       "       [9.95644694e-01, 4.35530587e-03],\n",
       "       [9.99208971e-01, 7.91028806e-04],\n",
       "       [9.84584556e-01, 1.54154444e-02],\n",
       "       [9.98040759e-01, 1.95924138e-03],\n",
       "       [9.92528927e-01, 7.47107264e-03],\n",
       "       [9.97710136e-01, 2.28986397e-03],\n",
       "       [9.96741587e-01, 3.25841276e-03],\n",
       "       [9.81114906e-01, 1.88850936e-02],\n",
       "       [1.67353292e-01, 8.32646708e-01],\n",
       "       [9.93733066e-01, 6.26693427e-03],\n",
       "       [9.91516127e-01, 8.48387349e-03],\n",
       "       [9.93614248e-01, 6.38575200e-03],\n",
       "       [4.39684885e-02, 9.56031511e-01],\n",
       "       [9.80555176e-01, 1.94448236e-02],\n",
       "       [9.87083156e-01, 1.29168441e-02],\n",
       "       [9.83594043e-01, 1.64059575e-02],\n",
       "       [2.82264670e-01, 7.17735330e-01],\n",
       "       [9.97656595e-01, 2.34340503e-03],\n",
       "       [3.90237893e-01, 6.09762107e-01],\n",
       "       [9.91421197e-01, 8.57880267e-03],\n",
       "       [9.73560246e-01, 2.64397540e-02],\n",
       "       [9.92199620e-01, 7.80037993e-03],\n",
       "       [9.91604766e-01, 8.39523392e-03],\n",
       "       [9.99865206e-01, 1.34794410e-04],\n",
       "       [9.70699119e-01, 2.93008808e-02],\n",
       "       [6.04883927e-01, 3.95116073e-01],\n",
       "       [9.99410786e-01, 5.89214395e-04],\n",
       "       [9.99452656e-01, 5.47343673e-04],\n",
       "       [5.56434399e-02, 9.44356560e-01],\n",
       "       [7.55355172e-01, 2.44644828e-01],\n",
       "       [9.91150908e-01, 8.84909226e-03],\n",
       "       [9.92224669e-01, 7.77533142e-03],\n",
       "       [9.94021591e-01, 5.97840882e-03],\n",
       "       [6.07480513e-02, 9.39251949e-01],\n",
       "       [9.85496058e-01, 1.45039419e-02],\n",
       "       [9.65480229e-01, 3.45197713e-02],\n",
       "       [6.84323043e-01, 3.15676957e-01],\n",
       "       [9.78629940e-01, 2.13700599e-02],\n",
       "       [9.79256780e-01, 2.07432204e-02],\n",
       "       [9.93357961e-01, 6.64203891e-03],\n",
       "       [9.05951425e-01, 9.40485750e-02],\n",
       "       [9.97259414e-01, 2.74058588e-03],\n",
       "       [9.98320692e-01, 1.67930815e-03],\n",
       "       [9.91121643e-01, 8.87835679e-03],\n",
       "       [9.87304499e-01, 1.26955006e-02],\n",
       "       [9.97792441e-01, 2.20755916e-03],\n",
       "       [9.92160142e-01, 7.83985825e-03],\n",
       "       [9.95427214e-01, 4.57278605e-03],\n",
       "       [1.44561083e-01, 8.55438917e-01],\n",
       "       [9.92299568e-01, 7.70043214e-03],\n",
       "       [7.58676032e-01, 2.41323968e-01],\n",
       "       [9.96979445e-01, 3.02055516e-03],\n",
       "       [1.03843891e-01, 8.96156109e-01],\n",
       "       [7.16990947e-01, 2.83009053e-01],\n",
       "       [9.96123460e-01, 3.87654016e-03],\n",
       "       [6.57555199e-02, 9.34244480e-01],\n",
       "       [9.89525102e-01, 1.04748980e-02],\n",
       "       [9.71500258e-01, 2.84997415e-02],\n",
       "       [5.08834474e-01, 4.91165526e-01],\n",
       "       [2.18272710e-02, 9.78172729e-01],\n",
       "       [9.93995216e-01, 6.00478377e-03],\n",
       "       [9.93330528e-01, 6.66947171e-03],\n",
       "       [9.87056218e-01, 1.29437818e-02],\n",
       "       [9.96940168e-01, 3.05983200e-03],\n",
       "       [9.87442084e-01, 1.25579155e-02],\n",
       "       [9.92875501e-01, 7.12449947e-03],\n",
       "       [3.29424364e-02, 9.67057564e-01],\n",
       "       [9.96820282e-01, 3.17971790e-03],\n",
       "       [1.11197010e-01, 8.88802990e-01],\n",
       "       [9.84753709e-01, 1.52462914e-02],\n",
       "       [9.96959619e-02, 9.00304038e-01],\n",
       "       [9.99888437e-01, 1.11563425e-04],\n",
       "       [2.02079801e-01, 7.97920199e-01],\n",
       "       [9.73945556e-01, 2.60544438e-02],\n",
       "       [9.85307710e-01, 1.46922903e-02],\n",
       "       [9.57990590e-01, 4.20094099e-02],\n",
       "       [9.98729060e-01, 1.27093955e-03],\n",
       "       [9.86264241e-01, 1.37357595e-02],\n",
       "       [9.12772302e-01, 8.72276979e-02],\n",
       "       [5.56860707e-02, 9.44313929e-01],\n",
       "       [9.94052448e-01, 5.94755175e-03],\n",
       "       [9.79500328e-01, 2.04996725e-02],\n",
       "       [4.28955997e-01, 5.71044003e-01],\n",
       "       [9.83861647e-01, 1.61383530e-02],\n",
       "       [9.84213427e-01, 1.57865732e-02],\n",
       "       [9.93122381e-01, 6.87761943e-03],\n",
       "       [1.67516668e-02, 9.83248333e-01],\n",
       "       [9.94359557e-01, 5.64044282e-03],\n",
       "       [8.80421714e-01, 1.19578286e-01],\n",
       "       [7.06199580e-01, 2.93800420e-01],\n",
       "       [9.78328172e-01, 2.16718275e-02],\n",
       "       [2.45357749e-02, 9.75464225e-01],\n",
       "       [1.41868880e-02, 9.85813112e-01],\n",
       "       [9.85504502e-01, 1.44954975e-02],\n",
       "       [9.98096653e-01, 1.90334653e-03],\n",
       "       [9.95863173e-01, 4.13682727e-03],\n",
       "       [9.97688881e-01, 2.31111870e-03],\n",
       "       [9.87478197e-01, 1.25218028e-02],\n",
       "       [9.79382917e-01, 2.06170831e-02],\n",
       "       [2.07374272e-02, 9.79262573e-01],\n",
       "       [9.92625478e-01, 7.37452170e-03],\n",
       "       [9.63786443e-01, 3.62135567e-02],\n",
       "       [9.82237725e-01, 1.77622752e-02],\n",
       "       [6.77035365e-01, 3.22964635e-01],\n",
       "       [9.99803480e-01, 1.96520043e-04],\n",
       "       [9.82201643e-01, 1.77983572e-02],\n",
       "       [9.90308072e-01, 9.69192812e-03],\n",
       "       [9.87447473e-01, 1.25525272e-02],\n",
       "       [9.52387192e-01, 4.76128079e-02],\n",
       "       [9.94912712e-01, 5.08728809e-03],\n",
       "       [9.88515672e-01, 1.14843278e-02],\n",
       "       [9.99107375e-01, 8.92624920e-04],\n",
       "       [9.62890739e-01, 3.71092610e-02],\n",
       "       [9.76720475e-01, 2.32795250e-02],\n",
       "       [9.97800731e-01, 2.19926912e-03],\n",
       "       [9.97360091e-01, 2.63990903e-03],\n",
       "       [9.92030824e-01, 7.96917641e-03],\n",
       "       [9.96577982e-01, 3.42201757e-03],\n",
       "       [2.84149849e-01, 7.15850151e-01],\n",
       "       [9.92240966e-01, 7.75903410e-03],\n",
       "       [9.99425762e-01, 5.74237934e-04],\n",
       "       [9.99451399e-01, 5.48601376e-04],\n",
       "       [9.89271624e-01, 1.07283759e-02],\n",
       "       [9.99203915e-01, 7.96084562e-04],\n",
       "       [9.81568428e-01, 1.84315720e-02],\n",
       "       [9.98212738e-01, 1.78726158e-03],\n",
       "       [9.76044078e-01, 2.39559219e-02],\n",
       "       [7.83605486e-02, 9.21639451e-01],\n",
       "       [9.98970959e-01, 1.02904058e-03],\n",
       "       [8.49389169e-01, 1.50610831e-01],\n",
       "       [1.75644577e-01, 8.24355423e-01],\n",
       "       [1.78760133e-01, 8.21239867e-01],\n",
       "       [8.01449706e-01, 1.98550294e-01],\n",
       "       [9.98464896e-01, 1.53510421e-03],\n",
       "       [3.82241410e-02, 9.61775859e-01],\n",
       "       [9.97411510e-01, 2.58849038e-03],\n",
       "       [8.17659020e-01, 1.82340980e-01],\n",
       "       [1.15062750e-01, 8.84937250e-01],\n",
       "       [9.23685757e-01, 7.63142427e-02],\n",
       "       [9.99428599e-01, 5.71400712e-04],\n",
       "       [9.97558717e-01, 2.44128294e-03],\n",
       "       [9.98352007e-01, 1.64799250e-03],\n",
       "       [9.57488363e-01, 4.25116372e-02],\n",
       "       [9.99722684e-01, 2.77315574e-04],\n",
       "       [9.98046084e-01, 1.95391571e-03],\n",
       "       [6.34759066e-01, 3.65240934e-01],\n",
       "       [9.95921394e-01, 4.07860557e-03],\n",
       "       [9.73978186e-01, 2.60218135e-02],\n",
       "       [9.97969827e-01, 2.03017295e-03],\n",
       "       [9.98248255e-01, 1.75174526e-03],\n",
       "       [6.06429739e-02, 9.39357026e-01],\n",
       "       [3.62745712e-01, 6.37254288e-01],\n",
       "       [9.93065233e-01, 6.93476717e-03],\n",
       "       [9.67451236e-01, 3.25487643e-02],\n",
       "       [9.97024318e-01, 2.97568235e-03],\n",
       "       [9.97556025e-01, 2.44397542e-03],\n",
       "       [9.98361788e-01, 1.63821223e-03],\n",
       "       [9.54063475e-02, 9.04593653e-01],\n",
       "       [9.92822852e-01, 7.17714756e-03],\n",
       "       [9.92382598e-01, 7.61740189e-03],\n",
       "       [9.62364033e-01, 3.76359671e-02],\n",
       "       [9.93982988e-01, 6.01701215e-03],\n",
       "       [9.93719921e-01, 6.28007929e-03],\n",
       "       [9.80061260e-01, 1.99387396e-02],\n",
       "       [9.99783506e-01, 2.16493896e-04],\n",
       "       [9.94576120e-01, 5.42388041e-03],\n",
       "       [9.81961516e-01, 1.80384844e-02],\n",
       "       [9.81339396e-01, 1.86606043e-02],\n",
       "       [9.91758650e-01, 8.24134990e-03],\n",
       "       [9.81960387e-01, 1.80396128e-02],\n",
       "       [9.90311613e-01, 9.68838694e-03],\n",
       "       [9.99236929e-01, 7.63070960e-04],\n",
       "       [9.99591102e-01, 4.08898187e-04],\n",
       "       [9.94081199e-01, 5.91880124e-03],\n",
       "       [9.95187651e-01, 4.81234855e-03],\n",
       "       [9.49884662e-01, 5.01153384e-02],\n",
       "       [9.96018349e-01, 3.98165103e-03],\n",
       "       [9.74756689e-01, 2.52433114e-02],\n",
       "       [9.80650556e-01, 1.93494442e-02],\n",
       "       [9.85327343e-01, 1.46726575e-02],\n",
       "       [9.98884270e-01, 1.11572977e-03],\n",
       "       [9.99521239e-01, 4.78760542e-04],\n",
       "       [9.95245958e-01, 4.75404194e-03],\n",
       "       [9.18645826e-01, 8.13541745e-02],\n",
       "       [9.85869888e-01, 1.41301119e-02],\n",
       "       [9.62001773e-01, 3.79982272e-02],\n",
       "       [9.18328159e-02, 9.08167184e-01],\n",
       "       [9.94587697e-01, 5.41230284e-03],\n",
       "       [9.93725228e-01, 6.27477187e-03],\n",
       "       [9.76442240e-01, 2.35577600e-02],\n",
       "       [9.16669412e-03, 9.90833306e-01],\n",
       "       [9.90386280e-01, 9.61371987e-03],\n",
       "       [9.96850150e-01, 3.14985027e-03],\n",
       "       [9.95746871e-01, 4.25312860e-03],\n",
       "       [9.99843030e-01, 1.56970368e-04],\n",
       "       [2.90137532e-02, 9.70986247e-01],\n",
       "       [9.88271769e-01, 1.17282306e-02],\n",
       "       [9.93707082e-01, 6.29291819e-03],\n",
       "       [9.99233549e-01, 7.66450644e-04],\n",
       "       [9.99461033e-01, 5.38967320e-04],\n",
       "       [9.46864209e-01, 5.31357912e-02],\n",
       "       [6.67766709e-01, 3.32233291e-01],\n",
       "       [1.69852477e-01, 8.30147523e-01],\n",
       "       [9.89021468e-01, 1.09785319e-02],\n",
       "       [9.94204192e-01, 5.79580811e-03],\n",
       "       [9.98414126e-01, 1.58587385e-03],\n",
       "       [9.81379795e-01, 1.86202049e-02],\n",
       "       [9.98848168e-01, 1.15183157e-03],\n",
       "       [7.05416758e-01, 2.94583242e-01],\n",
       "       [8.30572705e-01, 1.69427295e-01],\n",
       "       [9.82346949e-01, 1.76530508e-02],\n",
       "       [9.95060293e-01, 4.93970715e-03],\n",
       "       [9.82596288e-01, 1.74037122e-02],\n",
       "       [9.95350133e-01, 4.64986715e-03],\n",
       "       [8.79106761e-02, 9.12089324e-01],\n",
       "       [1.85463478e-02, 9.81453652e-01],\n",
       "       [9.87465322e-01, 1.25346779e-02],\n",
       "       [9.96599847e-01, 3.40015296e-03],\n",
       "       [9.96999306e-01, 3.00069396e-03],\n",
       "       [9.90518254e-01, 9.48174590e-03],\n",
       "       [9.28061013e-01, 7.19389871e-02],\n",
       "       [9.91069337e-01, 8.93066278e-03],\n",
       "       [9.96913656e-01, 3.08634405e-03],\n",
       "       [1.28070494e-01, 8.71929506e-01],\n",
       "       [9.84938973e-01, 1.50610265e-02],\n",
       "       [8.84780007e-01, 1.15219993e-01],\n",
       "       [9.80480252e-01, 1.95197481e-02],\n",
       "       [7.24238128e-02, 9.27576187e-01],\n",
       "       [9.94716496e-01, 5.28350362e-03],\n",
       "       [9.64497476e-01, 3.55025236e-02],\n",
       "       [6.27705506e-01, 3.72294494e-01],\n",
       "       [9.66128093e-01, 3.38719069e-02],\n",
       "       [9.95729857e-01, 4.27014312e-03],\n",
       "       [9.96965564e-01, 3.03443629e-03],\n",
       "       [9.36347128e-01, 6.36528716e-02],\n",
       "       [9.95282643e-01, 4.71735731e-03],\n",
       "       [9.94120994e-01, 5.87900598e-03],\n",
       "       [9.67696667e-01, 3.23033332e-02],\n",
       "       [8.80661146e-01, 1.19338854e-01],\n",
       "       [9.51671819e-01, 4.83281810e-02],\n",
       "       [9.94318532e-01, 5.68146808e-03],\n",
       "       [6.03548109e-01, 3.96451891e-01],\n",
       "       [9.99254553e-01, 7.45447227e-04],\n",
       "       [9.60064581e-01, 3.99354195e-02],\n",
       "       [4.46805162e-02, 9.55319484e-01],\n",
       "       [9.69878825e-01, 3.01211749e-02],\n",
       "       [9.97744054e-01, 2.25594558e-03],\n",
       "       [8.67290131e-01, 1.32709869e-01],\n",
       "       [7.67632940e-01, 2.32367060e-01],\n",
       "       [9.93680663e-01, 6.31933737e-03],\n",
       "       [9.74224338e-01, 2.57756622e-02],\n",
       "       [9.79552567e-01, 2.04474330e-02],\n",
       "       [9.87206068e-01, 1.27939323e-02],\n",
       "       [2.51945164e-02, 9.74805484e-01],\n",
       "       [9.95155269e-01, 4.84473117e-03],\n",
       "       [9.43119591e-01, 5.68804092e-02],\n",
       "       [9.70713109e-01, 2.92868909e-02],\n",
       "       [9.86626502e-01, 1.33734979e-02],\n",
       "       [8.21333001e-01, 1.78666999e-01],\n",
       "       [1.10377091e-01, 8.89622909e-01],\n",
       "       [9.89320610e-01, 1.06793901e-02],\n",
       "       [9.98181874e-01, 1.81812569e-03],\n",
       "       [9.82787846e-01, 1.72121539e-02],\n",
       "       [9.98195578e-01, 1.80442184e-03],\n",
       "       [9.70028984e-01, 2.99710161e-02],\n",
       "       [2.25556443e-01, 7.74443557e-01],\n",
       "       [9.98769422e-01, 1.23057824e-03],\n",
       "       [1.23627574e-02, 9.87637243e-01],\n",
       "       [9.67901197e-01, 3.20988033e-02],\n",
       "       [9.99374741e-01, 6.25258631e-04],\n",
       "       [9.96223238e-01, 3.77676178e-03],\n",
       "       [6.10442593e-01, 3.89557407e-01],\n",
       "       [9.95541278e-01, 4.45872202e-03],\n",
       "       [9.57599318e-01, 4.24006822e-02],\n",
       "       [9.65449759e-01, 3.45502410e-02],\n",
       "       [9.96107152e-01, 3.89284784e-03],\n",
       "       [9.82380357e-01, 1.76196430e-02],\n",
       "       [7.38880133e-01, 2.61119867e-01],\n",
       "       [9.90258877e-01, 9.74112270e-03],\n",
       "       [9.76612977e-01, 2.33870228e-02],\n",
       "       [7.51289033e-01, 2.48710967e-01],\n",
       "       [1.03266836e-01, 8.96733164e-01],\n",
       "       [4.86615895e-02, 9.51338411e-01],\n",
       "       [9.97327342e-01, 2.67265839e-03],\n",
       "       [9.91782011e-01, 8.21798863e-03],\n",
       "       [1.72653224e-01, 8.27346776e-01],\n",
       "       [1.99389532e-02, 9.80061047e-01],\n",
       "       [9.98591586e-01, 1.40841389e-03],\n",
       "       [8.18229688e-01, 1.81770312e-01],\n",
       "       [9.96592981e-01, 3.40701912e-03],\n",
       "       [9.95423007e-01, 4.57699317e-03],\n",
       "       [9.85409372e-01, 1.45906280e-02],\n",
       "       [9.92229513e-01, 7.77048705e-03],\n",
       "       [9.95707374e-01, 4.29262599e-03],\n",
       "       [9.98368177e-01, 1.63182284e-03],\n",
       "       [8.80208998e-01, 1.19791002e-01],\n",
       "       [9.91688296e-01, 8.31170377e-03],\n",
       "       [9.96729534e-01, 3.27046601e-03],\n",
       "       [9.98253414e-01, 1.74658581e-03],\n",
       "       [9.95308936e-01, 4.69106390e-03],\n",
       "       [9.89244974e-01, 1.07550255e-02],\n",
       "       [6.81507116e-02, 9.31849288e-01],\n",
       "       [5.74499619e-02, 9.42550038e-01],\n",
       "       [9.93570896e-01, 6.42910449e-03],\n",
       "       [9.96550907e-01, 3.44909274e-03],\n",
       "       [9.97089784e-01, 2.91021566e-03],\n",
       "       [9.13291288e-01, 8.67087121e-02],\n",
       "       [9.96963428e-01, 3.03657245e-03],\n",
       "       [9.95951593e-01, 4.04840718e-03],\n",
       "       [9.82691523e-01, 1.73084766e-02],\n",
       "       [9.80969454e-01, 1.90305464e-02],\n",
       "       [9.98442793e-01, 1.55720708e-03],\n",
       "       [9.49363830e-01, 5.06361701e-02],\n",
       "       [9.97496145e-01, 2.50385537e-03],\n",
       "       [9.81728979e-01, 1.82710212e-02],\n",
       "       [9.98862768e-01, 1.13723205e-03],\n",
       "       [9.62656621e-01, 3.73433788e-02],\n",
       "       [9.76748754e-01, 2.32512456e-02],\n",
       "       [1.32333473e-01, 8.67666527e-01],\n",
       "       [7.82533507e-01, 2.17466493e-01],\n",
       "       [9.54443564e-01, 4.55564361e-02],\n",
       "       [9.96878267e-01, 3.12173275e-03],\n",
       "       [8.76292671e-01, 1.23707329e-01],\n",
       "       [9.75385658e-01, 2.46143422e-02],\n",
       "       [9.97209691e-01, 2.79030944e-03],\n",
       "       [9.99383589e-01, 6.16411365e-04],\n",
       "       [9.88169688e-01, 1.18303118e-02],\n",
       "       [9.96384074e-01, 3.61592585e-03],\n",
       "       [9.94845784e-01, 5.15421551e-03],\n",
       "       [9.98636066e-01, 1.36393383e-03],\n",
       "       [1.64344619e-01, 8.35655381e-01],\n",
       "       [9.91601713e-01, 8.39828662e-03],\n",
       "       [1.34734756e-02, 9.86526524e-01],\n",
       "       [9.88672851e-01, 1.13271486e-02],\n",
       "       [9.88908686e-01, 1.10913139e-02],\n",
       "       [2.93804945e-02, 9.70619506e-01],\n",
       "       [9.76935824e-01, 2.30641760e-02],\n",
       "       [9.79975845e-01, 2.00241554e-02],\n",
       "       [9.72764405e-01, 2.72355953e-02],\n",
       "       [2.85488198e-02, 9.71451180e-01],\n",
       "       [1.94326794e-01, 8.05673206e-01],\n",
       "       [6.37329720e-01, 3.62670280e-01],\n",
       "       [9.85746007e-01, 1.42539926e-02],\n",
       "       [9.97289694e-01, 2.71030621e-03],\n",
       "       [6.90159585e-02, 9.30984041e-01],\n",
       "       [9.97220912e-01, 2.77908778e-03],\n",
       "       [9.91550971e-01, 8.44902866e-03],\n",
       "       [9.98469670e-01, 1.53032993e-03],\n",
       "       [9.28032407e-01, 7.19675933e-02],\n",
       "       [9.99510723e-01, 4.89276923e-04],\n",
       "       [9.86528070e-01, 1.34719303e-02],\n",
       "       [9.96596222e-01, 3.40377757e-03],\n",
       "       [9.93675100e-01, 6.32490013e-03],\n",
       "       [1.81527840e-02, 9.81847216e-01],\n",
       "       [9.95304182e-01, 4.69581811e-03],\n",
       "       [7.99512820e-01, 2.00487180e-01],\n",
       "       [9.55310020e-01, 4.46899801e-02],\n",
       "       [9.95636996e-01, 4.36300421e-03],\n",
       "       [5.61297554e-02, 9.43870245e-01],\n",
       "       [6.51126254e-01, 3.48873746e-01],\n",
       "       [9.95296696e-01, 4.70330422e-03],\n",
       "       [7.84222427e-01, 2.15777573e-01],\n",
       "       [9.93607523e-01, 6.39247671e-03],\n",
       "       [4.72018882e-02, 9.52798112e-01],\n",
       "       [9.98737735e-01, 1.26226466e-03],\n",
       "       [9.97083477e-01, 2.91652333e-03],\n",
       "       [9.69794838e-01, 3.02051618e-02],\n",
       "       [9.76559840e-01, 2.34401600e-02],\n",
       "       [9.81934380e-01, 1.80656203e-02],\n",
       "       [9.96777129e-01, 3.22287142e-03],\n",
       "       [9.84844180e-01, 1.51558201e-02],\n",
       "       [9.96229946e-01, 3.77005358e-03],\n",
       "       [1.34471150e-02, 9.86552885e-01],\n",
       "       [5.19246935e-02, 9.48075306e-01],\n",
       "       [9.93027076e-01, 6.97292407e-03],\n",
       "       [9.92672036e-01, 7.32796375e-03],\n",
       "       [9.87440684e-01, 1.25593165e-02],\n",
       "       [9.74098612e-01, 2.59013883e-02],\n",
       "       [9.92078890e-01, 7.92111001e-03],\n",
       "       [9.93760496e-01, 6.23950398e-03],\n",
       "       [9.94862640e-01, 5.13736042e-03],\n",
       "       [9.81700734e-01, 1.82992660e-02],\n",
       "       [9.94408454e-01, 5.59154597e-03],\n",
       "       [1.96750984e-02, 9.80324902e-01],\n",
       "       [9.82919543e-01, 1.70804568e-02],\n",
       "       [9.93287349e-01, 6.71265117e-03],\n",
       "       [9.47993235e-01, 5.20067649e-02],\n",
       "       [9.92969175e-01, 7.03082454e-03],\n",
       "       [9.76832806e-01, 2.31671935e-02],\n",
       "       [9.77854873e-01, 2.21451274e-02],\n",
       "       [9.99001530e-01, 9.98469844e-04],\n",
       "       [7.10328497e-02, 9.28967150e-01],\n",
       "       [8.96580594e-01, 1.03419406e-01],\n",
       "       [9.94674077e-01, 5.32592265e-03],\n",
       "       [9.91556876e-01, 8.44312397e-03],\n",
       "       [9.75881103e-01, 2.41188970e-02],\n",
       "       [9.94988750e-01, 5.01124984e-03],\n",
       "       [9.87087263e-01, 1.29127367e-02],\n",
       "       [9.96810643e-01, 3.18935687e-03],\n",
       "       [1.34754411e-02, 9.86524559e-01],\n",
       "       [9.93404331e-01, 6.59566887e-03],\n",
       "       [2.56096956e-01, 7.43903044e-01],\n",
       "       [3.75894031e-02, 9.62410597e-01],\n",
       "       [9.94212214e-01, 5.78778598e-03],\n",
       "       [9.92877601e-01, 7.12239877e-03],\n",
       "       [9.98845694e-01, 1.15430570e-03],\n",
       "       [9.84324058e-01, 1.56759419e-02],\n",
       "       [1.84474097e-01, 8.15525903e-01],\n",
       "       [9.86166576e-01, 1.38334242e-02],\n",
       "       [9.88636941e-01, 1.13630592e-02],\n",
       "       [9.95391554e-01, 4.60844586e-03],\n",
       "       [9.87423368e-01, 1.25766325e-02],\n",
       "       [1.11986696e-02, 9.88801330e-01],\n",
       "       [9.79175548e-01, 2.08244522e-02],\n",
       "       [9.95173788e-01, 4.82621192e-03],\n",
       "       [8.98038638e-01, 1.01961362e-01],\n",
       "       [9.46166477e-01, 5.38335229e-02],\n",
       "       [3.24929923e-01, 6.75070077e-01],\n",
       "       [9.98526118e-01, 1.47388223e-03],\n",
       "       [9.91386990e-01, 8.61300977e-03],\n",
       "       [9.87601935e-01, 1.23980653e-02],\n",
       "       [9.93163520e-01, 6.83647999e-03],\n",
       "       [9.96566141e-01, 3.43385920e-03],\n",
       "       [9.56633455e-01, 4.33665445e-02],\n",
       "       [9.89227997e-01, 1.07720032e-02],\n",
       "       [9.89055751e-01, 1.09442494e-02],\n",
       "       [9.96010722e-01, 3.98927802e-03],\n",
       "       [9.99275168e-01, 7.24831753e-04],\n",
       "       [6.02569863e-02, 9.39743014e-01],\n",
       "       [4.65850858e-01, 5.34149142e-01],\n",
       "       [4.65291364e-02, 9.53470864e-01],\n",
       "       [9.97320388e-01, 2.67961202e-03],\n",
       "       [9.99474391e-01, 5.25609154e-04],\n",
       "       [9.82491531e-01, 1.75084690e-02],\n",
       "       [9.63014564e-01, 3.69854359e-02],\n",
       "       [5.83488015e-02, 9.41651198e-01],\n",
       "       [2.42963663e-01, 7.57036337e-01],\n",
       "       [9.95132606e-01, 4.86739361e-03],\n",
       "       [1.86989745e-02, 9.81301026e-01],\n",
       "       [9.94430333e-01, 5.56966671e-03],\n",
       "       [8.27713873e-01, 1.72286127e-01],\n",
       "       [9.98458387e-01, 1.54161295e-03],\n",
       "       [9.92806004e-01, 7.19399637e-03],\n",
       "       [9.50553568e-01, 4.94464321e-02],\n",
       "       [9.99518640e-01, 4.81359679e-04],\n",
       "       [9.22347301e-01, 7.76526987e-02],\n",
       "       [9.96119853e-01, 3.88014734e-03],\n",
       "       [9.54686861e-01, 4.53131386e-02],\n",
       "       [9.96973336e-01, 3.02666422e-03],\n",
       "       [5.05521645e-02, 9.49447835e-01],\n",
       "       [9.84426214e-01, 1.55737863e-02],\n",
       "       [9.98082615e-01, 1.91738490e-03],\n",
       "       [9.99226650e-01, 7.73350481e-04],\n",
       "       [9.82050512e-01, 1.79494884e-02],\n",
       "       [9.89402006e-01, 1.05979943e-02],\n",
       "       [9.36360447e-01, 6.36395530e-02],\n",
       "       [1.51632064e-01, 8.48367936e-01],\n",
       "       [4.25246001e-02, 9.57475400e-01],\n",
       "       [7.55099130e-01, 2.44900870e-01],\n",
       "       [9.85944264e-01, 1.40557357e-02],\n",
       "       [9.97447852e-01, 2.55214792e-03],\n",
       "       [9.77238919e-01, 2.27610809e-02],\n",
       "       [7.81934007e-01, 2.18065993e-01],\n",
       "       [2.18112848e-01, 7.81887152e-01],\n",
       "       [9.99780771e-01, 2.19228937e-04],\n",
       "       [9.88350819e-01, 1.16491813e-02],\n",
       "       [2.99676323e-02, 9.70032368e-01],\n",
       "       [9.36239234e-01, 6.37607658e-02],\n",
       "       [9.80872900e-01, 1.91271001e-02],\n",
       "       [9.75960250e-01, 2.40397499e-02],\n",
       "       [9.51682550e-01, 4.83174501e-02],\n",
       "       [7.80699784e-03, 9.92193002e-01],\n",
       "       [9.40905445e-01, 5.90945548e-02],\n",
       "       [9.96094364e-01, 3.90563567e-03],\n",
       "       [9.95108946e-01, 4.89105380e-03],\n",
       "       [9.96200391e-01, 3.79960855e-03],\n",
       "       [9.98367011e-01, 1.63298860e-03],\n",
       "       [1.14641471e-01, 8.85358529e-01],\n",
       "       [9.96562759e-01, 3.43724122e-03],\n",
       "       [9.84425936e-01, 1.55740640e-02],\n",
       "       [9.99575890e-01, 4.24109799e-04],\n",
       "       [7.06028156e-01, 2.93971844e-01],\n",
       "       [7.82033022e-02, 9.21796698e-01],\n",
       "       [9.88326545e-01, 1.16734552e-02],\n",
       "       [9.96445439e-01, 3.55456081e-03],\n",
       "       [9.82384671e-01, 1.76153290e-02],\n",
       "       [5.81787517e-02, 9.41821248e-01],\n",
       "       [9.06300121e-01, 9.36998789e-02],\n",
       "       [1.47158795e-01, 8.52841205e-01],\n",
       "       [8.24643220e-01, 1.75356780e-01],\n",
       "       [9.14938240e-01, 8.50617598e-02],\n",
       "       [9.99100724e-01, 8.99275575e-04],\n",
       "       [9.98984314e-01, 1.01568600e-03],\n",
       "       [9.92789995e-01, 7.21000539e-03],\n",
       "       [9.95802236e-01, 4.19776368e-03],\n",
       "       [1.86438511e-02, 9.81356149e-01],\n",
       "       [9.92831591e-01, 7.16840888e-03],\n",
       "       [9.82720033e-01, 1.72799668e-02],\n",
       "       [9.71081843e-01, 2.89181574e-02],\n",
       "       [1.00297761e-01, 8.99702239e-01],\n",
       "       [9.80322864e-01, 1.96771360e-02],\n",
       "       [9.62986139e-01, 3.70138612e-02],\n",
       "       [9.93579212e-01, 6.42078815e-03],\n",
       "       [2.04990447e-01, 7.95009553e-01],\n",
       "       [9.97140871e-01, 2.85912939e-03],\n",
       "       [9.39281368e-01, 6.07186320e-02],\n",
       "       [9.86655576e-01, 1.33444238e-02],\n",
       "       [3.37176130e-02, 9.66282387e-01],\n",
       "       [6.84610167e-02, 9.31538983e-01],\n",
       "       [3.73239708e-02, 9.62676029e-01],\n",
       "       [9.84590813e-01, 1.54091871e-02],\n",
       "       [9.90782053e-01, 9.21794707e-03],\n",
       "       [9.90725650e-01, 9.27435025e-03],\n",
       "       [7.24613062e-01, 2.75386938e-01],\n",
       "       [9.75651843e-01, 2.43481565e-02],\n",
       "       [9.89288547e-01, 1.07114528e-02],\n",
       "       [9.90576780e-01, 9.42321998e-03],\n",
       "       [9.97229806e-01, 2.77019446e-03],\n",
       "       [9.86675432e-01, 1.33245682e-02],\n",
       "       [9.58351394e-01, 4.16486057e-02],\n",
       "       [9.31709505e-01, 6.82904950e-02],\n",
       "       [9.79666320e-01, 2.03336799e-02],\n",
       "       [9.99563292e-01, 4.36707581e-04],\n",
       "       [9.37361507e-01, 6.26384930e-02],\n",
       "       [9.90274151e-01, 9.72584854e-03],\n",
       "       [9.54299283e-01, 4.57007167e-02],\n",
       "       [9.84154394e-01, 1.58456061e-02],\n",
       "       [9.99196110e-01, 8.03889682e-04],\n",
       "       [9.93926091e-01, 6.07390932e-03],\n",
       "       [9.90731996e-01, 9.26800391e-03],\n",
       "       [6.26783109e-02, 9.37321689e-01],\n",
       "       [7.23247024e-02, 9.27675298e-01],\n",
       "       [5.73162812e-02, 9.42683719e-01],\n",
       "       [9.83427827e-01, 1.65721732e-02],\n",
       "       [9.91808374e-01, 8.19162600e-03],\n",
       "       [9.90844639e-01, 9.15536109e-03],\n",
       "       [9.72924618e-01, 2.70753823e-02],\n",
       "       [4.88976592e-02, 9.51102341e-01],\n",
       "       [9.97044139e-01, 2.95586082e-03],\n",
       "       [9.87506399e-01, 1.24936009e-02],\n",
       "       [9.47945013e-01, 5.20549871e-02],\n",
       "       [9.92583358e-01, 7.41664225e-03],\n",
       "       [9.88904727e-01, 1.10952731e-02],\n",
       "       [9.98041938e-01, 1.95806167e-03],\n",
       "       [9.93530706e-01, 6.46929404e-03],\n",
       "       [9.97665804e-01, 2.33419567e-03],\n",
       "       [9.98942497e-01, 1.05750325e-03],\n",
       "       [9.96042048e-01, 3.95795230e-03],\n",
       "       [9.92449611e-01, 7.55038866e-03],\n",
       "       [9.87279067e-01, 1.27209329e-02],\n",
       "       [9.90407140e-01, 9.59285981e-03],\n",
       "       [9.81764847e-01, 1.82351535e-02],\n",
       "       [9.99555542e-01, 4.44457971e-04],\n",
       "       [9.84536486e-01, 1.54635138e-02],\n",
       "       [9.74851829e-01, 2.51481711e-02],\n",
       "       [9.98922018e-01, 1.07798207e-03],\n",
       "       [2.46115956e-02, 9.75388404e-01],\n",
       "       [9.96601781e-01, 3.39821948e-03],\n",
       "       [9.88706024e-01, 1.12939764e-02],\n",
       "       [9.79989209e-01, 2.00107913e-02],\n",
       "       [9.90957770e-01, 9.04222972e-03],\n",
       "       [9.95547771e-01, 4.45222889e-03],\n",
       "       [9.95631939e-01, 4.36806128e-03],\n",
       "       [9.86926253e-01, 1.30737466e-02],\n",
       "       [9.83347664e-01, 1.66523361e-02],\n",
       "       [5.10936078e-01, 4.89063922e-01],\n",
       "       [9.72293905e-01, 2.77060950e-02],\n",
       "       [9.96245243e-01, 3.75475741e-03],\n",
       "       [9.97531461e-01, 2.46853935e-03],\n",
       "       [9.97113902e-01, 2.88609842e-03],\n",
       "       [9.79765780e-01, 2.02342196e-02],\n",
       "       [9.97758434e-01, 2.24156590e-03],\n",
       "       [1.46742827e-01, 8.53257173e-01],\n",
       "       [9.89051393e-01, 1.09486068e-02],\n",
       "       [9.82749656e-01, 1.72503441e-02],\n",
       "       [9.97389806e-01, 2.61019393e-03],\n",
       "       [9.95871306e-01, 4.12869354e-03],\n",
       "       [9.97576069e-01, 2.42393109e-03],\n",
       "       [3.44064909e-02, 9.65593509e-01],\n",
       "       [9.89551170e-01, 1.04488300e-02],\n",
       "       [9.90245186e-01, 9.75481408e-03],\n",
       "       [7.92299019e-02, 9.20770098e-01],\n",
       "       [9.97402821e-01, 2.59717917e-03],\n",
       "       [3.61636444e-03, 9.96383636e-01],\n",
       "       [9.54060385e-01, 4.59396146e-02],\n",
       "       [9.92945442e-01, 7.05455756e-03],\n",
       "       [9.93644184e-01, 6.35581634e-03],\n",
       "       [9.86997883e-01, 1.30021166e-02],\n",
       "       [9.73829174e-01, 2.61708256e-02],\n",
       "       [9.98869387e-01, 1.13061299e-03],\n",
       "       [9.96827898e-01, 3.17210207e-03],\n",
       "       [5.84484227e-01, 4.15515773e-01],\n",
       "       [9.42443767e-01, 5.75562334e-02],\n",
       "       [5.95309489e-02, 9.40469051e-01],\n",
       "       [9.89804166e-01, 1.01958338e-02],\n",
       "       [9.97390230e-01, 2.60977002e-03],\n",
       "       [9.76321662e-01, 2.36783383e-02],\n",
       "       [9.83292758e-01, 1.67072420e-02],\n",
       "       [9.71217033e-01, 2.87829670e-02],\n",
       "       [9.96738380e-01, 3.26161961e-03],\n",
       "       [2.57859538e-02, 9.74214046e-01],\n",
       "       [9.95366985e-01, 4.63301494e-03],\n",
       "       [9.98328014e-01, 1.67198590e-03],\n",
       "       [9.77645061e-01, 2.23549392e-02],\n",
       "       [9.90052363e-01, 9.94763744e-03],\n",
       "       [9.83909079e-01, 1.60909213e-02],\n",
       "       [9.92396284e-01, 7.60371611e-03],\n",
       "       [7.26000623e-01, 2.73999377e-01],\n",
       "       [9.95988001e-01, 4.01199852e-03],\n",
       "       [9.68489607e-01, 3.15103934e-02],\n",
       "       [9.98683569e-01, 1.31643128e-03],\n",
       "       [9.91742389e-01, 8.25761106e-03],\n",
       "       [9.91644499e-01, 8.35550070e-03],\n",
       "       [9.97630771e-01, 2.36922878e-03],\n",
       "       [9.95256320e-01, 4.74367976e-03],\n",
       "       [1.07335449e-01, 8.92664551e-01],\n",
       "       [9.97846107e-01, 2.15389299e-03],\n",
       "       [9.37521150e-01, 6.24788495e-02],\n",
       "       [7.53369535e-02, 9.24663047e-01],\n",
       "       [9.93237935e-01, 6.76206494e-03],\n",
       "       [9.97342037e-01, 2.65796321e-03],\n",
       "       [9.96716307e-01, 3.28369334e-03],\n",
       "       [9.87997462e-01, 1.20025381e-02],\n",
       "       [9.93718805e-01, 6.28119540e-03],\n",
       "       [9.98340148e-01, 1.65985209e-03],\n",
       "       [9.98859248e-01, 1.14075194e-03],\n",
       "       [5.06536089e-02, 9.49346391e-01],\n",
       "       [9.95464911e-01, 4.53508906e-03],\n",
       "       [9.78804410e-01, 2.11955896e-02],\n",
       "       [9.95911437e-01, 4.08856317e-03],\n",
       "       [2.17714369e-02, 9.78228563e-01],\n",
       "       [9.69472479e-01, 3.05275212e-02],\n",
       "       [9.55844380e-01, 4.41556200e-02],\n",
       "       [9.90378587e-01, 9.62141289e-03],\n",
       "       [9.94969477e-01, 5.03052347e-03],\n",
       "       [9.88980462e-01, 1.10195378e-02],\n",
       "       [9.95973747e-01, 4.02625312e-03],\n",
       "       [9.60992732e-01, 3.90072676e-02],\n",
       "       [9.98190985e-01, 1.80901474e-03],\n",
       "       [9.89905105e-01, 1.00948952e-02],\n",
       "       [9.85828661e-01, 1.41713389e-02],\n",
       "       [2.55838011e-02, 9.74416199e-01],\n",
       "       [1.35738437e-02, 9.86426156e-01],\n",
       "       [9.43946987e-01, 5.60530129e-02],\n",
       "       [9.49044753e-01, 5.09552472e-02],\n",
       "       [9.05480096e-01, 9.45199045e-02],\n",
       "       [5.64931624e-01, 4.35068376e-01],\n",
       "       [6.56557915e-01, 3.43442085e-01],\n",
       "       [9.94359080e-01, 5.64092006e-03],\n",
       "       [9.85833696e-01, 1.41663045e-02],\n",
       "       [9.96591077e-01, 3.40892281e-03],\n",
       "       [9.90466610e-01, 9.53339049e-03],\n",
       "       [9.99663106e-01, 3.36894412e-04],\n",
       "       [9.98786287e-01, 1.21371290e-03],\n",
       "       [9.64872135e-01, 3.51278654e-02],\n",
       "       [9.94906318e-01, 5.09368221e-03],\n",
       "       [5.17440296e-01, 4.82559704e-01],\n",
       "       [1.38057879e-01, 8.61942121e-01],\n",
       "       [9.94321660e-01, 5.67833961e-03],\n",
       "       [9.98437872e-01, 1.56212836e-03],\n",
       "       [9.87601735e-01, 1.23982645e-02],\n",
       "       [9.93449733e-01, 6.55026746e-03],\n",
       "       [3.56218452e-02, 9.64378155e-01],\n",
       "       [2.52654486e-02, 9.74734551e-01],\n",
       "       [9.95413705e-01, 4.58629465e-03],\n",
       "       [9.92814693e-01, 7.18530743e-03],\n",
       "       [9.95734988e-01, 4.26501237e-03],\n",
       "       [9.95677643e-01, 4.32235746e-03],\n",
       "       [9.07393599e-03, 9.90926064e-01],\n",
       "       [9.99148137e-01, 8.51863317e-04],\n",
       "       [9.94484441e-01, 5.51555926e-03],\n",
       "       [9.98653951e-01, 1.34604881e-03],\n",
       "       [9.78206583e-01, 2.17934168e-02],\n",
       "       [9.94841868e-01, 5.15813237e-03],\n",
       "       [9.72825472e-01, 2.71745284e-02],\n",
       "       [9.81792441e-01, 1.82075586e-02],\n",
       "       [9.87711544e-01, 1.22884559e-02],\n",
       "       [9.97755777e-01, 2.24422312e-03],\n",
       "       [9.84407185e-01, 1.55928149e-02],\n",
       "       [9.89990380e-01, 1.00096199e-02],\n",
       "       [9.96033942e-01, 3.96605816e-03],\n",
       "       [6.06275187e-02, 9.39372481e-01],\n",
       "       [9.98155101e-01, 1.84489936e-03],\n",
       "       [9.82937775e-01, 1.70622254e-02],\n",
       "       [9.72873495e-01, 2.71265053e-02],\n",
       "       [9.88859229e-01, 1.11407709e-02],\n",
       "       [9.96826050e-01, 3.17394992e-03],\n",
       "       [9.80232204e-01, 1.97677955e-02],\n",
       "       [9.85345001e-01, 1.46549989e-02],\n",
       "       [9.97152563e-01, 2.84743706e-03],\n",
       "       [9.96317002e-01, 3.68299816e-03],\n",
       "       [9.83794708e-01, 1.62052918e-02],\n",
       "       [9.68887479e-01, 3.11125210e-02],\n",
       "       [8.62451926e-01, 1.37548074e-01],\n",
       "       [9.92561745e-01, 7.43825479e-03],\n",
       "       [9.93058989e-01, 6.94101114e-03],\n",
       "       [9.92088716e-01, 7.91128424e-03],\n",
       "       [9.99518793e-01, 4.81206871e-04],\n",
       "       [9.88620901e-01, 1.13790986e-02],\n",
       "       [9.92075062e-01, 7.92493824e-03],\n",
       "       [9.99686815e-01, 3.13185184e-04],\n",
       "       [1.38256087e-01, 8.61743913e-01],\n",
       "       [7.57827695e-01, 2.42172305e-01],\n",
       "       [9.97302723e-01, 2.69727716e-03],\n",
       "       [9.94135658e-01, 5.86434224e-03],\n",
       "       [7.31462495e-03, 9.92685375e-01],\n",
       "       [9.66676450e-01, 3.33235504e-02],\n",
       "       [9.09462950e-01, 9.05370503e-02],\n",
       "       [9.28070185e-01, 7.19298152e-02],\n",
       "       [8.90624829e-01, 1.09375171e-01],\n",
       "       [9.47560241e-01, 5.24397585e-02],\n",
       "       [9.93706354e-01, 6.29364583e-03],\n",
       "       [9.65329932e-01, 3.46700683e-02],\n",
       "       [9.68498169e-01, 3.15018307e-02],\n",
       "       [9.04462431e-01, 9.55375688e-02],\n",
       "       [9.33715600e-01, 6.62844002e-02],\n",
       "       [9.94708771e-01, 5.29122864e-03],\n",
       "       [9.72925568e-01, 2.70744324e-02],\n",
       "       [9.98224854e-01, 1.77514570e-03],\n",
       "       [9.97407712e-01, 2.59228836e-03],\n",
       "       [9.47503767e-03, 9.90524962e-01],\n",
       "       [9.93448928e-01, 6.55107203e-03],\n",
       "       [2.10899543e-02, 9.78910046e-01],\n",
       "       [9.98366530e-01, 1.63347008e-03],\n",
       "       [8.64184169e-01, 1.35815831e-01],\n",
       "       [9.79126545e-01, 2.08734553e-02],\n",
       "       [9.86041356e-01, 1.39586438e-02],\n",
       "       [1.68427690e-01, 8.31572310e-01],\n",
       "       [9.99498826e-01, 5.01173675e-04],\n",
       "       [5.50538000e-02, 9.44946200e-01],\n",
       "       [3.94867550e-02, 9.60513245e-01],\n",
       "       [9.95237611e-01, 4.76238935e-03],\n",
       "       [7.68120227e-01, 2.31879773e-01],\n",
       "       [1.39096798e-01, 8.60903202e-01],\n",
       "       [9.96849294e-01, 3.15070595e-03],\n",
       "       [9.75066058e-01, 2.49339422e-02],\n",
       "       [9.98560068e-01, 1.43993248e-03],\n",
       "       [9.97439325e-01, 2.56067473e-03],\n",
       "       [9.98704310e-01, 1.29569030e-03],\n",
       "       [9.80501381e-01, 1.94986188e-02],\n",
       "       [9.95873535e-01, 4.12646546e-03],\n",
       "       [9.97934445e-01, 2.06555537e-03],\n",
       "       [9.91141423e-01, 8.85857704e-03],\n",
       "       [9.98371791e-01, 1.62820944e-03],\n",
       "       [9.91736524e-01, 8.26347624e-03],\n",
       "       [9.88278256e-01, 1.17217439e-02],\n",
       "       [9.69405633e-01, 3.05943671e-02],\n",
       "       [7.23754068e-01, 2.76245932e-01],\n",
       "       [9.97865314e-01, 2.13468620e-03],\n",
       "       [9.92983016e-01, 7.01698356e-03],\n",
       "       [9.98681953e-01, 1.31804705e-03],\n",
       "       [9.93685910e-01, 6.31408983e-03],\n",
       "       [9.83358340e-01, 1.66416598e-02],\n",
       "       [7.54524103e-01, 2.45475897e-01],\n",
       "       [9.97897839e-01, 2.10216078e-03],\n",
       "       [9.84757757e-01, 1.52422432e-02],\n",
       "       [2.92222611e-02, 9.70777739e-01],\n",
       "       [1.79747217e-01, 8.20252783e-01],\n",
       "       [1.66238224e-02, 9.83376178e-01],\n",
       "       [9.53765175e-01, 4.62348251e-02],\n",
       "       [9.90700323e-01, 9.29967716e-03],\n",
       "       [9.84302728e-01, 1.56972715e-02],\n",
       "       [9.91103845e-01, 8.89615456e-03],\n",
       "       [9.19899609e-01, 8.01003913e-02],\n",
       "       [7.69457535e-01, 2.30542465e-01],\n",
       "       [9.17647945e-01, 8.23520553e-02],\n",
       "       [9.83721161e-01, 1.62788386e-02],\n",
       "       [9.97199584e-01, 2.80041573e-03],\n",
       "       [9.98512922e-01, 1.48707750e-03],\n",
       "       [9.94349680e-01, 5.65032027e-03],\n",
       "       [9.89298697e-01, 1.07013032e-02],\n",
       "       [9.93532031e-01, 6.46796930e-03],\n",
       "       [9.38082189e-01, 6.19178109e-02],\n",
       "       [9.85508956e-01, 1.44910436e-02],\n",
       "       [5.44276268e-02, 9.45572373e-01],\n",
       "       [9.86027879e-01, 1.39721211e-02],\n",
       "       [3.16488969e-01, 6.83511031e-01],\n",
       "       [8.58629540e-01, 1.41370460e-01],\n",
       "       [9.90715295e-01, 9.28470520e-03],\n",
       "       [9.95020802e-01, 4.97919758e-03],\n",
       "       [9.24283100e-01, 7.57168999e-02],\n",
       "       [2.10951263e-02, 9.78904874e-01],\n",
       "       [9.85965103e-01, 1.40348973e-02],\n",
       "       [9.81194605e-01, 1.88053952e-02],\n",
       "       [1.08941384e-02, 9.89105862e-01],\n",
       "       [9.90473283e-01, 9.52671750e-03],\n",
       "       [9.91217799e-01, 8.78220054e-03],\n",
       "       [9.97571525e-01, 2.42847545e-03],\n",
       "       [1.76747984e-02, 9.82325202e-01],\n",
       "       [9.92565764e-01, 7.43423599e-03],\n",
       "       [9.81774220e-01, 1.82257804e-02],\n",
       "       [1.10767543e-01, 8.89232457e-01],\n",
       "       [9.98169838e-01, 1.83016217e-03],\n",
       "       [9.99344854e-01, 6.55145953e-04],\n",
       "       [9.87426291e-01, 1.25737093e-02],\n",
       "       [9.97617196e-01, 2.38280360e-03],\n",
       "       [9.92517877e-01, 7.48212302e-03],\n",
       "       [7.98619062e-02, 9.20138094e-01],\n",
       "       [9.34153766e-01, 6.58462338e-02],\n",
       "       [9.92890214e-01, 7.10978611e-03],\n",
       "       [9.82551802e-01, 1.74481981e-02],\n",
       "       [9.56266840e-01, 4.37331601e-02],\n",
       "       [1.55311353e-01, 8.44688647e-01],\n",
       "       [9.79516492e-01, 2.04835077e-02],\n",
       "       [9.57897522e-01, 4.21024781e-02],\n",
       "       [9.99377085e-01, 6.22914829e-04],\n",
       "       [8.33511851e-01, 1.66488149e-01],\n",
       "       [8.32374323e-01, 1.67625677e-01],\n",
       "       [1.90676720e-01, 8.09323280e-01],\n",
       "       [9.89862110e-01, 1.01378899e-02],\n",
       "       [9.98315305e-01, 1.68469525e-03],\n",
       "       [9.99115824e-01, 8.84176180e-04],\n",
       "       [6.67398554e-01, 3.32601446e-01],\n",
       "       [9.99706346e-01, 2.93653844e-04],\n",
       "       [9.95493393e-01, 4.50660715e-03],\n",
       "       [9.97479913e-01, 2.52008705e-03],\n",
       "       [9.59306149e-01, 4.06938506e-02],\n",
       "       [9.86359918e-01, 1.36400819e-02],\n",
       "       [9.90207516e-01, 9.79248375e-03],\n",
       "       [9.91943899e-01, 8.05610107e-03],\n",
       "       [9.97969236e-01, 2.03076352e-03],\n",
       "       [9.96782032e-01, 3.21796815e-03],\n",
       "       [9.96697260e-01, 3.30273953e-03],\n",
       "       [9.70662530e-01, 2.93374700e-02],\n",
       "       [9.98102889e-01, 1.89711084e-03],\n",
       "       [9.98356276e-01, 1.64372396e-03],\n",
       "       [8.64168951e-01, 1.35831049e-01],\n",
       "       [9.96530426e-01, 3.46957443e-03],\n",
       "       [9.94283700e-01, 5.71630025e-03],\n",
       "       [9.99302635e-01, 6.97365423e-04],\n",
       "       [9.98180058e-01, 1.81994184e-03],\n",
       "       [9.93314764e-01, 6.68523617e-03],\n",
       "       [9.99192077e-01, 8.07923032e-04],\n",
       "       [9.57392521e-01, 4.26074793e-02],\n",
       "       [9.83062751e-01, 1.69372486e-02],\n",
       "       [9.96101837e-01, 3.89816347e-03],\n",
       "       [9.92093030e-01, 7.90696978e-03],\n",
       "       [9.74892760e-01, 2.51072396e-02],\n",
       "       [6.13610593e-02, 9.38638941e-01],\n",
       "       [9.14519944e-02, 9.08548006e-01],\n",
       "       [9.95178731e-01, 4.82126886e-03],\n",
       "       [9.97480516e-01, 2.51948383e-03],\n",
       "       [9.95260757e-01, 4.73924313e-03],\n",
       "       [9.88078266e-01, 1.19217342e-02],\n",
       "       [9.89999364e-01, 1.00006356e-02],\n",
       "       [2.01237738e-02, 9.79876226e-01],\n",
       "       [9.89344911e-01, 1.06550894e-02],\n",
       "       [2.21599707e-02, 9.77840029e-01],\n",
       "       [9.98175342e-01, 1.82465776e-03],\n",
       "       [1.99079948e-02, 9.80092005e-01],\n",
       "       [2.78881278e-02, 9.72111872e-01],\n",
       "       [9.76101981e-01, 2.38980194e-02],\n",
       "       [9.86443168e-01, 1.35568315e-02],\n",
       "       [9.91468132e-01, 8.53186761e-03],\n",
       "       [9.96360678e-01, 3.63932165e-03],\n",
       "       [9.97996433e-01, 2.00356742e-03],\n",
       "       [9.84147980e-01, 1.58520202e-02],\n",
       "       [1.07519556e-02, 9.89248044e-01],\n",
       "       [9.50340990e-01, 4.96590104e-02],\n",
       "       [9.80504287e-01, 1.94957129e-02],\n",
       "       [9.92471382e-01, 7.52861807e-03],\n",
       "       [1.70680073e-02, 9.82931993e-01],\n",
       "       [9.97009263e-01, 2.99073725e-03],\n",
       "       [1.39598849e-02, 9.86040115e-01],\n",
       "       [9.94325187e-01, 5.67481275e-03],\n",
       "       [9.94889593e-01, 5.11040685e-03],\n",
       "       [9.91979553e-01, 8.02044714e-03],\n",
       "       [9.93380308e-01, 6.61969178e-03],\n",
       "       [9.86491329e-01, 1.35086707e-02],\n",
       "       [3.14424908e-02, 9.68557509e-01],\n",
       "       [9.98474983e-01, 1.52501703e-03],\n",
       "       [9.97841758e-01, 2.15824233e-03],\n",
       "       [9.22491188e-01, 7.75088118e-02],\n",
       "       [9.99087123e-01, 9.12877236e-04],\n",
       "       [2.01371763e-01, 7.98628237e-01],\n",
       "       [9.91178030e-01, 8.82196982e-03],\n",
       "       [9.85582064e-01, 1.44179362e-02],\n",
       "       [9.97042913e-01, 2.95708657e-03],\n",
       "       [9.72799749e-01, 2.72002506e-02],\n",
       "       [9.92533561e-01, 7.46643938e-03],\n",
       "       [9.91408668e-01, 8.59133183e-03],\n",
       "       [9.97182448e-01, 2.81755211e-03],\n",
       "       [9.89883320e-01, 1.01166801e-02],\n",
       "       [6.54148293e-01, 3.45851707e-01],\n",
       "       [9.61691001e-01, 3.83089994e-02],\n",
       "       [9.97055365e-01, 2.94463465e-03],\n",
       "       [9.23537202e-01, 7.64627982e-02],\n",
       "       [1.14863413e-01, 8.85136587e-01],\n",
       "       [1.53923232e-02, 9.84607677e-01],\n",
       "       [6.34872713e-01, 3.65127287e-01],\n",
       "       [9.93600873e-01, 6.39912672e-03],\n",
       "       [9.94963255e-01, 5.03674501e-03],\n",
       "       [9.51628029e-01, 4.83719710e-02],\n",
       "       [9.90563466e-01, 9.43653439e-03],\n",
       "       [9.57300772e-01, 4.26992280e-02],\n",
       "       [9.92801523e-01, 7.19847672e-03],\n",
       "       [9.90353241e-01, 9.64675911e-03],\n",
       "       [9.91378596e-01, 8.62140425e-03],\n",
       "       [9.95672655e-01, 4.32734522e-03],\n",
       "       [9.96762109e-01, 3.23789130e-03],\n",
       "       [9.34815557e-01, 6.51844428e-02],\n",
       "       [9.73950372e-01, 2.60496278e-02],\n",
       "       [9.94752249e-01, 5.24775088e-03],\n",
       "       [9.98151418e-01, 1.84858154e-03],\n",
       "       [9.64965025e-01, 3.50349754e-02],\n",
       "       [9.24194792e-01, 7.58052077e-02],\n",
       "       [9.99135432e-01, 8.64567712e-04],\n",
       "       [9.84263128e-01, 1.57368721e-02],\n",
       "       [3.47508036e-02, 9.65249196e-01],\n",
       "       [6.86712149e-01, 3.13287851e-01],\n",
       "       [9.95364837e-01, 4.63516284e-03],\n",
       "       [9.96805485e-01, 3.19451545e-03],\n",
       "       [9.97378217e-01, 2.62178299e-03],\n",
       "       [8.52385672e-01, 1.47614328e-01],\n",
       "       [9.97505909e-01, 2.49409141e-03],\n",
       "       [9.94371264e-01, 5.62873628e-03],\n",
       "       [9.75004416e-01, 2.49955843e-02],\n",
       "       [6.88506863e-01, 3.11493137e-01],\n",
       "       [9.77701361e-01, 2.22986390e-02],\n",
       "       [9.53553882e-01, 4.64461176e-02],\n",
       "       [9.92426359e-01, 7.57364113e-03],\n",
       "       [9.96781822e-01, 3.21817774e-03],\n",
       "       [9.99767311e-01, 2.32688682e-04],\n",
       "       [8.53376341e-01, 1.46623659e-01],\n",
       "       [1.55464020e-02, 9.84453598e-01],\n",
       "       [5.39539217e-02, 9.46046078e-01],\n",
       "       [9.99290079e-01, 7.09921244e-04],\n",
       "       [9.98290215e-01, 1.70978519e-03],\n",
       "       [9.99428799e-01, 5.71201318e-04],\n",
       "       [9.98657841e-01, 1.34215923e-03],\n",
       "       [9.84711199e-01, 1.52888008e-02],\n",
       "       [9.74154872e-01, 2.58451282e-02],\n",
       "       [9.97728785e-01, 2.27121513e-03],\n",
       "       [9.98649160e-01, 1.35084032e-03],\n",
       "       [8.99964684e-01, 1.00035316e-01]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_split)\n",
    "y_valid_probabilities_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# DISABLE THIS CELL TO RUN THE CODE AS IS; USE THIS CELL TO CHECK WHAT THE SCORES ARE FOR THE OLD RESULTS I HAD WHEN I DROPPED NA's:\n",
    "best_lgb_model.set_params(model__is_unbalance=True,\n",
    "                          model__learning_rate=0.05,\n",
    "                          model__max_depth=4,\n",
    "                          model__n_estimators=160)\n",
    "\n",
    "# Fit the best model on the training data\n",
    "best_lgb_model.fit(X_train_split, y_train_split)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n",
      "AUC for LightGBM on Validation Set: 0.9501996234110212\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set for LightGBM\n",
    "y_valid_probabilities_lgb = best_lgb_model.predict_proba(X_valid_split)\n",
    "auc_score_lgb = roc_auc_score(y_valid_split, y_valid_probabilities_lgb[:, 1])\n",
    "\n",
    "print(f'AUC for LightGBM on Validation Set: {auc_score_lgb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for LightGBM: {'model__learning_rate': 0.01, 'model__max_depth': 1, 'model__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Access the best hyperparameters for LightGBM\n",
    "best_hyperparameters_LGB = lgb_grid_search.best_params_\n",
    "print(f'Best Hyperparameters for LightGBM: {best_hyperparameters_LGB}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing pipeline to the validation set\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "X_test = X_test_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: model__learning_rate\n",
      "[LightGBM] [Warning] Unknown parameter: model__max_depth\n",
      "[LightGBM] [Warning] Unknown parameter: model__n_estimators\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nauc_score_test_lgb = roc_auc_score(y_test, y_test_probabilities_lgb[:, 1])\\nprint(f'AUC for LightGBM on Test Set: {auc_score_test_lgb}')\\n\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on the test set for LightGBM\n",
    "y_test_probabilities_lgb = best_lgb_model.predict_proba(X_test)\n",
    "'''\n",
    "auc_score_test_lgb = roc_auc_score(y_test, y_test_probabilities_lgb[:, 1])\n",
    "print(f'AUC for LightGBM on Test Set: {auc_score_test_lgb}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_0</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.916140</td>\n",
       "      <td>0.083860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.934870</td>\n",
       "      <td>0.065130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.992434</td>\n",
       "      <td>0.007566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.023292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.910674</td>\n",
       "      <td>0.089326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.979874</td>\n",
       "      <td>0.020126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.976952</td>\n",
       "      <td>0.023048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.998411</td>\n",
       "      <td>0.001589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_0    PROB_1\n",
       "0     K751808  0.999400  0.000600\n",
       "1     K837351  0.916140  0.083860\n",
       "2     K548114  0.934870  0.065130\n",
       "3     K736156  0.992434  0.007566\n",
       "4     K508080  0.995004  0.004996\n",
       "...       ...       ...       ...\n",
       "1677  K588314  0.976708  0.023292\n",
       "1678  K826807  0.910674  0.089326\n",
       "1679  K982731  0.979874  0.020126\n",
       "1680  K623037  0.976952  0.023048\n",
       "1681  K883413  0.998411  0.001589\n",
       "\n",
       "[1682 rows x 3 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_probabilities_lgb\n",
    "y_test_probabilities_lgb = pd.DataFrame(y_test_probabilities_lgb, columns=['PROB_0', 'PROB_1'])\n",
    "y_test_probabilities_lgb_with_id = pd.concat([data_test['id'], y_test_probabilities_lgb], axis=1)\n",
    "y_test_probabilities_lgb_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_LGB = y_test_probabilities_lgb_with_id.iloc[:, [0, 2]]\n",
    "result_LGB.to_csv('result_LGB_3.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>PROB_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K751808</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K837351</td>\n",
       "      <td>0.083860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K548114</td>\n",
       "      <td>0.065130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K736156</td>\n",
       "      <td>0.007566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K508080</td>\n",
       "      <td>0.004996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>K588314</td>\n",
       "      <td>0.023292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>K826807</td>\n",
       "      <td>0.089326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>K982731</td>\n",
       "      <td>0.020126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>K623037</td>\n",
       "      <td>0.023048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>K883413</td>\n",
       "      <td>0.001589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id    PROB_1\n",
       "0     K751808  0.000600\n",
       "1     K837351  0.083860\n",
       "2     K548114  0.065130\n",
       "3     K736156  0.007566\n",
       "4     K508080  0.004996\n",
       "...       ...       ...\n",
       "1677  K588314  0.023292\n",
       "1678  K826807  0.089326\n",
       "1679  K982731  0.020126\n",
       "1680  K623037  0.023048\n",
       "1681  K883413  0.001589\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the LGBM model from the pipeline\n",
    "best_lgb_model = lgb_grid_search.best_estimator_.named_steps['model']\n",
    "\n",
    "# Get feature importances from the LGBM model\n",
    "feature_importances = best_lgb_model.feature_importances_\n",
    "\n",
    "# Map feature names to their importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort features based on their importance\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print or visualize the feature importance\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter grid for XGBoost hyperparameter tuning\n",
    "xgb_param_grid = {\n",
    "    'model__n_estimators': [150, 160, 170, 180, 190, 200],\n",
    "    'model__max_depth': [1, 2, 3, 4, 5],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Create GridSearchCV instance for XGBoost\n",
    "xgb_grid_search = GridSearchCV(xgb_pipeline, xgb_param_grid, scoring={'auc': 'roc_auc'}, refit='auc', cv=5, verbose=2, n_jobs=1)\n",
    "\n",
    "# Fit the GridSearchCV on training data for XGBoost\n",
    "xgb_grid_search.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=KFold(n_splits=10)\n",
    "search=BayesSearchCV(model,search_spaces=random_grid,n_jobs=-1,cv=cv,n_iter=50, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Find optimal parameters\n",
    "search.fit(X_train,y_train)\n",
    "search.best_score_\n",
    "search.best_estimator_\n",
    "search.best_params_\n",
    "\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "pred = model.predict(X_val)\n",
    "MSE = mean_squared_error(y_val, pred)\n",
    "RMSE=np.sqrt(MSE)\n",
    "RMSE\n",
    "MAE=mean_absolute_error(y_val, pred)\n",
    "MAE\n",
    "\n",
    "\n",
    "pred_f = model.predict(df_test)\n",
    "pred_df = df_test[['property_id']]\n",
    "pred_df['pred_price'] = pred_f\n",
    "pred_df.to_csv('pred_rf_pipe2.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best XGBoost model from the grid search\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the validation set for XGBoost\n",
    "y_valid_probabilities_xgb = best_xgb_model.predict_proba(X_valid_split)\n",
    "auc_score_xgb = roc_auc_score(y_valid_split, y_valid_probabilities_xgb[:, 1])\n",
    "\n",
    "print(f'AUC for XGBoost on Validation Set: {auc_score_xgb}')\n",
    "\n",
    "# Access the best hyperparameters for XGBoost\n",
    "best_hyperparameters_XGB = xgb_grid_search.best_params_\n",
    "print(f'Best Hyperparameters for XGBoost: {best_hyperparameters_XGB}')\n",
    "\n",
    "# Evaluate on the test set for XGBoost\n",
    "y_test_probabilities_xgb = best_xgb_model.predict_proba(X_test)\n",
    "'''\n",
    "auc_score_test_xgb = roc_auc_score(y_test, y_test_probabilities_xgb[:, 1])\n",
    "print(f'AUC for XGBoost on Test Set: {auc_score_test_xgb}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the LGBM model from the pipeline\n",
    "best_xgb_model = xgb_grid_search.best_estimator_.named_steps['model']\n",
    "\n",
    "# Get feature importances from the LGBM model\n",
    "feature_importances = best_xgb_model.feature_importances_\n",
    "\n",
    "# Map feature names to their importance scores\n",
    "feature_names = X_train.columns  # Replace with your actual feature names\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "# Sort features based on their importance\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for feature, importance in sorted_feature_importance:\n",
    "    print(f\"{feature}: {float('{:.2f}'.format(importance))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use these:\n",
    "- RF\n",
    "- lightgbm\n",
    "- xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imbalanced data so:\n",
    "- use stratified CV to ensure that each fold maintains the class distribution\n",
    "- evaluate with proper metrics (as given by the prof)\n",
    "- use an ensemble of models (hence the above techniques - but also they are best techniques to work with tabular data)\n",
    "- possibly do data augmentation with techniques like SMOTE to make the distribution more balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also this exists to deal with imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=(1 - y.sum() / len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or lgb_model = lgb.LGBMClassifier(is_unbalance=True)\n",
    "lgb_model = lgb.LGBMClassifier(scale_pos_weight=(1 - y.sum() / len(y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
